I0921 14:34:48.023809      24 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-744630836
I0921 14:34:48.023953      24 e2e.go:92] Starting e2e run "b424c022-bf08-4981-a82e-57e78d0887a2" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1600698886 - Will randomize all specs
Will run 276 of 4847 specs

Sep 21 14:34:48.040: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 14:34:48.042: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 21 14:34:48.078: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 21 14:34:48.151: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 21 14:34:48.151: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
Sep 21 14:34:48.151: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 21 14:34:48.175: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Sep 21 14:34:48.175: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Sep 21 14:34:48.175: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Sep 21 14:34:48.175: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Sep 21 14:34:48.175: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Sep 21 14:34:48.175: INFO: e2e test version: v1.16.15
Sep 21 14:34:48.178: INFO: kube-apiserver version: v1.16.15+IKS
Sep 21 14:34:48.178: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 14:34:48.193: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:34:48.194: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
Sep 21 14:34:48.326: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Sep 21 14:34:48.361: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-e656dfa8-0824-4600-96a0-e1e9268758e5
STEP: Creating a pod to test consume secrets
Sep 21 14:34:48.524: INFO: Waiting up to 5m0s for pod "pod-secrets-c806ab15-1d3f-451b-825e-d4e2898d5850" in namespace "secrets-9679" to be "success or failure"
Sep 21 14:34:48.532: INFO: Pod "pod-secrets-c806ab15-1d3f-451b-825e-d4e2898d5850": Phase="Pending", Reason="", readiness=false. Elapsed: 7.59372ms
Sep 21 14:34:50.541: INFO: Pod "pod-secrets-c806ab15-1d3f-451b-825e-d4e2898d5850": Phase="Running", Reason="", readiness=true. Elapsed: 2.016895875s
Sep 21 14:34:52.550: INFO: Pod "pod-secrets-c806ab15-1d3f-451b-825e-d4e2898d5850": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026121054s
STEP: Saw pod success
Sep 21 14:34:52.550: INFO: Pod "pod-secrets-c806ab15-1d3f-451b-825e-d4e2898d5850" satisfied condition "success or failure"
Sep 21 14:34:52.559: INFO: Trying to get logs from node 10.189.39.107 pod pod-secrets-c806ab15-1d3f-451b-825e-d4e2898d5850 container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 14:34:52.623: INFO: Waiting for pod pod-secrets-c806ab15-1d3f-451b-825e-d4e2898d5850 to disappear
Sep 21 14:34:52.631: INFO: Pod pod-secrets-c806ab15-1d3f-451b-825e-d4e2898d5850 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:34:52.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9679" for this suite.
Sep 21 14:34:58.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:34:58.967: INFO: namespace secrets-9679 deletion completed in 6.326361388s

• [SLOW TEST:10.773 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:34:58.968: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2111
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Sep 21 14:34:59.221: INFO: Waiting up to 5m0s for pod "client-containers-cc300e3f-6cd5-4f6a-a98f-57281693c6ac" in namespace "containers-2111" to be "success or failure"
Sep 21 14:34:59.232: INFO: Pod "client-containers-cc300e3f-6cd5-4f6a-a98f-57281693c6ac": Phase="Pending", Reason="", readiness=false. Elapsed: 10.362246ms
Sep 21 14:35:01.243: INFO: Pod "client-containers-cc300e3f-6cd5-4f6a-a98f-57281693c6ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021860627s
Sep 21 14:35:03.252: INFO: Pod "client-containers-cc300e3f-6cd5-4f6a-a98f-57281693c6ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030813618s
STEP: Saw pod success
Sep 21 14:35:03.252: INFO: Pod "client-containers-cc300e3f-6cd5-4f6a-a98f-57281693c6ac" satisfied condition "success or failure"
Sep 21 14:35:03.261: INFO: Trying to get logs from node 10.189.39.107 pod client-containers-cc300e3f-6cd5-4f6a-a98f-57281693c6ac container test-container: <nil>
STEP: delete the pod
Sep 21 14:35:03.311: INFO: Waiting for pod client-containers-cc300e3f-6cd5-4f6a-a98f-57281693c6ac to disappear
Sep 21 14:35:03.318: INFO: Pod client-containers-cc300e3f-6cd5-4f6a-a98f-57281693c6ac no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:35:03.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2111" for this suite.
Sep 21 14:35:09.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:35:09.652: INFO: namespace containers-2111 deletion completed in 6.323532793s

• [SLOW TEST:10.684 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:35:09.652: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 14:35:37.930: INFO: Container started at 2020-09-21 14:35:12 +0000 UTC, pod became ready at 2020-09-21 14:35:36 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:35:37.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-101" for this suite.
Sep 21 14:36:07.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:36:08.282: INFO: namespace container-probe-101 deletion completed in 30.342610807s

• [SLOW TEST:58.630 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:36:08.288: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9280
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9280
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Sep 21 14:36:08.558: INFO: Found 0 stateful pods, waiting for 3
Sep 21 14:36:18.569: INFO: Found 2 stateful pods, waiting for 3
Sep 21 14:36:28.569: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 14:36:28.569: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 14:36:28.569: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 21 14:36:28.634: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 21 14:36:38.702: INFO: Updating stateful set ss2
Sep 21 14:36:38.726: INFO: Waiting for Pod statefulset-9280/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Sep 21 14:36:48.814: INFO: Found 2 stateful pods, waiting for 3
Sep 21 14:36:58.828: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 14:36:58.828: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 14:36:58.828: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Sep 21 14:37:08.823: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 14:37:08.823: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 14:37:08.823: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 21 14:37:08.884: INFO: Updating stateful set ss2
Sep 21 14:37:08.900: INFO: Waiting for Pod statefulset-9280/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 21 14:37:18.920: INFO: Waiting for Pod statefulset-9280/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 21 14:37:28.948: INFO: Updating stateful set ss2
Sep 21 14:37:28.967: INFO: Waiting for StatefulSet statefulset-9280/ss2 to complete update
Sep 21 14:37:28.967: INFO: Waiting for Pod statefulset-9280/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 21 14:37:38.987: INFO: Deleting all statefulset in ns statefulset-9280
Sep 21 14:37:38.996: INFO: Scaling statefulset ss2 to 0
Sep 21 14:37:59.032: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 14:37:59.042: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:37:59.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9280" for this suite.
Sep 21 14:38:07.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:38:07.479: INFO: namespace statefulset-9280 deletion completed in 8.388004417s

• [SLOW TEST:119.191 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:38:07.479: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5605
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Sep 21 14:38:07.722: INFO: PodSpec: initContainers in spec.initContainers
Sep 21 14:38:54.926: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c57d023b-3914-48a1-b3c7-722d514454d4", GenerateName:"", Namespace:"init-container-5605", SelfLink:"/api/v1/namespaces/init-container-5605/pods/pod-init-c57d023b-3914-48a1-b3c7-722d514454d4", UID:"5e3eb0a5-c6f9-4b3a-ae99-b1b1ba2510a8", ResourceVersion:"18115", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63736295887, loc:(*time.Location)(0x78ac9c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"722918349"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-77mmg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00113fd40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-77mmg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-77mmg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-77mmg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0011ea0b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.189.39.107", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002646ea0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0011ea140)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0011ea160)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0011ea168), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0011ea16c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736295887, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736295887, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736295887, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736295887, loc:(*time.Location)(0x78ac9c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.189.39.107", PodIP:"172.30.185.217", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.185.217"}}, StartTime:(*v1.Time)(0xc002c423a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ef8070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ef80e0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://33f4dab295f57c099c1c92493f2f54e5c36cf418606a26e5a5723780e20847fa", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c42520), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c42480), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0011ea224)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:38:54.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5605" for this suite.
Sep 21 14:39:06.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:39:07.305: INFO: namespace init-container-5605 deletion completed in 12.364628306s

• [SLOW TEST:59.826 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:39:07.306: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5092
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:39:18.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5092" for this suite.
Sep 21 14:39:24.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:39:25.101: INFO: namespace resourcequota-5092 deletion completed in 6.433824364s

• [SLOW TEST:17.795 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:39:25.101: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6694
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-642360c0-18cf-4bea-badf-7e679275b542
STEP: Creating a pod to test consume secrets
Sep 21 14:39:25.368: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-74a71b98-d2eb-41eb-9751-f41451cbbb7f" in namespace "projected-6694" to be "success or failure"
Sep 21 14:39:25.381: INFO: Pod "pod-projected-secrets-74a71b98-d2eb-41eb-9751-f41451cbbb7f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.505408ms
Sep 21 14:39:27.391: INFO: Pod "pod-projected-secrets-74a71b98-d2eb-41eb-9751-f41451cbbb7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023098502s
Sep 21 14:39:29.401: INFO: Pod "pod-projected-secrets-74a71b98-d2eb-41eb-9751-f41451cbbb7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032619398s
STEP: Saw pod success
Sep 21 14:39:29.401: INFO: Pod "pod-projected-secrets-74a71b98-d2eb-41eb-9751-f41451cbbb7f" satisfied condition "success or failure"
Sep 21 14:39:29.409: INFO: Trying to get logs from node 10.189.39.109 pod pod-projected-secrets-74a71b98-d2eb-41eb-9751-f41451cbbb7f container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 14:39:29.487: INFO: Waiting for pod pod-projected-secrets-74a71b98-d2eb-41eb-9751-f41451cbbb7f to disappear
Sep 21 14:39:29.495: INFO: Pod pod-projected-secrets-74a71b98-d2eb-41eb-9751-f41451cbbb7f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:39:29.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6694" for this suite.
Sep 21 14:39:35.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:39:35.845: INFO: namespace projected-6694 deletion completed in 6.336304775s

• [SLOW TEST:10.744 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:39:35.845: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9714
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-e1835790-9c68-457f-aa93-03a2f6c9ca89
Sep 21 14:39:36.120: INFO: Pod name my-hostname-basic-e1835790-9c68-457f-aa93-03a2f6c9ca89: Found 0 pods out of 1
Sep 21 14:39:41.129: INFO: Pod name my-hostname-basic-e1835790-9c68-457f-aa93-03a2f6c9ca89: Found 1 pods out of 1
Sep 21 14:39:41.129: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e1835790-9c68-457f-aa93-03a2f6c9ca89" are running
Sep 21 14:39:41.138: INFO: Pod "my-hostname-basic-e1835790-9c68-457f-aa93-03a2f6c9ca89-j6ghz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-21 14:39:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-21 14:39:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-21 14:39:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-21 14:39:36 +0000 UTC Reason: Message:}])
Sep 21 14:39:41.138: INFO: Trying to dial the pod
Sep 21 14:39:46.193: INFO: Controller my-hostname-basic-e1835790-9c68-457f-aa93-03a2f6c9ca89: Got expected result from replica 1 [my-hostname-basic-e1835790-9c68-457f-aa93-03a2f6c9ca89-j6ghz]: "my-hostname-basic-e1835790-9c68-457f-aa93-03a2f6c9ca89-j6ghz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:39:46.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9714" for this suite.
Sep 21 14:39:52.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:39:52.548: INFO: namespace replication-controller-9714 deletion completed in 6.334106822s

• [SLOW TEST:16.702 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:39:52.548: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4838
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 21 14:39:52.822: INFO: Waiting up to 5m0s for pod "pod-7620ce24-c448-47f6-b8ea-37149c35db53" in namespace "emptydir-4838" to be "success or failure"
Sep 21 14:39:52.831: INFO: Pod "pod-7620ce24-c448-47f6-b8ea-37149c35db53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.090609ms
Sep 21 14:39:54.840: INFO: Pod "pod-7620ce24-c448-47f6-b8ea-37149c35db53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01797313s
STEP: Saw pod success
Sep 21 14:39:54.840: INFO: Pod "pod-7620ce24-c448-47f6-b8ea-37149c35db53" satisfied condition "success or failure"
Sep 21 14:39:54.848: INFO: Trying to get logs from node 10.189.39.109 pod pod-7620ce24-c448-47f6-b8ea-37149c35db53 container test-container: <nil>
STEP: delete the pod
Sep 21 14:39:54.895: INFO: Waiting for pod pod-7620ce24-c448-47f6-b8ea-37149c35db53 to disappear
Sep 21 14:39:54.902: INFO: Pod pod-7620ce24-c448-47f6-b8ea-37149c35db53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:39:54.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4838" for this suite.
Sep 21 14:40:00.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:40:01.268: INFO: namespace emptydir-4838 deletion completed in 6.349409715s

• [SLOW TEST:8.721 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:40:01.269: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7172
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 14:40:02.161: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 14:40:04.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296002, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296002, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296002, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296002, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 14:40:07.226: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:40:19.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7172" for this suite.
Sep 21 14:40:25.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:40:26.021: INFO: namespace webhook-7172 deletion completed in 6.352115244s
STEP: Destroying namespace "webhook-7172-markers" for this suite.
Sep 21 14:40:32.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:40:32.354: INFO: namespace webhook-7172-markers deletion completed in 6.333433852s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:31.135 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:40:32.405: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-629
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-n9w4
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 14:40:32.712: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-n9w4" in namespace "subpath-629" to be "success or failure"
Sep 21 14:40:32.722: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.31065ms
Sep 21 14:40:34.731: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 2.018315338s
Sep 21 14:40:36.746: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 4.033498339s
Sep 21 14:40:38.755: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 6.042753867s
Sep 21 14:40:40.764: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 8.052022659s
Sep 21 14:40:42.774: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 10.062071532s
Sep 21 14:40:44.784: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 12.071597501s
Sep 21 14:40:46.795: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 14.0830667s
Sep 21 14:40:48.805: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 16.093036312s
Sep 21 14:40:50.816: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 18.103825988s
Sep 21 14:40:52.829: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Running", Reason="", readiness=true. Elapsed: 20.117082098s
Sep 21 14:40:54.839: INFO: Pod "pod-subpath-test-projected-n9w4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.126651516s
STEP: Saw pod success
Sep 21 14:40:54.839: INFO: Pod "pod-subpath-test-projected-n9w4" satisfied condition "success or failure"
Sep 21 14:40:54.847: INFO: Trying to get logs from node 10.189.39.109 pod pod-subpath-test-projected-n9w4 container test-container-subpath-projected-n9w4: <nil>
STEP: delete the pod
Sep 21 14:40:54.895: INFO: Waiting for pod pod-subpath-test-projected-n9w4 to disappear
Sep 21 14:40:54.902: INFO: Pod pod-subpath-test-projected-n9w4 no longer exists
STEP: Deleting pod pod-subpath-test-projected-n9w4
Sep 21 14:40:54.902: INFO: Deleting pod "pod-subpath-test-projected-n9w4" in namespace "subpath-629"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:40:54.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-629" for this suite.
Sep 21 14:41:00.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:41:01.285: INFO: namespace subpath-629 deletion completed in 6.354839002s

• [SLOW TEST:28.880 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:41:01.288: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7831
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7831.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7831.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 14:41:13.728: INFO: DNS probes using dns-7831/dns-test-fe332bca-e69d-4df5-8da7-45fd56d3cb8d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:41:13.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7831" for this suite.
Sep 21 14:41:19.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:41:20.114: INFO: namespace dns-7831 deletion completed in 6.341448917s

• [SLOW TEST:18.826 seconds]
[sig-network] DNS
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:41:20.114: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2756
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 14:41:20.355: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:41:25.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2756" for this suite.
Sep 21 14:41:31.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:41:31.417: INFO: namespace custom-resource-definition-2756 deletion completed in 6.323622227s

• [SLOW TEST:11.303 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:41:31.417: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-362
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-332fe78f-01bc-4ecd-8ca4-da12faded611
STEP: Creating a pod to test consume configMaps
Sep 21 14:41:31.678: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-17532bc0-b3c3-40f0-adb9-40efad365196" in namespace "projected-362" to be "success or failure"
Sep 21 14:41:31.689: INFO: Pod "pod-projected-configmaps-17532bc0-b3c3-40f0-adb9-40efad365196": Phase="Pending", Reason="", readiness=false. Elapsed: 11.369676ms
Sep 21 14:41:33.698: INFO: Pod "pod-projected-configmaps-17532bc0-b3c3-40f0-adb9-40efad365196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020382314s
Sep 21 14:41:35.709: INFO: Pod "pod-projected-configmaps-17532bc0-b3c3-40f0-adb9-40efad365196": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031478756s
STEP: Saw pod success
Sep 21 14:41:35.709: INFO: Pod "pod-projected-configmaps-17532bc0-b3c3-40f0-adb9-40efad365196" satisfied condition "success or failure"
Sep 21 14:41:35.720: INFO: Trying to get logs from node 10.189.39.114 pod pod-projected-configmaps-17532bc0-b3c3-40f0-adb9-40efad365196 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 14:41:35.792: INFO: Waiting for pod pod-projected-configmaps-17532bc0-b3c3-40f0-adb9-40efad365196 to disappear
Sep 21 14:41:35.804: INFO: Pod pod-projected-configmaps-17532bc0-b3c3-40f0-adb9-40efad365196 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:41:35.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-362" for this suite.
Sep 21 14:41:43.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:41:44.179: INFO: namespace projected-362 deletion completed in 8.352280894s

• [SLOW TEST:12.762 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:41:44.180: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Sep 21 14:42:24.497: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0921 14:42:24.497331      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:42:24.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7877" for this suite.
Sep 21 14:42:32.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:42:32.855: INFO: namespace gc-7877 deletion completed in 8.344390195s

• [SLOW TEST:48.675 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:42:32.855: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-061d34ff-d1c8-48c1-8469-45546ec62f66 in namespace container-probe-8865
Sep 21 14:42:37.135: INFO: Started pod test-webserver-061d34ff-d1c8-48c1-8469-45546ec62f66 in namespace container-probe-8865
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 14:42:37.148: INFO: Initial restart count of pod test-webserver-061d34ff-d1c8-48c1-8469-45546ec62f66 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:46:38.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8865" for this suite.
Sep 21 14:46:44.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:46:44.734: INFO: namespace container-probe-8865 deletion completed in 6.329769155s

• [SLOW TEST:251.879 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:46:44.735: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4351
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-3d232553-dd0f-49bd-a73f-4a2acccc93ea
STEP: Creating a pod to test consume secrets
Sep 21 14:46:44.990: INFO: Waiting up to 5m0s for pod "pod-secrets-984fe1af-fd6f-410d-8dc6-d13e0565082b" in namespace "secrets-4351" to be "success or failure"
Sep 21 14:46:45.002: INFO: Pod "pod-secrets-984fe1af-fd6f-410d-8dc6-d13e0565082b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.050882ms
Sep 21 14:46:47.012: INFO: Pod "pod-secrets-984fe1af-fd6f-410d-8dc6-d13e0565082b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021713495s
STEP: Saw pod success
Sep 21 14:46:47.012: INFO: Pod "pod-secrets-984fe1af-fd6f-410d-8dc6-d13e0565082b" satisfied condition "success or failure"
Sep 21 14:46:47.022: INFO: Trying to get logs from node 10.189.39.114 pod pod-secrets-984fe1af-fd6f-410d-8dc6-d13e0565082b container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 14:46:47.094: INFO: Waiting for pod pod-secrets-984fe1af-fd6f-410d-8dc6-d13e0565082b to disappear
Sep 21 14:46:47.101: INFO: Pod pod-secrets-984fe1af-fd6f-410d-8dc6-d13e0565082b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:46:47.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4351" for this suite.
Sep 21 14:46:53.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:46:53.494: INFO: namespace secrets-4351 deletion completed in 6.377865558s

• [SLOW TEST:8.759 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:46:53.494: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5038
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 21 14:46:56.787: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:46:56.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5038" for this suite.
Sep 21 14:47:02.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:47:03.164: INFO: namespace container-runtime-5038 deletion completed in 6.332256719s

• [SLOW TEST:9.670 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:47:03.171: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6770
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 14:47:03.407: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:47:05.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6770" for this suite.
Sep 21 14:47:51.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:47:51.838: INFO: namespace pods-6770 deletion completed in 46.32992186s

• [SLOW TEST:48.667 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:47:51.838: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7241
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-c6459d77-5568-4d88-8855-4fe6f8e3c4fe
STEP: Creating configMap with name cm-test-opt-upd-e6456baa-bc7b-4b4d-a7e6-2b80497d6bc2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c6459d77-5568-4d88-8855-4fe6f8e3c4fe
STEP: Updating configmap cm-test-opt-upd-e6456baa-bc7b-4b4d-a7e6-2b80497d6bc2
STEP: Creating configMap with name cm-test-opt-create-6be6bdc1-7d71-4619-b50b-c5089fe9b033
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:47:56.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7241" for this suite.
Sep 21 14:48:16.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:48:16.709: INFO: namespace configmap-7241 deletion completed in 20.356220722s

• [SLOW TEST:24.871 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:48:16.710: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7568
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Sep 21 14:48:17.036: INFO: Waiting up to 5m0s for pod "client-containers-b78786ff-ab29-4f66-a5c5-321c9ba56648" in namespace "containers-7568" to be "success or failure"
Sep 21 14:48:17.047: INFO: Pod "client-containers-b78786ff-ab29-4f66-a5c5-321c9ba56648": Phase="Pending", Reason="", readiness=false. Elapsed: 10.438013ms
Sep 21 14:48:19.056: INFO: Pod "client-containers-b78786ff-ab29-4f66-a5c5-321c9ba56648": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019842356s
Sep 21 14:48:21.065: INFO: Pod "client-containers-b78786ff-ab29-4f66-a5c5-321c9ba56648": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028900266s
STEP: Saw pod success
Sep 21 14:48:21.066: INFO: Pod "client-containers-b78786ff-ab29-4f66-a5c5-321c9ba56648" satisfied condition "success or failure"
Sep 21 14:48:21.074: INFO: Trying to get logs from node 10.189.39.107 pod client-containers-b78786ff-ab29-4f66-a5c5-321c9ba56648 container test-container: <nil>
STEP: delete the pod
Sep 21 14:48:21.125: INFO: Waiting for pod client-containers-b78786ff-ab29-4f66-a5c5-321c9ba56648 to disappear
Sep 21 14:48:21.133: INFO: Pod client-containers-b78786ff-ab29-4f66-a5c5-321c9ba56648 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:48:21.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7568" for this suite.
Sep 21 14:48:27.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:48:27.486: INFO: namespace containers-7568 deletion completed in 6.340306534s

• [SLOW TEST:10.776 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:48:27.486: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 14:48:27.747: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40ce55b7-82cb-4df2-96a0-86f80e12f252" in namespace "projected-2401" to be "success or failure"
Sep 21 14:48:27.757: INFO: Pod "downwardapi-volume-40ce55b7-82cb-4df2-96a0-86f80e12f252": Phase="Pending", Reason="", readiness=false. Elapsed: 10.042925ms
Sep 21 14:48:29.775: INFO: Pod "downwardapi-volume-40ce55b7-82cb-4df2-96a0-86f80e12f252": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028141282s
STEP: Saw pod success
Sep 21 14:48:29.776: INFO: Pod "downwardapi-volume-40ce55b7-82cb-4df2-96a0-86f80e12f252" satisfied condition "success or failure"
Sep 21 14:48:29.784: INFO: Trying to get logs from node 10.189.39.107 pod downwardapi-volume-40ce55b7-82cb-4df2-96a0-86f80e12f252 container client-container: <nil>
STEP: delete the pod
Sep 21 14:48:29.830: INFO: Waiting for pod downwardapi-volume-40ce55b7-82cb-4df2-96a0-86f80e12f252 to disappear
Sep 21 14:48:29.839: INFO: Pod downwardapi-volume-40ce55b7-82cb-4df2-96a0-86f80e12f252 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:48:29.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2401" for this suite.
Sep 21 14:48:35.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:48:36.206: INFO: namespace projected-2401 deletion completed in 6.354791803s

• [SLOW TEST:8.720 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:48:36.208: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 14:48:36.819: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Sep 21 14:48:38.846: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296516, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296516, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296516, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 14:48:41.881: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 14:48:41.892: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3158-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:48:43.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8695" for this suite.
Sep 21 14:48:51.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:48:51.467: INFO: namespace webhook-8695 deletion completed in 8.332895056s
STEP: Destroying namespace "webhook-8695-markers" for this suite.
Sep 21 14:48:57.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:48:58.030: INFO: namespace webhook-8695-markers deletion completed in 6.562804258s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.863 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:48:58.072: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6333
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-mnzb
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 14:48:58.348: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mnzb" in namespace "subpath-6333" to be "success or failure"
Sep 21 14:48:58.357: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.510761ms
Sep 21 14:49:00.367: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019507213s
Sep 21 14:49:02.379: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 4.030771807s
Sep 21 14:49:04.388: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 6.039983458s
Sep 21 14:49:06.399: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 8.05175111s
Sep 21 14:49:08.409: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 10.060796794s
Sep 21 14:49:10.418: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 12.070126784s
Sep 21 14:49:12.427: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 14.079557522s
Sep 21 14:49:14.436: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 16.08831862s
Sep 21 14:49:16.445: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 18.097360249s
Sep 21 14:49:18.454: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 20.106538317s
Sep 21 14:49:20.466: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Running", Reason="", readiness=true. Elapsed: 22.117953878s
Sep 21 14:49:22.476: INFO: Pod "pod-subpath-test-downwardapi-mnzb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.127943773s
STEP: Saw pod success
Sep 21 14:49:22.476: INFO: Pod "pod-subpath-test-downwardapi-mnzb" satisfied condition "success or failure"
Sep 21 14:49:22.485: INFO: Trying to get logs from node 10.189.39.114 pod pod-subpath-test-downwardapi-mnzb container test-container-subpath-downwardapi-mnzb: <nil>
STEP: delete the pod
Sep 21 14:49:22.550: INFO: Waiting for pod pod-subpath-test-downwardapi-mnzb to disappear
Sep 21 14:49:22.558: INFO: Pod pod-subpath-test-downwardapi-mnzb no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mnzb
Sep 21 14:49:22.559: INFO: Deleting pod "pod-subpath-test-downwardapi-mnzb" in namespace "subpath-6333"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:49:22.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6333" for this suite.
Sep 21 14:49:28.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:49:28.944: INFO: namespace subpath-6333 deletion completed in 6.359632177s

• [SLOW TEST:30.872 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:49:28.944: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7623
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 14:49:29.212: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0bd5ee8a-027e-4e0f-a9a8-3ad9fccdc019" in namespace "downward-api-7623" to be "success or failure"
Sep 21 14:49:29.221: INFO: Pod "downwardapi-volume-0bd5ee8a-027e-4e0f-a9a8-3ad9fccdc019": Phase="Pending", Reason="", readiness=false. Elapsed: 8.543821ms
Sep 21 14:49:31.230: INFO: Pod "downwardapi-volume-0bd5ee8a-027e-4e0f-a9a8-3ad9fccdc019": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017892385s
STEP: Saw pod success
Sep 21 14:49:31.230: INFO: Pod "downwardapi-volume-0bd5ee8a-027e-4e0f-a9a8-3ad9fccdc019" satisfied condition "success or failure"
Sep 21 14:49:31.239: INFO: Trying to get logs from node 10.189.39.114 pod downwardapi-volume-0bd5ee8a-027e-4e0f-a9a8-3ad9fccdc019 container client-container: <nil>
STEP: delete the pod
Sep 21 14:49:31.282: INFO: Waiting for pod downwardapi-volume-0bd5ee8a-027e-4e0f-a9a8-3ad9fccdc019 to disappear
Sep 21 14:49:31.290: INFO: Pod downwardapi-volume-0bd5ee8a-027e-4e0f-a9a8-3ad9fccdc019 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:49:31.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7623" for this suite.
Sep 21 14:49:37.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:49:37.641: INFO: namespace downward-api-7623 deletion completed in 6.336697923s

• [SLOW TEST:8.697 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:49:37.641: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5514
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Sep 21 14:49:37.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-5514 -- logs-generator --log-lines-total 100 --run-duration 20s'
Sep 21 14:49:38.072: INFO: stderr: ""
Sep 21 14:49:38.072: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Sep 21 14:49:38.072: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Sep 21 14:49:38.072: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5514" to be "running and ready, or succeeded"
Sep 21 14:49:38.081: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.740804ms
Sep 21 14:49:40.089: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.017064312s
Sep 21 14:49:40.089: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Sep 21 14:49:40.089: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Sep 21 14:49:40.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 logs logs-generator logs-generator --namespace=kubectl-5514'
Sep 21 14:49:40.219: INFO: stderr: ""
Sep 21 14:49:40.219: INFO: stdout: "I0921 14:49:39.394418       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/jb7 260\nI0921 14:49:39.594796       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/pps 316\nI0921 14:49:39.794754       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/bpdl 512\nI0921 14:49:39.995397       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/sxxp 212\nI0921 14:49:40.194758       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/h6zp 360\n"
STEP: limiting log lines
Sep 21 14:49:40.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 logs logs-generator logs-generator --namespace=kubectl-5514 --tail=1'
Sep 21 14:49:40.365: INFO: stderr: ""
Sep 21 14:49:40.365: INFO: stdout: "I0921 14:49:40.194758       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/h6zp 360\n"
STEP: limiting log bytes
Sep 21 14:49:40.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 logs logs-generator logs-generator --namespace=kubectl-5514 --limit-bytes=1'
Sep 21 14:49:40.471: INFO: stderr: ""
Sep 21 14:49:40.471: INFO: stdout: "I"
STEP: exposing timestamps
Sep 21 14:49:40.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 logs logs-generator logs-generator --namespace=kubectl-5514 --tail=1 --timestamps'
Sep 21 14:49:40.601: INFO: stderr: ""
Sep 21 14:49:40.601: INFO: stdout: "2020-09-21T14:49:40.595484266Z I0921 14:49:40.594846       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/rtb 470\n"
STEP: restricting to a time range
Sep 21 14:49:43.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 logs logs-generator logs-generator --namespace=kubectl-5514 --since=1s'
Sep 21 14:49:43.204: INFO: stderr: ""
Sep 21 14:49:43.204: INFO: stdout: "I0921 14:49:42.394678       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/jjg 272\nI0921 14:49:42.594684       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/xxh 529\nI0921 14:49:42.794760       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/wvhc 323\nI0921 14:49:42.995208       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/8rv 567\nI0921 14:49:43.194763       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/9x4h 232\n"
Sep 21 14:49:43.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 logs logs-generator logs-generator --namespace=kubectl-5514 --since=24h'
Sep 21 14:49:43.312: INFO: stderr: ""
Sep 21 14:49:43.312: INFO: stdout: "I0921 14:49:39.394418       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/jb7 260\nI0921 14:49:39.594796       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/pps 316\nI0921 14:49:39.794754       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/bpdl 512\nI0921 14:49:39.995397       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/sxxp 212\nI0921 14:49:40.194758       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/h6zp 360\nI0921 14:49:40.394748       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/m66k 381\nI0921 14:49:40.594846       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/rtb 470\nI0921 14:49:40.794864       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/nfc 307\nI0921 14:49:40.994736       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/6gz 448\nI0921 14:49:41.194688       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/pszq 388\nI0921 14:49:41.394944       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/zhc 455\nI0921 14:49:41.594724       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/ml26 288\nI0921 14:49:41.794884       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/8jd9 386\nI0921 14:49:41.994740       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/d6c 433\nI0921 14:49:42.194842       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/8xt 291\nI0921 14:49:42.394678       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/jjg 272\nI0921 14:49:42.594684       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/xxh 529\nI0921 14:49:42.794760       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/wvhc 323\nI0921 14:49:42.995208       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/8rv 567\nI0921 14:49:43.194763       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/9x4h 232\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Sep 21 14:49:43.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete pod logs-generator --namespace=kubectl-5514'
Sep 21 14:49:51.718: INFO: stderr: ""
Sep 21 14:49:51.718: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:49:51.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5514" for this suite.
Sep 21 14:49:57.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:49:58.092: INFO: namespace kubectl-5514 deletion completed in 6.358046462s

• [SLOW TEST:20.451 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:49:58.092: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2119
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-c9f5ad9f-1250-4185-a94c-c9beca7f07af
STEP: Creating a pod to test consume secrets
Sep 21 14:49:58.385: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-05e79ee5-105e-4b41-ad09-b7fa7e6aa4a6" in namespace "projected-2119" to be "success or failure"
Sep 21 14:49:58.395: INFO: Pod "pod-projected-secrets-05e79ee5-105e-4b41-ad09-b7fa7e6aa4a6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.83154ms
Sep 21 14:50:00.403: INFO: Pod "pod-projected-secrets-05e79ee5-105e-4b41-ad09-b7fa7e6aa4a6": Phase="Running", Reason="", readiness=true. Elapsed: 2.018547775s
Sep 21 14:50:02.414: INFO: Pod "pod-projected-secrets-05e79ee5-105e-4b41-ad09-b7fa7e6aa4a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028587997s
STEP: Saw pod success
Sep 21 14:50:02.414: INFO: Pod "pod-projected-secrets-05e79ee5-105e-4b41-ad09-b7fa7e6aa4a6" satisfied condition "success or failure"
Sep 21 14:50:02.424: INFO: Trying to get logs from node 10.189.39.109 pod pod-projected-secrets-05e79ee5-105e-4b41-ad09-b7fa7e6aa4a6 container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 14:50:02.479: INFO: Waiting for pod pod-projected-secrets-05e79ee5-105e-4b41-ad09-b7fa7e6aa4a6 to disappear
Sep 21 14:50:02.486: INFO: Pod pod-projected-secrets-05e79ee5-105e-4b41-ad09-b7fa7e6aa4a6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:50:02.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2119" for this suite.
Sep 21 14:50:08.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:50:08.829: INFO: namespace projected-2119 deletion completed in 6.329338603s

• [SLOW TEST:10.737 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:50:08.830: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3390
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 14:50:09.401: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 14:50:11.428: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296609, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296609, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296609, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296609, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 14:50:13.438: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296609, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296609, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296609, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296609, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 14:50:16.458: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 14:50:16.468: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:50:17.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3390" for this suite.
Sep 21 14:50:23.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:50:24.129: INFO: namespace webhook-3390 deletion completed in 6.346907425s
STEP: Destroying namespace "webhook-3390-markers" for this suite.
Sep 21 14:50:30.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:50:30.489: INFO: namespace webhook-3390-markers deletion completed in 6.359352002s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.710 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:50:30.541: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6567
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 14:50:31.442: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 14:50:34.491: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
Sep 21 14:50:44.550: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource definition that should be denied by the webhook
Sep 21 14:50:44.679: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:50:44.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6567" for this suite.
Sep 21 14:50:50.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:50:51.108: INFO: namespace webhook-6567 deletion completed in 6.377109387s
STEP: Destroying namespace "webhook-6567-markers" for this suite.
Sep 21 14:50:57.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:50:57.470: INFO: namespace webhook-6567-markers deletion completed in 6.362378448s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.972 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:50:57.512: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8657
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Sep 21 14:50:57.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-8657'
Sep 21 14:50:58.073: INFO: stderr: ""
Sep 21 14:50:58.073: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 21 14:50:59.084: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 14:50:59.084: INFO: Found 0 / 1
Sep 21 14:51:00.082: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 14:51:00.082: INFO: Found 0 / 1
Sep 21 14:51:01.082: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 14:51:01.082: INFO: Found 1 / 1
Sep 21 14:51:01.082: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 21 14:51:01.092: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 14:51:01.092: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 21 14:51:01.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 patch pod redis-master-zl9jx --namespace=kubectl-8657 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 21 14:51:01.176: INFO: stderr: ""
Sep 21 14:51:01.176: INFO: stdout: "pod/redis-master-zl9jx patched\n"
STEP: checking annotations
Sep 21 14:51:01.188: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 14:51:01.188: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:51:01.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8657" for this suite.
Sep 21 14:51:13.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:51:13.546: INFO: namespace kubectl-8657 deletion completed in 12.342383381s

• [SLOW TEST:16.034 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:51:13.547: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 14:51:13.837: INFO: (0) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 36.402775ms)
Sep 21 14:51:13.851: INFO: (1) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.755685ms)
Sep 21 14:51:13.864: INFO: (2) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.357053ms)
Sep 21 14:51:13.878: INFO: (3) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.677767ms)
Sep 21 14:51:13.892: INFO: (4) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.836974ms)
Sep 21 14:51:13.905: INFO: (5) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.925542ms)
Sep 21 14:51:13.919: INFO: (6) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.73853ms)
Sep 21 14:51:13.932: INFO: (7) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.884235ms)
Sep 21 14:51:13.944: INFO: (8) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.481998ms)
Sep 21 14:51:13.958: INFO: (9) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.863542ms)
Sep 21 14:51:13.973: INFO: (10) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.454636ms)
Sep 21 14:51:13.987: INFO: (11) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.387502ms)
Sep 21 14:51:14.000: INFO: (12) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.058657ms)
Sep 21 14:51:14.015: INFO: (13) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.010832ms)
Sep 21 14:51:14.029: INFO: (14) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.817045ms)
Sep 21 14:51:14.043: INFO: (15) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.871056ms)
Sep 21 14:51:14.059: INFO: (16) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.465713ms)
Sep 21 14:51:14.073: INFO: (17) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.769441ms)
Sep 21 14:51:14.087: INFO: (18) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.93181ms)
Sep 21 14:51:14.100: INFO: (19) /api/v1/nodes/10.189.39.107:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.819509ms)
[AfterEach] version v1
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:51:14.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7383" for this suite.
Sep 21 14:51:20.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:51:20.443: INFO: namespace proxy-7383 deletion completed in 6.330630603s

• [SLOW TEST:6.897 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:51:20.445: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 21 14:51:20.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1688'
Sep 21 14:51:20.783: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 21 14:51:20.783: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Sep 21 14:51:20.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete jobs e2e-test-httpd-job --namespace=kubectl-1688'
Sep 21 14:51:20.900: INFO: stderr: ""
Sep 21 14:51:20.900: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:51:20.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1688" for this suite.
Sep 21 14:51:26.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:51:27.256: INFO: namespace kubectl-1688 deletion completed in 6.339945487s

• [SLOW TEST:6.811 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:51:27.256: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1964
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1206
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8880
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:51:44.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1964" for this suite.
Sep 21 14:51:50.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:51:50.417: INFO: namespace namespaces-1964 deletion completed in 6.359266398s
STEP: Destroying namespace "nsdeletetest-1206" for this suite.
Sep 21 14:51:50.427: INFO: Namespace nsdeletetest-1206 was already deleted
STEP: Destroying namespace "nsdeletetest-8880" for this suite.
Sep 21 14:51:56.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:51:56.797: INFO: namespace nsdeletetest-8880 deletion completed in 6.369995898s

• [SLOW TEST:29.541 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:51:56.797: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5707
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Sep 21 14:51:57.039: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:51:59.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5707" for this suite.
Sep 21 14:52:05.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:52:06.009: INFO: namespace init-container-5707 deletion completed in 6.43125437s

• [SLOW TEST:9.212 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:52:06.010: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 21 14:52:12.422: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 21 14:52:12.439: INFO: Pod pod-with-poststart-http-hook still exists
Sep 21 14:52:14.440: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 21 14:52:14.449: INFO: Pod pod-with-poststart-http-hook still exists
Sep 21 14:52:16.440: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 21 14:52:16.448: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:52:16.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7836" for this suite.
Sep 21 14:52:46.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:52:46.798: INFO: namespace container-lifecycle-hook-7836 deletion completed in 30.33813543s

• [SLOW TEST:40.788 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:52:46.799: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1310
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 21 14:52:47.078: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-a 960d8852-21c3-4c9e-877f-e98132f46595 20973 0 2020-09-21 14:52:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 21 14:52:47.079: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-a 960d8852-21c3-4c9e-877f-e98132f46595 20973 0 2020-09-21 14:52:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 21 14:52:57.103: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-a 960d8852-21c3-4c9e-877f-e98132f46595 20986 0 2020-09-21 14:52:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 21 14:52:57.103: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-a 960d8852-21c3-4c9e-877f-e98132f46595 20986 0 2020-09-21 14:52:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 21 14:53:07.130: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-a 960d8852-21c3-4c9e-877f-e98132f46595 21001 0 2020-09-21 14:52:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 21 14:53:07.130: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-a 960d8852-21c3-4c9e-877f-e98132f46595 21001 0 2020-09-21 14:52:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 21 14:53:17.153: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-a 960d8852-21c3-4c9e-877f-e98132f46595 21015 0 2020-09-21 14:52:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 21 14:53:17.154: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-a 960d8852-21c3-4c9e-877f-e98132f46595 21015 0 2020-09-21 14:52:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 21 14:53:27.171: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-b f8e2fc3c-1e5d-4487-9ab3-b3850f981ef2 21031 0 2020-09-21 14:53:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 21 14:53:27.171: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-b f8e2fc3c-1e5d-4487-9ab3-b3850f981ef2 21031 0 2020-09-21 14:53:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 21 14:53:37.193: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-b f8e2fc3c-1e5d-4487-9ab3-b3850f981ef2 21046 0 2020-09-21 14:53:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 21 14:53:37.193: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1310 /api/v1/namespaces/watch-1310/configmaps/e2e-watch-test-configmap-b f8e2fc3c-1e5d-4487-9ab3-b3850f981ef2 21046 0 2020-09-21 14:53:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:53:47.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1310" for this suite.
Sep 21 14:53:53.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:53:53.540: INFO: namespace watch-1310 deletion completed in 6.331270022s

• [SLOW TEST:66.742 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:53:53.544: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-22
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 14:53:53.801: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Sep 21 14:53:56.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-22 create -f -'
Sep 21 14:53:57.299: INFO: stderr: ""
Sep 21 14:53:57.299: INFO: stdout: "e2e-test-crd-publish-openapi-9623-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 21 14:53:57.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-22 delete e2e-test-crd-publish-openapi-9623-crds test-foo'
Sep 21 14:53:57.440: INFO: stderr: ""
Sep 21 14:53:57.440: INFO: stdout: "e2e-test-crd-publish-openapi-9623-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Sep 21 14:53:57.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-22 apply -f -'
Sep 21 14:53:57.628: INFO: stderr: ""
Sep 21 14:53:57.628: INFO: stdout: "e2e-test-crd-publish-openapi-9623-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 21 14:53:57.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-22 delete e2e-test-crd-publish-openapi-9623-crds test-foo'
Sep 21 14:53:57.723: INFO: stderr: ""
Sep 21 14:53:57.723: INFO: stdout: "e2e-test-crd-publish-openapi-9623-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Sep 21 14:53:57.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-22 create -f -'
Sep 21 14:53:57.867: INFO: rc: 1
Sep 21 14:53:57.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-22 apply -f -'
Sep 21 14:53:58.147: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Sep 21 14:53:58.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-22 create -f -'
Sep 21 14:53:58.437: INFO: rc: 1
Sep 21 14:53:58.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-22 apply -f -'
Sep 21 14:53:58.648: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Sep 21 14:53:58.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 explain e2e-test-crd-publish-openapi-9623-crds'
Sep 21 14:53:58.961: INFO: stderr: ""
Sep 21 14:53:58.961: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9623-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Sep 21 14:53:58.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 explain e2e-test-crd-publish-openapi-9623-crds.metadata'
Sep 21 14:53:59.184: INFO: stderr: ""
Sep 21 14:53:59.184: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9623-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Sep 21 14:53:59.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 explain e2e-test-crd-publish-openapi-9623-crds.spec'
Sep 21 14:53:59.449: INFO: stderr: ""
Sep 21 14:53:59.449: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9623-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Sep 21 14:53:59.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 explain e2e-test-crd-publish-openapi-9623-crds.spec.bars'
Sep 21 14:53:59.665: INFO: stderr: ""
Sep 21 14:53:59.665: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9623-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Sep 21 14:53:59.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 explain e2e-test-crd-publish-openapi-9623-crds.spec.bars2'
Sep 21 14:53:59.979: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:54:02.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-22" for this suite.
Sep 21 14:54:08.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:54:09.332: INFO: namespace crd-publish-openapi-22 deletion completed in 6.389216827s

• [SLOW TEST:15.788 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:54:09.332: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4112
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 21 14:54:09.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-4112'
Sep 21 14:54:09.685: INFO: stderr: ""
Sep 21 14:54:09.685: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Sep 21 14:54:14.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pod e2e-test-httpd-pod --namespace=kubectl-4112 -o json'
Sep 21 14:54:14.805: INFO: stderr: ""
Sep 21 14:54:14.805: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-09-21T14:54:09Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4112\",\n        \"resourceVersion\": \"21146\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4112/pods/e2e-test-httpd-pod\",\n        \"uid\": \"9ec4ff70-c6cb-442a-8d8e-0d9abcc39526\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-6fgqs\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.189.39.107\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-6fgqs\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-6fgqs\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-21T14:54:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-21T14:54:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-21T14:54:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-21T14:54:09Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://bc5ce9b78753ed018edc54070ba8009b8bcf90affa652668f922310633ec1c26\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-09-21T14:54:10Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.189.39.107\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.185.227\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.185.227\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-09-21T14:54:09Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 21 14:54:14.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 replace -f - --namespace=kubectl-4112'
Sep 21 14:54:15.114: INFO: stderr: ""
Sep 21 14:54:15.114: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Sep 21 14:54:15.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete pods e2e-test-httpd-pod --namespace=kubectl-4112'
Sep 21 14:54:16.896: INFO: stderr: ""
Sep 21 14:54:16.896: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:54:16.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4112" for this suite.
Sep 21 14:54:22.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:54:23.252: INFO: namespace kubectl-4112 deletion completed in 6.343462753s

• [SLOW TEST:13.919 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:54:23.252: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 14:54:23.506: INFO: Waiting up to 5m0s for pod "downwardapi-volume-665280bf-005f-4cbf-884f-5b14d40f8273" in namespace "downward-api-4836" to be "success or failure"
Sep 21 14:54:23.515: INFO: Pod "downwardapi-volume-665280bf-005f-4cbf-884f-5b14d40f8273": Phase="Pending", Reason="", readiness=false. Elapsed: 8.623983ms
Sep 21 14:54:25.524: INFO: Pod "downwardapi-volume-665280bf-005f-4cbf-884f-5b14d40f8273": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017466479s
STEP: Saw pod success
Sep 21 14:54:25.524: INFO: Pod "downwardapi-volume-665280bf-005f-4cbf-884f-5b14d40f8273" satisfied condition "success or failure"
Sep 21 14:54:25.531: INFO: Trying to get logs from node 10.189.39.114 pod downwardapi-volume-665280bf-005f-4cbf-884f-5b14d40f8273 container client-container: <nil>
STEP: delete the pod
Sep 21 14:54:25.596: INFO: Waiting for pod downwardapi-volume-665280bf-005f-4cbf-884f-5b14d40f8273 to disappear
Sep 21 14:54:25.607: INFO: Pod downwardapi-volume-665280bf-005f-4cbf-884f-5b14d40f8273 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:54:25.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4836" for this suite.
Sep 21 14:54:31.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:54:31.963: INFO: namespace downward-api-4836 deletion completed in 6.340127751s

• [SLOW TEST:8.711 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:54:31.963: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 21 14:54:32.219: INFO: Waiting up to 5m0s for pod "pod-9598a296-c3da-4136-a982-76eb0f251566" in namespace "emptydir-6864" to be "success or failure"
Sep 21 14:54:32.228: INFO: Pod "pod-9598a296-c3da-4136-a982-76eb0f251566": Phase="Pending", Reason="", readiness=false. Elapsed: 8.545255ms
Sep 21 14:54:34.244: INFO: Pod "pod-9598a296-c3da-4136-a982-76eb0f251566": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024455816s
STEP: Saw pod success
Sep 21 14:54:34.244: INFO: Pod "pod-9598a296-c3da-4136-a982-76eb0f251566" satisfied condition "success or failure"
Sep 21 14:54:34.251: INFO: Trying to get logs from node 10.189.39.114 pod pod-9598a296-c3da-4136-a982-76eb0f251566 container test-container: <nil>
STEP: delete the pod
Sep 21 14:54:34.300: INFO: Waiting for pod pod-9598a296-c3da-4136-a982-76eb0f251566 to disappear
Sep 21 14:54:34.308: INFO: Pod pod-9598a296-c3da-4136-a982-76eb0f251566 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:54:34.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6864" for this suite.
Sep 21 14:54:40.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:54:40.655: INFO: namespace emptydir-6864 deletion completed in 6.334739225s

• [SLOW TEST:8.692 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:54:40.656: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 21 14:54:51.065: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0921 14:54:51.065930      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:54:51.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9834" for this suite.
Sep 21 14:54:59.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:54:59.412: INFO: namespace gc-9834 deletion completed in 8.334298537s

• [SLOW TEST:18.756 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:54:59.412: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-273
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-4351d3ef-c155-4035-91d6-00303f82f36f
STEP: Creating a pod to test consume secrets
Sep 21 14:54:59.684: INFO: Waiting up to 5m0s for pod "pod-secrets-54b5b250-1361-4cdd-82dc-eeb0cf350167" in namespace "secrets-273" to be "success or failure"
Sep 21 14:54:59.693: INFO: Pod "pod-secrets-54b5b250-1361-4cdd-82dc-eeb0cf350167": Phase="Pending", Reason="", readiness=false. Elapsed: 8.89305ms
Sep 21 14:55:01.703: INFO: Pod "pod-secrets-54b5b250-1361-4cdd-82dc-eeb0cf350167": Phase="Running", Reason="", readiness=true. Elapsed: 2.019160938s
Sep 21 14:55:03.712: INFO: Pod "pod-secrets-54b5b250-1361-4cdd-82dc-eeb0cf350167": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027710025s
STEP: Saw pod success
Sep 21 14:55:03.712: INFO: Pod "pod-secrets-54b5b250-1361-4cdd-82dc-eeb0cf350167" satisfied condition "success or failure"
Sep 21 14:55:03.720: INFO: Trying to get logs from node 10.189.39.107 pod pod-secrets-54b5b250-1361-4cdd-82dc-eeb0cf350167 container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 14:55:03.791: INFO: Waiting for pod pod-secrets-54b5b250-1361-4cdd-82dc-eeb0cf350167 to disappear
Sep 21 14:55:03.798: INFO: Pod pod-secrets-54b5b250-1361-4cdd-82dc-eeb0cf350167 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:55:03.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-273" for this suite.
Sep 21 14:55:09.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:55:10.162: INFO: namespace secrets-273 deletion completed in 6.350201013s

• [SLOW TEST:10.750 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:55:10.164: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8740
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-0527a831-4dd4-4e28-9e52-c5c80822bf98
STEP: Creating a pod to test consume secrets
Sep 21 14:55:10.441: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-722aba34-86fe-461c-b226-da7abc8d237b" in namespace "projected-8740" to be "success or failure"
Sep 21 14:55:10.457: INFO: Pod "pod-projected-secrets-722aba34-86fe-461c-b226-da7abc8d237b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.305576ms
Sep 21 14:55:12.467: INFO: Pod "pod-projected-secrets-722aba34-86fe-461c-b226-da7abc8d237b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026413904s
STEP: Saw pod success
Sep 21 14:55:12.467: INFO: Pod "pod-projected-secrets-722aba34-86fe-461c-b226-da7abc8d237b" satisfied condition "success or failure"
Sep 21 14:55:12.477: INFO: Trying to get logs from node 10.189.39.114 pod pod-projected-secrets-722aba34-86fe-461c-b226-da7abc8d237b container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 14:55:12.526: INFO: Waiting for pod pod-projected-secrets-722aba34-86fe-461c-b226-da7abc8d237b to disappear
Sep 21 14:55:12.534: INFO: Pod pod-projected-secrets-722aba34-86fe-461c-b226-da7abc8d237b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:55:12.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8740" for this suite.
Sep 21 14:55:18.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:55:18.891: INFO: namespace projected-8740 deletion completed in 6.34321306s

• [SLOW TEST:8.727 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:55:18.892: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-87200452-8a3b-4c0f-888a-b7de02a505e1
STEP: Creating a pod to test consume configMaps
Sep 21 14:55:19.167: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-786a83e7-8dba-4957-ba51-0b1e7e5209dc" in namespace "projected-4073" to be "success or failure"
Sep 21 14:55:19.179: INFO: Pod "pod-projected-configmaps-786a83e7-8dba-4957-ba51-0b1e7e5209dc": Phase="Pending", Reason="", readiness=false. Elapsed: 11.01879ms
Sep 21 14:55:21.188: INFO: Pod "pod-projected-configmaps-786a83e7-8dba-4957-ba51-0b1e7e5209dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020894249s
Sep 21 14:55:23.199: INFO: Pod "pod-projected-configmaps-786a83e7-8dba-4957-ba51-0b1e7e5209dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031498099s
STEP: Saw pod success
Sep 21 14:55:23.199: INFO: Pod "pod-projected-configmaps-786a83e7-8dba-4957-ba51-0b1e7e5209dc" satisfied condition "success or failure"
Sep 21 14:55:23.208: INFO: Trying to get logs from node 10.189.39.114 pod pod-projected-configmaps-786a83e7-8dba-4957-ba51-0b1e7e5209dc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 14:55:23.257: INFO: Waiting for pod pod-projected-configmaps-786a83e7-8dba-4957-ba51-0b1e7e5209dc to disappear
Sep 21 14:55:23.277: INFO: Pod pod-projected-configmaps-786a83e7-8dba-4957-ba51-0b1e7e5209dc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:55:23.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4073" for this suite.
Sep 21 14:55:29.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:55:29.643: INFO: namespace projected-4073 deletion completed in 6.351230409s

• [SLOW TEST:10.751 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:55:29.644: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3238
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 14:55:29.896: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d53bcda-e1d4-46b1-87da-bfcdd7130c99" in namespace "projected-3238" to be "success or failure"
Sep 21 14:55:29.905: INFO: Pod "downwardapi-volume-5d53bcda-e1d4-46b1-87da-bfcdd7130c99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.647875ms
Sep 21 14:55:31.915: INFO: Pod "downwardapi-volume-5d53bcda-e1d4-46b1-87da-bfcdd7130c99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018412462s
Sep 21 14:55:33.924: INFO: Pod "downwardapi-volume-5d53bcda-e1d4-46b1-87da-bfcdd7130c99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027508522s
STEP: Saw pod success
Sep 21 14:55:33.924: INFO: Pod "downwardapi-volume-5d53bcda-e1d4-46b1-87da-bfcdd7130c99" satisfied condition "success or failure"
Sep 21 14:55:33.932: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-5d53bcda-e1d4-46b1-87da-bfcdd7130c99 container client-container: <nil>
STEP: delete the pod
Sep 21 14:55:34.015: INFO: Waiting for pod downwardapi-volume-5d53bcda-e1d4-46b1-87da-bfcdd7130c99 to disappear
Sep 21 14:55:34.023: INFO: Pod downwardapi-volume-5d53bcda-e1d4-46b1-87da-bfcdd7130c99 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:55:34.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3238" for this suite.
Sep 21 14:55:40.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:55:40.366: INFO: namespace projected-3238 deletion completed in 6.332086355s

• [SLOW TEST:10.722 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:55:40.366: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8276
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Sep 21 14:55:41.184: INFO: created pod pod-service-account-defaultsa
Sep 21 14:55:41.184: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 21 14:55:41.196: INFO: created pod pod-service-account-mountsa
Sep 21 14:55:41.196: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 21 14:55:41.206: INFO: created pod pod-service-account-nomountsa
Sep 21 14:55:41.206: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 21 14:55:41.218: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 21 14:55:41.218: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 21 14:55:41.230: INFO: created pod pod-service-account-mountsa-mountspec
Sep 21 14:55:41.230: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 21 14:55:41.240: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 21 14:55:41.240: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 21 14:55:41.253: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 21 14:55:41.253: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 21 14:55:41.274: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 21 14:55:41.274: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 21 14:55:41.284: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 21 14:55:41.284: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:55:41.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8276" for this suite.
Sep 21 14:55:49.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:55:49.793: INFO: namespace svcaccounts-8276 deletion completed in 8.494958198s

• [SLOW TEST:9.427 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:55:49.796: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5554
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 14:55:50.492: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 14:55:52.533: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296950, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296950, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296950, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736296950, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 14:55:55.564: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
Sep 21 14:56:05.746: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:56:06.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5554" for this suite.
Sep 21 14:56:14.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:56:14.500: INFO: namespace webhook-5554 deletion completed in 8.347550828s
STEP: Destroying namespace "webhook-5554-markers" for this suite.
Sep 21 14:56:20.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:56:20.889: INFO: namespace webhook-5554-markers deletion completed in 6.388482115s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:31.137 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:56:20.933: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8937
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 21 14:56:21.186: INFO: Waiting up to 5m0s for pod "pod-dcdff644-8822-460c-b875-b78f44b6fb82" in namespace "emptydir-8937" to be "success or failure"
Sep 21 14:56:21.195: INFO: Pod "pod-dcdff644-8822-460c-b875-b78f44b6fb82": Phase="Pending", Reason="", readiness=false. Elapsed: 9.377539ms
Sep 21 14:56:23.207: INFO: Pod "pod-dcdff644-8822-460c-b875-b78f44b6fb82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02125072s
Sep 21 14:56:25.216: INFO: Pod "pod-dcdff644-8822-460c-b875-b78f44b6fb82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030615161s
STEP: Saw pod success
Sep 21 14:56:25.216: INFO: Pod "pod-dcdff644-8822-460c-b875-b78f44b6fb82" satisfied condition "success or failure"
Sep 21 14:56:25.224: INFO: Trying to get logs from node 10.189.39.109 pod pod-dcdff644-8822-460c-b875-b78f44b6fb82 container test-container: <nil>
STEP: delete the pod
Sep 21 14:56:25.274: INFO: Waiting for pod pod-dcdff644-8822-460c-b875-b78f44b6fb82 to disappear
Sep 21 14:56:25.281: INFO: Pod pod-dcdff644-8822-460c-b875-b78f44b6fb82 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:56:25.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8937" for this suite.
Sep 21 14:56:31.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:56:31.625: INFO: namespace emptydir-8937 deletion completed in 6.3322578s

• [SLOW TEST:10.693 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:56:31.626: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-f072cecd-62c3-4458-8cdc-01b857b62520
STEP: Creating a pod to test consume secrets
Sep 21 14:56:31.900: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-60d822c4-2869-43a3-ad26-c5bb5c912784" in namespace "projected-7064" to be "success or failure"
Sep 21 14:56:31.912: INFO: Pod "pod-projected-secrets-60d822c4-2869-43a3-ad26-c5bb5c912784": Phase="Pending", Reason="", readiness=false. Elapsed: 11.618476ms
Sep 21 14:56:33.921: INFO: Pod "pod-projected-secrets-60d822c4-2869-43a3-ad26-c5bb5c912784": Phase="Running", Reason="", readiness=true. Elapsed: 2.02130419s
Sep 21 14:56:35.931: INFO: Pod "pod-projected-secrets-60d822c4-2869-43a3-ad26-c5bb5c912784": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030949111s
STEP: Saw pod success
Sep 21 14:56:35.931: INFO: Pod "pod-projected-secrets-60d822c4-2869-43a3-ad26-c5bb5c912784" satisfied condition "success or failure"
Sep 21 14:56:35.940: INFO: Trying to get logs from node 10.189.39.109 pod pod-projected-secrets-60d822c4-2869-43a3-ad26-c5bb5c912784 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 14:56:35.990: INFO: Waiting for pod pod-projected-secrets-60d822c4-2869-43a3-ad26-c5bb5c912784 to disappear
Sep 21 14:56:35.999: INFO: Pod pod-projected-secrets-60d822c4-2869-43a3-ad26-c5bb5c912784 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:56:35.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7064" for this suite.
Sep 21 14:56:44.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:56:44.368: INFO: namespace projected-7064 deletion completed in 8.354756476s

• [SLOW TEST:12.742 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:56:44.371: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4710
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-5cd9862f-3849-489c-878b-ce962a1809d1
STEP: Creating secret with name s-test-opt-upd-f3048bfc-d7f5-4cef-93cc-8312801b76ed
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5cd9862f-3849-489c-878b-ce962a1809d1
STEP: Updating secret s-test-opt-upd-f3048bfc-d7f5-4cef-93cc-8312801b76ed
STEP: Creating secret with name s-test-opt-create-c59712b0-a218-44bb-837f-705e0ed0c7c1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 14:56:48.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4710" for this suite.
Sep 21 14:57:00.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 14:57:01.236: INFO: namespace projected-4710 deletion completed in 12.317901763s

• [SLOW TEST:16.865 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 14:57:01.237: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7879
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-a7a5ae01-a906-4040-816f-a850e7aef3c0 in namespace container-probe-7879
Sep 21 14:57:03.508: INFO: Started pod busybox-a7a5ae01-a906-4040-816f-a850e7aef3c0 in namespace container-probe-7879
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 14:57:03.517: INFO: Initial restart count of pod busybox-a7a5ae01-a906-4040-816f-a850e7aef3c0 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:01:04.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7879" for this suite.
Sep 21 15:01:10.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:01:11.105: INFO: namespace container-probe-7879 deletion completed in 6.354637495s

• [SLOW TEST:249.869 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:01:11.106: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-2343/secret-test-df2506df-7491-4693-a21f-fd33060fba70
STEP: Creating a pod to test consume secrets
Sep 21 15:01:11.385: INFO: Waiting up to 5m0s for pod "pod-configmaps-90df1e69-f815-4e77-9c53-c469dc2227d1" in namespace "secrets-2343" to be "success or failure"
Sep 21 15:01:11.398: INFO: Pod "pod-configmaps-90df1e69-f815-4e77-9c53-c469dc2227d1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.523011ms
Sep 21 15:01:13.407: INFO: Pod "pod-configmaps-90df1e69-f815-4e77-9c53-c469dc2227d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022392069s
STEP: Saw pod success
Sep 21 15:01:13.407: INFO: Pod "pod-configmaps-90df1e69-f815-4e77-9c53-c469dc2227d1" satisfied condition "success or failure"
Sep 21 15:01:13.416: INFO: Trying to get logs from node 10.189.39.107 pod pod-configmaps-90df1e69-f815-4e77-9c53-c469dc2227d1 container env-test: <nil>
STEP: delete the pod
Sep 21 15:01:13.484: INFO: Waiting for pod pod-configmaps-90df1e69-f815-4e77-9c53-c469dc2227d1 to disappear
Sep 21 15:01:13.491: INFO: Pod pod-configmaps-90df1e69-f815-4e77-9c53-c469dc2227d1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:01:13.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2343" for this suite.
Sep 21 15:01:19.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:01:19.862: INFO: namespace secrets-2343 deletion completed in 6.35419489s

• [SLOW TEST:8.756 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:01:19.864: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-d5f37808-915d-4262-a40f-45662bf9b793
STEP: Creating a pod to test consume configMaps
Sep 21 15:01:20.149: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-52b0bba6-f71a-4aa7-b7b7-ab4c60351e8b" in namespace "projected-6884" to be "success or failure"
Sep 21 15:01:20.157: INFO: Pod "pod-projected-configmaps-52b0bba6-f71a-4aa7-b7b7-ab4c60351e8b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.655456ms
Sep 21 15:01:22.167: INFO: Pod "pod-projected-configmaps-52b0bba6-f71a-4aa7-b7b7-ab4c60351e8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018179336s
Sep 21 15:01:24.176: INFO: Pod "pod-projected-configmaps-52b0bba6-f71a-4aa7-b7b7-ab4c60351e8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027782635s
STEP: Saw pod success
Sep 21 15:01:24.176: INFO: Pod "pod-projected-configmaps-52b0bba6-f71a-4aa7-b7b7-ab4c60351e8b" satisfied condition "success or failure"
Sep 21 15:01:24.185: INFO: Trying to get logs from node 10.189.39.109 pod pod-projected-configmaps-52b0bba6-f71a-4aa7-b7b7-ab4c60351e8b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 15:01:24.264: INFO: Waiting for pod pod-projected-configmaps-52b0bba6-f71a-4aa7-b7b7-ab4c60351e8b to disappear
Sep 21 15:01:24.274: INFO: Pod pod-projected-configmaps-52b0bba6-f71a-4aa7-b7b7-ab4c60351e8b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:01:24.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6884" for this suite.
Sep 21 15:01:30.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:01:30.628: INFO: namespace projected-6884 deletion completed in 6.335965687s

• [SLOW TEST:10.764 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:01:30.628: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2860
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Sep 21 15:01:30.882: INFO: Waiting up to 5m0s for pod "var-expansion-50be927e-949f-4130-b639-81ef336f353f" in namespace "var-expansion-2860" to be "success or failure"
Sep 21 15:01:30.893: INFO: Pod "var-expansion-50be927e-949f-4130-b639-81ef336f353f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.885165ms
Sep 21 15:01:32.904: INFO: Pod "var-expansion-50be927e-949f-4130-b639-81ef336f353f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021678324s
STEP: Saw pod success
Sep 21 15:01:32.904: INFO: Pod "var-expansion-50be927e-949f-4130-b639-81ef336f353f" satisfied condition "success or failure"
Sep 21 15:01:32.914: INFO: Trying to get logs from node 10.189.39.109 pod var-expansion-50be927e-949f-4130-b639-81ef336f353f container dapi-container: <nil>
STEP: delete the pod
Sep 21 15:01:32.965: INFO: Waiting for pod var-expansion-50be927e-949f-4130-b639-81ef336f353f to disappear
Sep 21 15:01:32.972: INFO: Pod var-expansion-50be927e-949f-4130-b639-81ef336f353f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:01:32.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2860" for this suite.
Sep 21 15:01:39.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:01:39.327: INFO: namespace var-expansion-2860 deletion completed in 6.340274776s

• [SLOW TEST:8.698 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:01:39.327: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:01:39.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6b56d06-5cfc-4934-82a1-5239ffb7d6ed" in namespace "projected-1386" to be "success or failure"
Sep 21 15:01:39.611: INFO: Pod "downwardapi-volume-e6b56d06-5cfc-4934-82a1-5239ffb7d6ed": Phase="Pending", Reason="", readiness=false. Elapsed: 8.893395ms
Sep 21 15:01:41.621: INFO: Pod "downwardapi-volume-e6b56d06-5cfc-4934-82a1-5239ffb7d6ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019504797s
STEP: Saw pod success
Sep 21 15:01:41.621: INFO: Pod "downwardapi-volume-e6b56d06-5cfc-4934-82a1-5239ffb7d6ed" satisfied condition "success or failure"
Sep 21 15:01:41.631: INFO: Trying to get logs from node 10.189.39.114 pod downwardapi-volume-e6b56d06-5cfc-4934-82a1-5239ffb7d6ed container client-container: <nil>
STEP: delete the pod
Sep 21 15:01:41.707: INFO: Waiting for pod downwardapi-volume-e6b56d06-5cfc-4934-82a1-5239ffb7d6ed to disappear
Sep 21 15:01:41.714: INFO: Pod downwardapi-volume-e6b56d06-5cfc-4934-82a1-5239ffb7d6ed no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:01:41.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1386" for this suite.
Sep 21 15:01:47.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:01:48.075: INFO: namespace projected-1386 deletion completed in 6.347284259s

• [SLOW TEST:8.748 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:01:48.075: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9747
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:01:50.384: INFO: Waiting up to 5m0s for pod "client-envvars-d55d0b14-293b-46ec-95bb-a8e8f9e58f0f" in namespace "pods-9747" to be "success or failure"
Sep 21 15:01:50.394: INFO: Pod "client-envvars-d55d0b14-293b-46ec-95bb-a8e8f9e58f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.377181ms
Sep 21 15:01:52.404: INFO: Pod "client-envvars-d55d0b14-293b-46ec-95bb-a8e8f9e58f0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019410058s
STEP: Saw pod success
Sep 21 15:01:52.404: INFO: Pod "client-envvars-d55d0b14-293b-46ec-95bb-a8e8f9e58f0f" satisfied condition "success or failure"
Sep 21 15:01:52.414: INFO: Trying to get logs from node 10.189.39.107 pod client-envvars-d55d0b14-293b-46ec-95bb-a8e8f9e58f0f container env3cont: <nil>
STEP: delete the pod
Sep 21 15:01:52.465: INFO: Waiting for pod client-envvars-d55d0b14-293b-46ec-95bb-a8e8f9e58f0f to disappear
Sep 21 15:01:52.474: INFO: Pod client-envvars-d55d0b14-293b-46ec-95bb-a8e8f9e58f0f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:01:52.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9747" for this suite.
Sep 21 15:02:22.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:02:22.833: INFO: namespace pods-9747 deletion completed in 30.340596858s

• [SLOW TEST:34.758 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:02:22.833: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1105
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-ca8a2a9a-8bfa-407b-804e-f0b0a86bc38a
STEP: Creating a pod to test consume configMaps
Sep 21 15:02:23.098: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-de76d573-524a-4190-a901-8fad8bf5024c" in namespace "projected-1105" to be "success or failure"
Sep 21 15:02:23.108: INFO: Pod "pod-projected-configmaps-de76d573-524a-4190-a901-8fad8bf5024c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.990698ms
Sep 21 15:02:25.117: INFO: Pod "pod-projected-configmaps-de76d573-524a-4190-a901-8fad8bf5024c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01924734s
STEP: Saw pod success
Sep 21 15:02:25.117: INFO: Pod "pod-projected-configmaps-de76d573-524a-4190-a901-8fad8bf5024c" satisfied condition "success or failure"
Sep 21 15:02:25.127: INFO: Trying to get logs from node 10.189.39.109 pod pod-projected-configmaps-de76d573-524a-4190-a901-8fad8bf5024c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 15:02:25.185: INFO: Waiting for pod pod-projected-configmaps-de76d573-524a-4190-a901-8fad8bf5024c to disappear
Sep 21 15:02:25.194: INFO: Pod pod-projected-configmaps-de76d573-524a-4190-a901-8fad8bf5024c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:02:25.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1105" for this suite.
Sep 21 15:02:31.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:02:31.547: INFO: namespace projected-1105 deletion completed in 6.335318998s

• [SLOW TEST:8.714 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:02:31.548: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-243
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:02:31.813: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0ae20e2-ba41-4c51-ae51-bdedc8b4f766" in namespace "projected-243" to be "success or failure"
Sep 21 15:02:31.823: INFO: Pod "downwardapi-volume-a0ae20e2-ba41-4c51-ae51-bdedc8b4f766": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020956ms
Sep 21 15:02:33.833: INFO: Pod "downwardapi-volume-a0ae20e2-ba41-4c51-ae51-bdedc8b4f766": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019915862s
STEP: Saw pod success
Sep 21 15:02:33.833: INFO: Pod "downwardapi-volume-a0ae20e2-ba41-4c51-ae51-bdedc8b4f766" satisfied condition "success or failure"
Sep 21 15:02:33.841: INFO: Trying to get logs from node 10.189.39.114 pod downwardapi-volume-a0ae20e2-ba41-4c51-ae51-bdedc8b4f766 container client-container: <nil>
STEP: delete the pod
Sep 21 15:02:33.889: INFO: Waiting for pod downwardapi-volume-a0ae20e2-ba41-4c51-ae51-bdedc8b4f766 to disappear
Sep 21 15:02:33.897: INFO: Pod downwardapi-volume-a0ae20e2-ba41-4c51-ae51-bdedc8b4f766 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:02:33.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-243" for this suite.
Sep 21 15:02:39.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:02:40.245: INFO: namespace projected-243 deletion completed in 6.333230937s

• [SLOW TEST:8.698 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:02:40.245: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1997
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 15:02:40.932: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 15:02:42.957: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736297360, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736297360, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736297360, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736297360, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 15:02:45.991: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Sep 21 15:02:48.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 attach --namespace=webhook-1997 to-be-attached-pod -i -c=container1'
Sep 21 15:02:48.187: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:02:48.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1997" for this suite.
Sep 21 15:03:00.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:03:00.551: INFO: namespace webhook-1997 deletion completed in 12.328180313s
STEP: Destroying namespace "webhook-1997-markers" for this suite.
Sep 21 15:03:06.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:03:06.910: INFO: namespace webhook-1997-markers deletion completed in 6.35930835s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.708 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:03:06.955: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2076
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-2076/configmap-test-bc219571-486a-4bff-b11a-91de5e2bb63d
STEP: Creating a pod to test consume configMaps
Sep 21 15:03:07.237: INFO: Waiting up to 5m0s for pod "pod-configmaps-04925a75-83e2-4144-82e8-24dde19ef8df" in namespace "configmap-2076" to be "success or failure"
Sep 21 15:03:07.246: INFO: Pod "pod-configmaps-04925a75-83e2-4144-82e8-24dde19ef8df": Phase="Pending", Reason="", readiness=false. Elapsed: 9.140417ms
Sep 21 15:03:09.255: INFO: Pod "pod-configmaps-04925a75-83e2-4144-82e8-24dde19ef8df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018053098s
Sep 21 15:03:11.265: INFO: Pod "pod-configmaps-04925a75-83e2-4144-82e8-24dde19ef8df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028376374s
Sep 21 15:03:13.275: INFO: Pod "pod-configmaps-04925a75-83e2-4144-82e8-24dde19ef8df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038379324s
STEP: Saw pod success
Sep 21 15:03:13.275: INFO: Pod "pod-configmaps-04925a75-83e2-4144-82e8-24dde19ef8df" satisfied condition "success or failure"
Sep 21 15:03:13.283: INFO: Trying to get logs from node 10.189.39.114 pod pod-configmaps-04925a75-83e2-4144-82e8-24dde19ef8df container env-test: <nil>
STEP: delete the pod
Sep 21 15:03:13.332: INFO: Waiting for pod pod-configmaps-04925a75-83e2-4144-82e8-24dde19ef8df to disappear
Sep 21 15:03:13.340: INFO: Pod pod-configmaps-04925a75-83e2-4144-82e8-24dde19ef8df no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:03:13.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2076" for this suite.
Sep 21 15:03:19.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:03:19.726: INFO: namespace configmap-2076 deletion completed in 6.372872007s

• [SLOW TEST:12.771 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:03:19.726: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6404
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-fb65cca3-450d-4fd5-a63a-8859b3b1c400
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:03:22.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6404" for this suite.
Sep 21 15:03:34.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:03:34.463: INFO: namespace configmap-6404 deletion completed in 12.341554551s

• [SLOW TEST:14.737 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:03:34.464: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6519
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:03:34.720: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:03:36.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6519" for this suite.
Sep 21 15:04:26.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:04:27.289: INFO: namespace pods-6519 deletion completed in 50.412706302s

• [SLOW TEST:52.826 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:04:27.290: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3085
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3085
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-3085
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3085
Sep 21 15:04:27.602: INFO: Found 0 stateful pods, waiting for 1
Sep 21 15:04:37.613: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 21 15:04:37.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-3085 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:04:37.964: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:04:37.964: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:04:37.964: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 15:04:37.976: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 21 15:04:47.987: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 15:04:47.987: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 15:04:48.023: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998722s
Sep 21 15:04:49.032: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.991457699s
Sep 21 15:04:50.044: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.982167179s
Sep 21 15:04:51.054: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.970798591s
Sep 21 15:04:52.064: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.960794924s
Sep 21 15:04:53.076: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.950244183s
Sep 21 15:04:54.091: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.938913469s
Sep 21 15:04:55.103: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.923165056s
Sep 21 15:04:56.113: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.911554426s
Sep 21 15:04:57.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 901.317382ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3085
Sep 21 15:04:58.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-3085 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:04:58.371: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 15:04:58.371: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 15:04:58.371: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 15:04:58.380: INFO: Found 1 stateful pods, waiting for 3
Sep 21 15:05:08.393: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 15:05:08.393: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 15:05:08.393: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 21 15:05:08.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-3085 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:05:08.617: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:05:08.617: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:05:08.617: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 15:05:08.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-3085 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:05:08.878: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:05:08.878: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:05:08.878: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 15:05:08.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-3085 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:05:09.092: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:05:09.092: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:05:09.092: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 15:05:09.092: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 15:05:09.101: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Sep 21 15:05:19.120: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 15:05:19.120: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 15:05:19.120: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 15:05:19.148: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998721s
Sep 21 15:05:20.159: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991549686s
Sep 21 15:05:21.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98052862s
Sep 21 15:05:22.181: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.969409368s
Sep 21 15:05:23.191: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.957595066s
Sep 21 15:05:24.201: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.947902657s
Sep 21 15:05:25.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.937917489s
Sep 21 15:05:26.222: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.927337509s
Sep 21 15:05:27.243: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.916667685s
Sep 21 15:05:28.253: INFO: Verifying statefulset ss doesn't scale past 3 for another 895.947052ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3085
Sep 21 15:05:29.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-3085 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:05:29.459: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 15:05:29.459: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 15:05:29.459: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 15:05:29.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-3085 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:05:29.703: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 15:05:29.703: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 15:05:29.703: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 15:05:29.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-3085 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:05:29.956: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 15:05:29.956: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 15:05:29.956: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 15:05:29.956: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 21 15:05:49.998: INFO: Deleting all statefulset in ns statefulset-3085
Sep 21 15:05:50.008: INFO: Scaling statefulset ss to 0
Sep 21 15:05:50.037: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 15:05:50.045: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:05:50.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3085" for this suite.
Sep 21 15:05:58.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:05:58.511: INFO: namespace statefulset-3085 deletion completed in 8.414572754s

• [SLOW TEST:91.221 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:05:58.511: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6816
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 21 15:05:58.784: INFO: Waiting up to 5m0s for pod "downward-api-68ef9b81-28ea-46bc-b70a-e305931b2785" in namespace "downward-api-6816" to be "success or failure"
Sep 21 15:05:58.796: INFO: Pod "downward-api-68ef9b81-28ea-46bc-b70a-e305931b2785": Phase="Pending", Reason="", readiness=false. Elapsed: 11.909996ms
Sep 21 15:06:00.806: INFO: Pod "downward-api-68ef9b81-28ea-46bc-b70a-e305931b2785": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021297476s
STEP: Saw pod success
Sep 21 15:06:00.806: INFO: Pod "downward-api-68ef9b81-28ea-46bc-b70a-e305931b2785" satisfied condition "success or failure"
Sep 21 15:06:00.815: INFO: Trying to get logs from node 10.189.39.114 pod downward-api-68ef9b81-28ea-46bc-b70a-e305931b2785 container dapi-container: <nil>
STEP: delete the pod
Sep 21 15:06:00.879: INFO: Waiting for pod downward-api-68ef9b81-28ea-46bc-b70a-e305931b2785 to disappear
Sep 21 15:06:00.887: INFO: Pod downward-api-68ef9b81-28ea-46bc-b70a-e305931b2785 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:06:00.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6816" for this suite.
Sep 21 15:06:06.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:06:07.263: INFO: namespace downward-api-6816 deletion completed in 6.361269472s

• [SLOW TEST:8.751 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:06:07.265: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 21 15:06:07.524: INFO: Waiting up to 5m0s for pod "pod-1f434e8e-e6ac-4cde-a37c-add8277db7d9" in namespace "emptydir-7417" to be "success or failure"
Sep 21 15:06:07.535: INFO: Pod "pod-1f434e8e-e6ac-4cde-a37c-add8277db7d9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.147096ms
Sep 21 15:06:09.544: INFO: Pod "pod-1f434e8e-e6ac-4cde-a37c-add8277db7d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020486265s
STEP: Saw pod success
Sep 21 15:06:09.544: INFO: Pod "pod-1f434e8e-e6ac-4cde-a37c-add8277db7d9" satisfied condition "success or failure"
Sep 21 15:06:09.553: INFO: Trying to get logs from node 10.189.39.107 pod pod-1f434e8e-e6ac-4cde-a37c-add8277db7d9 container test-container: <nil>
STEP: delete the pod
Sep 21 15:06:09.617: INFO: Waiting for pod pod-1f434e8e-e6ac-4cde-a37c-add8277db7d9 to disappear
Sep 21 15:06:09.625: INFO: Pod pod-1f434e8e-e6ac-4cde-a37c-add8277db7d9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:06:09.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7417" for this suite.
Sep 21 15:06:15.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:06:15.973: INFO: namespace emptydir-7417 deletion completed in 6.334378719s

• [SLOW TEST:8.708 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:06:15.973: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3367
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 21 15:06:21.299: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:06:22.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3367" for this suite.
Sep 21 15:06:52.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:06:52.739: INFO: namespace replicaset-3367 deletion completed in 30.384564575s

• [SLOW TEST:36.766 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:06:52.740: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6606
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6606
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Sep 21 15:06:53.024: INFO: Found 0 stateful pods, waiting for 3
Sep 21 15:07:03.036: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 15:07:03.036: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 15:07:03.036: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 15:07:03.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-6606 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:07:03.329: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:07:03.329: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:07:03.329: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 21 15:07:13.396: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 21 15:07:23.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-6606 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:07:23.695: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 15:07:23.695: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 15:07:23.695: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 15:07:33.748: INFO: Waiting for StatefulSet statefulset-6606/ss2 to complete update
Sep 21 15:07:33.748: INFO: Waiting for Pod statefulset-6606/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 21 15:07:33.748: INFO: Waiting for Pod statefulset-6606/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 21 15:07:33.748: INFO: Waiting for Pod statefulset-6606/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 21 15:07:43.769: INFO: Waiting for StatefulSet statefulset-6606/ss2 to complete update
Sep 21 15:07:43.769: INFO: Waiting for Pod statefulset-6606/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Sep 21 15:07:53.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-6606 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:07:54.015: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:07:54.015: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:07:54.015: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 15:08:04.082: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 21 15:08:14.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-6606 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:08:14.398: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 15:08:14.398: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 15:08:14.398: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 15:08:24.459: INFO: Waiting for StatefulSet statefulset-6606/ss2 to complete update
Sep 21 15:08:24.459: INFO: Waiting for Pod statefulset-6606/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Sep 21 15:08:24.459: INFO: Waiting for Pod statefulset-6606/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Sep 21 15:08:34.480: INFO: Waiting for StatefulSet statefulset-6606/ss2 to complete update
Sep 21 15:08:34.480: INFO: Waiting for Pod statefulset-6606/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 21 15:08:44.480: INFO: Deleting all statefulset in ns statefulset-6606
Sep 21 15:08:44.487: INFO: Scaling statefulset ss2 to 0
Sep 21 15:09:04.524: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 15:09:04.532: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:09:04.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6606" for this suite.
Sep 21 15:09:12.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:09:12.939: INFO: namespace statefulset-6606 deletion completed in 8.358387304s

• [SLOW TEST:140.199 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:09:12.941: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8780
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-6421fdab-e9ab-419a-be25-48e288396b61
STEP: Creating a pod to test consume configMaps
Sep 21 15:09:13.224: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c555a783-df6e-4593-860c-75339153a204" in namespace "projected-8780" to be "success or failure"
Sep 21 15:09:13.233: INFO: Pod "pod-projected-configmaps-c555a783-df6e-4593-860c-75339153a204": Phase="Pending", Reason="", readiness=false. Elapsed: 9.05993ms
Sep 21 15:09:15.243: INFO: Pod "pod-projected-configmaps-c555a783-df6e-4593-860c-75339153a204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019153249s
STEP: Saw pod success
Sep 21 15:09:15.243: INFO: Pod "pod-projected-configmaps-c555a783-df6e-4593-860c-75339153a204" satisfied condition "success or failure"
Sep 21 15:09:15.253: INFO: Trying to get logs from node 10.189.39.107 pod pod-projected-configmaps-c555a783-df6e-4593-860c-75339153a204 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 15:09:15.322: INFO: Waiting for pod pod-projected-configmaps-c555a783-df6e-4593-860c-75339153a204 to disappear
Sep 21 15:09:15.331: INFO: Pod pod-projected-configmaps-c555a783-df6e-4593-860c-75339153a204 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:09:15.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8780" for this suite.
Sep 21 15:09:21.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:09:21.672: INFO: namespace projected-8780 deletion completed in 6.32585338s

• [SLOW TEST:8.731 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:09:21.672: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 21 15:09:30.017: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 21 15:09:30.027: INFO: Pod pod-with-prestop-http-hook still exists
Sep 21 15:09:32.027: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 21 15:09:32.037: INFO: Pod pod-with-prestop-http-hook still exists
Sep 21 15:09:34.027: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 21 15:09:34.037: INFO: Pod pod-with-prestop-http-hook still exists
Sep 21 15:09:36.027: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 21 15:09:36.038: INFO: Pod pod-with-prestop-http-hook still exists
Sep 21 15:09:38.027: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 21 15:09:38.037: INFO: Pod pod-with-prestop-http-hook still exists
Sep 21 15:09:40.027: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 21 15:09:40.037: INFO: Pod pod-with-prestop-http-hook still exists
Sep 21 15:09:42.027: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 21 15:09:42.037: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:09:42.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5674" for this suite.
Sep 21 15:09:54.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:09:54.441: INFO: namespace container-lifecycle-hook-5674 deletion completed in 12.339252305s

• [SLOW TEST:32.769 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:09:54.441: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5199
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Sep 21 15:09:54.712: INFO: Waiting up to 5m0s for pod "var-expansion-104448fb-5e7a-4965-9782-2f5ee5582231" in namespace "var-expansion-5199" to be "success or failure"
Sep 21 15:09:54.724: INFO: Pod "var-expansion-104448fb-5e7a-4965-9782-2f5ee5582231": Phase="Pending", Reason="", readiness=false. Elapsed: 12.770696ms
Sep 21 15:09:56.946: INFO: Pod "var-expansion-104448fb-5e7a-4965-9782-2f5ee5582231": Phase="Pending", Reason="", readiness=false. Elapsed: 2.234524126s
Sep 21 15:09:58.955: INFO: Pod "var-expansion-104448fb-5e7a-4965-9782-2f5ee5582231": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.242956871s
STEP: Saw pod success
Sep 21 15:09:58.955: INFO: Pod "var-expansion-104448fb-5e7a-4965-9782-2f5ee5582231" satisfied condition "success or failure"
Sep 21 15:09:58.965: INFO: Trying to get logs from node 10.189.39.107 pod var-expansion-104448fb-5e7a-4965-9782-2f5ee5582231 container dapi-container: <nil>
STEP: delete the pod
Sep 21 15:09:59.034: INFO: Waiting for pod var-expansion-104448fb-5e7a-4965-9782-2f5ee5582231 to disappear
Sep 21 15:09:59.042: INFO: Pod var-expansion-104448fb-5e7a-4965-9782-2f5ee5582231 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:09:59.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5199" for this suite.
Sep 21 15:10:05.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:10:05.432: INFO: namespace var-expansion-5199 deletion completed in 6.375618664s

• [SLOW TEST:10.991 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:10:05.432: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:10:16.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7264" for this suite.
Sep 21 15:10:22.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:10:23.153: INFO: namespace resourcequota-7264 deletion completed in 6.344747057s

• [SLOW TEST:17.721 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:10:23.154: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4125
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 21 15:10:23.415: INFO: Waiting up to 5m0s for pod "pod-c205c67e-1ae7-4325-ad13-4328e3c036c1" in namespace "emptydir-4125" to be "success or failure"
Sep 21 15:10:23.425: INFO: Pod "pod-c205c67e-1ae7-4325-ad13-4328e3c036c1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.118409ms
Sep 21 15:10:25.434: INFO: Pod "pod-c205c67e-1ae7-4325-ad13-4328e3c036c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018912128s
STEP: Saw pod success
Sep 21 15:10:25.434: INFO: Pod "pod-c205c67e-1ae7-4325-ad13-4328e3c036c1" satisfied condition "success or failure"
Sep 21 15:10:25.442: INFO: Trying to get logs from node 10.189.39.114 pod pod-c205c67e-1ae7-4325-ad13-4328e3c036c1 container test-container: <nil>
STEP: delete the pod
Sep 21 15:10:25.524: INFO: Waiting for pod pod-c205c67e-1ae7-4325-ad13-4328e3c036c1 to disappear
Sep 21 15:10:25.531: INFO: Pod pod-c205c67e-1ae7-4325-ad13-4328e3c036c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:10:25.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4125" for this suite.
Sep 21 15:10:31.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:10:31.956: INFO: namespace emptydir-4125 deletion completed in 6.408821668s

• [SLOW TEST:8.802 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:10:31.959: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8325
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8325
STEP: Creating statefulset with conflicting port in namespace statefulset-8325
STEP: Waiting until pod test-pod will start running in namespace statefulset-8325
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8325
Sep 21 15:10:36.275: INFO: Observed stateful pod in namespace: statefulset-8325, name: ss-0, uid: 3fe42901-988a-4da9-b96d-39cda4f3283c, status phase: Pending. Waiting for statefulset controller to delete.
Sep 21 15:10:36.365: INFO: Observed stateful pod in namespace: statefulset-8325, name: ss-0, uid: 3fe42901-988a-4da9-b96d-39cda4f3283c, status phase: Failed. Waiting for statefulset controller to delete.
Sep 21 15:10:36.383: INFO: Observed stateful pod in namespace: statefulset-8325, name: ss-0, uid: 3fe42901-988a-4da9-b96d-39cda4f3283c, status phase: Failed. Waiting for statefulset controller to delete.
Sep 21 15:10:36.391: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8325
STEP: Removing pod with conflicting port in namespace statefulset-8325
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8325 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 21 15:10:38.435: INFO: Deleting all statefulset in ns statefulset-8325
Sep 21 15:10:38.444: INFO: Scaling statefulset ss to 0
Sep 21 15:10:48.482: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 15:10:48.490: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:10:48.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8325" for this suite.
Sep 21 15:10:56.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:10:56.887: INFO: namespace statefulset-8325 deletion completed in 8.341530768s

• [SLOW TEST:24.928 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:10:56.887: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8238
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 21 15:11:00.199: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:11:00.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8238" for this suite.
Sep 21 15:11:06.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:11:06.575: INFO: namespace container-runtime-8238 deletion completed in 6.326690601s

• [SLOW TEST:9.688 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:11:06.575: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2700
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Sep 21 15:11:06.840: INFO: Waiting up to 5m0s for pod "var-expansion-aa8d093b-5119-4321-9535-ee32a378bce6" in namespace "var-expansion-2700" to be "success or failure"
Sep 21 15:11:06.848: INFO: Pod "var-expansion-aa8d093b-5119-4321-9535-ee32a378bce6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.39525ms
Sep 21 15:11:08.860: INFO: Pod "var-expansion-aa8d093b-5119-4321-9535-ee32a378bce6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019703741s
Sep 21 15:11:10.871: INFO: Pod "var-expansion-aa8d093b-5119-4321-9535-ee32a378bce6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03065272s
STEP: Saw pod success
Sep 21 15:11:10.871: INFO: Pod "var-expansion-aa8d093b-5119-4321-9535-ee32a378bce6" satisfied condition "success or failure"
Sep 21 15:11:10.879: INFO: Trying to get logs from node 10.189.39.107 pod var-expansion-aa8d093b-5119-4321-9535-ee32a378bce6 container dapi-container: <nil>
STEP: delete the pod
Sep 21 15:11:10.931: INFO: Waiting for pod var-expansion-aa8d093b-5119-4321-9535-ee32a378bce6 to disappear
Sep 21 15:11:10.942: INFO: Pod var-expansion-aa8d093b-5119-4321-9535-ee32a378bce6 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:11:10.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2700" for this suite.
Sep 21 15:11:16.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:11:17.285: INFO: namespace var-expansion-2700 deletion completed in 6.330199591s

• [SLOW TEST:10.710 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:11:17.286: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9146
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:11:17.533: INFO: Creating ReplicaSet my-hostname-basic-ffdef5d2-9bd5-40df-a87c-b13c34d10b27
Sep 21 15:11:17.550: INFO: Pod name my-hostname-basic-ffdef5d2-9bd5-40df-a87c-b13c34d10b27: Found 0 pods out of 1
Sep 21 15:11:22.561: INFO: Pod name my-hostname-basic-ffdef5d2-9bd5-40df-a87c-b13c34d10b27: Found 1 pods out of 1
Sep 21 15:11:22.561: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-ffdef5d2-9bd5-40df-a87c-b13c34d10b27" is running
Sep 21 15:11:22.570: INFO: Pod "my-hostname-basic-ffdef5d2-9bd5-40df-a87c-b13c34d10b27-r5fr7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-21 15:11:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-21 15:11:19 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-21 15:11:19 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-21 15:11:17 +0000 UTC Reason: Message:}])
Sep 21 15:11:22.570: INFO: Trying to dial the pod
Sep 21 15:11:27.608: INFO: Controller my-hostname-basic-ffdef5d2-9bd5-40df-a87c-b13c34d10b27: Got expected result from replica 1 [my-hostname-basic-ffdef5d2-9bd5-40df-a87c-b13c34d10b27-r5fr7]: "my-hostname-basic-ffdef5d2-9bd5-40df-a87c-b13c34d10b27-r5fr7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:11:27.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9146" for this suite.
Sep 21 15:11:33.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:11:33.957: INFO: namespace replicaset-9146 deletion completed in 6.33669633s

• [SLOW TEST:16.672 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:11:33.958: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 21 15:11:38.337: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 21 15:11:38.347: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 21 15:11:40.347: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 21 15:11:40.356: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 21 15:11:42.347: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 21 15:11:42.357: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 21 15:11:44.347: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 21 15:11:44.357: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:11:44.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5622" for this suite.
Sep 21 15:11:56.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:11:56.709: INFO: namespace container-lifecycle-hook-5622 deletion completed in 12.339385129s

• [SLOW TEST:22.752 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:11:56.710: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 21 15:11:59.536: INFO: Successfully updated pod "pod-update-705badf8-8a88-4c89-981d-5dc8e1015b88"
STEP: verifying the updated pod is in kubernetes
Sep 21 15:11:59.552: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:11:59.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-271" for this suite.
Sep 21 15:12:29.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:12:29.906: INFO: namespace pods-271 deletion completed in 30.338980205s

• [SLOW TEST:33.196 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:12:29.906: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2476
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 21 15:12:30.166: INFO: Waiting up to 5m0s for pod "pod-8f130e45-e3d2-449f-a59f-086096cda3b4" in namespace "emptydir-2476" to be "success or failure"
Sep 21 15:12:30.175: INFO: Pod "pod-8f130e45-e3d2-449f-a59f-086096cda3b4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.780578ms
Sep 21 15:12:32.185: INFO: Pod "pod-8f130e45-e3d2-449f-a59f-086096cda3b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018983518s
STEP: Saw pod success
Sep 21 15:12:32.185: INFO: Pod "pod-8f130e45-e3d2-449f-a59f-086096cda3b4" satisfied condition "success or failure"
Sep 21 15:12:32.195: INFO: Trying to get logs from node 10.189.39.109 pod pod-8f130e45-e3d2-449f-a59f-086096cda3b4 container test-container: <nil>
STEP: delete the pod
Sep 21 15:12:32.242: INFO: Waiting for pod pod-8f130e45-e3d2-449f-a59f-086096cda3b4 to disappear
Sep 21 15:12:32.250: INFO: Pod pod-8f130e45-e3d2-449f-a59f-086096cda3b4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:12:32.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2476" for this suite.
Sep 21 15:12:38.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:12:38.630: INFO: namespace emptydir-2476 deletion completed in 6.367300504s

• [SLOW TEST:8.723 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:12:38.630: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3523
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 15:12:39.181: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 15:12:41.206: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736297959, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736297959, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736297959, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736297959, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 15:12:44.238: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:12:44.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3523" for this suite.
Sep 21 15:12:50.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:12:50.613: INFO: namespace webhook-3523 deletion completed in 6.341184496s
STEP: Destroying namespace "webhook-3523-markers" for this suite.
Sep 21 15:12:56.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:12:56.967: INFO: namespace webhook-3523-markers deletion completed in 6.353811343s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.385 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:12:57.017: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2411
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Sep 21 15:12:59.873: INFO: Successfully updated pod "labelsupdated2792be0-8289-46ab-98e4-98aaa9c97954"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:13:01.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2411" for this suite.
Sep 21 15:13:31.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:13:32.341: INFO: namespace downward-api-2411 deletion completed in 30.403955577s

• [SLOW TEST:35.325 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:13:32.341: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-b45c224e-1bfb-4f2a-ac24-96bd070f24b4 in namespace container-probe-3363
Sep 21 15:13:36.629: INFO: Started pod busybox-b45c224e-1bfb-4f2a-ac24-96bd070f24b4 in namespace container-probe-3363
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 15:13:36.637: INFO: Initial restart count of pod busybox-b45c224e-1bfb-4f2a-ac24-96bd070f24b4 is 0
Sep 21 15:14:22.884: INFO: Restart count of pod container-probe-3363/busybox-b45c224e-1bfb-4f2a-ac24-96bd070f24b4 is now 1 (46.246182286s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:14:22.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3363" for this suite.
Sep 21 15:14:28.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:14:29.271: INFO: namespace container-probe-3363 deletion completed in 6.34575678s

• [SLOW TEST:56.930 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:14:29.272: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2709
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Sep 21 15:14:39.599: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0921 15:14:39.599441      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:14:39.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2709" for this suite.
Sep 21 15:14:45.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:14:46.003: INFO: namespace gc-2709 deletion completed in 6.388684466s

• [SLOW TEST:16.732 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:14:46.004: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-rn52
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 15:14:46.294: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rn52" in namespace "subpath-8004" to be "success or failure"
Sep 21 15:14:46.302: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Pending", Reason="", readiness=false. Elapsed: 8.111694ms
Sep 21 15:14:48.311: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 2.016521717s
Sep 21 15:14:50.320: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 4.026323251s
Sep 21 15:14:52.330: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 6.035644279s
Sep 21 15:14:54.339: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 8.045249458s
Sep 21 15:14:56.348: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 10.053954671s
Sep 21 15:14:58.358: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 12.063574014s
Sep 21 15:15:00.368: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 14.073873445s
Sep 21 15:15:02.379: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 16.08470345s
Sep 21 15:15:04.388: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 18.094232746s
Sep 21 15:15:06.399: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Running", Reason="", readiness=true. Elapsed: 20.105276929s
Sep 21 15:15:08.409: INFO: Pod "pod-subpath-test-configmap-rn52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.115281599s
STEP: Saw pod success
Sep 21 15:15:08.409: INFO: Pod "pod-subpath-test-configmap-rn52" satisfied condition "success or failure"
Sep 21 15:15:08.418: INFO: Trying to get logs from node 10.189.39.114 pod pod-subpath-test-configmap-rn52 container test-container-subpath-configmap-rn52: <nil>
STEP: delete the pod
Sep 21 15:15:08.476: INFO: Waiting for pod pod-subpath-test-configmap-rn52 to disappear
Sep 21 15:15:08.483: INFO: Pod pod-subpath-test-configmap-rn52 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rn52
Sep 21 15:15:08.483: INFO: Deleting pod "pod-subpath-test-configmap-rn52" in namespace "subpath-8004"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:15:08.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8004" for this suite.
Sep 21 15:15:14.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:15:14.868: INFO: namespace subpath-8004 deletion completed in 6.360119431s

• [SLOW TEST:28.865 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:15:14.869: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Sep 21 15:15:15.125: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-744630836 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:15:15.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8643" for this suite.
Sep 21 15:15:21.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:15:21.537: INFO: namespace kubectl-8643 deletion completed in 6.322249274s

• [SLOW TEST:6.669 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:15:21.538: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9169
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:15:21.811: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 21 15:15:25.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-9169 create -f -'
Sep 21 15:15:25.797: INFO: stderr: ""
Sep 21 15:15:25.797: INFO: stdout: "e2e-test-crd-publish-openapi-8871-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 21 15:15:25.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-9169 delete e2e-test-crd-publish-openapi-8871-crds test-cr'
Sep 21 15:15:25.974: INFO: stderr: ""
Sep 21 15:15:25.974: INFO: stdout: "e2e-test-crd-publish-openapi-8871-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Sep 21 15:15:25.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-9169 apply -f -'
Sep 21 15:15:26.275: INFO: stderr: ""
Sep 21 15:15:26.275: INFO: stdout: "e2e-test-crd-publish-openapi-8871-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 21 15:15:26.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-9169 delete e2e-test-crd-publish-openapi-8871-crds test-cr'
Sep 21 15:15:26.382: INFO: stderr: ""
Sep 21 15:15:26.382: INFO: stdout: "e2e-test-crd-publish-openapi-8871-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 21 15:15:26.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 explain e2e-test-crd-publish-openapi-8871-crds'
Sep 21 15:15:26.695: INFO: stderr: ""
Sep 21 15:15:26.695: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8871-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:15:30.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9169" for this suite.
Sep 21 15:15:36.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:15:36.544: INFO: namespace crd-publish-openapi-9169 deletion completed in 6.332525816s

• [SLOW TEST:15.006 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:15:36.545: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8937
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 21 15:15:36.809: INFO: Waiting up to 5m0s for pod "downward-api-bdef48b0-eaa4-40f5-9845-c59b68e3b572" in namespace "downward-api-8937" to be "success or failure"
Sep 21 15:15:36.818: INFO: Pod "downward-api-bdef48b0-eaa4-40f5-9845-c59b68e3b572": Phase="Pending", Reason="", readiness=false. Elapsed: 8.689257ms
Sep 21 15:15:38.829: INFO: Pod "downward-api-bdef48b0-eaa4-40f5-9845-c59b68e3b572": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019487242s
Sep 21 15:15:40.838: INFO: Pod "downward-api-bdef48b0-eaa4-40f5-9845-c59b68e3b572": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02839437s
STEP: Saw pod success
Sep 21 15:15:40.838: INFO: Pod "downward-api-bdef48b0-eaa4-40f5-9845-c59b68e3b572" satisfied condition "success or failure"
Sep 21 15:15:40.847: INFO: Trying to get logs from node 10.189.39.114 pod downward-api-bdef48b0-eaa4-40f5-9845-c59b68e3b572 container dapi-container: <nil>
STEP: delete the pod
Sep 21 15:15:40.904: INFO: Waiting for pod downward-api-bdef48b0-eaa4-40f5-9845-c59b68e3b572 to disappear
Sep 21 15:15:40.917: INFO: Pod downward-api-bdef48b0-eaa4-40f5-9845-c59b68e3b572 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:15:40.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8937" for this suite.
Sep 21 15:15:46.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:15:47.313: INFO: namespace downward-api-8937 deletion completed in 6.381953465s

• [SLOW TEST:10.768 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:15:47.313: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:15:49.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6641" for this suite.
Sep 21 15:16:35.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:16:35.995: INFO: namespace kubelet-test-6641 deletion completed in 46.331651533s

• [SLOW TEST:48.682 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:16:35.996: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3193
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-5cbd27f7-9237-4d59-ba18-14083fa9c802
STEP: Creating secret with name s-test-opt-upd-f1116bf8-907a-40aa-af79-2f7ccd65c731
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5cbd27f7-9237-4d59-ba18-14083fa9c802
STEP: Updating secret s-test-opt-upd-f1116bf8-907a-40aa-af79-2f7ccd65c731
STEP: Creating secret with name s-test-opt-create-44e494a2-d459-4336-a24b-6ece1b276e24
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:18:05.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3193" for this suite.
Sep 21 15:18:17.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:18:17.931: INFO: namespace secrets-3193 deletion completed in 12.354048603s

• [SLOW TEST:101.936 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:18:17.932: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 21 15:18:18.226: INFO: Waiting up to 5m0s for pod "downward-api-968a5470-c8f7-4670-8a23-df57011b2c08" in namespace "downward-api-5691" to be "success or failure"
Sep 21 15:18:18.237: INFO: Pod "downward-api-968a5470-c8f7-4670-8a23-df57011b2c08": Phase="Pending", Reason="", readiness=false. Elapsed: 11.70493ms
Sep 21 15:18:20.253: INFO: Pod "downward-api-968a5470-c8f7-4670-8a23-df57011b2c08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027402764s
STEP: Saw pod success
Sep 21 15:18:20.253: INFO: Pod "downward-api-968a5470-c8f7-4670-8a23-df57011b2c08" satisfied condition "success or failure"
Sep 21 15:18:20.261: INFO: Trying to get logs from node 10.189.39.114 pod downward-api-968a5470-c8f7-4670-8a23-df57011b2c08 container dapi-container: <nil>
STEP: delete the pod
Sep 21 15:18:20.331: INFO: Waiting for pod downward-api-968a5470-c8f7-4670-8a23-df57011b2c08 to disappear
Sep 21 15:18:20.339: INFO: Pod downward-api-968a5470-c8f7-4670-8a23-df57011b2c08 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:18:20.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5691" for this suite.
Sep 21 15:18:26.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:18:26.706: INFO: namespace downward-api-5691 deletion completed in 6.35145457s

• [SLOW TEST:8.775 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:18:26.707: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:18:26.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-8480'
Sep 21 15:18:27.270: INFO: stderr: ""
Sep 21 15:18:27.270: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep 21 15:18:27.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-8480'
Sep 21 15:18:27.461: INFO: stderr: ""
Sep 21 15:18:27.461: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 21 15:18:28.471: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 15:18:28.471: INFO: Found 0 / 1
Sep 21 15:18:29.471: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 15:18:29.471: INFO: Found 1 / 1
Sep 21 15:18:29.471: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 21 15:18:29.480: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 15:18:29.480: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 21 15:18:29.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 describe pod redis-master-tx946 --namespace=kubectl-8480'
Sep 21 15:18:29.585: INFO: stderr: ""
Sep 21 15:18:29.585: INFO: stdout: "Name:         redis-master-tx946\nNamespace:    kubectl-8480\nPriority:     0\nNode:         10.189.39.114/10.189.39.114\nStart Time:   Mon, 21 Sep 2020 15:18:27 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           172.30.21.6\nIPs:\n  IP:           172.30.21.6\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://a2ccf63e0229ff91fc245b3401b81c07122cf42441fde8ab3d99981fc9168293\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 21 Sep 2020 15:18:28 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-bskkw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-bskkw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-bskkw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  2s    default-scheduler       Successfully assigned kubectl-8480/redis-master-tx946 to 10.189.39.114\n  Normal  Pulled     1s    kubelet, 10.189.39.114  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, 10.189.39.114  Created container redis-master\n  Normal  Started    1s    kubelet, 10.189.39.114  Started container redis-master\n"
Sep 21 15:18:29.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 describe rc redis-master --namespace=kubectl-8480'
Sep 21 15:18:29.714: INFO: stderr: ""
Sep 21 15:18:29.714: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8480\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-tx946\n"
Sep 21 15:18:29.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 describe service redis-master --namespace=kubectl-8480'
Sep 21 15:18:29.835: INFO: stderr: ""
Sep 21 15:18:29.835: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8480\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.245.243\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.21.6:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 21 15:18:29.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 describe node 10.189.39.107'
Sep 21 15:18:29.970: INFO: stderr: ""
Sep 21 15:18:29.970: INFO: stdout: "Name:               10.189.39.107\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc06\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.60.73.248\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.189.39.107\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-east\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-btka5icw0n6mlk4u6bag-kubee2epvgl-default-00000218\n                    ibm-cloud.kubernetes.io/worker-pool-id=btka5icw0n6mlk4u6bag-96bac49\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.16.14_1546\n                    ibm-cloud.kubernetes.io/zone=wdc06\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.189.39.107\n                    kubernetes.io/os=linux\n                    privateVLAN=2722950\n                    publicVLAN=2722948\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 21 Sep 2020 13:11:00 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 21 Sep 2020 15:17:30 +0000   Mon, 21 Sep 2020 13:11:00 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 21 Sep 2020 15:17:30 +0000   Mon, 21 Sep 2020 13:11:00 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 21 Sep 2020 15:17:30 +0000   Mon, 21 Sep 2020 13:11:00 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 21 Sep 2020 15:17:30 +0000   Mon, 21 Sep 2020 13:11:10 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.189.39.107\n  ExternalIP:  169.60.73.248\n  Hostname:    10.189.39.107\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419664Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627216Ki\n pods:               110\nSystem Info:\n Machine ID:                 234b7828a74440a2b8224d4a37bd4e4e\n System UUID:                9F1132E1-170B-01CA-0CBE-93731F5E08E4\n Boot ID:                    94d1ad0b-71e2-4a51-88dd-e9ceafc63894\n Kernel Version:             4.15.0-117-generic\n OS Image:                   Ubuntu 18.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.3.4\n Kubelet Version:            v1.16.14+IKS\n Kube-Proxy Version:         v1.16.14+IKS\nProviderID:                  ibm://fee034388aa6435883a1f720010ab3a2///btka5icw0n6mlk4u6bag/kube-btka5icw0n6mlk4u6bag-kubee2epvgl-default-00000218\nNon-terminated Pods:         (16 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  ibm-system                 catalog-operator-67cbc5d959-dq2t6                          10m (0%)      0 (0%)      80Mi (0%)        0 (0%)         130m\n  ibm-system                 olm-operator-6f74dfc868-pmh8h                              10m (0%)      0 (0%)      160Mi (1%)       0 (0%)         130m\n  kube-system                calico-kube-controllers-66c5f69b5f-cbmg6                   10m (0%)      0 (0%)      25Mi (0%)        3Gi (23%)      132m\n  kube-system                calico-node-bsqdv                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         127m\n  kube-system                coredns-55db5d97fb-x5w82                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     117m\n  kube-system                coredns-autoscaler-65c89858bf-nbnlc                        20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         132m\n  kube-system                dashboard-metrics-scraper-76756886dc-mkkzv                 1m (0%)       0 (0%)      10Mi (0%)        0 (0%)         130m\n  kube-system                ibm-file-plugin-75656db994-jw4r2                           50m (1%)      200m (5%)   100Mi (0%)       200Mi (1%)     131m\n  kube-system                ibm-keepalived-watcher-zkkcm                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         127m\n  kube-system                ibm-master-proxy-static-10.189.39.107                      25m (0%)      300m (7%)   32M (0%)         512M (3%)      126m\n  kube-system                ibm-storage-watcher-69664bb666-tt4h6                       50m (1%)      200m (5%)   100Mi (0%)       200Mi (1%)     131m\n  kube-system                kubernetes-dashboard-5977b5969-2nxvq                       50m (1%)      0 (0%)      100Mi (0%)       0 (0%)         130m\n  kube-system                metrics-server-c86549c5-x7xfd                              121m (3%)     216m (5%)   186Mi (1%)       436Mi (3%)     127m\n  kube-system                vpn-79845b6f9d-jkrfr                                       5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         118m\n  sonobuoy                   sonobuoy-e2e-job-6e9ba11f9ded426e                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pk8wt    0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                707m (18%)     916m (23%)\n  memory             989714Ki (7%)  4911392Ki (36%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Sep 21 15:18:29.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 describe namespace kubectl-8480'
Sep 21 15:18:30.084: INFO: stderr: ""
Sep 21 15:18:30.084: INFO: stdout: "Name:         kubectl-8480\nLabels:       e2e-framework=kubectl\n              e2e-run=b424c022-bf08-4981-a82e-57e78d0887a2\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:18:30.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8480" for this suite.
Sep 21 15:18:58.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:18:58.443: INFO: namespace kubectl-8480 deletion completed in 28.342662669s

• [SLOW TEST:31.736 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:18:58.443: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4105
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-4105
Sep 21 15:18:58.735: INFO: Found 0 stateful pods, waiting for 1
Sep 21 15:19:08.746: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 21 15:19:08.815: INFO: Deleting all statefulset in ns statefulset-4105
Sep 21 15:19:08.825: INFO: Scaling statefulset ss to 0
Sep 21 15:19:28.883: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 15:19:28.893: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:19:28.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4105" for this suite.
Sep 21 15:19:36.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:19:37.325: INFO: namespace statefulset-4105 deletion completed in 8.381678331s

• [SLOW TEST:38.882 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:19:37.325: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7000
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:19:37.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 version'
Sep 21 15:19:37.639: INFO: stderr: ""
Sep 21 15:19:37.639: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.15\", GitCommit:\"2adc8d7091e89b6e3ca8d048140618ec89b39369\", GitTreeState:\"clean\", BuildDate:\"2020-09-02T11:40:00Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.15+IKS\", GitCommit:\"a7ace239946d71c9305593eacf74b9a9efa25e3b\", GitTreeState:\"clean\", BuildDate:\"2020-09-09T00:11:53Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:19:37.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7000" for this suite.
Sep 21 15:19:43.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:19:43.981: INFO: namespace kubectl-7000 deletion completed in 6.319514636s

• [SLOW TEST:6.656 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:19:43.981: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-04d84c1a-607c-4b69-a7b7-ee4547d7dd94
STEP: Creating a pod to test consume configMaps
Sep 21 15:19:44.257: INFO: Waiting up to 5m0s for pod "pod-configmaps-90a4fad2-c6c3-45c5-aa10-c6d15b1eb222" in namespace "configmap-5813" to be "success or failure"
Sep 21 15:19:44.268: INFO: Pod "pod-configmaps-90a4fad2-c6c3-45c5-aa10-c6d15b1eb222": Phase="Pending", Reason="", readiness=false. Elapsed: 10.989919ms
Sep 21 15:19:46.277: INFO: Pod "pod-configmaps-90a4fad2-c6c3-45c5-aa10-c6d15b1eb222": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019763955s
STEP: Saw pod success
Sep 21 15:19:46.277: INFO: Pod "pod-configmaps-90a4fad2-c6c3-45c5-aa10-c6d15b1eb222" satisfied condition "success or failure"
Sep 21 15:19:46.285: INFO: Trying to get logs from node 10.189.39.107 pod pod-configmaps-90a4fad2-c6c3-45c5-aa10-c6d15b1eb222 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 15:19:46.346: INFO: Waiting for pod pod-configmaps-90a4fad2-c6c3-45c5-aa10-c6d15b1eb222 to disappear
Sep 21 15:19:46.354: INFO: Pod pod-configmaps-90a4fad2-c6c3-45c5-aa10-c6d15b1eb222 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:19:46.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5813" for this suite.
Sep 21 15:19:52.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:19:52.709: INFO: namespace configmap-5813 deletion completed in 6.334033811s

• [SLOW TEST:8.727 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:19:52.709: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2031
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-2031/configmap-test-2cf23e2d-6ab3-4cbf-a461-f272ce774132
STEP: Creating a pod to test consume configMaps
Sep 21 15:19:52.972: INFO: Waiting up to 5m0s for pod "pod-configmaps-1808a7ad-fd00-411d-a1ab-194499b6ee05" in namespace "configmap-2031" to be "success or failure"
Sep 21 15:19:52.987: INFO: Pod "pod-configmaps-1808a7ad-fd00-411d-a1ab-194499b6ee05": Phase="Pending", Reason="", readiness=false. Elapsed: 15.178773ms
Sep 21 15:19:54.996: INFO: Pod "pod-configmaps-1808a7ad-fd00-411d-a1ab-194499b6ee05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023652396s
STEP: Saw pod success
Sep 21 15:19:54.996: INFO: Pod "pod-configmaps-1808a7ad-fd00-411d-a1ab-194499b6ee05" satisfied condition "success or failure"
Sep 21 15:19:55.004: INFO: Trying to get logs from node 10.189.39.114 pod pod-configmaps-1808a7ad-fd00-411d-a1ab-194499b6ee05 container env-test: <nil>
STEP: delete the pod
Sep 21 15:19:55.077: INFO: Waiting for pod pod-configmaps-1808a7ad-fd00-411d-a1ab-194499b6ee05 to disappear
Sep 21 15:19:55.084: INFO: Pod pod-configmaps-1808a7ad-fd00-411d-a1ab-194499b6ee05 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:19:55.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2031" for this suite.
Sep 21 15:20:02.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:20:03.571: INFO: namespace configmap-2031 deletion completed in 8.473048395s

• [SLOW TEST:10.862 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:20:03.572: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6452
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-grx9
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 15:20:03.865: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-grx9" in namespace "subpath-6452" to be "success or failure"
Sep 21 15:20:03.874: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.302056ms
Sep 21 15:20:05.884: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 2.018527644s
Sep 21 15:20:07.894: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 4.02841732s
Sep 21 15:20:09.903: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 6.037811279s
Sep 21 15:20:11.914: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 8.048220303s
Sep 21 15:20:13.929: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 10.063530854s
Sep 21 15:20:15.941: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 12.07540355s
Sep 21 15:20:17.950: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 14.084598319s
Sep 21 15:20:19.960: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 16.094195958s
Sep 21 15:20:21.970: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 18.104103171s
Sep 21 15:20:23.979: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 20.113330293s
Sep 21 15:20:25.990: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Running", Reason="", readiness=true. Elapsed: 22.124056787s
Sep 21 15:20:27.999: INFO: Pod "pod-subpath-test-configmap-grx9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.133445369s
STEP: Saw pod success
Sep 21 15:20:27.999: INFO: Pod "pod-subpath-test-configmap-grx9" satisfied condition "success or failure"
Sep 21 15:20:28.009: INFO: Trying to get logs from node 10.189.39.107 pod pod-subpath-test-configmap-grx9 container test-container-subpath-configmap-grx9: <nil>
STEP: delete the pod
Sep 21 15:20:28.058: INFO: Waiting for pod pod-subpath-test-configmap-grx9 to disappear
Sep 21 15:20:28.066: INFO: Pod pod-subpath-test-configmap-grx9 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-grx9
Sep 21 15:20:28.066: INFO: Deleting pod "pod-subpath-test-configmap-grx9" in namespace "subpath-6452"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:20:28.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6452" for this suite.
Sep 21 15:20:34.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:20:34.422: INFO: namespace subpath-6452 deletion completed in 6.330637224s

• [SLOW TEST:30.850 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:20:34.424: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-624
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:20:34.680: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-3e9df71b-4381-41c0-ae97-b9c1c56a623e" in namespace "security-context-test-624" to be "success or failure"
Sep 21 15:20:34.690: INFO: Pod "alpine-nnp-false-3e9df71b-4381-41c0-ae97-b9c1c56a623e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.119544ms
Sep 21 15:20:36.699: INFO: Pod "alpine-nnp-false-3e9df71b-4381-41c0-ae97-b9c1c56a623e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019261828s
Sep 21 15:20:38.709: INFO: Pod "alpine-nnp-false-3e9df71b-4381-41c0-ae97-b9c1c56a623e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029447512s
Sep 21 15:20:38.709: INFO: Pod "alpine-nnp-false-3e9df71b-4381-41c0-ae97-b9c1c56a623e" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:20:38.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-624" for this suite.
Sep 21 15:20:44.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:20:45.093: INFO: namespace security-context-test-624 deletion completed in 6.347737281s

• [SLOW TEST:10.670 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:20:45.094: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3913
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Sep 21 15:20:45.333: INFO: namespace kubectl-3913
Sep 21 15:20:45.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-3913'
Sep 21 15:20:45.513: INFO: stderr: ""
Sep 21 15:20:45.513: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 21 15:20:46.522: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 15:20:46.522: INFO: Found 0 / 1
Sep 21 15:20:47.523: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 15:20:47.523: INFO: Found 0 / 1
Sep 21 15:20:48.534: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 15:20:48.534: INFO: Found 1 / 1
Sep 21 15:20:48.534: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 21 15:20:48.544: INFO: Selector matched 1 pods for map[app:redis]
Sep 21 15:20:48.544: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 21 15:20:48.544: INFO: wait on redis-master startup in kubectl-3913 
Sep 21 15:20:48.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 logs redis-master-8wndn redis-master --namespace=kubectl-3913'
Sep 21 15:20:48.667: INFO: stderr: ""
Sep 21 15:20:48.667: INFO: stdout: "1:C 21 Sep 2020 15:20:47.606 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 21 Sep 2020 15:20:47.607 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 21 Sep 2020 15:20:47.607 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 21 Sep 2020 15:20:47.608 * Running mode=standalone, port=6379.\n1:M 21 Sep 2020 15:20:47.608 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Sep 2020 15:20:47.608 # Server initialized\n1:M 21 Sep 2020 15:20:47.608 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Sep 2020 15:20:47.608 * Ready to accept connections\n"
STEP: exposing RC
Sep 21 15:20:48.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3913'
Sep 21 15:20:48.778: INFO: stderr: ""
Sep 21 15:20:48.778: INFO: stdout: "service/rm2 exposed\n"
Sep 21 15:20:48.787: INFO: Service rm2 in namespace kubectl-3913 found.
STEP: exposing service
Sep 21 15:20:50.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3913'
Sep 21 15:20:50.934: INFO: stderr: ""
Sep 21 15:20:50.934: INFO: stdout: "service/rm3 exposed\n"
Sep 21 15:20:50.943: INFO: Service rm3 in namespace kubectl-3913 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:20:52.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3913" for this suite.
Sep 21 15:21:05.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:21:05.336: INFO: namespace kubectl-3913 deletion completed in 12.35493064s

• [SLOW TEST:20.243 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:21:05.336: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 21 15:21:05.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-5791'
Sep 21 15:21:05.705: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 21 15:21:05.705: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Sep 21 15:21:05.717: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Sep 21 15:21:05.724: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep 21 15:21:05.733: INFO: scanned /root for discovery docs: <nil>
Sep 21 15:21:05.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-5791'
Sep 21 15:21:21.637: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 21 15:21:21.637: INFO: stdout: "Created e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521\nScaling up e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Sep 21 15:21:21.637: INFO: stdout: "Created e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521\nScaling up e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Sep 21 15:21:21.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-5791'
Sep 21 15:21:21.720: INFO: stderr: ""
Sep 21 15:21:21.720: INFO: stdout: "e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521-qxkgr "
Sep 21 15:21:21.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521-qxkgr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5791'
Sep 21 15:21:21.790: INFO: stderr: ""
Sep 21 15:21:21.790: INFO: stdout: "true"
Sep 21 15:21:21.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521-qxkgr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5791'
Sep 21 15:21:21.859: INFO: stderr: ""
Sep 21 15:21:21.859: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Sep 21 15:21:21.859: INFO: e2e-test-httpd-rc-967de8362a16a0ee9bf493ecee7ff521-qxkgr is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Sep 21 15:21:21.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete rc e2e-test-httpd-rc --namespace=kubectl-5791'
Sep 21 15:21:21.956: INFO: stderr: ""
Sep 21 15:21:21.956: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:21:21.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5791" for this suite.
Sep 21 15:21:34.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:21:34.335: INFO: namespace kubectl-5791 deletion completed in 12.356235756s

• [SLOW TEST:28.999 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:21:34.337: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8128
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:21:34.577: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 21 15:21:37.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-8128 create -f -'
Sep 21 15:21:37.891: INFO: stderr: ""
Sep 21 15:21:37.891: INFO: stdout: "e2e-test-crd-publish-openapi-8906-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 21 15:21:37.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-8128 delete e2e-test-crd-publish-openapi-8906-crds test-cr'
Sep 21 15:21:37.987: INFO: stderr: ""
Sep 21 15:21:37.987: INFO: stdout: "e2e-test-crd-publish-openapi-8906-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Sep 21 15:21:37.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-8128 apply -f -'
Sep 21 15:21:38.409: INFO: stderr: ""
Sep 21 15:21:38.410: INFO: stdout: "e2e-test-crd-publish-openapi-8906-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 21 15:21:38.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-8128 delete e2e-test-crd-publish-openapi-8906-crds test-cr'
Sep 21 15:21:38.510: INFO: stderr: ""
Sep 21 15:21:38.510: INFO: stdout: "e2e-test-crd-publish-openapi-8906-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Sep 21 15:21:38.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 explain e2e-test-crd-publish-openapi-8906-crds'
Sep 21 15:21:38.657: INFO: stderr: ""
Sep 21 15:21:38.657: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8906-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:21:41.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8128" for this suite.
Sep 21 15:21:47.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:21:47.997: INFO: namespace crd-publish-openapi-8128 deletion completed in 6.341607139s

• [SLOW TEST:13.661 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:21:47.999: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2296
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:21:48.289: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"72bca49c-9cd4-4973-b32e-956c08d082cd", Controller:(*bool)(0xc005d174c6), BlockOwnerDeletion:(*bool)(0xc005d174c7)}}
Sep 21 15:21:48.298: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"061d3124-4083-4a98-a99f-f68c8918cc20", Controller:(*bool)(0xc005bfd5ce), BlockOwnerDeletion:(*bool)(0xc005bfd5cf)}}
Sep 21 15:21:48.308: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"e21b629a-6ecb-4b76-bd31-b08a786a61d0", Controller:(*bool)(0xc005bdf63e), BlockOwnerDeletion:(*bool)(0xc005bdf63f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:21:53.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2296" for this suite.
Sep 21 15:21:59.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:21:59.682: INFO: namespace gc-2296 deletion completed in 6.336312601s

• [SLOW TEST:11.683 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:21:59.682: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9544
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 15:22:00.412: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 15:22:02.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736298520, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736298520, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736298520, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736298520, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 15:22:05.472: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:22:05.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9544" for this suite.
Sep 21 15:22:11.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:22:11.917: INFO: namespace webhook-9544 deletion completed in 6.337684025s
STEP: Destroying namespace "webhook-9544-markers" for this suite.
Sep 21 15:22:17.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:22:18.285: INFO: namespace webhook-9544-markers deletion completed in 6.36770369s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.650 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:22:18.334: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8696
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8696
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8696
STEP: creating replication controller externalsvc in namespace services-8696
I0921 15:22:18.652801      24 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8696, replica count: 2
I0921 15:22:21.703546      24 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Sep 21 15:22:21.760: INFO: Creating new exec pod
Sep 21 15:22:25.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-8696 execpod5kpsb -- /bin/sh -x -c nslookup nodeport-service'
Sep 21 15:22:26.084: INFO: stderr: "+ nslookup nodeport-service\n"
Sep 21 15:22:26.084: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-8696.svc.cluster.local\tcanonical name = externalsvc.services-8696.svc.cluster.local.\nName:\texternalsvc.services-8696.svc.cluster.local\nAddress: 172.21.239.81\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8696, will wait for the garbage collector to delete the pods
Sep 21 15:22:26.164: INFO: Deleting ReplicationController externalsvc took: 18.848941ms
Sep 21 15:22:26.264: INFO: Terminating ReplicationController externalsvc pods took: 100.26106ms
Sep 21 15:22:38.316: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:22:38.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8696" for this suite.
Sep 21 15:22:46.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:22:46.718: INFO: namespace services-8696 deletion completed in 8.352452804s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:28.385 seconds]
[sig-network] Services
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:22:46.720: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4642
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 21 15:22:49.532: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4642 pod-service-account-d4388481-79c1-40fa-83b6-a03e41ae0f7c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 21 15:22:49.734: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4642 pod-service-account-d4388481-79c1-40fa-83b6-a03e41ae0f7c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 21 15:22:49.947: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4642 pod-service-account-d4388481-79c1-40fa-83b6-a03e41ae0f7c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:22:50.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4642" for this suite.
Sep 21 15:22:56.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:22:56.591: INFO: namespace svcaccounts-4642 deletion completed in 6.40122955s

• [SLOW TEST:9.871 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:22:56.591: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 21 15:22:56.851: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 21 15:23:01.862: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:23:02.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5944" for this suite.
Sep 21 15:23:08.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:23:09.260: INFO: namespace replication-controller-5944 deletion completed in 6.345842406s

• [SLOW TEST:12.669 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:23:09.261: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4483
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-305bb6ff-fc7e-4ec9-849f-a5539e3f3c68
STEP: Creating a pod to test consume secrets
Sep 21 15:23:09.537: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bbbc290d-222a-40ff-b466-8d768f9f4c22" in namespace "projected-4483" to be "success or failure"
Sep 21 15:23:09.549: INFO: Pod "pod-projected-secrets-bbbc290d-222a-40ff-b466-8d768f9f4c22": Phase="Pending", Reason="", readiness=false. Elapsed: 12.187351ms
Sep 21 15:23:11.561: INFO: Pod "pod-projected-secrets-bbbc290d-222a-40ff-b466-8d768f9f4c22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023982669s
STEP: Saw pod success
Sep 21 15:23:11.561: INFO: Pod "pod-projected-secrets-bbbc290d-222a-40ff-b466-8d768f9f4c22" satisfied condition "success or failure"
Sep 21 15:23:11.570: INFO: Trying to get logs from node 10.189.39.114 pod pod-projected-secrets-bbbc290d-222a-40ff-b466-8d768f9f4c22 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 15:23:11.640: INFO: Waiting for pod pod-projected-secrets-bbbc290d-222a-40ff-b466-8d768f9f4c22 to disappear
Sep 21 15:23:11.648: INFO: Pod pod-projected-secrets-bbbc290d-222a-40ff-b466-8d768f9f4c22 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:23:11.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4483" for this suite.
Sep 21 15:23:17.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:23:17.990: INFO: namespace projected-4483 deletion completed in 6.328566408s

• [SLOW TEST:8.729 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:23:17.990: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7646
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:23:20.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7646" for this suite.
Sep 21 15:24:10.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:24:10.650: INFO: namespace kubelet-test-7646 deletion completed in 50.345967444s

• [SLOW TEST:52.660 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:24:10.653: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-298
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 21 15:24:10.892: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 21 15:24:37.115: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.21.19:8080/dial?request=hostName&protocol=http&host=172.30.21.14&port=8080&tries=1'] Namespace:pod-network-test-298 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:24:37.115: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:24:37.284: INFO: Waiting for endpoints: map[]
Sep 21 15:24:37.294: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.21.19:8080/dial?request=hostName&protocol=http&host=172.30.195.247&port=8080&tries=1'] Namespace:pod-network-test-298 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:24:37.294: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:24:37.413: INFO: Waiting for endpoints: map[]
Sep 21 15:24:37.422: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.21.19:8080/dial?request=hostName&protocol=http&host=172.30.185.211&port=8080&tries=1'] Namespace:pod-network-test-298 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:24:37.422: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:24:37.563: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:24:37.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-298" for this suite.
Sep 21 15:24:49.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:24:49.902: INFO: namespace pod-network-test-298 deletion completed in 12.326036172s

• [SLOW TEST:39.249 seconds]
[sig-network] Networking
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:24:49.902: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2545
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Sep 21 15:24:50.160: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:24:53.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2545" for this suite.
Sep 21 15:24:59.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:25:00.086: INFO: namespace init-container-2545 deletion completed in 6.372179065s

• [SLOW TEST:10.183 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:25:00.086: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-79
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Sep 21 15:25:04.970: INFO: Successfully updated pod "annotationupdate047df872-8a13-47b3-9266-65e6470f65c0"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:25:07.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-79" for this suite.
Sep 21 15:25:37.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:25:37.410: INFO: namespace projected-79 deletion completed in 30.361471559s

• [SLOW TEST:37.324 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:25:37.413: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2746
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-913
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:25:44.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8924" for this suite.
Sep 21 15:25:50.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:25:50.589: INFO: namespace namespaces-8924 deletion completed in 6.362721285s
STEP: Destroying namespace "nsdeletetest-2746" for this suite.
Sep 21 15:25:50.599: INFO: Namespace nsdeletetest-2746 was already deleted
STEP: Destroying namespace "nsdeletetest-913" for this suite.
Sep 21 15:25:56.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:25:56.964: INFO: namespace nsdeletetest-913 deletion completed in 6.364620422s

• [SLOW TEST:19.551 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:25:56.965: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2730
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 21 15:25:57.244: INFO: Waiting up to 5m0s for pod "pod-5450a6a8-bace-4d30-a839-f87995c9b7a0" in namespace "emptydir-2730" to be "success or failure"
Sep 21 15:25:57.255: INFO: Pod "pod-5450a6a8-bace-4d30-a839-f87995c9b7a0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.813257ms
Sep 21 15:25:59.265: INFO: Pod "pod-5450a6a8-bace-4d30-a839-f87995c9b7a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020432603s
STEP: Saw pod success
Sep 21 15:25:59.265: INFO: Pod "pod-5450a6a8-bace-4d30-a839-f87995c9b7a0" satisfied condition "success or failure"
Sep 21 15:25:59.274: INFO: Trying to get logs from node 10.189.39.109 pod pod-5450a6a8-bace-4d30-a839-f87995c9b7a0 container test-container: <nil>
STEP: delete the pod
Sep 21 15:25:59.324: INFO: Waiting for pod pod-5450a6a8-bace-4d30-a839-f87995c9b7a0 to disappear
Sep 21 15:25:59.333: INFO: Pod pod-5450a6a8-bace-4d30-a839-f87995c9b7a0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:25:59.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2730" for this suite.
Sep 21 15:26:05.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:26:05.700: INFO: namespace emptydir-2730 deletion completed in 6.348234738s

• [SLOW TEST:8.736 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:26:05.701: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3768
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3768.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3768.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3768.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3768.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3768.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3768.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3768.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3768.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3768.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3768.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 6.157.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.157.6_udp@PTR;check="$$(dig +tcp +noall +answer +search 6.157.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.157.6_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3768.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3768.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3768.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3768.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3768.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3768.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3768.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3768.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3768.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3768.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3768.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 6.157.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.157.6_udp@PTR;check="$$(dig +tcp +noall +answer +search 6.157.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.157.6_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 15:26:10.086: INFO: Unable to read wheezy_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:10.099: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:10.114: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:10.129: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:10.239: INFO: Unable to read jessie_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:10.253: INFO: Unable to read jessie_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:10.268: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:10.283: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:10.383: INFO: Lookups using dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1 failed for: [wheezy_udp@dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_udp@dns-test-service.dns-3768.svc.cluster.local jessie_tcp@dns-test-service.dns-3768.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local]

Sep 21 15:26:15.401: INFO: Unable to read wheezy_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:15.417: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:15.430: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:15.448: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:15.541: INFO: Unable to read jessie_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:15.555: INFO: Unable to read jessie_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:15.570: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:15.582: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:15.680: INFO: Lookups using dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1 failed for: [wheezy_udp@dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_udp@dns-test-service.dns-3768.svc.cluster.local jessie_tcp@dns-test-service.dns-3768.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local]

Sep 21 15:26:20.399: INFO: Unable to read wheezy_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:20.412: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:20.434: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:20.452: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:20.565: INFO: Unable to read jessie_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:20.577: INFO: Unable to read jessie_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:20.591: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:20.612: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:20.711: INFO: Lookups using dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1 failed for: [wheezy_udp@dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_udp@dns-test-service.dns-3768.svc.cluster.local jessie_tcp@dns-test-service.dns-3768.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local]

Sep 21 15:26:25.397: INFO: Unable to read wheezy_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:25.411: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:25.425: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:25.439: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:25.529: INFO: Unable to read jessie_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:25.541: INFO: Unable to read jessie_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:25.554: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:25.569: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:25.649: INFO: Lookups using dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1 failed for: [wheezy_udp@dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_udp@dns-test-service.dns-3768.svc.cluster.local jessie_tcp@dns-test-service.dns-3768.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local]

Sep 21 15:26:30.398: INFO: Unable to read wheezy_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:30.414: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:30.429: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:30.441: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:30.539: INFO: Unable to read jessie_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:30.553: INFO: Unable to read jessie_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:30.566: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:30.583: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:30.660: INFO: Lookups using dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1 failed for: [wheezy_udp@dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_udp@dns-test-service.dns-3768.svc.cluster.local jessie_tcp@dns-test-service.dns-3768.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local]

Sep 21 15:26:35.398: INFO: Unable to read wheezy_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:35.412: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:35.426: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:35.439: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:35.548: INFO: Unable to read jessie_udp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:35.562: INFO: Unable to read jessie_tcp@dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:35.575: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:35.590: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local from pod dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1: the server could not find the requested resource (get pods dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1)
Sep 21 15:26:35.696: INFO: Lookups using dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1 failed for: [wheezy_udp@dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@dns-test-service.dns-3768.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_udp@dns-test-service.dns-3768.svc.cluster.local jessie_tcp@dns-test-service.dns-3768.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3768.svc.cluster.local]

Sep 21 15:26:40.700: INFO: DNS probes using dns-3768/dns-test-509bc4ea-a692-4da6-bc7b-99f26c674ab1 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:26:40.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3768" for this suite.
Sep 21 15:26:46.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:26:47.159: INFO: namespace dns-3768 deletion completed in 6.323748928s

• [SLOW TEST:41.458 seconds]
[sig-network] DNS
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:26:47.160: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7166
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:26:47.427: INFO: Waiting up to 5m0s for pod "downwardapi-volume-74c0f350-85d5-4fa1-883f-2e72ed6ff065" in namespace "projected-7166" to be "success or failure"
Sep 21 15:26:47.451: INFO: Pod "downwardapi-volume-74c0f350-85d5-4fa1-883f-2e72ed6ff065": Phase="Pending", Reason="", readiness=false. Elapsed: 23.674992ms
Sep 21 15:26:49.460: INFO: Pod "downwardapi-volume-74c0f350-85d5-4fa1-883f-2e72ed6ff065": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032437081s
STEP: Saw pod success
Sep 21 15:26:49.460: INFO: Pod "downwardapi-volume-74c0f350-85d5-4fa1-883f-2e72ed6ff065" satisfied condition "success or failure"
Sep 21 15:26:49.467: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-74c0f350-85d5-4fa1-883f-2e72ed6ff065 container client-container: <nil>
STEP: delete the pod
Sep 21 15:26:49.516: INFO: Waiting for pod downwardapi-volume-74c0f350-85d5-4fa1-883f-2e72ed6ff065 to disappear
Sep 21 15:26:49.524: INFO: Pod downwardapi-volume-74c0f350-85d5-4fa1-883f-2e72ed6ff065 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:26:49.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7166" for this suite.
Sep 21 15:26:55.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:26:55.888: INFO: namespace projected-7166 deletion completed in 6.346490166s

• [SLOW TEST:8.728 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:26:55.888: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Sep 21 15:26:58.937: INFO: Successfully updated pod "annotationupdate6f385685-c193-407d-b078-d953fe583087"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:27:00.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9369" for this suite.
Sep 21 15:27:13.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:27:13.338: INFO: namespace downward-api-9369 deletion completed in 12.3367826s

• [SLOW TEST:17.450 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:27:13.339: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7627
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 21 15:27:16.165: INFO: Successfully updated pod "pod-update-activedeadlineseconds-71eca669-e512-44f3-8eda-2831fe2aa4a8"
Sep 21 15:27:16.165: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-71eca669-e512-44f3-8eda-2831fe2aa4a8" in namespace "pods-7627" to be "terminated due to deadline exceeded"
Sep 21 15:27:16.173: INFO: Pod "pod-update-activedeadlineseconds-71eca669-e512-44f3-8eda-2831fe2aa4a8": Phase="Running", Reason="", readiness=true. Elapsed: 7.553539ms
Sep 21 15:27:18.183: INFO: Pod "pod-update-activedeadlineseconds-71eca669-e512-44f3-8eda-2831fe2aa4a8": Phase="Running", Reason="", readiness=true. Elapsed: 2.01767598s
Sep 21 15:27:20.193: INFO: Pod "pod-update-activedeadlineseconds-71eca669-e512-44f3-8eda-2831fe2aa4a8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.027676902s
Sep 21 15:27:20.193: INFO: Pod "pod-update-activedeadlineseconds-71eca669-e512-44f3-8eda-2831fe2aa4a8" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:27:20.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7627" for this suite.
Sep 21 15:27:26.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:27:26.534: INFO: namespace pods-7627 deletion completed in 6.325433559s

• [SLOW TEST:13.195 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:27:26.534: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-e1bd693f-46da-4a5f-9f9e-a828b65810e4
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:27:26.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-347" for this suite.
Sep 21 15:27:32.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:27:33.136: INFO: namespace configmap-347 deletion completed in 6.344771645s

• [SLOW TEST:6.602 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:27:33.136: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-2944
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 21 15:27:33.378: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 21 15:27:55.595: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.195.252:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2944 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:27:55.595: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:27:55.774: INFO: Found all expected endpoints: [netserver-0]
Sep 21 15:27:55.783: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.185.214:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2944 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:27:55.783: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:27:55.966: INFO: Found all expected endpoints: [netserver-1]
Sep 21 15:27:55.974: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.21.18:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2944 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:27:55.974: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:27:56.167: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:27:56.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2944" for this suite.
Sep 21 15:28:08.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:28:08.549: INFO: namespace pod-network-test-2944 deletion completed in 12.348781067s

• [SLOW TEST:35.413 seconds]
[sig-network] Networking
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:28:08.549: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6006
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:28:34.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6006" for this suite.
Sep 21 15:28:42.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:28:42.710: INFO: namespace container-runtime-6006 deletion completed in 8.363594903s

• [SLOW TEST:34.161 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:28:42.711: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3970
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-e1c93a7d-1131-495e-8f48-61f03ef3efca
STEP: Creating configMap with name cm-test-opt-upd-9f8b3d84-bd6e-4104-ab8c-40e48c53edc1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e1c93a7d-1131-495e-8f48-61f03ef3efca
STEP: Updating configmap cm-test-opt-upd-9f8b3d84-bd6e-4104-ab8c-40e48c53edc1
STEP: Creating configMap with name cm-test-opt-create-e71b2df2-757e-438b-b35f-9bb04d2f7865
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:30:06.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3970" for this suite.
Sep 21 15:30:26.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:30:26.678: INFO: namespace projected-3970 deletion completed in 20.367585171s

• [SLOW TEST:103.968 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:30:26.679: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7426
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7dad2fcf-2aeb-4b7e-961c-17af9fc92e1b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-7dad2fcf-2aeb-4b7e-961c-17af9fc92e1b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:30:31.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7426" for this suite.
Sep 21 15:30:43.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:30:43.431: INFO: namespace projected-7426 deletion completed in 12.339777209s

• [SLOW TEST:16.752 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:30:43.431: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3078
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8533
STEP: Creating secret with name secret-test-babe3a0b-c51e-40c7-866b-b247892f3bf7
STEP: Creating a pod to test consume secrets
Sep 21 15:30:43.960: INFO: Waiting up to 5m0s for pod "pod-secrets-daab014a-0d5f-459b-9ca0-e9239f97d41d" in namespace "secrets-3078" to be "success or failure"
Sep 21 15:30:43.968: INFO: Pod "pod-secrets-daab014a-0d5f-459b-9ca0-e9239f97d41d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.196403ms
Sep 21 15:30:45.979: INFO: Pod "pod-secrets-daab014a-0d5f-459b-9ca0-e9239f97d41d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018794654s
STEP: Saw pod success
Sep 21 15:30:45.979: INFO: Pod "pod-secrets-daab014a-0d5f-459b-9ca0-e9239f97d41d" satisfied condition "success or failure"
Sep 21 15:30:45.988: INFO: Trying to get logs from node 10.189.39.114 pod pod-secrets-daab014a-0d5f-459b-9ca0-e9239f97d41d container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 15:30:46.061: INFO: Waiting for pod pod-secrets-daab014a-0d5f-459b-9ca0-e9239f97d41d to disappear
Sep 21 15:30:46.068: INFO: Pod pod-secrets-daab014a-0d5f-459b-9ca0-e9239f97d41d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:30:46.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3078" for this suite.
Sep 21 15:30:54.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:30:54.424: INFO: namespace secrets-3078 deletion completed in 8.340585274s
STEP: Destroying namespace "secret-namespace-8533" for this suite.
Sep 21 15:31:00.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:31:00.881: INFO: namespace secret-namespace-8533 deletion completed in 6.456418193s

• [SLOW TEST:17.449 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:31:00.882: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:31:05.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4687" for this suite.
Sep 21 15:31:11.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:31:11.709: INFO: namespace kubelet-test-4687 deletion completed in 6.493429693s

• [SLOW TEST:10.828 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:31:11.710: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-143
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:31:11.972: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-0158620b-930b-4f31-93a5-5d214ea42736" in namespace "security-context-test-143" to be "success or failure"
Sep 21 15:31:11.983: INFO: Pod "busybox-privileged-false-0158620b-930b-4f31-93a5-5d214ea42736": Phase="Pending", Reason="", readiness=false. Elapsed: 10.954421ms
Sep 21 15:31:13.993: INFO: Pod "busybox-privileged-false-0158620b-930b-4f31-93a5-5d214ea42736": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020635197s
Sep 21 15:31:16.005: INFO: Pod "busybox-privileged-false-0158620b-930b-4f31-93a5-5d214ea42736": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032213213s
Sep 21 15:31:16.005: INFO: Pod "busybox-privileged-false-0158620b-930b-4f31-93a5-5d214ea42736" satisfied condition "success or failure"
Sep 21 15:31:16.081: INFO: Got logs for pod "busybox-privileged-false-0158620b-930b-4f31-93a5-5d214ea42736": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:31:16.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-143" for this suite.
Sep 21 15:31:24.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:31:24.474: INFO: namespace security-context-test-143 deletion completed in 8.374510317s

• [SLOW TEST:12.764 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:31:24.474: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-6866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 21 15:31:25.238: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Sep 21 15:31:27.267: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299085, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299085, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299085, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299085, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 15:31:30.300: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:31:30.311: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:31:31.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6866" for this suite.
Sep 21 15:31:37.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:31:37.986: INFO: namespace crd-webhook-6866 deletion completed in 6.376383868s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.556 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:31:38.031: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 21 15:31:38.299: INFO: Waiting up to 5m0s for pod "pod-7ccb0405-2791-474b-b705-84d8073703ed" in namespace "emptydir-6264" to be "success or failure"
Sep 21 15:31:38.310: INFO: Pod "pod-7ccb0405-2791-474b-b705-84d8073703ed": Phase="Pending", Reason="", readiness=false. Elapsed: 11.102778ms
Sep 21 15:31:40.320: INFO: Pod "pod-7ccb0405-2791-474b-b705-84d8073703ed": Phase="Running", Reason="", readiness=true. Elapsed: 2.021091589s
Sep 21 15:31:42.332: INFO: Pod "pod-7ccb0405-2791-474b-b705-84d8073703ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03302744s
STEP: Saw pod success
Sep 21 15:31:42.332: INFO: Pod "pod-7ccb0405-2791-474b-b705-84d8073703ed" satisfied condition "success or failure"
Sep 21 15:31:42.343: INFO: Trying to get logs from node 10.189.39.107 pod pod-7ccb0405-2791-474b-b705-84d8073703ed container test-container: <nil>
STEP: delete the pod
Sep 21 15:31:42.392: INFO: Waiting for pod pod-7ccb0405-2791-474b-b705-84d8073703ed to disappear
Sep 21 15:31:42.399: INFO: Pod pod-7ccb0405-2791-474b-b705-84d8073703ed no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:31:42.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6264" for this suite.
Sep 21 15:31:48.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:31:48.763: INFO: namespace emptydir-6264 deletion completed in 6.347156613s

• [SLOW TEST:10.732 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:31:48.764: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 15:31:49.609: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 15:31:51.635: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299109, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299109, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299109, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299109, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 15:31:54.675: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:31:55.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-591" for this suite.
Sep 21 15:32:01.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:32:01.504: INFO: namespace webhook-591 deletion completed in 6.357273123s
STEP: Destroying namespace "webhook-591-markers" for this suite.
Sep 21 15:32:07.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:32:07.843: INFO: namespace webhook-591-markers deletion completed in 6.339795952s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.124 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:32:07.888: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-2679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 21 15:32:12.189: INFO: &Pod{ObjectMeta:{send-events-f65b105d-055f-4d45-a63b-1cd2020d95fe  events-2679 /api/v1/namespaces/events-2679/pods/send-events-f65b105d-055f-4d45-a63b-1cd2020d95fe baa92987-e0cf-437f-b5f2-edb22334a5a2 29832 0 2020-09-21 15:32:08 +0000 UTC <nil> <nil> map[name:foo time:127118192] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-vkrmm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-vkrmm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-vkrmm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:32:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:32:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:32:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:32:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:172.30.195.195,StartTime:2020-09-21 15:32:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:32:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://c684df6e0423e98fc28cdcaec2a3e7b411aa837e0988cd93804036a5e3b9ec63,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.195.195,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Sep 21 15:32:14.198: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 21 15:32:16.208: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:32:16.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2679" for this suite.
Sep 21 15:33:02.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:33:02.608: INFO: namespace events-2679 deletion completed in 46.373260285s

• [SLOW TEST:54.720 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:33:02.608: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-6232
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Sep 21 15:33:02.847: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 21 15:34:02.920: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:34:02.930: INFO: Starting informer...
STEP: Starting pod...
Sep 21 15:34:03.162: INFO: Pod is running on 10.189.39.109. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Sep 21 15:34:03.192: INFO: Pod wasn't evicted. Proceeding
Sep 21 15:34:03.192: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Sep 21 15:35:18.243: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:35:18.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-6232" for this suite.
Sep 21 15:35:48.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:35:48.588: INFO: namespace taint-single-pod-6232 deletion completed in 30.33127157s

• [SLOW TEST:165.980 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:35:48.588: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1310
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:35:48.823: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 21 15:35:51.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-1310 create -f -'
Sep 21 15:35:52.286: INFO: stderr: ""
Sep 21 15:35:52.286: INFO: stdout: "e2e-test-crd-publish-openapi-5313-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 21 15:35:52.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-1310 delete e2e-test-crd-publish-openapi-5313-crds test-cr'
Sep 21 15:35:52.436: INFO: stderr: ""
Sep 21 15:35:52.436: INFO: stdout: "e2e-test-crd-publish-openapi-5313-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Sep 21 15:35:52.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-1310 apply -f -'
Sep 21 15:35:52.695: INFO: stderr: ""
Sep 21 15:35:52.695: INFO: stdout: "e2e-test-crd-publish-openapi-5313-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 21 15:35:52.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=crd-publish-openapi-1310 delete e2e-test-crd-publish-openapi-5313-crds test-cr'
Sep 21 15:35:52.796: INFO: stderr: ""
Sep 21 15:35:52.796: INFO: stdout: "e2e-test-crd-publish-openapi-5313-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 21 15:35:52.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 explain e2e-test-crd-publish-openapi-5313-crds'
Sep 21 15:35:52.938: INFO: stderr: ""
Sep 21 15:35:52.938: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5313-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:35:55.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1310" for this suite.
Sep 21 15:36:01.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:36:02.297: INFO: namespace crd-publish-openapi-1310 deletion completed in 6.387865145s

• [SLOW TEST:13.709 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:36:02.299: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9917
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-n7bn
STEP: Creating a pod to test atomic-volume-subpath
Sep 21 15:36:02.598: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-n7bn" in namespace "subpath-9917" to be "success or failure"
Sep 21 15:36:02.607: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Pending", Reason="", readiness=false. Elapsed: 9.349303ms
Sep 21 15:36:04.621: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023549968s
Sep 21 15:36:06.630: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 4.032663587s
Sep 21 15:36:08.641: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 6.043147066s
Sep 21 15:36:10.651: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 8.05378497s
Sep 21 15:36:12.662: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 10.064446544s
Sep 21 15:36:14.671: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 12.073004353s
Sep 21 15:36:16.680: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 14.082418976s
Sep 21 15:36:18.692: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 16.094320092s
Sep 21 15:36:20.701: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 18.103110543s
Sep 21 15:36:22.710: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 20.112377153s
Sep 21 15:36:24.720: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Running", Reason="", readiness=true. Elapsed: 22.122389871s
Sep 21 15:36:26.729: INFO: Pod "pod-subpath-test-secret-n7bn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.131314339s
STEP: Saw pod success
Sep 21 15:36:26.729: INFO: Pod "pod-subpath-test-secret-n7bn" satisfied condition "success or failure"
Sep 21 15:36:26.737: INFO: Trying to get logs from node 10.189.39.109 pod pod-subpath-test-secret-n7bn container test-container-subpath-secret-n7bn: <nil>
STEP: delete the pod
Sep 21 15:36:26.813: INFO: Waiting for pod pod-subpath-test-secret-n7bn to disappear
Sep 21 15:36:26.820: INFO: Pod pod-subpath-test-secret-n7bn no longer exists
STEP: Deleting pod pod-subpath-test-secret-n7bn
Sep 21 15:36:26.820: INFO: Deleting pod "pod-subpath-test-secret-n7bn" in namespace "subpath-9917"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:36:26.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9917" for this suite.
Sep 21 15:36:32.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:36:33.208: INFO: namespace subpath-9917 deletion completed in 6.364926045s

• [SLOW TEST:30.909 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:36:33.208: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6368
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:36:33.526: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f1253460-48de-4e66-8eee-e4ebcb35b510" in namespace "downward-api-6368" to be "success or failure"
Sep 21 15:36:33.534: INFO: Pod "downwardapi-volume-f1253460-48de-4e66-8eee-e4ebcb35b510": Phase="Pending", Reason="", readiness=false. Elapsed: 7.840898ms
Sep 21 15:36:35.542: INFO: Pod "downwardapi-volume-f1253460-48de-4e66-8eee-e4ebcb35b510": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016159226s
STEP: Saw pod success
Sep 21 15:36:35.542: INFO: Pod "downwardapi-volume-f1253460-48de-4e66-8eee-e4ebcb35b510" satisfied condition "success or failure"
Sep 21 15:36:35.551: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-f1253460-48de-4e66-8eee-e4ebcb35b510 container client-container: <nil>
STEP: delete the pod
Sep 21 15:36:35.598: INFO: Waiting for pod downwardapi-volume-f1253460-48de-4e66-8eee-e4ebcb35b510 to disappear
Sep 21 15:36:35.605: INFO: Pod downwardapi-volume-f1253460-48de-4e66-8eee-e4ebcb35b510 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:36:35.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6368" for this suite.
Sep 21 15:36:41.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:36:41.966: INFO: namespace downward-api-6368 deletion completed in 6.340976496s

• [SLOW TEST:8.758 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:36:41.966: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5666
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:36:42.221: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10569c71-a8b2-4cd8-be3f-696f2dd789b7" in namespace "projected-5666" to be "success or failure"
Sep 21 15:36:42.229: INFO: Pod "downwardapi-volume-10569c71-a8b2-4cd8-be3f-696f2dd789b7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.225698ms
Sep 21 15:36:44.243: INFO: Pod "downwardapi-volume-10569c71-a8b2-4cd8-be3f-696f2dd789b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021992666s
Sep 21 15:36:46.253: INFO: Pod "downwardapi-volume-10569c71-a8b2-4cd8-be3f-696f2dd789b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031974567s
STEP: Saw pod success
Sep 21 15:36:46.253: INFO: Pod "downwardapi-volume-10569c71-a8b2-4cd8-be3f-696f2dd789b7" satisfied condition "success or failure"
Sep 21 15:36:46.271: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-10569c71-a8b2-4cd8-be3f-696f2dd789b7 container client-container: <nil>
STEP: delete the pod
Sep 21 15:36:46.320: INFO: Waiting for pod downwardapi-volume-10569c71-a8b2-4cd8-be3f-696f2dd789b7 to disappear
Sep 21 15:36:46.329: INFO: Pod downwardapi-volume-10569c71-a8b2-4cd8-be3f-696f2dd789b7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:36:46.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5666" for this suite.
Sep 21 15:36:52.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:36:52.712: INFO: namespace projected-5666 deletion completed in 6.366523592s

• [SLOW TEST:10.746 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:36:52.713: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4456
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 21 15:36:52.964: INFO: Waiting up to 5m0s for pod "pod-4b49055a-9fd8-471e-a40c-f2b8fb369766" in namespace "emptydir-4456" to be "success or failure"
Sep 21 15:36:52.973: INFO: Pod "pod-4b49055a-9fd8-471e-a40c-f2b8fb369766": Phase="Pending", Reason="", readiness=false. Elapsed: 9.162236ms
Sep 21 15:36:54.983: INFO: Pod "pod-4b49055a-9fd8-471e-a40c-f2b8fb369766": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018735287s
Sep 21 15:36:56.993: INFO: Pod "pod-4b49055a-9fd8-471e-a40c-f2b8fb369766": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028718072s
STEP: Saw pod success
Sep 21 15:36:56.993: INFO: Pod "pod-4b49055a-9fd8-471e-a40c-f2b8fb369766" satisfied condition "success or failure"
Sep 21 15:36:57.002: INFO: Trying to get logs from node 10.189.39.109 pod pod-4b49055a-9fd8-471e-a40c-f2b8fb369766 container test-container: <nil>
STEP: delete the pod
Sep 21 15:36:57.054: INFO: Waiting for pod pod-4b49055a-9fd8-471e-a40c-f2b8fb369766 to disappear
Sep 21 15:36:57.062: INFO: Pod pod-4b49055a-9fd8-471e-a40c-f2b8fb369766 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:36:57.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4456" for this suite.
Sep 21 15:37:03.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:37:03.438: INFO: namespace emptydir-4456 deletion completed in 6.354419578s

• [SLOW TEST:10.726 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:37:03.439: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-28
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep 21 15:37:07.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec pod-sharedvolume-2b76e52d-ce8a-4cfd-a6f3-deafb8f1c6c6 -c busybox-main-container --namespace=emptydir-28 -- cat /usr/share/volumeshare/shareddata.txt'
Sep 21 15:37:08.027: INFO: stderr: ""
Sep 21 15:37:08.027: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:37:08.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-28" for this suite.
Sep 21 15:37:14.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:37:14.406: INFO: namespace emptydir-28 deletion completed in 6.349429536s

• [SLOW TEST:10.967 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:37:14.406: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8932
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Sep 21 15:37:14.645: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:37:19.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8932" for this suite.
Sep 21 15:37:49.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:37:49.835: INFO: namespace init-container-8932 deletion completed in 30.380552705s

• [SLOW TEST:35.430 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:37:49.836: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9334
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-e5a5a76f-3fe4-4d0e-aa14-b4795520b99d
STEP: Creating a pod to test consume configMaps
Sep 21 15:37:50.118: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6be7295c-1a8e-43a4-b3c2-21a3baa7b160" in namespace "projected-9334" to be "success or failure"
Sep 21 15:37:50.129: INFO: Pod "pod-projected-configmaps-6be7295c-1a8e-43a4-b3c2-21a3baa7b160": Phase="Pending", Reason="", readiness=false. Elapsed: 10.192352ms
Sep 21 15:37:52.361: INFO: Pod "pod-projected-configmaps-6be7295c-1a8e-43a4-b3c2-21a3baa7b160": Phase="Running", Reason="", readiness=true. Elapsed: 2.242564107s
Sep 21 15:37:54.370: INFO: Pod "pod-projected-configmaps-6be7295c-1a8e-43a4-b3c2-21a3baa7b160": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.25179627s
STEP: Saw pod success
Sep 21 15:37:54.370: INFO: Pod "pod-projected-configmaps-6be7295c-1a8e-43a4-b3c2-21a3baa7b160" satisfied condition "success or failure"
Sep 21 15:37:54.379: INFO: Trying to get logs from node 10.189.39.109 pod pod-projected-configmaps-6be7295c-1a8e-43a4-b3c2-21a3baa7b160 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 15:37:54.432: INFO: Waiting for pod pod-projected-configmaps-6be7295c-1a8e-43a4-b3c2-21a3baa7b160 to disappear
Sep 21 15:37:54.440: INFO: Pod pod-projected-configmaps-6be7295c-1a8e-43a4-b3c2-21a3baa7b160 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:37:54.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9334" for this suite.
Sep 21 15:38:00.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:38:00.792: INFO: namespace projected-9334 deletion completed in 6.335089755s

• [SLOW TEST:10.956 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:38:00.793: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-1889
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Sep 21 15:38:01.035: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 21 15:39:01.103: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:39:01.113: INFO: Starting informer...
STEP: Starting pods...
Sep 21 15:39:01.351: INFO: Pod1 is running on 10.189.39.109. Tainting Node
Sep 21 15:39:03.599: INFO: Pod2 is running on 10.189.39.109. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Sep 21 15:39:21.731: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Sep 21 15:39:41.716: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:39:41.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-1889" for this suite.
Sep 21 15:39:47.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:39:48.100: INFO: namespace taint-multiple-pods-1889 deletion completed in 6.346505533s

• [SLOW TEST:107.307 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:39:48.101: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9096
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-9096
STEP: creating replication controller nodeport-test in namespace services-9096
I0921 15:39:48.422599      24 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-9096, replica count: 2
I0921 15:39:51.473402      24 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 15:39:51.473: INFO: Creating new exec pod
Sep 21 15:39:56.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-9096 execpodvvggr -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Sep 21 15:39:56.931: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Sep 21 15:39:56.931: INFO: stdout: ""
Sep 21 15:39:56.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-9096 execpodvvggr -- /bin/sh -x -c nc -zv -t -w 2 172.21.183.155 80'
Sep 21 15:39:57.239: INFO: stderr: "+ nc -zv -t -w 2 172.21.183.155 80\nConnection to 172.21.183.155 80 port [tcp/http] succeeded!\n"
Sep 21 15:39:57.239: INFO: stdout: ""
Sep 21 15:39:57.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-9096 execpodvvggr -- /bin/sh -x -c nc -zv -t -w 2 10.189.39.107 30493'
Sep 21 15:39:57.505: INFO: stderr: "+ nc -zv -t -w 2 10.189.39.107 30493\nConnection to 10.189.39.107 30493 port [tcp/30493] succeeded!\n"
Sep 21 15:39:57.505: INFO: stdout: ""
Sep 21 15:39:57.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-9096 execpodvvggr -- /bin/sh -x -c nc -zv -t -w 2 10.189.39.109 30493'
Sep 21 15:39:57.753: INFO: stderr: "+ nc -zv -t -w 2 10.189.39.109 30493\nConnection to 10.189.39.109 30493 port [tcp/30493] succeeded!\n"
Sep 21 15:39:57.753: INFO: stdout: ""
Sep 21 15:39:57.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-9096 execpodvvggr -- /bin/sh -x -c nc -zv -t -w 2 169.60.73.248 30493'
Sep 21 15:39:58.007: INFO: stderr: "+ nc -zv -t -w 2 169.60.73.248 30493\nConnection to 169.60.73.248 30493 port [tcp/30493] succeeded!\n"
Sep 21 15:39:58.007: INFO: stdout: ""
Sep 21 15:39:58.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-9096 execpodvvggr -- /bin/sh -x -c nc -zv -t -w 2 169.60.73.249 30493'
Sep 21 15:39:58.280: INFO: stderr: "+ nc -zv -t -w 2 169.60.73.249 30493\nConnection to 169.60.73.249 30493 port [tcp/30493] succeeded!\n"
Sep 21 15:39:58.280: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:39:58.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9096" for this suite.
Sep 21 15:40:06.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:40:06.695: INFO: namespace services-9096 deletion completed in 8.403073954s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.594 seconds]
[sig-network] Services
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:40:06.695: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5042
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Sep 21 15:40:06.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 cluster-info'
Sep 21 15:40:07.058: INFO: stderr: ""
Sep 21 15:40:07.058: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\x1b[0;32mNodeLocalDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/node-local-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:40:07.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5042" for this suite.
Sep 21 15:40:13.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:40:13.408: INFO: namespace kubectl-5042 deletion completed in 6.329874545s

• [SLOW TEST:6.713 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:40:13.409: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-932
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-96a4cd88-d728-408b-8b5b-943bf2a6b10a
STEP: Creating a pod to test consume secrets
Sep 21 15:40:13.703: INFO: Waiting up to 5m0s for pod "pod-secrets-5a0bc3fe-2dd6-460e-a3ed-57cf1472a4f6" in namespace "secrets-932" to be "success or failure"
Sep 21 15:40:13.715: INFO: Pod "pod-secrets-5a0bc3fe-2dd6-460e-a3ed-57cf1472a4f6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.347951ms
Sep 21 15:40:15.725: INFO: Pod "pod-secrets-5a0bc3fe-2dd6-460e-a3ed-57cf1472a4f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021544447s
Sep 21 15:40:17.734: INFO: Pod "pod-secrets-5a0bc3fe-2dd6-460e-a3ed-57cf1472a4f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030638772s
STEP: Saw pod success
Sep 21 15:40:17.734: INFO: Pod "pod-secrets-5a0bc3fe-2dd6-460e-a3ed-57cf1472a4f6" satisfied condition "success or failure"
Sep 21 15:40:17.749: INFO: Trying to get logs from node 10.189.39.109 pod pod-secrets-5a0bc3fe-2dd6-460e-a3ed-57cf1472a4f6 container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 15:40:17.821: INFO: Waiting for pod pod-secrets-5a0bc3fe-2dd6-460e-a3ed-57cf1472a4f6 to disappear
Sep 21 15:40:17.828: INFO: Pod pod-secrets-5a0bc3fe-2dd6-460e-a3ed-57cf1472a4f6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:40:17.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-932" for this suite.
Sep 21 15:40:23.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:40:24.207: INFO: namespace secrets-932 deletion completed in 6.366188618s

• [SLOW TEST:10.798 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:40:24.207: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5309
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Sep 21 15:40:24.441: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Sep 21 15:40:36.426: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:40:39.415: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:40:51.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5309" for this suite.
Sep 21 15:40:57.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:40:57.536: INFO: namespace crd-publish-openapi-5309 deletion completed in 6.335322258s

• [SLOW TEST:33.329 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:40:57.537: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5681
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 21 15:40:57.805: INFO: Waiting up to 5m0s for pod "pod-4626a64e-09b1-4f99-af9a-4fe7c959c7e0" in namespace "emptydir-5681" to be "success or failure"
Sep 21 15:40:57.815: INFO: Pod "pod-4626a64e-09b1-4f99-af9a-4fe7c959c7e0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.981307ms
Sep 21 15:40:59.827: INFO: Pod "pod-4626a64e-09b1-4f99-af9a-4fe7c959c7e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022120689s
STEP: Saw pod success
Sep 21 15:40:59.827: INFO: Pod "pod-4626a64e-09b1-4f99-af9a-4fe7c959c7e0" satisfied condition "success or failure"
Sep 21 15:40:59.837: INFO: Trying to get logs from node 10.189.39.109 pod pod-4626a64e-09b1-4f99-af9a-4fe7c959c7e0 container test-container: <nil>
STEP: delete the pod
Sep 21 15:40:59.891: INFO: Waiting for pod pod-4626a64e-09b1-4f99-af9a-4fe7c959c7e0 to disappear
Sep 21 15:40:59.900: INFO: Pod pod-4626a64e-09b1-4f99-af9a-4fe7c959c7e0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:40:59.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5681" for this suite.
Sep 21 15:41:05.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:41:06.268: INFO: namespace emptydir-5681 deletion completed in 6.352749129s

• [SLOW TEST:8.731 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:41:06.269: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 21 15:41:12.617: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:12.617: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:12.786: INFO: Exec stderr: ""
Sep 21 15:41:12.786: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:12.786: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:12.937: INFO: Exec stderr: ""
Sep 21 15:41:12.937: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:12.937: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:13.086: INFO: Exec stderr: ""
Sep 21 15:41:13.086: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:13.086: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:13.260: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 21 15:41:13.260: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:13.260: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:13.429: INFO: Exec stderr: ""
Sep 21 15:41:13.429: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:13.429: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:13.599: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 21 15:41:13.599: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:13.600: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:13.741: INFO: Exec stderr: ""
Sep 21 15:41:13.741: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:13.741: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:13.879: INFO: Exec stderr: ""
Sep 21 15:41:13.880: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:13.880: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:14.046: INFO: Exec stderr: ""
Sep 21 15:41:14.047: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6104 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 15:41:14.047: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:41:14.176: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:41:14.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6104" for this suite.
Sep 21 15:42:04.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:42:04.528: INFO: namespace e2e-kubelet-etc-hosts-6104 deletion completed in 50.339301127s

• [SLOW TEST:58.260 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:42:04.529: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 21 15:42:04.864: INFO: Number of nodes with available pods: 0
Sep 21 15:42:04.864: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:42:05.885: INFO: Number of nodes with available pods: 0
Sep 21 15:42:05.885: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:42:06.884: INFO: Number of nodes with available pods: 3
Sep 21 15:42:06.885: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 21 15:42:06.934: INFO: Number of nodes with available pods: 2
Sep 21 15:42:06.934: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:42:07.954: INFO: Number of nodes with available pods: 2
Sep 21 15:42:07.954: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:42:08.953: INFO: Number of nodes with available pods: 2
Sep 21 15:42:08.953: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:42:09.956: INFO: Number of nodes with available pods: 2
Sep 21 15:42:09.956: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:42:10.958: INFO: Number of nodes with available pods: 2
Sep 21 15:42:10.958: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:42:11.958: INFO: Number of nodes with available pods: 2
Sep 21 15:42:11.958: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:42:12.956: INFO: Number of nodes with available pods: 3
Sep 21 15:42:12.956: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6716, will wait for the garbage collector to delete the pods
Sep 21 15:42:13.044: INFO: Deleting DaemonSet.extensions daemon-set took: 19.533817ms
Sep 21 15:42:13.344: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.380243ms
Sep 21 15:42:21.756: INFO: Number of nodes with available pods: 0
Sep 21 15:42:21.756: INFO: Number of running nodes: 0, number of available pods: 0
Sep 21 15:42:21.766: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6716/daemonsets","resourceVersion":"31682"},"items":null}

Sep 21 15:42:21.774: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6716/pods","resourceVersion":"31682"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:42:21.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6716" for this suite.
Sep 21 15:42:29.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:42:30.182: INFO: namespace daemonsets-6716 deletion completed in 8.358520585s

• [SLOW TEST:25.653 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:42:30.182: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:42:30.450: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b02f40e9-faa5-435a-8f5a-c39f76a6c058" in namespace "downward-api-9939" to be "success or failure"
Sep 21 15:42:30.458: INFO: Pod "downwardapi-volume-b02f40e9-faa5-435a-8f5a-c39f76a6c058": Phase="Pending", Reason="", readiness=false. Elapsed: 7.572967ms
Sep 21 15:42:32.470: INFO: Pod "downwardapi-volume-b02f40e9-faa5-435a-8f5a-c39f76a6c058": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019140362s
Sep 21 15:42:34.480: INFO: Pod "downwardapi-volume-b02f40e9-faa5-435a-8f5a-c39f76a6c058": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029370479s
STEP: Saw pod success
Sep 21 15:42:34.480: INFO: Pod "downwardapi-volume-b02f40e9-faa5-435a-8f5a-c39f76a6c058" satisfied condition "success or failure"
Sep 21 15:42:34.490: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-b02f40e9-faa5-435a-8f5a-c39f76a6c058 container client-container: <nil>
STEP: delete the pod
Sep 21 15:42:34.564: INFO: Waiting for pod downwardapi-volume-b02f40e9-faa5-435a-8f5a-c39f76a6c058 to disappear
Sep 21 15:42:34.574: INFO: Pod downwardapi-volume-b02f40e9-faa5-435a-8f5a-c39f76a6c058 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:42:34.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9939" for this suite.
Sep 21 15:42:40.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:42:40.971: INFO: namespace downward-api-9939 deletion completed in 6.387232617s

• [SLOW TEST:10.789 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:42:40.971: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3752
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 21 15:42:41.222: INFO: Waiting up to 5m0s for pod "pod-d1861188-572f-4e49-aadf-a7c4fe819f8d" in namespace "emptydir-3752" to be "success or failure"
Sep 21 15:42:41.232: INFO: Pod "pod-d1861188-572f-4e49-aadf-a7c4fe819f8d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.442901ms
Sep 21 15:42:43.241: INFO: Pod "pod-d1861188-572f-4e49-aadf-a7c4fe819f8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018654213s
Sep 21 15:42:45.250: INFO: Pod "pod-d1861188-572f-4e49-aadf-a7c4fe819f8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028185917s
STEP: Saw pod success
Sep 21 15:42:45.250: INFO: Pod "pod-d1861188-572f-4e49-aadf-a7c4fe819f8d" satisfied condition "success or failure"
Sep 21 15:42:45.259: INFO: Trying to get logs from node 10.189.39.109 pod pod-d1861188-572f-4e49-aadf-a7c4fe819f8d container test-container: <nil>
STEP: delete the pod
Sep 21 15:42:45.307: INFO: Waiting for pod pod-d1861188-572f-4e49-aadf-a7c4fe819f8d to disappear
Sep 21 15:42:45.315: INFO: Pod pod-d1861188-572f-4e49-aadf-a7c4fe819f8d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:42:45.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3752" for this suite.
Sep 21 15:42:51.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:42:51.660: INFO: namespace emptydir-3752 deletion completed in 6.334695741s

• [SLOW TEST:10.689 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:42:51.661: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5003
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 15:42:52.288: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 15:42:54.314: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299772, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299772, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299772, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736299772, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 15:42:57.348: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:42:57.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5003" for this suite.
Sep 21 15:43:03.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:43:03.953: INFO: namespace webhook-5003 deletion completed in 6.396963336s
STEP: Destroying namespace "webhook-5003-markers" for this suite.
Sep 21 15:43:09.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:43:10.318: INFO: namespace webhook-5003-markers deletion completed in 6.364960144s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.699 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:43:10.361: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5248
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:43:10.625: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e38f60f4-e9a2-4795-bf29-54844999d95c" in namespace "downward-api-5248" to be "success or failure"
Sep 21 15:43:10.636: INFO: Pod "downwardapi-volume-e38f60f4-e9a2-4795-bf29-54844999d95c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.715142ms
Sep 21 15:43:12.645: INFO: Pod "downwardapi-volume-e38f60f4-e9a2-4795-bf29-54844999d95c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020361111s
Sep 21 15:43:14.656: INFO: Pod "downwardapi-volume-e38f60f4-e9a2-4795-bf29-54844999d95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030689331s
STEP: Saw pod success
Sep 21 15:43:14.656: INFO: Pod "downwardapi-volume-e38f60f4-e9a2-4795-bf29-54844999d95c" satisfied condition "success or failure"
Sep 21 15:43:14.664: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-e38f60f4-e9a2-4795-bf29-54844999d95c container client-container: <nil>
STEP: delete the pod
Sep 21 15:43:14.713: INFO: Waiting for pod downwardapi-volume-e38f60f4-e9a2-4795-bf29-54844999d95c to disappear
Sep 21 15:43:14.721: INFO: Pod downwardapi-volume-e38f60f4-e9a2-4795-bf29-54844999d95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:43:14.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5248" for this suite.
Sep 21 15:43:20.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:43:21.124: INFO: namespace downward-api-5248 deletion completed in 6.389574942s

• [SLOW TEST:10.763 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:43:21.124: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-766
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 21 15:43:21.425: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-766 /api/v1/namespaces/watch-766/configmaps/e2e-watch-test-label-changed 2d86795c-1c70-4aee-b98b-2afe36f815a9 32005 0 2020-09-21 15:43:21 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 21 15:43:21.425: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-766 /api/v1/namespaces/watch-766/configmaps/e2e-watch-test-label-changed 2d86795c-1c70-4aee-b98b-2afe36f815a9 32006 0 2020-09-21 15:43:21 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 21 15:43:21.425: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-766 /api/v1/namespaces/watch-766/configmaps/e2e-watch-test-label-changed 2d86795c-1c70-4aee-b98b-2afe36f815a9 32007 0 2020-09-21 15:43:21 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 21 15:43:31.507: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-766 /api/v1/namespaces/watch-766/configmaps/e2e-watch-test-label-changed 2d86795c-1c70-4aee-b98b-2afe36f815a9 32024 0 2020-09-21 15:43:21 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 21 15:43:31.507: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-766 /api/v1/namespaces/watch-766/configmaps/e2e-watch-test-label-changed 2d86795c-1c70-4aee-b98b-2afe36f815a9 32025 0 2020-09-21 15:43:21 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep 21 15:43:31.507: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-766 /api/v1/namespaces/watch-766/configmaps/e2e-watch-test-label-changed 2d86795c-1c70-4aee-b98b-2afe36f815a9 32026 0 2020-09-21 15:43:21 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:43:31.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-766" for this suite.
Sep 21 15:43:37.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:43:37.849: INFO: namespace watch-766 deletion completed in 6.329028869s

• [SLOW TEST:16.725 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:43:37.851: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-5854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Sep 21 15:43:42.645: INFO: Successfully updated pod "adopt-release-hnw9q"
STEP: Checking that the Job readopts the Pod
Sep 21 15:43:42.645: INFO: Waiting up to 15m0s for pod "adopt-release-hnw9q" in namespace "job-5854" to be "adopted"
Sep 21 15:43:42.656: INFO: Pod "adopt-release-hnw9q": Phase="Running", Reason="", readiness=true. Elapsed: 11.085241ms
Sep 21 15:43:44.667: INFO: Pod "adopt-release-hnw9q": Phase="Running", Reason="", readiness=true. Elapsed: 2.021384843s
Sep 21 15:43:44.667: INFO: Pod "adopt-release-hnw9q" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Sep 21 15:43:45.188: INFO: Successfully updated pod "adopt-release-hnw9q"
STEP: Checking that the Job releases the Pod
Sep 21 15:43:45.188: INFO: Waiting up to 15m0s for pod "adopt-release-hnw9q" in namespace "job-5854" to be "released"
Sep 21 15:43:45.198: INFO: Pod "adopt-release-hnw9q": Phase="Running", Reason="", readiness=true. Elapsed: 9.993487ms
Sep 21 15:43:47.207: INFO: Pod "adopt-release-hnw9q": Phase="Running", Reason="", readiness=true. Elapsed: 2.018944542s
Sep 21 15:43:47.207: INFO: Pod "adopt-release-hnw9q" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:43:47.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5854" for this suite.
Sep 21 15:44:33.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:44:33.553: INFO: namespace job-5854 deletion completed in 46.333342659s

• [SLOW TEST:55.702 seconds]
[sig-apps] Job
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:44:33.553: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2780
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:44:33.801: INFO: Creating deployment "webserver-deployment"
Sep 21 15:44:33.812: INFO: Waiting for observed generation 1
Sep 21 15:44:35.832: INFO: Waiting for all required pods to come up
Sep 21 15:44:35.841: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 21 15:44:37.861: INFO: Waiting for deployment "webserver-deployment" to complete
Sep 21 15:44:37.878: INFO: Updating deployment "webserver-deployment" with a non-existent image
Sep 21 15:44:37.896: INFO: Updating deployment webserver-deployment
Sep 21 15:44:37.896: INFO: Waiting for observed generation 2
Sep 21 15:44:39.913: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 21 15:44:39.922: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 21 15:44:39.930: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 21 15:44:39.957: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 21 15:44:39.957: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 21 15:44:39.965: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 21 15:44:39.980: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Sep 21 15:44:39.980: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Sep 21 15:44:39.997: INFO: Updating deployment webserver-deployment
Sep 21 15:44:39.997: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Sep 21 15:44:40.015: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 21 15:44:40.036: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 21 15:44:40.072: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2780 /apis/apps/v1/namespaces/deployment-2780/deployments/webserver-deployment 3b110224-4dd9-4cbc-93e9-4db190bf00bd 32477 3 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00385c448 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-09-21 15:44:38 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-09-21 15:44:40 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Sep 21 15:44:40.091: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-2780 /apis/apps/v1/namespaces/deployment-2780/replicasets/webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 32471 3 2020-09-21 15:44:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 3b110224-4dd9-4cbc-93e9-4db190bf00bd 0xc00385c957 0xc00385c958}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00385c9c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 15:44:40.091: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Sep 21 15:44:40.091: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-2780 /apis/apps/v1/namespaces/deployment-2780/replicasets/webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 32470 3 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 3b110224-4dd9-4cbc-93e9-4db190bf00bd 0xc00385c897 0xc00385c898}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00385c8f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Sep 21 15:44:40.125: INFO: Pod "webserver-deployment-595b5b9587-5zwvb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5zwvb webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-5zwvb b9b51483-d94d-4ffe-83bf-b5cab14ecd70 32513 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385cea7 0xc00385cea8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.125: INFO: Pod "webserver-deployment-595b5b9587-68lnm" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-68lnm webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-68lnm 654335cf-a577-4426-98e5-7a845127c477 32358 0 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385cf97 0xc00385cf98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:172.30.195.222,StartTime:2020-09-21 15:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:44:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://b8e2ed02aa974f40c4a3235a0e64428ebf579e01b9fc049264272c233d0db1b2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.195.222,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.125: INFO: Pod "webserver-deployment-595b5b9587-6lvdd" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6lvdd webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-6lvdd 76d6083a-f64a-4d84-b23b-96dccfd20b32 32364 0 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385d117 0xc00385d118}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.107,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.107,PodIP:172.30.185.224,StartTime:2020-09-21 15:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:44:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://ce76e8349aae95522fcd09975f5e0ea15c04349bb1f2e245d7e02a77f243dbf5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.185.224,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.125: INFO: Pod "webserver-deployment-595b5b9587-6mcd2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6mcd2 webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-6mcd2 779cae8e-2b90-4073-8383-72e1dbcf704c 32509 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385d2a7 0xc00385d2a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.126: INFO: Pod "webserver-deployment-595b5b9587-7zhkb" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7zhkb webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-7zhkb 3be1e6bf-bcf4-4da8-9928-2bf85e9da06a 32351 0 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385d3d0 0xc00385d3d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:172.30.195.223,StartTime:2020-09-21 15:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:44:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://0264bbfbe847eb385420416ede1e34a564b7b7d5e854aef6560d854e3f0e26a5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.195.223,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.126: INFO: Pod "webserver-deployment-595b5b9587-8mq8q" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8mq8q webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-8mq8q bec8b94e-ba5f-48b4-9a68-786c62b6ef23 32344 0 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385d567 0xc00385d568}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.114,PodIP:172.30.21.25,StartTime:2020-09-21 15:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:44:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://6cb192d970215e5df17a87f7ed6308b5c2257896a12b50ad3cbf75770c35729a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.21.25,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.126: INFO: Pod "webserver-deployment-595b5b9587-8w75k" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8w75k webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-8w75k 9f124209-b937-4e11-9b89-4b4dcde25a96 32489 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385d6f7 0xc00385d6f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.126: INFO: Pod "webserver-deployment-595b5b9587-9nrdw" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9nrdw webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-9nrdw f0b8e1bc-d3c4-47f4-aefd-a39ff2befc7a 32312 0 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385d810 0xc00385d811}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.107,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.107,PodIP:172.30.185.223,StartTime:2020-09-21 15:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:44:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://2ea8e26bd663b4570b8286de79173d5d28b70c2dd208d81571c577e34adae664,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.185.223,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.126: INFO: Pod "webserver-deployment-595b5b9587-b9m74" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-b9m74 webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-b9m74 58d8fd8f-faad-46a5-a0ad-a41d80632316 32505 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385d9c7 0xc00385d9c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.127: INFO: Pod "webserver-deployment-595b5b9587-brhdk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-brhdk webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-brhdk 94c354c3-ca41-4232-8d6a-a460442d59a4 32339 0 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385dae0 0xc00385dae1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.114,PodIP:172.30.21.28,StartTime:2020-09-21 15:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:44:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://907cd8dc6dbb0fda8419123e0b57844ceb3219572113e2ca2331cb5bf7c94edc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.21.28,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.127: INFO: Pod "webserver-deployment-595b5b9587-gpfcz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gpfcz webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-gpfcz 98df99d5-61b2-4517-8687-868cbfc25acd 32508 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385dc67 0xc00385dc68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.127: INFO: Pod "webserver-deployment-595b5b9587-h87kt" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-h87kt webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-h87kt 292c8c8c-aa7d-4d79-ace1-ddeb52556558 32355 0 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385dd57 0xc00385dd58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:172.30.195.221,StartTime:2020-09-21 15:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:44:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://d0fb113b9178ff8d8f07dd33c0fe1029332e9a552258ed55e79ffa65e9523c9f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.195.221,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.127: INFO: Pod "webserver-deployment-595b5b9587-mg9bn" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mg9bn webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-mg9bn 80a3d1da-9e57-4b7a-86d6-e02d3e93e89f 32488 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385ded7 0xc00385ded8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.127: INFO: Pod "webserver-deployment-595b5b9587-qqzqg" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qqzqg webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-qqzqg 75fde108-c833-408d-8e03-e417262c452b 32510 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc00385dff0 0xc00385dff1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.127: INFO: Pod "webserver-deployment-595b5b9587-tmkdw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tmkdw webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-tmkdw f094d305-8af4-4df3-a3f5-c9f561d4bb05 32476 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc003a0e0d7 0xc003a0e0d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.131: INFO: Pod "webserver-deployment-595b5b9587-tt7fq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tt7fq webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-tt7fq 0f151317-8f04-43f1-9826-91b893b96767 32506 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc003a0e1f0 0xc003a0e1f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.132: INFO: Pod "webserver-deployment-595b5b9587-vnx7s" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vnx7s webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-vnx7s d0e3e47a-6407-4137-be7c-2eb48b1286f3 32361 0 2020-09-21 15:44:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc003a0e300 0xc003a0e301}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:172.30.195.225,StartTime:2020-09-21 15:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:44:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://b03446d1a3660342843e9ac4ad04747e132ddac2ba307c7585e0a076e6e25ecd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.195.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.132: INFO: Pod "webserver-deployment-595b5b9587-wwwgs" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wwwgs webserver-deployment-595b5b9587- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-595b5b9587-wwwgs 7b9543fd-02b2-40ac-82b4-36acfa271f38 32507 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dc04a953-9eef-412e-b058-9a99b5277432 0xc003a0e477 0xc003a0e478}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.107,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.132: INFO: Pod "webserver-deployment-c7997dcc8-292dl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-292dl webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-292dl 52894876-9b66-40c6-a4e5-8f086b87915f 32480 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0e590 0xc003a0e591}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.107,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.132: INFO: Pod "webserver-deployment-c7997dcc8-5nbwt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5nbwt webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-5nbwt 7b08b12c-06be-456b-bbf3-0d9051483e83 32511 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0e6b0 0xc003a0e6b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.107,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.132: INFO: Pod "webserver-deployment-c7997dcc8-7dfl7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7dfl7 webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-7dfl7 519bd4d1-6bc9-47d0-b010-4617f7e0ba08 32484 0 2020-09-21 15:44:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0e7d0 0xc003a0e7d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:172.30.195.224,StartTime:2020-09-21 15:44:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.195.224,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.133: INFO: Pod "webserver-deployment-c7997dcc8-cknwn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cknwn webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-cknwn a695def3-374f-4167-9e22-d188353f5695 32456 0 2020-09-21 15:44:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0e987 0xc003a0e988}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.107,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.107,PodIP:172.30.185.226,StartTime:2020-09-21 15:44:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.185.226,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.133: INFO: Pod "webserver-deployment-c7997dcc8-f7srr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-f7srr webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-f7srr 429a0b65-a012-447f-b138-a489fca0c5a5 32493 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0eb37 0xc003a0eb38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.133: INFO: Pod "webserver-deployment-c7997dcc8-gs8dd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gs8dd webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-gs8dd 5b2a84b1-a108-4f40-9635-4da788638404 32494 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0ec60 0xc003a0ec61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.133: INFO: Pod "webserver-deployment-c7997dcc8-hkk7j" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hkk7j webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-hkk7j f9764580-a555-4182-9e53-a181d7a67f06 32398 0 2020-09-21 15:44:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0ed80 0xc003a0ed81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:,StartTime:2020-09-21 15:44:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.133: INFO: Pod "webserver-deployment-c7997dcc8-jvdgt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-jvdgt webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-jvdgt 40585aa6-3834-4f30-a598-30b79e0c0f8e 32503 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0eef7 0xc003a0eef8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.133: INFO: Pod "webserver-deployment-c7997dcc8-nqbh8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nqbh8 webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-nqbh8 5b9ed2f0-9d48-4fe2-bf1e-171b307dc44b 32512 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0eff7 0xc003a0eff8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.134: INFO: Pod "webserver-deployment-c7997dcc8-pdtt2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pdtt2 webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-pdtt2 837d3ce3-84aa-49ea-a4d9-ec1ada3c4cd0 32502 0 2020-09-21 15:44:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0f120 0xc003a0f121}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.134: INFO: Pod "webserver-deployment-c7997dcc8-pxqn2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pxqn2 webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-pxqn2 b2b42d0b-d9a1-43ee-9558-d751e44c212a 32422 0 2020-09-21 15:44:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0f217 0xc003a0f218}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:,StartTime:2020-09-21 15:44:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 21 15:44:40.134: INFO: Pod "webserver-deployment-c7997dcc8-vh5dz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vh5dz webserver-deployment-c7997dcc8- deployment-2780 /api/v1/namespaces/deployment-2780/pods/webserver-deployment-c7997dcc8-vh5dz b7dcdd72-b890-4a90-80e4-bd70d026b747 32465 0 2020-09-21 15:44:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 6310a2c7-9a44-4058-9583-1ed7d6a86dbc 0xc003a0f397 0xc003a0f398}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nvpsh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nvpsh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nvpsh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.114,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:44:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.114,PodIP:172.30.21.32,StartTime:2020-09-21 15:44:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.21.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:44:40.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2780" for this suite.
Sep 21 15:44:50.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:44:50.535: INFO: namespace deployment-2780 deletion completed in 10.386263203s

• [SLOW TEST:16.982 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:44:50.535: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6137
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:44:50.851: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 21 15:44:50.882: INFO: Number of nodes with available pods: 0
Sep 21 15:44:50.882: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:44:51.905: INFO: Number of nodes with available pods: 0
Sep 21 15:44:51.905: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:44:52.907: INFO: Number of nodes with available pods: 2
Sep 21 15:44:52.907: INFO: Node 10.189.39.109 is running more than one daemon pod
Sep 21 15:44:53.904: INFO: Number of nodes with available pods: 3
Sep 21 15:44:53.904: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 21 15:44:53.978: INFO: Wrong image for pod: daemon-set-9qdkc. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:53.978: INFO: Wrong image for pod: daemon-set-bwqpf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:53.978: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:55.002: INFO: Wrong image for pod: daemon-set-9qdkc. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:55.002: INFO: Wrong image for pod: daemon-set-bwqpf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:55.002: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:56.003: INFO: Wrong image for pod: daemon-set-9qdkc. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:56.003: INFO: Pod daemon-set-9qdkc is not available
Sep 21 15:44:56.003: INFO: Wrong image for pod: daemon-set-bwqpf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:56.003: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:57.002: INFO: Wrong image for pod: daemon-set-bwqpf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:57.002: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:57.002: INFO: Pod daemon-set-pm5hj is not available
Sep 21 15:44:58.002: INFO: Wrong image for pod: daemon-set-bwqpf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:58.002: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:58.002: INFO: Pod daemon-set-pm5hj is not available
Sep 21 15:44:59.003: INFO: Wrong image for pod: daemon-set-bwqpf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:44:59.003: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:00.001: INFO: Wrong image for pod: daemon-set-bwqpf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:00.001: INFO: Pod daemon-set-bwqpf is not available
Sep 21 15:45:00.001: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:01.000: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:01.000: INFO: Pod daemon-set-mjgfj is not available
Sep 21 15:45:02.003: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:02.003: INFO: Pod daemon-set-mjgfj is not available
Sep 21 15:45:03.003: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:04.003: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:04.003: INFO: Pod daemon-set-kz9bj is not available
Sep 21 15:45:05.001: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:05.001: INFO: Pod daemon-set-kz9bj is not available
Sep 21 15:45:06.001: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:06.001: INFO: Pod daemon-set-kz9bj is not available
Sep 21 15:45:07.003: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:07.003: INFO: Pod daemon-set-kz9bj is not available
Sep 21 15:45:08.003: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:08.003: INFO: Pod daemon-set-kz9bj is not available
Sep 21 15:45:09.003: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:09.003: INFO: Pod daemon-set-kz9bj is not available
Sep 21 15:45:10.003: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:10.003: INFO: Pod daemon-set-kz9bj is not available
Sep 21 15:45:11.002: INFO: Wrong image for pod: daemon-set-kz9bj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 21 15:45:11.002: INFO: Pod daemon-set-kz9bj is not available
Sep 21 15:45:12.139: INFO: Pod daemon-set-7h6db is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 21 15:45:12.199: INFO: Number of nodes with available pods: 2
Sep 21 15:45:12.199: INFO: Node 10.189.39.109 is running more than one daemon pod
Sep 21 15:45:13.223: INFO: Number of nodes with available pods: 2
Sep 21 15:45:13.223: INFO: Node 10.189.39.109 is running more than one daemon pod
Sep 21 15:45:14.222: INFO: Number of nodes with available pods: 2
Sep 21 15:45:14.222: INFO: Node 10.189.39.109 is running more than one daemon pod
Sep 21 15:45:15.233: INFO: Number of nodes with available pods: 2
Sep 21 15:45:15.233: INFO: Node 10.189.39.109 is running more than one daemon pod
Sep 21 15:45:16.232: INFO: Number of nodes with available pods: 3
Sep 21 15:45:16.232: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6137, will wait for the garbage collector to delete the pods
Sep 21 15:45:16.363: INFO: Deleting DaemonSet.extensions daemon-set took: 20.493598ms
Sep 21 15:45:16.664: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.406861ms
Sep 21 15:45:28.277: INFO: Number of nodes with available pods: 0
Sep 21 15:45:28.277: INFO: Number of running nodes: 0, number of available pods: 0
Sep 21 15:45:28.287: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6137/daemonsets","resourceVersion":"33186"},"items":null}

Sep 21 15:45:28.297: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6137/pods","resourceVersion":"33186"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:45:28.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6137" for this suite.
Sep 21 15:45:36.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:45:36.757: INFO: namespace daemonsets-6137 deletion completed in 8.405648894s

• [SLOW TEST:46.222 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:45:36.758: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5052
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 21 15:45:37.574: INFO: Pod name wrapped-volume-race-bfcda577-217a-4f23-a537-23b624f21138: Found 0 pods out of 5
Sep 21 15:45:42.591: INFO: Pod name wrapped-volume-race-bfcda577-217a-4f23-a537-23b624f21138: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-bfcda577-217a-4f23-a537-23b624f21138 in namespace emptydir-wrapper-5052, will wait for the garbage collector to delete the pods
Sep 21 15:45:42.720: INFO: Deleting ReplicationController wrapped-volume-race-bfcda577-217a-4f23-a537-23b624f21138 took: 24.151678ms
Sep 21 15:45:43.020: INFO: Terminating ReplicationController wrapped-volume-race-bfcda577-217a-4f23-a537-23b624f21138 pods took: 300.270269ms
STEP: Creating RC which spawns configmap-volume pods
Sep 21 15:46:24.663: INFO: Pod name wrapped-volume-race-4c1755bc-a09e-4b49-b483-2b6242cdbf08: Found 0 pods out of 5
Sep 21 15:46:29.685: INFO: Pod name wrapped-volume-race-4c1755bc-a09e-4b49-b483-2b6242cdbf08: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4c1755bc-a09e-4b49-b483-2b6242cdbf08 in namespace emptydir-wrapper-5052, will wait for the garbage collector to delete the pods
Sep 21 15:46:29.808: INFO: Deleting ReplicationController wrapped-volume-race-4c1755bc-a09e-4b49-b483-2b6242cdbf08 took: 19.953829ms
Sep 21 15:46:30.108: INFO: Terminating ReplicationController wrapped-volume-race-4c1755bc-a09e-4b49-b483-2b6242cdbf08 pods took: 300.220867ms
STEP: Creating RC which spawns configmap-volume pods
Sep 21 15:47:14.650: INFO: Pod name wrapped-volume-race-b3fdbdbf-1227-4e3c-aa4b-90776a867700: Found 0 pods out of 5
Sep 21 15:47:19.665: INFO: Pod name wrapped-volume-race-b3fdbdbf-1227-4e3c-aa4b-90776a867700: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b3fdbdbf-1227-4e3c-aa4b-90776a867700 in namespace emptydir-wrapper-5052, will wait for the garbage collector to delete the pods
Sep 21 15:47:19.788: INFO: Deleting ReplicationController wrapped-volume-race-b3fdbdbf-1227-4e3c-aa4b-90776a867700 took: 19.45346ms
Sep 21 15:47:20.188: INFO: Terminating ReplicationController wrapped-volume-race-b3fdbdbf-1227-4e3c-aa4b-90776a867700 pods took: 400.273526ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:48:05.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5052" for this suite.
Sep 21 15:48:13.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:48:13.872: INFO: namespace emptydir-wrapper-5052 deletion completed in 8.341845303s

• [SLOW TEST:157.115 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:48:13.873: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-627
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-2804363d-e48e-451a-a8ba-44097f347fab
STEP: Creating secret with name secret-projected-all-test-volume-e411a76c-1f21-405c-b9d6-52bd88505d42
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 21 15:48:14.159: INFO: Waiting up to 5m0s for pod "projected-volume-e6c9b870-db16-42f3-8da9-8a0a9c02fe5e" in namespace "projected-627" to be "success or failure"
Sep 21 15:48:14.167: INFO: Pod "projected-volume-e6c9b870-db16-42f3-8da9-8a0a9c02fe5e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.097758ms
Sep 21 15:48:16.178: INFO: Pod "projected-volume-e6c9b870-db16-42f3-8da9-8a0a9c02fe5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019584045s
STEP: Saw pod success
Sep 21 15:48:16.179: INFO: Pod "projected-volume-e6c9b870-db16-42f3-8da9-8a0a9c02fe5e" satisfied condition "success or failure"
Sep 21 15:48:16.193: INFO: Trying to get logs from node 10.189.39.109 pod projected-volume-e6c9b870-db16-42f3-8da9-8a0a9c02fe5e container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 21 15:48:16.273: INFO: Waiting for pod projected-volume-e6c9b870-db16-42f3-8da9-8a0a9c02fe5e to disappear
Sep 21 15:48:16.281: INFO: Pod projected-volume-e6c9b870-db16-42f3-8da9-8a0a9c02fe5e no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:48:16.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-627" for this suite.
Sep 21 15:48:22.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:48:22.642: INFO: namespace projected-627 deletion completed in 6.347420795s

• [SLOW TEST:8.769 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:48:22.642: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2442
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 21 15:48:22.878: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 21 15:48:22.921: INFO: Waiting for terminating namespaces to be deleted...
Sep 21 15:48:22.932: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.107 before test
Sep 21 15:48:23.011: INFO: catalog-operator-67cbc5d959-dq2t6 from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.012: INFO: 	Container catalog-operator ready: true, restart count 0
Sep 21 15:48:23.012: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-wl754 from kube-system started at 2020-09-21 15:34:03 +0000 UTC (4 container statuses recorded)
Sep 21 15:48:23.012: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 15:48:23.012: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 15:48:23.012: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 15:48:23.012: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 15:48:23.012: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pk8wt from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:48:23.012: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 15:48:23.012: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 15:48:23.012: INFO: vpn-79845b6f9d-jkrfr from kube-system started at 2020-09-21 13:20:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.012: INFO: 	Container vpn ready: true, restart count 0
Sep 21 15:48:23.012: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-99989 from ibm-system started at 2020-09-21 15:34:03 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.012: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
Sep 21 15:48:23.012: INFO: ibm-master-proxy-static-10.189.39.107 from kube-system started at 2020-09-21 13:10:54 +0000 UTC (2 container statuses recorded)
Sep 21 15:48:23.012: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 15:48:23.012: INFO: 	Container pause ready: true, restart count 0
Sep 21 15:48:23.012: INFO: ibm-keepalived-watcher-zkkcm from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.012: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 15:48:23.012: INFO: dashboard-metrics-scraper-76756886dc-mkkzv from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.013: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 21 15:48:23.013: INFO: ibm-storage-watcher-69664bb666-tt4h6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.013: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Sep 21 15:48:23.013: INFO: coredns-autoscaler-65c89858bf-nbnlc from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.013: INFO: 	Container autoscaler ready: true, restart count 0
Sep 21 15:48:23.013: INFO: kubernetes-dashboard-5977b5969-2nxvq from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.013: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 21 15:48:23.013: INFO: sonobuoy-e2e-job-6e9ba11f9ded426e from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:48:23.013: INFO: 	Container e2e ready: true, restart count 0
Sep 21 15:48:23.013: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 15:48:23.013: INFO: metrics-server-c86549c5-x7xfd from kube-system started at 2020-09-21 13:11:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:48:23.013: INFO: 	Container metrics-server ready: true, restart count 0
Sep 21 15:48:23.013: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Sep 21 15:48:23.013: INFO: calico-node-bsqdv from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.013: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 15:48:23.013: INFO: ibm-file-plugin-75656db994-jw4r2 from kube-system started at 2020-09-21 13:11:19 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.013: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Sep 21 15:48:23.013: INFO: coredns-55db5d97fb-x5w82 from kube-system started at 2020-09-21 13:20:46 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.013: INFO: 	Container coredns ready: true, restart count 0
Sep 21 15:48:23.013: INFO: calico-kube-controllers-66c5f69b5f-cbmg6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.014: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 21 15:48:23.014: INFO: olm-operator-6f74dfc868-pmh8h from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.014: INFO: 	Container olm-operator ready: true, restart count 0
Sep 21 15:48:23.014: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.109 before test
Sep 21 15:48:23.054: INFO: addon-catalog-source-zchlp from ibm-system started at 2020-09-21 13:13:49 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.054: INFO: 	Container configmap-registry-server ready: true, restart count 0
Sep 21 15:48:23.054: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pgfzj from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:48:23.054: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 15:48:23.054: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 15:48:23.054: INFO: ibm-master-proxy-static-10.189.39.109 from kube-system started at 2020-09-21 13:12:01 +0000 UTC (2 container statuses recorded)
Sep 21 15:48:23.054: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 15:48:23.054: INFO: 	Container pause ready: true, restart count 0
Sep 21 15:48:23.054: INFO: calico-node-pplqw from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.054: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 15:48:23.054: INFO: ibm-keepalived-watcher-fb29r from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.054: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 15:48:23.054: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.114 before test
Sep 21 15:48:23.115: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-kgtrl from kube-system started at 2020-09-21 13:25:35 +0000 UTC (4 container statuses recorded)
Sep 21 15:48:23.116: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 15:48:23.116: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 15:48:23.116: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 15:48:23.116: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 15:48:23.116: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-ntgzw from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:48:23.116: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 15:48:23.116: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 15:48:23.116: INFO: ibm-master-proxy-static-10.189.39.114 from kube-system started at 2020-09-21 13:11:38 +0000 UTC (2 container statuses recorded)
Sep 21 15:48:23.116: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 15:48:23.116: INFO: 	Container pause ready: true, restart count 0
Sep 21 15:48:23.116: INFO: ibm-keepalived-watcher-4r8qr from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.116: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 15:48:23.116: INFO: coredns-55db5d97fb-z9cdn from kube-system started at 2020-09-21 13:20:47 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.116: INFO: 	Container coredns ready: true, restart count 0
Sep 21 15:48:23.116: INFO: calico-node-xtntd from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.116: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 15:48:23.116: INFO: sonobuoy from sonobuoy started at 2020-09-21 14:34:24 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.116: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 21 15:48:23.116: INFO: coredns-55db5d97fb-wkf29 from kube-system started at 2020-09-21 15:39:03 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.116: INFO: 	Container coredns ready: true, restart count 0
Sep 21 15:48:23.117: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-pp552 from ibm-system started at 2020-09-21 13:18:25 +0000 UTC (1 container statuses recorded)
Sep 21 15:48:23.117: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 10.189.39.107
STEP: verifying the node has the label node 10.189.39.109
STEP: verifying the node has the label node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod addon-catalog-source-zchlp requesting resource cpu=10m on Node 10.189.39.109
Sep 21 15:48:23.261: INFO: Pod catalog-operator-67cbc5d959-dq2t6 requesting resource cpu=10m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod ibm-cloud-provider-ip-169-63-175-234-749787685c-99989 requesting resource cpu=5m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod ibm-cloud-provider-ip-169-63-175-234-749787685c-pp552 requesting resource cpu=5m on Node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod olm-operator-6f74dfc868-pmh8h requesting resource cpu=10m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod calico-kube-controllers-66c5f69b5f-cbmg6 requesting resource cpu=10m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod calico-node-bsqdv requesting resource cpu=250m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod calico-node-pplqw requesting resource cpu=250m on Node 10.189.39.109
Sep 21 15:48:23.261: INFO: Pod calico-node-xtntd requesting resource cpu=250m on Node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod coredns-55db5d97fb-wkf29 requesting resource cpu=100m on Node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod coredns-55db5d97fb-x5w82 requesting resource cpu=100m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod coredns-55db5d97fb-z9cdn requesting resource cpu=100m on Node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod coredns-autoscaler-65c89858bf-nbnlc requesting resource cpu=20m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod dashboard-metrics-scraper-76756886dc-mkkzv requesting resource cpu=1m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod ibm-file-plugin-75656db994-jw4r2 requesting resource cpu=50m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod ibm-keepalived-watcher-4r8qr requesting resource cpu=5m on Node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod ibm-keepalived-watcher-fb29r requesting resource cpu=5m on Node 10.189.39.109
Sep 21 15:48:23.261: INFO: Pod ibm-keepalived-watcher-zkkcm requesting resource cpu=5m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod ibm-master-proxy-static-10.189.39.107 requesting resource cpu=25m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod ibm-master-proxy-static-10.189.39.109 requesting resource cpu=25m on Node 10.189.39.109
Sep 21 15:48:23.261: INFO: Pod ibm-master-proxy-static-10.189.39.114 requesting resource cpu=25m on Node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod ibm-storage-watcher-69664bb666-tt4h6 requesting resource cpu=50m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod kubernetes-dashboard-5977b5969-2nxvq requesting resource cpu=50m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod metrics-server-c86549c5-x7xfd requesting resource cpu=121m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-kgtrl requesting resource cpu=10m on Node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-wl754 requesting resource cpu=10m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod vpn-79845b6f9d-jkrfr requesting resource cpu=5m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod sonobuoy-e2e-job-6e9ba11f9ded426e requesting resource cpu=0m on Node 10.189.39.107
Sep 21 15:48:23.261: INFO: Pod sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-ntgzw requesting resource cpu=0m on Node 10.189.39.114
Sep 21 15:48:23.261: INFO: Pod sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pgfzj requesting resource cpu=0m on Node 10.189.39.109
Sep 21 15:48:23.261: INFO: Pod sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pk8wt requesting resource cpu=0m on Node 10.189.39.107
STEP: Starting Pods to consume most of the cluster CPU.
Sep 21 15:48:23.261: INFO: Creating a pod which consumes cpu=2231m on Node 10.189.39.107
Sep 21 15:48:23.280: INFO: Creating a pod which consumes cpu=2534m on Node 10.189.39.109
Sep 21 15:48:23.293: INFO: Creating a pod which consumes cpu=2390m on Node 10.189.39.114
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-41bfd193-33b9-4663-99f0-6b06b072483c.1636d72c66ecf52e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2442/filler-pod-41bfd193-33b9-4663-99f0-6b06b072483c to 10.189.39.107]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-41bfd193-33b9-4663-99f0-6b06b072483c.1636d72ca1c3380c], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-41bfd193-33b9-4663-99f0-6b06b072483c.1636d72cb3743275], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-41bfd193-33b9-4663-99f0-6b06b072483c.1636d72cb664d6bb], Reason = [Created], Message = [Created container filler-pod-41bfd193-33b9-4663-99f0-6b06b072483c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-41bfd193-33b9-4663-99f0-6b06b072483c.1636d72cc06cf908], Reason = [Started], Message = [Started container filler-pod-41bfd193-33b9-4663-99f0-6b06b072483c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2aa081e-794d-45d6-9951-c825f9aa922a.1636d72c67a569e6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2442/filler-pod-d2aa081e-794d-45d6-9951-c825f9aa922a to 10.189.39.109]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2aa081e-794d-45d6-9951-c825f9aa922a.1636d72ca9b1f637], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2aa081e-794d-45d6-9951-c825f9aa922a.1636d72cadd0bf53], Reason = [Created], Message = [Created container filler-pod-d2aa081e-794d-45d6-9951-c825f9aa922a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2aa081e-794d-45d6-9951-c825f9aa922a.1636d72cb98c566b], Reason = [Started], Message = [Started container filler-pod-d2aa081e-794d-45d6-9951-c825f9aa922a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f668ee62-8614-487b-8581-d65de263556f.1636d72c687d59e6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2442/filler-pod-f668ee62-8614-487b-8581-d65de263556f to 10.189.39.114]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f668ee62-8614-487b-8581-d65de263556f.1636d72ca15bc076], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f668ee62-8614-487b-8581-d65de263556f.1636d72cb3a92b24], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f668ee62-8614-487b-8581-d65de263556f.1636d72cb71b3f18], Reason = [Created], Message = [Created container filler-pod-f668ee62-8614-487b-8581-d65de263556f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f668ee62-8614-487b-8581-d65de263556f.1636d72cc02111b6], Reason = [Started], Message = [Started container filler-pod-f668ee62-8614-487b-8581-d65de263556f]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1636d72cf15dc886], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.189.39.107
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.189.39.109
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.189.39.114
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:48:26.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2442" for this suite.
Sep 21 15:48:34.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:48:35.107: INFO: namespace sched-pred-2442 deletion completed in 8.367031513s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:12.465 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:48:35.107: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-8929
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-8929
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8929
STEP: Deleting pre-stop pod
Sep 21 15:48:44.461: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:48:44.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8929" for this suite.
Sep 21 15:49:30.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:49:31.031: INFO: namespace prestop-8929 deletion completed in 46.541369523s

• [SLOW TEST:55.925 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:49:31.032: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7427
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:49:31.324: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddb80710-47c2-497f-8550-dccfb2c47766" in namespace "downward-api-7427" to be "success or failure"
Sep 21 15:49:31.333: INFO: Pod "downwardapi-volume-ddb80710-47c2-497f-8550-dccfb2c47766": Phase="Pending", Reason="", readiness=false. Elapsed: 9.602927ms
Sep 21 15:49:33.344: INFO: Pod "downwardapi-volume-ddb80710-47c2-497f-8550-dccfb2c47766": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020568878s
STEP: Saw pod success
Sep 21 15:49:33.344: INFO: Pod "downwardapi-volume-ddb80710-47c2-497f-8550-dccfb2c47766" satisfied condition "success or failure"
Sep 21 15:49:33.353: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-ddb80710-47c2-497f-8550-dccfb2c47766 container client-container: <nil>
STEP: delete the pod
Sep 21 15:49:33.414: INFO: Waiting for pod downwardapi-volume-ddb80710-47c2-497f-8550-dccfb2c47766 to disappear
Sep 21 15:49:33.421: INFO: Pod downwardapi-volume-ddb80710-47c2-497f-8550-dccfb2c47766 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:49:33.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7427" for this suite.
Sep 21 15:49:39.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:49:39.780: INFO: namespace downward-api-7427 deletion completed in 6.342010282s

• [SLOW TEST:8.748 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:49:39.781: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8249
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:49:57.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8249" for this suite.
Sep 21 15:50:03.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:50:03.500: INFO: namespace resourcequota-8249 deletion completed in 6.336572233s

• [SLOW TEST:23.719 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:50:03.502: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9874
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 15:50:04.183: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 15:50:06.208: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300204, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300204, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300204, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300204, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 15:50:09.248: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:50:09.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9874" for this suite.
Sep 21 15:50:15.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:50:15.762: INFO: namespace webhook-9874 deletion completed in 6.35234238s
STEP: Destroying namespace "webhook-9874-markers" for this suite.
Sep 21 15:50:21.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:50:22.620: INFO: namespace webhook-9874-markers deletion completed in 6.857450038s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.166 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:50:22.669: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6407
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 15:50:23.518: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Sep 21 15:50:25.542: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300223, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300223, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300223, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300223, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 15:50:28.575: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:50:28.586: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8264-crds.webhook.example.com via the AdmissionRegistration API
Sep 21 15:50:39.176: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:50:40.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6407" for this suite.
Sep 21 15:50:46.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:50:46.444: INFO: namespace webhook-6407 deletion completed in 6.330601534s
STEP: Destroying namespace "webhook-6407-markers" for this suite.
Sep 21 15:50:52.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:50:52.783: INFO: namespace webhook-6407-markers deletion completed in 6.339282322s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.161 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:50:52.830: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3501
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-fb330b14-1e79-44ca-8486-541ff86102bc
STEP: Creating a pod to test consume secrets
Sep 21 15:50:53.122: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-25b47a1c-3163-4b06-92e2-2c37d0d1fdfe" in namespace "projected-3501" to be "success or failure"
Sep 21 15:50:53.133: INFO: Pod "pod-projected-secrets-25b47a1c-3163-4b06-92e2-2c37d0d1fdfe": Phase="Pending", Reason="", readiness=false. Elapsed: 10.796311ms
Sep 21 15:50:55.143: INFO: Pod "pod-projected-secrets-25b47a1c-3163-4b06-92e2-2c37d0d1fdfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021336682s
Sep 21 15:50:57.154: INFO: Pod "pod-projected-secrets-25b47a1c-3163-4b06-92e2-2c37d0d1fdfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032019077s
STEP: Saw pod success
Sep 21 15:50:57.154: INFO: Pod "pod-projected-secrets-25b47a1c-3163-4b06-92e2-2c37d0d1fdfe" satisfied condition "success or failure"
Sep 21 15:50:57.165: INFO: Trying to get logs from node 10.189.39.109 pod pod-projected-secrets-25b47a1c-3163-4b06-92e2-2c37d0d1fdfe container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 21 15:50:57.212: INFO: Waiting for pod pod-projected-secrets-25b47a1c-3163-4b06-92e2-2c37d0d1fdfe to disappear
Sep 21 15:50:57.219: INFO: Pod pod-projected-secrets-25b47a1c-3163-4b06-92e2-2c37d0d1fdfe no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:50:57.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3501" for this suite.
Sep 21 15:51:03.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:51:03.584: INFO: namespace projected-3501 deletion completed in 6.350382521s

• [SLOW TEST:10.754 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:51:03.585: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 21 15:51:03.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-3725'
Sep 21 15:51:04.020: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 21 15:51:04.020: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Sep 21 15:51:08.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete deployment e2e-test-httpd-deployment --namespace=kubectl-3725'
Sep 21 15:51:08.142: INFO: stderr: ""
Sep 21 15:51:08.142: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:51:08.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3725" for this suite.
Sep 21 15:51:14.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:51:14.490: INFO: namespace kubectl-3725 deletion completed in 6.332421657s

• [SLOW TEST:10.905 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:51:14.490: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4920
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:51:16.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4920" for this suite.
Sep 21 15:51:22.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:51:23.241: INFO: namespace emptydir-wrapper-4920 deletion completed in 6.343826608s

• [SLOW TEST:8.751 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:51:23.243: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6209
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Sep 21 15:51:23.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-6209'
Sep 21 15:51:23.892: INFO: stderr: ""
Sep 21 15:51:23.892: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 15:51:23.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6209'
Sep 21 15:51:23.966: INFO: stderr: ""
Sep 21 15:51:23.966: INFO: stdout: "update-demo-nautilus-6hq9q update-demo-nautilus-lbgk5 "
Sep 21 15:51:23.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-6hq9q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6209'
Sep 21 15:51:24.044: INFO: stderr: ""
Sep 21 15:51:24.044: INFO: stdout: ""
Sep 21 15:51:24.045: INFO: update-demo-nautilus-6hq9q is created but not running
Sep 21 15:51:29.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6209'
Sep 21 15:51:29.139: INFO: stderr: ""
Sep 21 15:51:29.139: INFO: stdout: "update-demo-nautilus-6hq9q update-demo-nautilus-lbgk5 "
Sep 21 15:51:29.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-6hq9q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6209'
Sep 21 15:51:29.218: INFO: stderr: ""
Sep 21 15:51:29.218: INFO: stdout: "true"
Sep 21 15:51:29.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-6hq9q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6209'
Sep 21 15:51:29.306: INFO: stderr: ""
Sep 21 15:51:29.306: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 15:51:29.306: INFO: validating pod update-demo-nautilus-6hq9q
Sep 21 15:51:29.327: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 15:51:29.327: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 15:51:29.327: INFO: update-demo-nautilus-6hq9q is verified up and running
Sep 21 15:51:29.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-lbgk5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6209'
Sep 21 15:51:29.402: INFO: stderr: ""
Sep 21 15:51:29.402: INFO: stdout: "true"
Sep 21 15:51:29.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-lbgk5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6209'
Sep 21 15:51:29.490: INFO: stderr: ""
Sep 21 15:51:29.490: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 15:51:29.490: INFO: validating pod update-demo-nautilus-lbgk5
Sep 21 15:51:29.510: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 15:51:29.510: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 15:51:29.510: INFO: update-demo-nautilus-lbgk5 is verified up and running
STEP: rolling-update to new replication controller
Sep 21 15:51:29.513: INFO: scanned /root for discovery docs: <nil>
Sep 21 15:51:29.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6209'
Sep 21 15:51:52.167: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 21 15:51:52.167: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 15:51:52.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6209'
Sep 21 15:51:52.266: INFO: stderr: ""
Sep 21 15:51:52.266: INFO: stdout: "update-demo-kitten-4v4mj update-demo-kitten-lmz7v "
Sep 21 15:51:52.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-kitten-4v4mj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6209'
Sep 21 15:51:52.333: INFO: stderr: ""
Sep 21 15:51:52.333: INFO: stdout: "true"
Sep 21 15:51:52.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-kitten-4v4mj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6209'
Sep 21 15:51:52.411: INFO: stderr: ""
Sep 21 15:51:52.411: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 21 15:51:52.411: INFO: validating pod update-demo-kitten-4v4mj
Sep 21 15:51:52.446: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 21 15:51:52.446: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 21 15:51:52.446: INFO: update-demo-kitten-4v4mj is verified up and running
Sep 21 15:51:52.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-kitten-lmz7v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6209'
Sep 21 15:51:52.521: INFO: stderr: ""
Sep 21 15:51:52.522: INFO: stdout: "true"
Sep 21 15:51:52.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-kitten-lmz7v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6209'
Sep 21 15:51:52.606: INFO: stderr: ""
Sep 21 15:51:52.607: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 21 15:51:52.607: INFO: validating pod update-demo-kitten-lmz7v
Sep 21 15:51:52.638: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 21 15:51:52.638: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 21 15:51:52.638: INFO: update-demo-kitten-lmz7v is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:51:52.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6209" for this suite.
Sep 21 15:52:22.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:52:23.064: INFO: namespace kubectl-6209 deletion completed in 30.413641667s

• [SLOW TEST:59.821 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:52:23.068: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:52:25.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5417" for this suite.
Sep 21 15:52:43.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:52:43.783: INFO: namespace containers-5417 deletion completed in 18.401030004s

• [SLOW TEST:20.716 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:52:43.784: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2592
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-6c089ebc-623d-4a7a-90a2-3e9bbf807c41
STEP: Creating a pod to test consume configMaps
Sep 21 15:52:44.064: INFO: Waiting up to 5m0s for pod "pod-configmaps-36465c6b-b897-41c1-af2b-697b0bb11cc0" in namespace "configmap-2592" to be "success or failure"
Sep 21 15:52:44.072: INFO: Pod "pod-configmaps-36465c6b-b897-41c1-af2b-697b0bb11cc0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.750238ms
Sep 21 15:52:46.083: INFO: Pod "pod-configmaps-36465c6b-b897-41c1-af2b-697b0bb11cc0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019280173s
STEP: Saw pod success
Sep 21 15:52:46.083: INFO: Pod "pod-configmaps-36465c6b-b897-41c1-af2b-697b0bb11cc0" satisfied condition "success or failure"
Sep 21 15:52:46.092: INFO: Trying to get logs from node 10.189.39.109 pod pod-configmaps-36465c6b-b897-41c1-af2b-697b0bb11cc0 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 15:52:46.141: INFO: Waiting for pod pod-configmaps-36465c6b-b897-41c1-af2b-697b0bb11cc0 to disappear
Sep 21 15:52:46.148: INFO: Pod pod-configmaps-36465c6b-b897-41c1-af2b-697b0bb11cc0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:52:46.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2592" for this suite.
Sep 21 15:52:52.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:52:52.498: INFO: namespace configmap-2592 deletion completed in 6.335282737s

• [SLOW TEST:8.714 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:52:52.498: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 21 15:52:52.745: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 21 15:52:52.782: INFO: Waiting for terminating namespaces to be deleted...
Sep 21 15:52:52.792: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.107 before test
Sep 21 15:52:52.855: INFO: ibm-master-proxy-static-10.189.39.107 from kube-system started at 2020-09-21 13:10:54 +0000 UTC (2 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 15:52:52.856: INFO: 	Container pause ready: true, restart count 0
Sep 21 15:52:52.856: INFO: ibm-keepalived-watcher-zkkcm from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 15:52:52.856: INFO: dashboard-metrics-scraper-76756886dc-mkkzv from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 21 15:52:52.856: INFO: ibm-storage-watcher-69664bb666-tt4h6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Sep 21 15:52:52.856: INFO: vpn-79845b6f9d-jkrfr from kube-system started at 2020-09-21 13:20:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container vpn ready: true, restart count 0
Sep 21 15:52:52.856: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-99989 from ibm-system started at 2020-09-21 15:34:03 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
Sep 21 15:52:52.856: INFO: coredns-autoscaler-65c89858bf-nbnlc from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container autoscaler ready: true, restart count 0
Sep 21 15:52:52.856: INFO: kubernetes-dashboard-5977b5969-2nxvq from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 21 15:52:52.856: INFO: sonobuoy-e2e-job-6e9ba11f9ded426e from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container e2e ready: true, restart count 0
Sep 21 15:52:52.856: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 15:52:52.856: INFO: metrics-server-c86549c5-x7xfd from kube-system started at 2020-09-21 13:11:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container metrics-server ready: true, restart count 0
Sep 21 15:52:52.856: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Sep 21 15:52:52.856: INFO: calico-node-bsqdv from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 15:52:52.856: INFO: ibm-file-plugin-75656db994-jw4r2 from kube-system started at 2020-09-21 13:11:19 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Sep 21 15:52:52.856: INFO: coredns-55db5d97fb-x5w82 from kube-system started at 2020-09-21 13:20:46 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container coredns ready: true, restart count 0
Sep 21 15:52:52.856: INFO: calico-kube-controllers-66c5f69b5f-cbmg6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 21 15:52:52.856: INFO: olm-operator-6f74dfc868-pmh8h from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container olm-operator ready: true, restart count 0
Sep 21 15:52:52.856: INFO: catalog-operator-67cbc5d959-dq2t6 from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container catalog-operator ready: true, restart count 0
Sep 21 15:52:52.856: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-wl754 from kube-system started at 2020-09-21 15:34:03 +0000 UTC (4 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 15:52:52.856: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 15:52:52.856: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 15:52:52.856: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 15:52:52.856: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pk8wt from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:52:52.856: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 15:52:52.856: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 15:52:52.856: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.109 before test
Sep 21 15:52:52.882: INFO: ibm-master-proxy-static-10.189.39.109 from kube-system started at 2020-09-21 13:12:01 +0000 UTC (2 container statuses recorded)
Sep 21 15:52:52.882: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 15:52:52.882: INFO: 	Container pause ready: true, restart count 0
Sep 21 15:52:52.882: INFO: calico-node-pplqw from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.882: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 15:52:52.882: INFO: ibm-keepalived-watcher-fb29r from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.882: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 15:52:52.882: INFO: addon-catalog-source-zchlp from ibm-system started at 2020-09-21 13:13:49 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.882: INFO: 	Container configmap-registry-server ready: true, restart count 0
Sep 21 15:52:52.882: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pgfzj from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:52:52.882: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 15:52:52.882: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 15:52:52.882: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.114 before test
Sep 21 15:52:52.934: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-pp552 from ibm-system started at 2020-09-21 13:18:25 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.934: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
Sep 21 15:52:52.934: INFO: sonobuoy from sonobuoy started at 2020-09-21 14:34:24 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.934: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 21 15:52:52.934: INFO: coredns-55db5d97fb-wkf29 from kube-system started at 2020-09-21 15:39:03 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.934: INFO: 	Container coredns ready: true, restart count 0
Sep 21 15:52:52.934: INFO: ibm-master-proxy-static-10.189.39.114 from kube-system started at 2020-09-21 13:11:38 +0000 UTC (2 container statuses recorded)
Sep 21 15:52:52.934: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 15:52:52.934: INFO: 	Container pause ready: true, restart count 0
Sep 21 15:52:52.934: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-kgtrl from kube-system started at 2020-09-21 13:25:35 +0000 UTC (4 container statuses recorded)
Sep 21 15:52:52.934: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 15:52:52.934: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 15:52:52.934: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 15:52:52.934: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 15:52:52.934: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-ntgzw from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 15:52:52.934: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 15:52:52.934: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 15:52:52.934: INFO: calico-node-xtntd from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.934: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 15:52:52.934: INFO: ibm-keepalived-watcher-4r8qr from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.934: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 15:52:52.934: INFO: coredns-55db5d97fb-z9cdn from kube-system started at 2020-09-21 13:20:47 +0000 UTC (1 container statuses recorded)
Sep 21 15:52:52.934: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9bf8938b-dcf0-4653-b53b-19e78d56ef11 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-9bf8938b-dcf0-4653-b53b-19e78d56ef11 off the node 10.189.39.109
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9bf8938b-dcf0-4653-b53b-19e78d56ef11
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:52:57.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1536" for this suite.
Sep 21 15:53:15.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:53:15.491: INFO: namespace sched-pred-1536 deletion completed in 18.382949681s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:22.993 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:53:15.491: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9442
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 21 15:53:23.831: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 21 15:53:23.840: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 21 15:53:25.840: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 21 15:53:25.858: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 21 15:53:27.840: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 21 15:53:27.850: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:53:27.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9442" for this suite.
Sep 21 15:53:57.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:53:58.254: INFO: namespace container-lifecycle-hook-9442 deletion completed in 30.361069282s

• [SLOW TEST:42.763 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:53:58.254: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1307
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Sep 21 15:53:58.495: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 15:54:01.450: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:54:13.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1307" for this suite.
Sep 21 15:54:19.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:54:19.664: INFO: namespace crd-publish-openapi-1307 deletion completed in 6.351107479s

• [SLOW TEST:21.410 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:54:19.666: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:54:19.933: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4d2a84a-13d2-4f41-89be-200b85b3e3f4" in namespace "downward-api-1945" to be "success or failure"
Sep 21 15:54:19.954: INFO: Pod "downwardapi-volume-b4d2a84a-13d2-4f41-89be-200b85b3e3f4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.221794ms
Sep 21 15:54:21.964: INFO: Pod "downwardapi-volume-b4d2a84a-13d2-4f41-89be-200b85b3e3f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030998426s
Sep 21 15:54:23.973: INFO: Pod "downwardapi-volume-b4d2a84a-13d2-4f41-89be-200b85b3e3f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040129687s
STEP: Saw pod success
Sep 21 15:54:23.973: INFO: Pod "downwardapi-volume-b4d2a84a-13d2-4f41-89be-200b85b3e3f4" satisfied condition "success or failure"
Sep 21 15:54:23.982: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-b4d2a84a-13d2-4f41-89be-200b85b3e3f4 container client-container: <nil>
STEP: delete the pod
Sep 21 15:54:24.041: INFO: Waiting for pod downwardapi-volume-b4d2a84a-13d2-4f41-89be-200b85b3e3f4 to disappear
Sep 21 15:54:24.051: INFO: Pod downwardapi-volume-b4d2a84a-13d2-4f41-89be-200b85b3e3f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:54:24.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1945" for this suite.
Sep 21 15:54:30.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:54:30.423: INFO: namespace downward-api-1945 deletion completed in 6.347216789s

• [SLOW TEST:10.757 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:54:30.424: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 21 15:54:30.700: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4443 /api/v1/namespaces/watch-4443/configmaps/e2e-watch-test-watch-closed 2fce58c0-a286-43bd-8ff9-1b977cb09e5a 35513 0 2020-09-21 15:54:30 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 21 15:54:30.700: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4443 /api/v1/namespaces/watch-4443/configmaps/e2e-watch-test-watch-closed 2fce58c0-a286-43bd-8ff9-1b977cb09e5a 35514 0 2020-09-21 15:54:30 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 21 15:54:30.741: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4443 /api/v1/namespaces/watch-4443/configmaps/e2e-watch-test-watch-closed 2fce58c0-a286-43bd-8ff9-1b977cb09e5a 35515 0 2020-09-21 15:54:30 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 21 15:54:30.741: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4443 /api/v1/namespaces/watch-4443/configmaps/e2e-watch-test-watch-closed 2fce58c0-a286-43bd-8ff9-1b977cb09e5a 35516 0 2020-09-21 15:54:30 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:54:30.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4443" for this suite.
Sep 21 15:54:36.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:54:37.102: INFO: namespace watch-4443 deletion completed in 6.34872546s

• [SLOW TEST:6.679 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:54:37.104: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6368
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:54:37.411: INFO: Create a RollingUpdate DaemonSet
Sep 21 15:54:37.422: INFO: Check that daemon pods launch on every node of the cluster
Sep 21 15:54:37.443: INFO: Number of nodes with available pods: 0
Sep 21 15:54:37.443: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:54:38.464: INFO: Number of nodes with available pods: 0
Sep 21 15:54:38.464: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 15:54:39.464: INFO: Number of nodes with available pods: 3
Sep 21 15:54:39.464: INFO: Number of running nodes: 3, number of available pods: 3
Sep 21 15:54:39.464: INFO: Update the DaemonSet to trigger a rollout
Sep 21 15:54:39.483: INFO: Updating DaemonSet daemon-set
Sep 21 15:54:52.532: INFO: Roll back the DaemonSet before rollout is complete
Sep 21 15:54:52.552: INFO: Updating DaemonSet daemon-set
Sep 21 15:54:52.552: INFO: Make sure DaemonSet rollback is complete
Sep 21 15:54:52.560: INFO: Wrong image for pod: daemon-set-q7t47. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 21 15:54:52.560: INFO: Pod daemon-set-q7t47 is not available
Sep 21 15:54:53.581: INFO: Wrong image for pod: daemon-set-q7t47. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 21 15:54:53.581: INFO: Pod daemon-set-q7t47 is not available
Sep 21 15:54:54.580: INFO: Pod daemon-set-9w86n is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6368, will wait for the garbage collector to delete the pods
Sep 21 15:54:54.683: INFO: Deleting DaemonSet.extensions daemon-set took: 17.064002ms
Sep 21 15:54:54.983: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.238603ms
Sep 21 15:55:04.395: INFO: Number of nodes with available pods: 0
Sep 21 15:55:04.395: INFO: Number of running nodes: 0, number of available pods: 0
Sep 21 15:55:04.405: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6368/daemonsets","resourceVersion":"35692"},"items":null}

Sep 21 15:55:04.416: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6368/pods","resourceVersion":"35692"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:55:04.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6368" for this suite.
Sep 21 15:55:12.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:55:12.855: INFO: namespace daemonsets-6368 deletion completed in 8.352666977s

• [SLOW TEST:35.751 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:55:12.855: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1563
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 15:55:13.128: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e3419c60-9925-4a1f-a25f-1ff924e31e4d" in namespace "projected-1563" to be "success or failure"
Sep 21 15:55:13.137: INFO: Pod "downwardapi-volume-e3419c60-9925-4a1f-a25f-1ff924e31e4d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.400441ms
Sep 21 15:55:15.148: INFO: Pod "downwardapi-volume-e3419c60-9925-4a1f-a25f-1ff924e31e4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020119304s
Sep 21 15:55:17.162: INFO: Pod "downwardapi-volume-e3419c60-9925-4a1f-a25f-1ff924e31e4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033872092s
STEP: Saw pod success
Sep 21 15:55:17.162: INFO: Pod "downwardapi-volume-e3419c60-9925-4a1f-a25f-1ff924e31e4d" satisfied condition "success or failure"
Sep 21 15:55:17.170: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-e3419c60-9925-4a1f-a25f-1ff924e31e4d container client-container: <nil>
STEP: delete the pod
Sep 21 15:55:17.218: INFO: Waiting for pod downwardapi-volume-e3419c60-9925-4a1f-a25f-1ff924e31e4d to disappear
Sep 21 15:55:17.228: INFO: Pod downwardapi-volume-e3419c60-9925-4a1f-a25f-1ff924e31e4d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:55:17.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1563" for this suite.
Sep 21 15:55:23.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:55:23.579: INFO: namespace projected-1563 deletion completed in 6.339242826s

• [SLOW TEST:10.723 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:55:23.579: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 21 15:55:23.855: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:55:31.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7203" for this suite.
Sep 21 15:55:37.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:55:38.154: INFO: namespace pods-7203 deletion completed in 6.409949409s

• [SLOW TEST:14.575 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:55:38.154: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8181
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:55:38.409: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 21 15:55:38.427: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 21 15:55:43.437: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 21 15:55:43.437: INFO: Creating deployment "test-rolling-update-deployment"
Sep 21 15:55:43.447: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 21 15:55:43.466: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 21 15:55:45.485: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 21 15:55:45.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300543, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300543, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300543, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300543, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 15:55:47.503: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 21 15:55:47.532: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-8181 /apis/apps/v1/namespaces/deployment-8181/deployments/test-rolling-update-deployment e9313371-a298-4f52-814a-83489ac1f090 35915 1 2020-09-21 15:55:43 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00625d058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-09-21 15:55:43 +0000 UTC,LastTransitionTime:2020-09-21 15:55:43 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-09-21 15:55:45 +0000 UTC,LastTransitionTime:2020-09-21 15:55:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 21 15:55:47.541: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-8181 /apis/apps/v1/namespaces/deployment-8181/replicasets/test-rolling-update-deployment-55d946486 f0d663b6-7809-4e11-86e0-600895a4eab3 35904 1 2020-09-21 15:55:43 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment e9313371-a298-4f52-814a-83489ac1f090 0xc00625da70 0xc00625da71}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00625db18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 21 15:55:47.541: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 21 15:55:47.541: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-8181 /apis/apps/v1/namespaces/deployment-8181/replicasets/test-rolling-update-controller 6c6139f9-13e8-4e60-a48e-c7970e343d5d 35913 2 2020-09-21 15:55:38 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment e9313371-a298-4f52-814a-83489ac1f090 0xc00625d837 0xc00625d838}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00625d8c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 15:55:47.553: INFO: Pod "test-rolling-update-deployment-55d946486-lw7df" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-lw7df test-rolling-update-deployment-55d946486- deployment-8181 /api/v1/namespaces/deployment-8181/pods/test-rolling-update-deployment-55d946486-lw7df fe4f974c-4cc1-46f5-a979-967408b00313 35903 0 2020-09-21 15:55:43 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 f0d663b6-7809-4e11-86e0-600895a4eab3 0xc006282350 0xc006282351}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hv9jj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hv9jj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hv9jj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:55:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:55:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:172.30.195.202,StartTime:2020-09-21 15:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:55:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://b23539a7c9125a56e1f91c76b5573130e895c2e74a1aa0b0ee632600d3f1f76d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.195.202,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:55:47.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8181" for this suite.
Sep 21 15:55:55.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:55:55.922: INFO: namespace deployment-8181 deletion completed in 8.352518467s

• [SLOW TEST:17.768 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:55:55.922: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4066
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:55:56.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4066" for this suite.
Sep 21 15:56:02.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:56:02.499: INFO: namespace custom-resource-definition-4066 deletion completed in 6.337216689s

• [SLOW TEST:6.578 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:56:02.500: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1822
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1822
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1822
STEP: creating replication controller externalsvc in namespace services-1822
I0921 15:56:02.843349      24 runners.go:184] Created replication controller with name: externalsvc, namespace: services-1822, replica count: 2
I0921 15:56:05.897547      24 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Sep 21 15:56:05.946: INFO: Creating new exec pod
Sep 21 15:56:07.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-1822 execpod6jk9g -- /bin/sh -x -c nslookup clusterip-service'
Sep 21 15:56:08.279: INFO: stderr: "+ nslookup clusterip-service\n"
Sep 21 15:56:08.279: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-1822.svc.cluster.local\tcanonical name = externalsvc.services-1822.svc.cluster.local.\nName:\texternalsvc.services-1822.svc.cluster.local\nAddress: 172.21.0.218\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1822, will wait for the garbage collector to delete the pods
Sep 21 15:56:08.362: INFO: Deleting ReplicationController externalsvc took: 22.722364ms
Sep 21 15:56:08.663: INFO: Terminating ReplicationController externalsvc pods took: 300.236524ms
Sep 21 15:56:22.028: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:56:22.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1822" for this suite.
Sep 21 15:56:30.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:56:30.516: INFO: namespace services-1822 deletion completed in 8.426842196s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:28.017 seconds]
[sig-network] Services
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:56:30.517: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3412
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-f01a79f8-86c0-4f18-b66d-d906e30774a7
STEP: Creating a pod to test consume configMaps
Sep 21 15:56:30.796: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-df64f674-f7af-4e54-a32a-38384e97bc5e" in namespace "projected-3412" to be "success or failure"
Sep 21 15:56:30.805: INFO: Pod "pod-projected-configmaps-df64f674-f7af-4e54-a32a-38384e97bc5e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.705338ms
Sep 21 15:56:32.817: INFO: Pod "pod-projected-configmaps-df64f674-f7af-4e54-a32a-38384e97bc5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020618138s
STEP: Saw pod success
Sep 21 15:56:32.817: INFO: Pod "pod-projected-configmaps-df64f674-f7af-4e54-a32a-38384e97bc5e" satisfied condition "success or failure"
Sep 21 15:56:32.826: INFO: Trying to get logs from node 10.189.39.109 pod pod-projected-configmaps-df64f674-f7af-4e54-a32a-38384e97bc5e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 15:56:32.873: INFO: Waiting for pod pod-projected-configmaps-df64f674-f7af-4e54-a32a-38384e97bc5e to disappear
Sep 21 15:56:32.886: INFO: Pod pod-projected-configmaps-df64f674-f7af-4e54-a32a-38384e97bc5e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:56:32.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3412" for this suite.
Sep 21 15:56:38.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:56:39.257: INFO: namespace projected-3412 deletion completed in 6.356251909s

• [SLOW TEST:8.741 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:56:39.258: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7956
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 15:56:39.525: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 21 15:56:44.536: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 21 15:56:44.536: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 21 15:56:46.546: INFO: Creating deployment "test-rollover-deployment"
Sep 21 15:56:46.564: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 21 15:56:48.581: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 21 15:56:48.604: INFO: Ensure that both replica sets have 1 created replica
Sep 21 15:56:48.620: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 21 15:56:48.638: INFO: Updating deployment test-rollover-deployment
Sep 21 15:56:48.638: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 21 15:56:50.660: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 21 15:56:50.678: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 21 15:56:50.696: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 15:56:50.696: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300608, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 15:56:52.714: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 15:56:52.714: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300610, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 15:56:54.715: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 15:56:54.715: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300610, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 15:56:56.715: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 15:56:56.715: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300610, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 15:56:58.717: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 15:56:58.717: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300610, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 15:57:00.722: INFO: all replica sets need to contain the pod-template-hash label
Sep 21 15:57:00.722: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300610, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736300606, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 15:57:02.714: INFO: 
Sep 21 15:57:02.714: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 21 15:57:02.740: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7956 /apis/apps/v1/namespaces/deployment-7956/deployments/test-rollover-deployment 36e64d83-542f-41da-8bba-8caf1b4420f7 36303 2 2020-09-21 15:56:46 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002fc0f68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-09-21 15:56:46 +0000 UTC,LastTransitionTime:2020-09-21 15:56:46 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-09-21 15:57:00 +0000 UTC,LastTransitionTime:2020-09-21 15:56:46 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 21 15:57:02.749: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-7956 /apis/apps/v1/namespaces/deployment-7956/replicasets/test-rollover-deployment-7d7dc6548c 6fb8d452-8296-4f65-95a6-db3778c9a8c4 36292 2 2020-09-21 15:56:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 36e64d83-542f-41da-8bba-8caf1b4420f7 0xc00360f997 0xc00360f998}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00360f9f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 21 15:57:02.749: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 21 15:57:02.749: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7956 /apis/apps/v1/namespaces/deployment-7956/replicasets/test-rollover-controller b4456c74-dfed-4310-afa0-cb3d65adcb5a 36301 2 2020-09-21 15:56:39 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 36e64d83-542f-41da-8bba-8caf1b4420f7 0xc00360f8c7 0xc00360f8c8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00360f928 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 15:57:02.749: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-7956 /apis/apps/v1/namespaces/deployment-7956/replicasets/test-rollover-deployment-f6c94f66c 74b1c488-e327-420e-b1e3-f4a7a68ca93b 36257 2 2020-09-21 15:56:46 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 36e64d83-542f-41da-8bba-8caf1b4420f7 0xc00360fa60 0xc00360fa61}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00360fad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 15:57:02.757: INFO: Pod "test-rollover-deployment-7d7dc6548c-5kjjx" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-5kjjx test-rollover-deployment-7d7dc6548c- deployment-7956 /api/v1/namespaces/deployment-7956/pods/test-rollover-deployment-7d7dc6548c-5kjjx cad76054-0216-42ea-99c0-cfc42a27e858 36275 0 2020-09-21 15:56:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 6fb8d452-8296-4f65-95a6-db3778c9a8c4 0xc005c54a07 0xc005c54a08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wq2dm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wq2dm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wq2dm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:56:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:56:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:56:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 15:56:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:172.30.195.197,StartTime:2020-09-21 15:56:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 15:56:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://535464923dbcf55035c95b3f0dbdb8e7d7108c4895d867430334b600fffc0478,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.195.197,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 15:57:02.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7956" for this suite.
Sep 21 15:57:10.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 15:57:11.109: INFO: namespace deployment-7956 deletion completed in 8.332712657s

• [SLOW TEST:31.851 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 15:57:11.109: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2059
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2059
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-2059
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2059
Sep 21 15:57:11.377: INFO: Found 0 stateful pods, waiting for 1
Sep 21 15:57:21.387: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 21 15:57:21.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:57:21.655: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:57:21.655: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:57:21.655: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 15:57:21.664: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 21 15:57:31.674: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 15:57:31.674: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 15:57:31.711: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:57:31.711: INFO: ss-0  10.189.39.109  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:57:31.711: INFO: 
Sep 21 15:57:31.711: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 21 15:57:32.720: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988857281s
Sep 21 15:57:33.732: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979945581s
Sep 21 15:57:34.742: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.968236387s
Sep 21 15:57:35.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.95780678s
Sep 21 15:57:36.762: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.948033728s
Sep 21 15:57:37.771: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.93792342s
Sep 21 15:57:38.782: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.928415249s
Sep 21 15:57:39.792: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.91808973s
Sep 21 15:57:40.802: INFO: Verifying statefulset ss doesn't scale past 3 for another 908.222446ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2059
Sep 21 15:57:41.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:57:42.069: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 21 15:57:42.069: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 15:57:42.069: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 15:57:42.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:57:42.301: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 21 15:57:42.302: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 15:57:42.302: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 15:57:42.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:57:42.506: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 21 15:57:42.506: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 21 15:57:42.506: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 21 15:57:42.515: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 21 15:57:52.526: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 15:57:52.526: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 21 15:57:52.526: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 21 15:57:52.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:57:52.784: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:57:52.784: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:57:52.784: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 15:57:52.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:57:53.008: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:57:53.008: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:57:53.008: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 15:57:53.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 21 15:57:53.222: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 21 15:57:53.222: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 21 15:57:53.222: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 21 15:57:53.222: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 15:57:53.231: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 21 15:58:03.252: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 15:58:03.252: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 15:58:03.252: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 21 15:58:03.289: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:03.289: INFO: ss-0  10.189.39.109  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:58:03.289: INFO: ss-1  10.189.39.114  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:03.289: INFO: ss-2  10.189.39.107  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:03.289: INFO: 
Sep 21 15:58:03.289: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 21 15:58:04.301: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:04.301: INFO: ss-0  10.189.39.109  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:58:04.301: INFO: ss-1  10.189.39.114  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:04.301: INFO: ss-2  10.189.39.107  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:04.301: INFO: 
Sep 21 15:58:04.301: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 21 15:58:05.313: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:05.313: INFO: ss-0  10.189.39.109  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:58:05.313: INFO: ss-1  10.189.39.114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:05.313: INFO: ss-2  10.189.39.107  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:05.313: INFO: 
Sep 21 15:58:05.313: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 21 15:58:06.322: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:06.322: INFO: ss-0  10.189.39.109  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:58:06.322: INFO: ss-1  10.189.39.114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:06.322: INFO: ss-2  10.189.39.107  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:06.322: INFO: 
Sep 21 15:58:06.322: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 21 15:58:07.332: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:07.332: INFO: ss-0  10.189.39.109  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:58:07.332: INFO: ss-1  10.189.39.114  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:07.332: INFO: ss-2  10.189.39.107  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:07.332: INFO: 
Sep 21 15:58:07.332: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 21 15:58:08.344: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:08.344: INFO: ss-0  10.189.39.109  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:58:08.344: INFO: ss-2  10.189.39.107  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:08.344: INFO: 
Sep 21 15:58:08.344: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 21 15:58:09.357: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:09.357: INFO: ss-0  10.189.39.109  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:58:09.357: INFO: ss-2  10.189.39.107  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:09.357: INFO: 
Sep 21 15:58:09.357: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 21 15:58:10.370: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:10.370: INFO: ss-0  10.189.39.109  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:58:10.371: INFO: ss-2  10.189.39.107  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:10.371: INFO: 
Sep 21 15:58:10.371: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 21 15:58:11.381: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:11.381: INFO: ss-0  10.189.39.109  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:11 +0000 UTC  }]
Sep 21 15:58:11.381: INFO: ss-2  10.189.39.107  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:11.381: INFO: 
Sep 21 15:58:11.381: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 21 15:58:12.394: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Sep 21 15:58:12.394: INFO: ss-2  10.189.39.107  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-21 15:57:31 +0000 UTC  }]
Sep 21 15:58:12.394: INFO: 
Sep 21 15:58:12.394: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2059
Sep 21 15:58:13.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:58:13.521: INFO: rc: 1
Sep 21 15:58:13.521: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Sep 21 15:58:23.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:58:23.617: INFO: rc: 1
Sep 21 15:58:23.617: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 15:58:33.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:58:33.703: INFO: rc: 1
Sep 21 15:58:33.703: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 15:58:43.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:58:43.790: INFO: rc: 1
Sep 21 15:58:43.790: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 15:58:53.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:58:53.880: INFO: rc: 1
Sep 21 15:58:53.881: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 15:59:03.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:59:03.971: INFO: rc: 1
Sep 21 15:59:03.971: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 15:59:13.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:59:14.065: INFO: rc: 1
Sep 21 15:59:14.065: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 15:59:24.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:59:24.142: INFO: rc: 1
Sep 21 15:59:24.142: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 15:59:34.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:59:34.231: INFO: rc: 1
Sep 21 15:59:34.231: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 15:59:44.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:59:44.319: INFO: rc: 1
Sep 21 15:59:44.319: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 15:59:54.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 15:59:54.408: INFO: rc: 1
Sep 21 15:59:54.408: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:00:04.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:00:04.497: INFO: rc: 1
Sep 21 16:00:04.497: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:00:14.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:00:14.595: INFO: rc: 1
Sep 21 16:00:14.595: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:00:24.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:00:24.687: INFO: rc: 1
Sep 21 16:00:24.687: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:00:34.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:00:34.781: INFO: rc: 1
Sep 21 16:00:34.782: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:00:44.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:00:44.868: INFO: rc: 1
Sep 21 16:00:44.868: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:00:54.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:00:54.956: INFO: rc: 1
Sep 21 16:00:54.956: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:01:04.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:01:05.148: INFO: rc: 1
Sep 21 16:01:05.148: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:01:15.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:01:15.229: INFO: rc: 1
Sep 21 16:01:15.229: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:01:25.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:01:25.317: INFO: rc: 1
Sep 21 16:01:25.317: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:01:35.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:01:35.418: INFO: rc: 1
Sep 21 16:01:35.418: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:01:45.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:01:45.509: INFO: rc: 1
Sep 21 16:01:45.509: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:01:55.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:01:55.587: INFO: rc: 1
Sep 21 16:01:55.587: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:02:05.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:02:05.688: INFO: rc: 1
Sep 21 16:02:05.688: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:02:15.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:02:15.788: INFO: rc: 1
Sep 21 16:02:15.788: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:02:25.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:02:25.877: INFO: rc: 1
Sep 21 16:02:25.877: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:02:35.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:02:35.965: INFO: rc: 1
Sep 21 16:02:35.965: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:02:45.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:02:46.056: INFO: rc: 1
Sep 21 16:02:46.056: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:02:56.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:02:56.144: INFO: rc: 1
Sep 21 16:02:56.144: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:03:06.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:03:06.233: INFO: rc: 1
Sep 21 16:03:06.233: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Sep 21 16:03:16.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=statefulset-2059 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 21 16:03:16.328: INFO: rc: 1
Sep 21 16:03:16.328: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Sep 21 16:03:16.328: INFO: Scaling statefulset ss to 0
Sep 21 16:03:16.355: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 21 16:03:16.364: INFO: Deleting all statefulset in ns statefulset-2059
Sep 21 16:03:16.373: INFO: Scaling statefulset ss to 0
Sep 21 16:03:16.399: INFO: Waiting for statefulset status.replicas updated to 0
Sep 21 16:03:16.407: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:03:16.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2059" for this suite.
Sep 21 16:03:24.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:03:24.799: INFO: namespace statefulset-2059 deletion completed in 8.344695835s

• [SLOW TEST:373.690 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:03:24.800: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 21 16:03:25.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2800'
Sep 21 16:03:25.123: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 21 16:03:25.123: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Sep 21 16:03:27.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete deployment e2e-test-httpd-deployment --namespace=kubectl-2800'
Sep 21 16:03:27.256: INFO: stderr: ""
Sep 21 16:03:27.256: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:03:27.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2800" for this suite.
Sep 21 16:03:57.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:03:57.616: INFO: namespace kubectl-2800 deletion completed in 30.345025972s

• [SLOW TEST:32.816 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:03:57.616: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-7559
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 21 16:03:58.244: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Sep 21 16:04:00.274: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301038, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301038, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301038, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301038, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 16:04:03.312: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:04:03.323: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:04:04.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7559" for this suite.
Sep 21 16:04:10.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:04:11.153: INFO: namespace crd-webhook-7559 deletion completed in 6.370235896s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.584 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:04:11.201: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6062
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 21 16:04:11.462: INFO: Waiting up to 5m0s for pod "pod-3180b080-64e4-47e1-9a87-232c1bbf911f" in namespace "emptydir-6062" to be "success or failure"
Sep 21 16:04:11.473: INFO: Pod "pod-3180b080-64e4-47e1-9a87-232c1bbf911f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.772994ms
Sep 21 16:04:13.481: INFO: Pod "pod-3180b080-64e4-47e1-9a87-232c1bbf911f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019325125s
STEP: Saw pod success
Sep 21 16:04:13.481: INFO: Pod "pod-3180b080-64e4-47e1-9a87-232c1bbf911f" satisfied condition "success or failure"
Sep 21 16:04:13.490: INFO: Trying to get logs from node 10.189.39.109 pod pod-3180b080-64e4-47e1-9a87-232c1bbf911f container test-container: <nil>
STEP: delete the pod
Sep 21 16:04:13.564: INFO: Waiting for pod pod-3180b080-64e4-47e1-9a87-232c1bbf911f to disappear
Sep 21 16:04:13.571: INFO: Pod pod-3180b080-64e4-47e1-9a87-232c1bbf911f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:04:13.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6062" for this suite.
Sep 21 16:04:19.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:04:19.928: INFO: namespace emptydir-6062 deletion completed in 6.345702472s

• [SLOW TEST:8.727 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:04:19.929: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-660
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:04:20.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-660" for this suite.
Sep 21 16:04:26.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:04:26.577: INFO: namespace tables-660 deletion completed in 6.371526226s

• [SLOW TEST:6.648 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:04:26.577: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1490
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:04:40.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1490" for this suite.
Sep 21 16:04:46.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:04:46.574: INFO: namespace resourcequota-1490 deletion completed in 6.371705208s

• [SLOW TEST:19.997 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:04:46.574: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1279
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1279
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-1279
I0921 16:04:46.882577      24 runners.go:184] Created replication controller with name: externalname-service, namespace: services-1279, replica count: 2
Sep 21 16:04:49.933: INFO: Creating new exec pod
I0921 16:04:49.933040      24 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 16:04:52.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-1279 execpodk9dp7 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 21 16:04:53.236: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 21 16:04:53.236: INFO: stdout: ""
Sep 21 16:04:53.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-1279 execpodk9dp7 -- /bin/sh -x -c nc -zv -t -w 2 172.21.2.123 80'
Sep 21 16:04:53.476: INFO: stderr: "+ nc -zv -t -w 2 172.21.2.123 80\nConnection to 172.21.2.123 80 port [tcp/http] succeeded!\n"
Sep 21 16:04:53.476: INFO: stdout: ""
Sep 21 16:04:53.476: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:04:53.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1279" for this suite.
Sep 21 16:05:01.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:05:02.201: INFO: namespace services-1279 deletion completed in 8.656762805s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.627 seconds]
[sig-network] Services
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:05:02.201: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9132
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Sep 21 16:05:02.462: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-744630836 proxy --unix-socket=/tmp/kubectl-proxy-unix177034043/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:05:02.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9132" for this suite.
Sep 21 16:05:08.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:05:08.978: INFO: namespace kubectl-9132 deletion completed in 6.434147139s

• [SLOW TEST:6.777 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:05:08.980: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1714
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1714
I0921 16:05:09.233336      24 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1714, replica count: 1
I0921 16:05:10.283945      24 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 16:05:11.284180      24 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 16:05:12.284412      24 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 16:05:12.410: INFO: Created: latency-svc-zvttq
Sep 21 16:05:12.423: INFO: Got endpoints: latency-svc-zvttq [38.613788ms]
Sep 21 16:05:12.446: INFO: Created: latency-svc-xf6q2
Sep 21 16:05:12.458: INFO: Created: latency-svc-fhgrg
Sep 21 16:05:12.462: INFO: Got endpoints: latency-svc-xf6q2 [38.656008ms]
Sep 21 16:05:12.469: INFO: Created: latency-svc-8tmwt
Sep 21 16:05:12.477: INFO: Got endpoints: latency-svc-fhgrg [53.118484ms]
Sep 21 16:05:12.479: INFO: Got endpoints: latency-svc-8tmwt [55.825345ms]
Sep 21 16:05:12.482: INFO: Created: latency-svc-94sfg
Sep 21 16:05:12.494: INFO: Got endpoints: latency-svc-94sfg [70.15167ms]
Sep 21 16:05:12.496: INFO: Created: latency-svc-qjxm6
Sep 21 16:05:12.509: INFO: Got endpoints: latency-svc-qjxm6 [85.324299ms]
Sep 21 16:05:12.510: INFO: Created: latency-svc-rkzm4
Sep 21 16:05:12.521: INFO: Got endpoints: latency-svc-rkzm4 [96.95185ms]
Sep 21 16:05:12.521: INFO: Created: latency-svc-9h49w
Sep 21 16:05:12.531: INFO: Got endpoints: latency-svc-9h49w [107.591717ms]
Sep 21 16:05:12.533: INFO: Created: latency-svc-kfwdc
Sep 21 16:05:12.545: INFO: Got endpoints: latency-svc-kfwdc [121.393154ms]
Sep 21 16:05:12.547: INFO: Created: latency-svc-8sxr2
Sep 21 16:05:12.561: INFO: Created: latency-svc-gx2p4
Sep 21 16:05:12.561: INFO: Got endpoints: latency-svc-8sxr2 [137.46239ms]
Sep 21 16:05:12.575: INFO: Created: latency-svc-v2qvt
Sep 21 16:05:12.575: INFO: Got endpoints: latency-svc-gx2p4 [151.420825ms]
Sep 21 16:05:12.589: INFO: Got endpoints: latency-svc-v2qvt [165.476779ms]
Sep 21 16:05:12.591: INFO: Created: latency-svc-pb8mf
Sep 21 16:05:12.606: INFO: Created: latency-svc-29s56
Sep 21 16:05:12.606: INFO: Got endpoints: latency-svc-pb8mf [182.098625ms]
Sep 21 16:05:12.615: INFO: Created: latency-svc-276fz
Sep 21 16:05:12.627: INFO: Got endpoints: latency-svc-29s56 [203.839927ms]
Sep 21 16:05:12.632: INFO: Got endpoints: latency-svc-276fz [207.858128ms]
Sep 21 16:05:12.632: INFO: Created: latency-svc-8qks8
Sep 21 16:05:12.644: INFO: Created: latency-svc-bm7ps
Sep 21 16:05:12.646: INFO: Got endpoints: latency-svc-8qks8 [221.688226ms]
Sep 21 16:05:12.657: INFO: Created: latency-svc-ncthd
Sep 21 16:05:12.657: INFO: Got endpoints: latency-svc-bm7ps [195.319669ms]
Sep 21 16:05:12.670: INFO: Got endpoints: latency-svc-ncthd [193.82474ms]
Sep 21 16:05:12.670: INFO: Created: latency-svc-95tsd
Sep 21 16:05:12.682: INFO: Got endpoints: latency-svc-95tsd [202.929401ms]
Sep 21 16:05:12.683: INFO: Created: latency-svc-q5btp
Sep 21 16:05:12.693: INFO: Got endpoints: latency-svc-q5btp [199.596131ms]
Sep 21 16:05:12.697: INFO: Created: latency-svc-zm292
Sep 21 16:05:12.707: INFO: Got endpoints: latency-svc-zm292 [198.362579ms]
Sep 21 16:05:12.710: INFO: Created: latency-svc-rzr2l
Sep 21 16:05:12.725: INFO: Got endpoints: latency-svc-rzr2l [203.891934ms]
Sep 21 16:05:12.726: INFO: Created: latency-svc-tczb8
Sep 21 16:05:12.738: INFO: Created: latency-svc-sffp2
Sep 21 16:05:12.739: INFO: Got endpoints: latency-svc-tczb8 [207.511786ms]
Sep 21 16:05:12.749: INFO: Created: latency-svc-2bkks
Sep 21 16:05:12.757: INFO: Got endpoints: latency-svc-sffp2 [212.372664ms]
Sep 21 16:05:12.760: INFO: Created: latency-svc-tkpnc
Sep 21 16:05:12.771: INFO: Got endpoints: latency-svc-2bkks [209.592131ms]
Sep 21 16:05:12.775: INFO: Got endpoints: latency-svc-tkpnc [199.497914ms]
Sep 21 16:05:12.776: INFO: Created: latency-svc-vs7cr
Sep 21 16:05:12.783: INFO: Created: latency-svc-p8ftf
Sep 21 16:05:12.784: INFO: Got endpoints: latency-svc-vs7cr [195.090757ms]
Sep 21 16:05:12.792: INFO: Got endpoints: latency-svc-p8ftf [186.261103ms]
Sep 21 16:05:12.795: INFO: Created: latency-svc-np79c
Sep 21 16:05:12.806: INFO: Got endpoints: latency-svc-np79c [178.463941ms]
Sep 21 16:05:12.807: INFO: Created: latency-svc-kqtb5
Sep 21 16:05:12.818: INFO: Created: latency-svc-gfv29
Sep 21 16:05:12.819: INFO: Got endpoints: latency-svc-kqtb5 [34.459073ms]
Sep 21 16:05:12.831: INFO: Got endpoints: latency-svc-gfv29 [199.498262ms]
Sep 21 16:05:12.833: INFO: Created: latency-svc-ndlhw
Sep 21 16:05:12.845: INFO: Created: latency-svc-zcjqk
Sep 21 16:05:12.847: INFO: Got endpoints: latency-svc-ndlhw [200.969186ms]
Sep 21 16:05:12.856: INFO: Got endpoints: latency-svc-zcjqk [199.280353ms]
Sep 21 16:05:12.858: INFO: Created: latency-svc-qzwvs
Sep 21 16:05:12.868: INFO: Got endpoints: latency-svc-qzwvs [196.997119ms]
Sep 21 16:05:12.869: INFO: Created: latency-svc-kv2bc
Sep 21 16:05:12.878: INFO: Got endpoints: latency-svc-kv2bc [195.18783ms]
Sep 21 16:05:12.885: INFO: Created: latency-svc-86l7k
Sep 21 16:05:12.898: INFO: Got endpoints: latency-svc-86l7k [204.02841ms]
Sep 21 16:05:12.900: INFO: Created: latency-svc-g5vf7
Sep 21 16:05:12.912: INFO: Got endpoints: latency-svc-g5vf7 [205.024322ms]
Sep 21 16:05:12.915: INFO: Created: latency-svc-7v2sw
Sep 21 16:05:12.927: INFO: Got endpoints: latency-svc-7v2sw [202.037882ms]
Sep 21 16:05:12.928: INFO: Created: latency-svc-74jfn
Sep 21 16:05:12.939: INFO: Got endpoints: latency-svc-74jfn [200.211699ms]
Sep 21 16:05:12.942: INFO: Created: latency-svc-p4fhv
Sep 21 16:05:12.952: INFO: Got endpoints: latency-svc-p4fhv [194.015989ms]
Sep 21 16:05:12.956: INFO: Created: latency-svc-sjqw4
Sep 21 16:05:12.965: INFO: Got endpoints: latency-svc-sjqw4 [194.390431ms]
Sep 21 16:05:12.965: INFO: Created: latency-svc-qs4kx
Sep 21 16:05:12.977: INFO: Got endpoints: latency-svc-qs4kx [202.623659ms]
Sep 21 16:05:12.980: INFO: Created: latency-svc-dsqqt
Sep 21 16:05:12.990: INFO: Created: latency-svc-jfwqk
Sep 21 16:05:12.992: INFO: Got endpoints: latency-svc-dsqqt [200.033956ms]
Sep 21 16:05:13.002: INFO: Got endpoints: latency-svc-jfwqk [196.07946ms]
Sep 21 16:05:13.002: INFO: Created: latency-svc-5ffls
Sep 21 16:05:13.013: INFO: Got endpoints: latency-svc-5ffls [194.573787ms]
Sep 21 16:05:13.015: INFO: Created: latency-svc-c8s84
Sep 21 16:05:13.026: INFO: Got endpoints: latency-svc-c8s84 [194.249878ms]
Sep 21 16:05:13.027: INFO: Created: latency-svc-tgntw
Sep 21 16:05:13.039: INFO: Created: latency-svc-2cf2x
Sep 21 16:05:13.040: INFO: Got endpoints: latency-svc-tgntw [193.373948ms]
Sep 21 16:05:13.049: INFO: Created: latency-svc-gwpjk
Sep 21 16:05:13.050: INFO: Got endpoints: latency-svc-2cf2x [193.49708ms]
Sep 21 16:05:13.060: INFO: Created: latency-svc-tvpll
Sep 21 16:05:13.061: INFO: Got endpoints: latency-svc-gwpjk [192.896206ms]
Sep 21 16:05:13.072: INFO: Got endpoints: latency-svc-tvpll [194.195982ms]
Sep 21 16:05:13.073: INFO: Created: latency-svc-p668l
Sep 21 16:05:13.084: INFO: Got endpoints: latency-svc-p668l [186.794973ms]
Sep 21 16:05:13.086: INFO: Created: latency-svc-mbs42
Sep 21 16:05:13.094: INFO: Got endpoints: latency-svc-mbs42 [181.974448ms]
Sep 21 16:05:13.096: INFO: Created: latency-svc-9t82r
Sep 21 16:05:13.107: INFO: Created: latency-svc-kcmqx
Sep 21 16:05:13.110: INFO: Got endpoints: latency-svc-9t82r [183.002551ms]
Sep 21 16:05:13.119: INFO: Created: latency-svc-sqzdm
Sep 21 16:05:13.120: INFO: Got endpoints: latency-svc-kcmqx [180.440853ms]
Sep 21 16:05:13.132: INFO: Got endpoints: latency-svc-sqzdm [180.05142ms]
Sep 21 16:05:13.133: INFO: Created: latency-svc-6qpmk
Sep 21 16:05:13.142: INFO: Got endpoints: latency-svc-6qpmk [176.713173ms]
Sep 21 16:05:13.144: INFO: Created: latency-svc-l5mcl
Sep 21 16:05:13.155: INFO: Created: latency-svc-6s2qr
Sep 21 16:05:13.156: INFO: Got endpoints: latency-svc-l5mcl [178.589565ms]
Sep 21 16:05:13.166: INFO: Created: latency-svc-shx6f
Sep 21 16:05:13.169: INFO: Got endpoints: latency-svc-6s2qr [176.210845ms]
Sep 21 16:05:13.177: INFO: Got endpoints: latency-svc-shx6f [174.956309ms]
Sep 21 16:05:13.179: INFO: Created: latency-svc-jzhs5
Sep 21 16:05:13.190: INFO: Got endpoints: latency-svc-jzhs5 [176.367536ms]
Sep 21 16:05:13.194: INFO: Created: latency-svc-pq97m
Sep 21 16:05:13.205: INFO: Got endpoints: latency-svc-pq97m [178.945641ms]
Sep 21 16:05:13.205: INFO: Created: latency-svc-55xft
Sep 21 16:05:13.215: INFO: Created: latency-svc-chw9n
Sep 21 16:05:13.215: INFO: Got endpoints: latency-svc-55xft [175.241809ms]
Sep 21 16:05:13.225: INFO: Created: latency-svc-fn8zd
Sep 21 16:05:13.226: INFO: Got endpoints: latency-svc-chw9n [176.279963ms]
Sep 21 16:05:13.236: INFO: Got endpoints: latency-svc-fn8zd [175.676842ms]
Sep 21 16:05:13.237: INFO: Created: latency-svc-g8hrr
Sep 21 16:05:13.245: INFO: Got endpoints: latency-svc-g8hrr [172.828092ms]
Sep 21 16:05:13.250: INFO: Created: latency-svc-x59xv
Sep 21 16:05:13.259: INFO: Got endpoints: latency-svc-x59xv [174.858846ms]
Sep 21 16:05:13.261: INFO: Created: latency-svc-7bbvs
Sep 21 16:05:13.272: INFO: Created: latency-svc-m4j5b
Sep 21 16:05:13.273: INFO: Got endpoints: latency-svc-7bbvs [178.201714ms]
Sep 21 16:05:13.283: INFO: Got endpoints: latency-svc-m4j5b [173.416576ms]
Sep 21 16:05:13.284: INFO: Created: latency-svc-pqj57
Sep 21 16:05:13.296: INFO: Got endpoints: latency-svc-pqj57 [175.460514ms]
Sep 21 16:05:13.296: INFO: Created: latency-svc-vp2dr
Sep 21 16:05:13.304: INFO: Got endpoints: latency-svc-vp2dr [172.176529ms]
Sep 21 16:05:13.306: INFO: Created: latency-svc-7sk6k
Sep 21 16:05:13.315: INFO: Created: latency-svc-jswsc
Sep 21 16:05:13.316: INFO: Got endpoints: latency-svc-7sk6k [173.657918ms]
Sep 21 16:05:13.326: INFO: Created: latency-svc-wxt8v
Sep 21 16:05:13.327: INFO: Got endpoints: latency-svc-jswsc [170.685166ms]
Sep 21 16:05:13.336: INFO: Got endpoints: latency-svc-wxt8v [166.832381ms]
Sep 21 16:05:13.337: INFO: Created: latency-svc-tlzr2
Sep 21 16:05:13.348: INFO: Got endpoints: latency-svc-tlzr2 [170.870581ms]
Sep 21 16:05:13.348: INFO: Created: latency-svc-tpwr2
Sep 21 16:05:13.359: INFO: Created: latency-svc-qfw9s
Sep 21 16:05:13.360: INFO: Got endpoints: latency-svc-tpwr2 [169.803958ms]
Sep 21 16:05:13.368: INFO: Created: latency-svc-qk9nw
Sep 21 16:05:13.371: INFO: Got endpoints: latency-svc-qfw9s [165.393667ms]
Sep 21 16:05:13.385: INFO: Created: latency-svc-t6tw6
Sep 21 16:05:13.385: INFO: Got endpoints: latency-svc-qk9nw [169.570647ms]
Sep 21 16:05:13.396: INFO: Created: latency-svc-xh2vm
Sep 21 16:05:13.396: INFO: Got endpoints: latency-svc-t6tw6 [170.189532ms]
Sep 21 16:05:13.407: INFO: Created: latency-svc-vbvdh
Sep 21 16:05:13.407: INFO: Got endpoints: latency-svc-xh2vm [170.117202ms]
Sep 21 16:05:13.417: INFO: Created: latency-svc-kh8bd
Sep 21 16:05:13.418: INFO: Got endpoints: latency-svc-vbvdh [172.887863ms]
Sep 21 16:05:13.428: INFO: Created: latency-svc-89hq2
Sep 21 16:05:13.428: INFO: Got endpoints: latency-svc-kh8bd [168.805761ms]
Sep 21 16:05:13.440: INFO: Created: latency-svc-dvklx
Sep 21 16:05:13.445: INFO: Got endpoints: latency-svc-89hq2 [171.78108ms]
Sep 21 16:05:13.450: INFO: Got endpoints: latency-svc-dvklx [166.771005ms]
Sep 21 16:05:13.451: INFO: Created: latency-svc-7k4s5
Sep 21 16:05:13.462: INFO: Got endpoints: latency-svc-7k4s5 [166.647128ms]
Sep 21 16:05:13.463: INFO: Created: latency-svc-2q62z
Sep 21 16:05:13.474: INFO: Created: latency-svc-c4n6t
Sep 21 16:05:13.476: INFO: Got endpoints: latency-svc-2q62z [171.289523ms]
Sep 21 16:05:13.487: INFO: Created: latency-svc-6sdpz
Sep 21 16:05:13.488: INFO: Got endpoints: latency-svc-c4n6t [171.940811ms]
Sep 21 16:05:13.500: INFO: Created: latency-svc-tbjbt
Sep 21 16:05:13.502: INFO: Got endpoints: latency-svc-6sdpz [174.985416ms]
Sep 21 16:05:13.509: INFO: Created: latency-svc-qslxg
Sep 21 16:05:13.511: INFO: Got endpoints: latency-svc-tbjbt [174.740694ms]
Sep 21 16:05:13.521: INFO: Created: latency-svc-tmx72
Sep 21 16:05:13.524: INFO: Got endpoints: latency-svc-qslxg [175.970764ms]
Sep 21 16:05:13.534: INFO: Got endpoints: latency-svc-tmx72 [173.768428ms]
Sep 21 16:05:13.534: INFO: Created: latency-svc-m6bw4
Sep 21 16:05:13.545: INFO: Got endpoints: latency-svc-m6bw4 [174.575697ms]
Sep 21 16:05:13.547: INFO: Created: latency-svc-j86f6
Sep 21 16:05:13.559: INFO: Got endpoints: latency-svc-j86f6 [173.897967ms]
Sep 21 16:05:13.560: INFO: Created: latency-svc-vz9p6
Sep 21 16:05:13.572: INFO: Got endpoints: latency-svc-vz9p6 [175.408165ms]
Sep 21 16:05:13.573: INFO: Created: latency-svc-lj2qv
Sep 21 16:05:13.586: INFO: Created: latency-svc-z2r6l
Sep 21 16:05:13.587: INFO: Got endpoints: latency-svc-lj2qv [180.255584ms]
Sep 21 16:05:13.595: INFO: Created: latency-svc-5ll7s
Sep 21 16:05:13.597: INFO: Got endpoints: latency-svc-z2r6l [179.257783ms]
Sep 21 16:05:13.606: INFO: Got endpoints: latency-svc-5ll7s [177.807237ms]
Sep 21 16:05:13.610: INFO: Created: latency-svc-m7tfn
Sep 21 16:05:13.622: INFO: Created: latency-svc-wbpnk
Sep 21 16:05:13.625: INFO: Got endpoints: latency-svc-m7tfn [180.719703ms]
Sep 21 16:05:13.633: INFO: Created: latency-svc-w77gj
Sep 21 16:05:13.635: INFO: Got endpoints: latency-svc-wbpnk [184.827591ms]
Sep 21 16:05:13.651: INFO: Got endpoints: latency-svc-w77gj [188.381351ms]
Sep 21 16:05:13.653: INFO: Created: latency-svc-hzh8b
Sep 21 16:05:13.664: INFO: Got endpoints: latency-svc-hzh8b [188.937179ms]
Sep 21 16:05:13.666: INFO: Created: latency-svc-2pk97
Sep 21 16:05:13.680: INFO: Got endpoints: latency-svc-2pk97 [192.100267ms]
Sep 21 16:05:13.682: INFO: Created: latency-svc-dh8j2
Sep 21 16:05:13.694: INFO: Created: latency-svc-ks4wq
Sep 21 16:05:13.698: INFO: Got endpoints: latency-svc-dh8j2 [195.986558ms]
Sep 21 16:05:13.706: INFO: Got endpoints: latency-svc-ks4wq [194.930921ms]
Sep 21 16:05:13.707: INFO: Created: latency-svc-8mspb
Sep 21 16:05:13.720: INFO: Got endpoints: latency-svc-8mspb [196.447219ms]
Sep 21 16:05:13.721: INFO: Created: latency-svc-pc97r
Sep 21 16:05:13.729: INFO: Created: latency-svc-d49lm
Sep 21 16:05:13.737: INFO: Got endpoints: latency-svc-pc97r [203.427915ms]
Sep 21 16:05:13.742: INFO: Created: latency-svc-r8s85
Sep 21 16:05:13.743: INFO: Got endpoints: latency-svc-d49lm [197.18574ms]
Sep 21 16:05:13.754: INFO: Got endpoints: latency-svc-r8s85 [194.862029ms]
Sep 21 16:05:13.759: INFO: Created: latency-svc-jhdpm
Sep 21 16:05:13.770: INFO: Got endpoints: latency-svc-jhdpm [198.392845ms]
Sep 21 16:05:13.771: INFO: Created: latency-svc-km429
Sep 21 16:05:13.783: INFO: Created: latency-svc-2mgks
Sep 21 16:05:13.784: INFO: Got endpoints: latency-svc-km429 [197.136112ms]
Sep 21 16:05:13.799: INFO: Got endpoints: latency-svc-2mgks [202.068123ms]
Sep 21 16:05:13.803: INFO: Created: latency-svc-t4qh8
Sep 21 16:05:13.813: INFO: Got endpoints: latency-svc-t4qh8 [206.952516ms]
Sep 21 16:05:13.817: INFO: Created: latency-svc-s2t7c
Sep 21 16:05:13.829: INFO: Got endpoints: latency-svc-s2t7c [203.981217ms]
Sep 21 16:05:13.833: INFO: Created: latency-svc-z8czv
Sep 21 16:05:13.845: INFO: Got endpoints: latency-svc-z8czv [210.119822ms]
Sep 21 16:05:13.856: INFO: Created: latency-svc-9z64f
Sep 21 16:05:13.864: INFO: Got endpoints: latency-svc-9z64f [212.81389ms]
Sep 21 16:05:13.868: INFO: Created: latency-svc-ttksq
Sep 21 16:05:13.879: INFO: Created: latency-svc-pwds6
Sep 21 16:05:13.881: INFO: Got endpoints: latency-svc-ttksq [216.196263ms]
Sep 21 16:05:13.891: INFO: Got endpoints: latency-svc-pwds6 [210.741254ms]
Sep 21 16:05:13.891: INFO: Created: latency-svc-cb94j
Sep 21 16:05:13.904: INFO: Got endpoints: latency-svc-cb94j [205.974629ms]
Sep 21 16:05:13.905: INFO: Created: latency-svc-qzzrv
Sep 21 16:05:13.924: INFO: Got endpoints: latency-svc-qzzrv [218.745904ms]
Sep 21 16:05:13.926: INFO: Created: latency-svc-mvrrs
Sep 21 16:05:13.937: INFO: Created: latency-svc-mwfpb
Sep 21 16:05:13.941: INFO: Got endpoints: latency-svc-mvrrs [220.874591ms]
Sep 21 16:05:13.948: INFO: Created: latency-svc-2h9q5
Sep 21 16:05:13.949: INFO: Got endpoints: latency-svc-mwfpb [211.893484ms]
Sep 21 16:05:13.959: INFO: Created: latency-svc-69q42
Sep 21 16:05:13.961: INFO: Got endpoints: latency-svc-2h9q5 [218.321769ms]
Sep 21 16:05:13.970: INFO: Got endpoints: latency-svc-69q42 [216.695903ms]
Sep 21 16:05:13.973: INFO: Created: latency-svc-vdqxw
Sep 21 16:05:13.981: INFO: Created: latency-svc-jhwxh
Sep 21 16:05:13.984: INFO: Got endpoints: latency-svc-vdqxw [213.771164ms]
Sep 21 16:05:13.991: INFO: Created: latency-svc-xsc44
Sep 21 16:05:13.993: INFO: Got endpoints: latency-svc-jhwxh [208.909265ms]
Sep 21 16:05:14.000: INFO: Got endpoints: latency-svc-xsc44 [200.814513ms]
Sep 21 16:05:14.002: INFO: Created: latency-svc-2tf4j
Sep 21 16:05:14.011: INFO: Created: latency-svc-f2brq
Sep 21 16:05:14.014: INFO: Got endpoints: latency-svc-2tf4j [200.370345ms]
Sep 21 16:05:14.021: INFO: Created: latency-svc-2c9hh
Sep 21 16:05:14.022: INFO: Got endpoints: latency-svc-f2brq [192.664642ms]
Sep 21 16:05:14.036: INFO: Created: latency-svc-5xjw5
Sep 21 16:05:14.036: INFO: Got endpoints: latency-svc-2c9hh [191.080968ms]
Sep 21 16:05:14.047: INFO: Created: latency-svc-57mkj
Sep 21 16:05:14.055: INFO: Got endpoints: latency-svc-5xjw5 [191.102974ms]
Sep 21 16:05:14.066: INFO: Got endpoints: latency-svc-57mkj [185.222394ms]
Sep 21 16:05:14.075: INFO: Created: latency-svc-rtdmm
Sep 21 16:05:14.083: INFO: Got endpoints: latency-svc-rtdmm [192.438769ms]
Sep 21 16:05:14.093: INFO: Created: latency-svc-2dwlh
Sep 21 16:05:14.129: INFO: Got endpoints: latency-svc-2dwlh [224.513266ms]
Sep 21 16:05:14.138: INFO: Created: latency-svc-hf7p9
Sep 21 16:05:14.172: INFO: Got endpoints: latency-svc-hf7p9 [247.403488ms]
Sep 21 16:05:14.174: INFO: Created: latency-svc-9jr44
Sep 21 16:05:14.185: INFO: Got endpoints: latency-svc-9jr44 [244.138079ms]
Sep 21 16:05:14.199: INFO: Created: latency-svc-q9gmg
Sep 21 16:05:14.221: INFO: Got endpoints: latency-svc-q9gmg [271.812025ms]
Sep 21 16:05:14.222: INFO: Created: latency-svc-mvg2j
Sep 21 16:05:14.240: INFO: Got endpoints: latency-svc-mvg2j [279.239644ms]
Sep 21 16:05:14.243: INFO: Created: latency-svc-btgzh
Sep 21 16:05:14.255: INFO: Got endpoints: latency-svc-btgzh [284.463352ms]
Sep 21 16:05:14.258: INFO: Created: latency-svc-l5whw
Sep 21 16:05:14.267: INFO: Got endpoints: latency-svc-l5whw [283.27417ms]
Sep 21 16:05:14.270: INFO: Created: latency-svc-z8ll5
Sep 21 16:05:14.280: INFO: Created: latency-svc-f7ksd
Sep 21 16:05:14.281: INFO: Got endpoints: latency-svc-z8ll5 [287.256744ms]
Sep 21 16:05:14.292: INFO: Got endpoints: latency-svc-f7ksd [291.292046ms]
Sep 21 16:05:14.294: INFO: Created: latency-svc-t5bwd
Sep 21 16:05:14.306: INFO: Got endpoints: latency-svc-t5bwd [292.164915ms]
Sep 21 16:05:14.309: INFO: Created: latency-svc-b2sdd
Sep 21 16:05:14.316: INFO: Created: latency-svc-kv5dm
Sep 21 16:05:14.317: INFO: Got endpoints: latency-svc-b2sdd [294.371518ms]
Sep 21 16:05:14.329: INFO: Created: latency-svc-24rxm
Sep 21 16:05:14.330: INFO: Got endpoints: latency-svc-kv5dm [293.129725ms]
Sep 21 16:05:14.341: INFO: Created: latency-svc-kjbsl
Sep 21 16:05:14.342: INFO: Got endpoints: latency-svc-24rxm [286.801782ms]
Sep 21 16:05:14.354: INFO: Created: latency-svc-xkz44
Sep 21 16:05:14.357: INFO: Got endpoints: latency-svc-kjbsl [290.638978ms]
Sep 21 16:05:14.368: INFO: Got endpoints: latency-svc-xkz44 [285.005649ms]
Sep 21 16:05:14.372: INFO: Created: latency-svc-9rnbd
Sep 21 16:05:14.375: INFO: Got endpoints: latency-svc-9rnbd [246.295079ms]
Sep 21 16:05:14.388: INFO: Created: latency-svc-gfqmp
Sep 21 16:05:14.398: INFO: Created: latency-svc-mf6qq
Sep 21 16:05:14.398: INFO: Got endpoints: latency-svc-gfqmp [226.321466ms]
Sep 21 16:05:14.408: INFO: Created: latency-svc-85gqg
Sep 21 16:05:14.409: INFO: Got endpoints: latency-svc-mf6qq [223.845742ms]
Sep 21 16:05:14.423: INFO: Got endpoints: latency-svc-85gqg [202.305985ms]
Sep 21 16:05:14.424: INFO: Created: latency-svc-979db
Sep 21 16:05:14.434: INFO: Got endpoints: latency-svc-979db [193.878983ms]
Sep 21 16:05:14.438: INFO: Created: latency-svc-wgdpl
Sep 21 16:05:14.452: INFO: Created: latency-svc-cbsnr
Sep 21 16:05:14.453: INFO: Got endpoints: latency-svc-wgdpl [198.331444ms]
Sep 21 16:05:14.461: INFO: Got endpoints: latency-svc-cbsnr [193.649295ms]
Sep 21 16:05:14.463: INFO: Created: latency-svc-rhhpt
Sep 21 16:05:14.473: INFO: Created: latency-svc-tqsfk
Sep 21 16:05:14.476: INFO: Got endpoints: latency-svc-rhhpt [195.544431ms]
Sep 21 16:05:14.483: INFO: Created: latency-svc-vbv9m
Sep 21 16:05:14.483: INFO: Got endpoints: latency-svc-tqsfk [191.595538ms]
Sep 21 16:05:14.494: INFO: Created: latency-svc-8gcm2
Sep 21 16:05:14.495: INFO: Got endpoints: latency-svc-vbv9m [188.801991ms]
Sep 21 16:05:14.505: INFO: Created: latency-svc-sdr2d
Sep 21 16:05:14.506: INFO: Got endpoints: latency-svc-8gcm2 [189.282555ms]
Sep 21 16:05:14.515: INFO: Created: latency-svc-rg949
Sep 21 16:05:14.517: INFO: Got endpoints: latency-svc-sdr2d [187.806655ms]
Sep 21 16:05:14.526: INFO: Got endpoints: latency-svc-rg949 [184.085703ms]
Sep 21 16:05:14.527: INFO: Created: latency-svc-qqcmh
Sep 21 16:05:14.536: INFO: Created: latency-svc-pgldg
Sep 21 16:05:14.543: INFO: Got endpoints: latency-svc-qqcmh [186.395279ms]
Sep 21 16:05:14.549: INFO: Created: latency-svc-sfxv4
Sep 21 16:05:14.550: INFO: Got endpoints: latency-svc-pgldg [181.519635ms]
Sep 21 16:05:14.559: INFO: Got endpoints: latency-svc-sfxv4 [184.133299ms]
Sep 21 16:05:14.560: INFO: Created: latency-svc-8tfm6
Sep 21 16:05:14.571: INFO: Created: latency-svc-n8rdl
Sep 21 16:05:14.571: INFO: Got endpoints: latency-svc-8tfm6 [172.891697ms]
Sep 21 16:05:14.582: INFO: Created: latency-svc-klcfc
Sep 21 16:05:14.583: INFO: Got endpoints: latency-svc-n8rdl [173.75896ms]
Sep 21 16:05:14.595: INFO: Got endpoints: latency-svc-klcfc [171.992675ms]
Sep 21 16:05:14.595: INFO: Created: latency-svc-4zgmx
Sep 21 16:05:14.605: INFO: Created: latency-svc-vqgcn
Sep 21 16:05:14.607: INFO: Got endpoints: latency-svc-4zgmx [172.350652ms]
Sep 21 16:05:14.615: INFO: Got endpoints: latency-svc-vqgcn [161.745957ms]
Sep 21 16:05:14.616: INFO: Created: latency-svc-x6bkd
Sep 21 16:05:14.623: INFO: Created: latency-svc-nz4l2
Sep 21 16:05:14.627: INFO: Got endpoints: latency-svc-x6bkd [165.976024ms]
Sep 21 16:05:14.634: INFO: Created: latency-svc-5n654
Sep 21 16:05:14.634: INFO: Got endpoints: latency-svc-nz4l2 [157.845279ms]
Sep 21 16:05:14.645: INFO: Created: latency-svc-c44sn
Sep 21 16:05:14.647: INFO: Got endpoints: latency-svc-5n654 [163.007342ms]
Sep 21 16:05:14.662: INFO: Created: latency-svc-tj6td
Sep 21 16:05:14.663: INFO: Got endpoints: latency-svc-c44sn [167.306099ms]
Sep 21 16:05:14.668: INFO: Created: latency-svc-nk4sr
Sep 21 16:05:14.670: INFO: Got endpoints: latency-svc-tj6td [164.157555ms]
Sep 21 16:05:14.679: INFO: Created: latency-svc-mrhvk
Sep 21 16:05:14.681: INFO: Got endpoints: latency-svc-nk4sr [163.569422ms]
Sep 21 16:05:14.693: INFO: Got endpoints: latency-svc-mrhvk [166.837724ms]
Sep 21 16:05:14.695: INFO: Created: latency-svc-5x5hr
Sep 21 16:05:14.707: INFO: Created: latency-svc-r4b5p
Sep 21 16:05:14.707: INFO: Got endpoints: latency-svc-5x5hr [163.936308ms]
Sep 21 16:05:14.718: INFO: Got endpoints: latency-svc-r4b5p [168.320824ms]
Sep 21 16:05:14.721: INFO: Created: latency-svc-zznw4
Sep 21 16:05:14.732: INFO: Got endpoints: latency-svc-zznw4 [172.706545ms]
Sep 21 16:05:14.733: INFO: Created: latency-svc-5w7fq
Sep 21 16:05:14.742: INFO: Created: latency-svc-wrzw8
Sep 21 16:05:14.746: INFO: Got endpoints: latency-svc-5w7fq [174.898733ms]
Sep 21 16:05:14.754: INFO: Got endpoints: latency-svc-wrzw8 [170.522001ms]
Sep 21 16:05:14.754: INFO: Created: latency-svc-c4p6m
Sep 21 16:05:14.765: INFO: Got endpoints: latency-svc-c4p6m [169.503695ms]
Sep 21 16:05:14.767: INFO: Created: latency-svc-qjrwt
Sep 21 16:05:14.776: INFO: Got endpoints: latency-svc-qjrwt [169.051746ms]
Sep 21 16:05:14.778: INFO: Created: latency-svc-c8xvq
Sep 21 16:05:14.789: INFO: Got endpoints: latency-svc-c8xvq [173.763598ms]
Sep 21 16:05:14.791: INFO: Created: latency-svc-c4v2m
Sep 21 16:05:14.802: INFO: Got endpoints: latency-svc-c4v2m [174.776026ms]
Sep 21 16:05:14.803: INFO: Created: latency-svc-hjb67
Sep 21 16:05:14.817: INFO: Got endpoints: latency-svc-hjb67 [182.469469ms]
Sep 21 16:05:14.821: INFO: Created: latency-svc-7brdj
Sep 21 16:05:14.831: INFO: Got endpoints: latency-svc-7brdj [184.367245ms]
Sep 21 16:05:14.832: INFO: Created: latency-svc-4r8cm
Sep 21 16:05:14.847: INFO: Created: latency-svc-xq5jg
Sep 21 16:05:14.847: INFO: Got endpoints: latency-svc-4r8cm [184.312258ms]
Sep 21 16:05:14.858: INFO: Got endpoints: latency-svc-xq5jg [187.529828ms]
Sep 21 16:05:14.859: INFO: Created: latency-svc-q9vvd
Sep 21 16:05:14.871: INFO: Created: latency-svc-wjmf9
Sep 21 16:05:14.871: INFO: Got endpoints: latency-svc-q9vvd [190.179904ms]
Sep 21 16:05:14.882: INFO: Got endpoints: latency-svc-wjmf9 [189.745301ms]
Sep 21 16:05:14.884: INFO: Created: latency-svc-tcmxf
Sep 21 16:05:14.896: INFO: Created: latency-svc-vmdrq
Sep 21 16:05:14.897: INFO: Got endpoints: latency-svc-tcmxf [189.875301ms]
Sep 21 16:05:14.908: INFO: Got endpoints: latency-svc-vmdrq [190.278449ms]
Sep 21 16:05:14.909: INFO: Created: latency-svc-wf5mk
Sep 21 16:05:14.920: INFO: Created: latency-svc-jwnx5
Sep 21 16:05:14.921: INFO: Got endpoints: latency-svc-wf5mk [189.314679ms]
Sep 21 16:05:14.927: INFO: Got endpoints: latency-svc-jwnx5 [180.922103ms]
Sep 21 16:05:14.932: INFO: Created: latency-svc-w68rh
Sep 21 16:05:14.941: INFO: Created: latency-svc-rmmpn
Sep 21 16:05:14.943: INFO: Got endpoints: latency-svc-w68rh [189.045502ms]
Sep 21 16:05:14.955: INFO: Got endpoints: latency-svc-rmmpn [190.211921ms]
Sep 21 16:05:14.956: INFO: Created: latency-svc-f5rxn
Sep 21 16:05:14.966: INFO: Created: latency-svc-nppkx
Sep 21 16:05:14.975: INFO: Got endpoints: latency-svc-f5rxn [199.601233ms]
Sep 21 16:05:14.978: INFO: Created: latency-svc-wnz4m
Sep 21 16:05:14.978: INFO: Got endpoints: latency-svc-nppkx [189.395775ms]
Sep 21 16:05:14.989: INFO: Got endpoints: latency-svc-wnz4m [187.34866ms]
Sep 21 16:05:14.996: INFO: Created: latency-svc-gb6s4
Sep 21 16:05:15.006: INFO: Got endpoints: latency-svc-gb6s4 [188.718844ms]
Sep 21 16:05:15.006: INFO: Created: latency-svc-lcsh2
Sep 21 16:05:15.019: INFO: Got endpoints: latency-svc-lcsh2 [187.159964ms]
Sep 21 16:05:15.022: INFO: Created: latency-svc-nbck5
Sep 21 16:05:15.036: INFO: Got endpoints: latency-svc-nbck5 [189.005004ms]
Sep 21 16:05:15.036: INFO: Latencies: [34.459073ms 38.656008ms 53.118484ms 55.825345ms 70.15167ms 85.324299ms 96.95185ms 107.591717ms 121.393154ms 137.46239ms 151.420825ms 157.845279ms 161.745957ms 163.007342ms 163.569422ms 163.936308ms 164.157555ms 165.393667ms 165.476779ms 165.976024ms 166.647128ms 166.771005ms 166.832381ms 166.837724ms 167.306099ms 168.320824ms 168.805761ms 169.051746ms 169.503695ms 169.570647ms 169.803958ms 170.117202ms 170.189532ms 170.522001ms 170.685166ms 170.870581ms 171.289523ms 171.78108ms 171.940811ms 171.992675ms 172.176529ms 172.350652ms 172.706545ms 172.828092ms 172.887863ms 172.891697ms 173.416576ms 173.657918ms 173.75896ms 173.763598ms 173.768428ms 173.897967ms 174.575697ms 174.740694ms 174.776026ms 174.858846ms 174.898733ms 174.956309ms 174.985416ms 175.241809ms 175.408165ms 175.460514ms 175.676842ms 175.970764ms 176.210845ms 176.279963ms 176.367536ms 176.713173ms 177.807237ms 178.201714ms 178.463941ms 178.589565ms 178.945641ms 179.257783ms 180.05142ms 180.255584ms 180.440853ms 180.719703ms 180.922103ms 181.519635ms 181.974448ms 182.098625ms 182.469469ms 183.002551ms 184.085703ms 184.133299ms 184.312258ms 184.367245ms 184.827591ms 185.222394ms 186.261103ms 186.395279ms 186.794973ms 187.159964ms 187.34866ms 187.529828ms 187.806655ms 188.381351ms 188.718844ms 188.801991ms 188.937179ms 189.005004ms 189.045502ms 189.282555ms 189.314679ms 189.395775ms 189.745301ms 189.875301ms 190.179904ms 190.211921ms 190.278449ms 191.080968ms 191.102974ms 191.595538ms 192.100267ms 192.438769ms 192.664642ms 192.896206ms 193.373948ms 193.49708ms 193.649295ms 193.82474ms 193.878983ms 194.015989ms 194.195982ms 194.249878ms 194.390431ms 194.573787ms 194.862029ms 194.930921ms 195.090757ms 195.18783ms 195.319669ms 195.544431ms 195.986558ms 196.07946ms 196.447219ms 196.997119ms 197.136112ms 197.18574ms 198.331444ms 198.362579ms 198.392845ms 199.280353ms 199.497914ms 199.498262ms 199.596131ms 199.601233ms 200.033956ms 200.211699ms 200.370345ms 200.814513ms 200.969186ms 202.037882ms 202.068123ms 202.305985ms 202.623659ms 202.929401ms 203.427915ms 203.839927ms 203.891934ms 203.981217ms 204.02841ms 205.024322ms 205.974629ms 206.952516ms 207.511786ms 207.858128ms 208.909265ms 209.592131ms 210.119822ms 210.741254ms 211.893484ms 212.372664ms 212.81389ms 213.771164ms 216.196263ms 216.695903ms 218.321769ms 218.745904ms 220.874591ms 221.688226ms 223.845742ms 224.513266ms 226.321466ms 244.138079ms 246.295079ms 247.403488ms 271.812025ms 279.239644ms 283.27417ms 284.463352ms 285.005649ms 286.801782ms 287.256744ms 290.638978ms 291.292046ms 292.164915ms 293.129725ms 294.371518ms]
Sep 21 16:05:15.036: INFO: 50 %ile: 188.937179ms
Sep 21 16:05:15.036: INFO: 90 %ile: 220.874591ms
Sep 21 16:05:15.036: INFO: 99 %ile: 293.129725ms
Sep 21 16:05:15.036: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:05:15.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1714" for this suite.
Sep 21 16:05:35.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:05:35.419: INFO: namespace svc-latency-1714 deletion completed in 20.366168489s

• [SLOW TEST:26.439 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:05:35.420: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6179
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 16:05:36.190: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Sep 21 16:05:38.220: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301136, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301136, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301136, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301136, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 16:05:41.262: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:05:41.328: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5437-crds.webhook.example.com via the AdmissionRegistration API
Sep 21 16:05:51.906: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:05:52.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6179" for this suite.
Sep 21 16:05:58.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:05:59.054: INFO: namespace webhook-6179 deletion completed in 6.374445339s
STEP: Destroying namespace "webhook-6179-markers" for this suite.
Sep 21 16:06:05.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:06:05.389: INFO: namespace webhook-6179-markers deletion completed in 6.334370522s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.012 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:06:05.432: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Sep 21 16:06:05.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 --namespace=kubectl-6580 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep 21 16:06:07.841: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep 21 16:06:07.842: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:06:09.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6580" for this suite.
Sep 21 16:06:15.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:06:16.214: INFO: namespace kubectl-6580 deletion completed in 6.341894274s

• [SLOW TEST:10.782 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:06:16.216: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:06:27.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8854" for this suite.
Sep 21 16:06:33.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:06:33.898: INFO: namespace resourcequota-8854 deletion completed in 6.338595588s

• [SLOW TEST:17.682 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:06:33.898: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2990
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Sep 21 16:06:34.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-2990'
Sep 21 16:06:34.460: INFO: stderr: ""
Sep 21 16:06:34.460: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 16:06:34.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2990'
Sep 21 16:06:34.543: INFO: stderr: ""
Sep 21 16:06:34.543: INFO: stdout: "update-demo-nautilus-dspwh update-demo-nautilus-r5sr8 "
Sep 21 16:06:34.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-dspwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:34.624: INFO: stderr: ""
Sep 21 16:06:34.624: INFO: stdout: ""
Sep 21 16:06:34.624: INFO: update-demo-nautilus-dspwh is created but not running
Sep 21 16:06:39.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2990'
Sep 21 16:06:39.706: INFO: stderr: ""
Sep 21 16:06:39.706: INFO: stdout: "update-demo-nautilus-dspwh update-demo-nautilus-r5sr8 "
Sep 21 16:06:39.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-dspwh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:39.787: INFO: stderr: ""
Sep 21 16:06:39.787: INFO: stdout: "true"
Sep 21 16:06:39.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-dspwh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:39.859: INFO: stderr: ""
Sep 21 16:06:39.859: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 16:06:39.859: INFO: validating pod update-demo-nautilus-dspwh
Sep 21 16:06:39.878: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 16:06:39.878: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 16:06:39.878: INFO: update-demo-nautilus-dspwh is verified up and running
Sep 21 16:06:39.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-r5sr8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:39.955: INFO: stderr: ""
Sep 21 16:06:39.955: INFO: stdout: "true"
Sep 21 16:06:39.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-r5sr8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:40.027: INFO: stderr: ""
Sep 21 16:06:40.027: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 16:06:40.027: INFO: validating pod update-demo-nautilus-r5sr8
Sep 21 16:06:40.049: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 16:06:40.049: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 16:06:40.049: INFO: update-demo-nautilus-r5sr8 is verified up and running
STEP: scaling down the replication controller
Sep 21 16:06:40.051: INFO: scanned /root for discovery docs: <nil>
Sep 21 16:06:40.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2990'
Sep 21 16:06:41.173: INFO: stderr: ""
Sep 21 16:06:41.173: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 16:06:41.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2990'
Sep 21 16:06:41.242: INFO: stderr: ""
Sep 21 16:06:41.242: INFO: stdout: "update-demo-nautilus-dspwh update-demo-nautilus-r5sr8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 21 16:06:46.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2990'
Sep 21 16:06:46.322: INFO: stderr: ""
Sep 21 16:06:46.322: INFO: stdout: "update-demo-nautilus-dspwh update-demo-nautilus-r5sr8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 21 16:06:51.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2990'
Sep 21 16:06:51.408: INFO: stderr: ""
Sep 21 16:06:51.408: INFO: stdout: "update-demo-nautilus-r5sr8 "
Sep 21 16:06:51.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-r5sr8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:51.487: INFO: stderr: ""
Sep 21 16:06:51.487: INFO: stdout: "true"
Sep 21 16:06:51.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-r5sr8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:51.559: INFO: stderr: ""
Sep 21 16:06:51.559: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 16:06:51.559: INFO: validating pod update-demo-nautilus-r5sr8
Sep 21 16:06:51.573: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 16:06:51.573: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 16:06:51.573: INFO: update-demo-nautilus-r5sr8 is verified up and running
STEP: scaling up the replication controller
Sep 21 16:06:51.575: INFO: scanned /root for discovery docs: <nil>
Sep 21 16:06:51.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2990'
Sep 21 16:06:52.707: INFO: stderr: ""
Sep 21 16:06:52.707: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 16:06:52.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2990'
Sep 21 16:06:52.795: INFO: stderr: ""
Sep 21 16:06:52.795: INFO: stdout: "update-demo-nautilus-r5sr8 update-demo-nautilus-w7tpg "
Sep 21 16:06:52.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-r5sr8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:52.888: INFO: stderr: ""
Sep 21 16:06:52.888: INFO: stdout: "true"
Sep 21 16:06:52.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-r5sr8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:52.962: INFO: stderr: ""
Sep 21 16:06:52.962: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 16:06:52.962: INFO: validating pod update-demo-nautilus-r5sr8
Sep 21 16:06:52.976: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 16:06:52.976: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 16:06:52.976: INFO: update-demo-nautilus-r5sr8 is verified up and running
Sep 21 16:06:52.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-w7tpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:53.049: INFO: stderr: ""
Sep 21 16:06:53.049: INFO: stdout: ""
Sep 21 16:06:53.049: INFO: update-demo-nautilus-w7tpg is created but not running
Sep 21 16:06:58.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2990'
Sep 21 16:06:58.132: INFO: stderr: ""
Sep 21 16:06:58.132: INFO: stdout: "update-demo-nautilus-r5sr8 update-demo-nautilus-w7tpg "
Sep 21 16:06:58.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-r5sr8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:58.217: INFO: stderr: ""
Sep 21 16:06:58.217: INFO: stdout: "true"
Sep 21 16:06:58.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-r5sr8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:58.294: INFO: stderr: ""
Sep 21 16:06:58.294: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 16:06:58.294: INFO: validating pod update-demo-nautilus-r5sr8
Sep 21 16:06:58.308: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 16:06:58.308: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 16:06:58.308: INFO: update-demo-nautilus-r5sr8 is verified up and running
Sep 21 16:06:58.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-w7tpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:58.378: INFO: stderr: ""
Sep 21 16:06:58.378: INFO: stdout: "true"
Sep 21 16:06:58.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-w7tpg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2990'
Sep 21 16:06:58.455: INFO: stderr: ""
Sep 21 16:06:58.455: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 16:06:58.455: INFO: validating pod update-demo-nautilus-w7tpg
Sep 21 16:06:58.489: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 16:06:58.489: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 16:06:58.489: INFO: update-demo-nautilus-w7tpg is verified up and running
STEP: using delete to clean up resources
Sep 21 16:06:58.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete --grace-period=0 --force -f - --namespace=kubectl-2990'
Sep 21 16:06:58.574: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 16:06:58.574: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 21 16:06:58.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2990'
Sep 21 16:06:58.666: INFO: stderr: "No resources found in kubectl-2990 namespace.\n"
Sep 21 16:06:58.666: INFO: stdout: ""
Sep 21 16:06:58.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -l name=update-demo --namespace=kubectl-2990 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 21 16:06:58.742: INFO: stderr: ""
Sep 21 16:06:58.742: INFO: stdout: "update-demo-nautilus-r5sr8\nupdate-demo-nautilus-w7tpg\n"
Sep 21 16:06:59.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2990'
Sep 21 16:06:59.340: INFO: stderr: "No resources found in kubectl-2990 namespace.\n"
Sep 21 16:06:59.340: INFO: stdout: ""
Sep 21 16:06:59.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -l name=update-demo --namespace=kubectl-2990 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 21 16:06:59.450: INFO: stderr: ""
Sep 21 16:06:59.450: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:06:59.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2990" for this suite.
Sep 21 16:07:29.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:07:29.810: INFO: namespace kubectl-2990 deletion completed in 30.346624045s

• [SLOW TEST:55.913 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:07:29.811: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2773
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Sep 21 16:07:32.663: INFO: Successfully updated pod "labelsupdateef2aa25d-e295-443a-ac5e-53cccf1cbbde"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:07:34.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2773" for this suite.
Sep 21 16:07:46.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:07:47.071: INFO: namespace projected-2773 deletion completed in 12.342701782s

• [SLOW TEST:17.260 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:07:47.071: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6205
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:08:03.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6205" for this suite.
Sep 21 16:08:09.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:08:09.888: INFO: namespace resourcequota-6205 deletion completed in 6.349966347s

• [SLOW TEST:22.817 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:08:09.894: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7261
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-01ddff77-06e8-4bd8-82b5-a3ad43b18bfe in namespace container-probe-7261
Sep 21 16:08:12.194: INFO: Started pod liveness-01ddff77-06e8-4bd8-82b5-a3ad43b18bfe in namespace container-probe-7261
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 16:08:12.202: INFO: Initial restart count of pod liveness-01ddff77-06e8-4bd8-82b5-a3ad43b18bfe is 0
Sep 21 16:08:30.302: INFO: Restart count of pod container-probe-7261/liveness-01ddff77-06e8-4bd8-82b5-a3ad43b18bfe is now 1 (18.099738956s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:08:30.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7261" for this suite.
Sep 21 16:08:36.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:08:36.690: INFO: namespace container-probe-7261 deletion completed in 6.348729178s

• [SLOW TEST:26.796 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:08:36.691: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2839
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:08:36.954: INFO: Waiting up to 5m0s for pod "busybox-user-65534-651f3784-ef31-48b5-b008-8acec5b6b07c" in namespace "security-context-test-2839" to be "success or failure"
Sep 21 16:08:36.966: INFO: Pod "busybox-user-65534-651f3784-ef31-48b5-b008-8acec5b6b07c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.090133ms
Sep 21 16:08:38.975: INFO: Pod "busybox-user-65534-651f3784-ef31-48b5-b008-8acec5b6b07c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020312384s
Sep 21 16:08:40.984: INFO: Pod "busybox-user-65534-651f3784-ef31-48b5-b008-8acec5b6b07c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02949067s
Sep 21 16:08:40.984: INFO: Pod "busybox-user-65534-651f3784-ef31-48b5-b008-8acec5b6b07c" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:08:40.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2839" for this suite.
Sep 21 16:08:47.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:08:47.351: INFO: namespace security-context-test-2839 deletion completed in 6.353815091s

• [SLOW TEST:10.660 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:08:47.352: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-796
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-796
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 21 16:08:47.593: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 21 16:09:09.812: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.195.228:8080/dial?request=hostName&protocol=udp&host=172.30.185.254&port=8081&tries=1'] Namespace:pod-network-test-796 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 16:09:09.812: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 16:09:09.994: INFO: Waiting for endpoints: map[]
Sep 21 16:09:10.002: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.195.228:8080/dial?request=hostName&protocol=udp&host=172.30.21.51&port=8081&tries=1'] Namespace:pod-network-test-796 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 16:09:10.002: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 16:09:10.154: INFO: Waiting for endpoints: map[]
Sep 21 16:09:10.163: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.195.228:8080/dial?request=hostName&protocol=udp&host=172.30.195.224&port=8081&tries=1'] Namespace:pod-network-test-796 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 16:09:10.164: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 16:09:10.337: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:09:10.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-796" for this suite.
Sep 21 16:09:22.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:09:22.698: INFO: namespace pod-network-test-796 deletion completed in 12.347116735s

• [SLOW TEST:35.346 seconds]
[sig-network] Networking
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:09:22.698: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-46b37e09-7be2-4c11-bec8-6b6c20e357c6 in namespace container-probe-3665
Sep 21 16:09:24.969: INFO: Started pod liveness-46b37e09-7be2-4c11-bec8-6b6c20e357c6 in namespace container-probe-3665
STEP: checking the pod's current state and verifying that restartCount is present
Sep 21 16:09:24.977: INFO: Initial restart count of pod liveness-46b37e09-7be2-4c11-bec8-6b6c20e357c6 is 0
Sep 21 16:09:39.057: INFO: Restart count of pod container-probe-3665/liveness-46b37e09-7be2-4c11-bec8-6b6c20e357c6 is now 1 (14.079776317s elapsed)
Sep 21 16:09:59.154: INFO: Restart count of pod container-probe-3665/liveness-46b37e09-7be2-4c11-bec8-6b6c20e357c6 is now 2 (34.177186218s elapsed)
Sep 21 16:10:19.262: INFO: Restart count of pod container-probe-3665/liveness-46b37e09-7be2-4c11-bec8-6b6c20e357c6 is now 3 (54.285366274s elapsed)
Sep 21 16:10:39.368: INFO: Restart count of pod container-probe-3665/liveness-46b37e09-7be2-4c11-bec8-6b6c20e357c6 is now 4 (1m14.39100094s elapsed)
Sep 21 16:11:51.747: INFO: Restart count of pod container-probe-3665/liveness-46b37e09-7be2-4c11-bec8-6b6c20e357c6 is now 5 (2m26.769663717s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:11:51.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3665" for this suite.
Sep 21 16:11:57.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:11:58.158: INFO: namespace container-probe-3665 deletion completed in 6.363602207s

• [SLOW TEST:155.460 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:11:58.158: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-6529
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Sep 21 16:11:58.410: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-6529" to be "success or failure"
Sep 21 16:11:58.418: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.434968ms
Sep 21 16:12:00.428: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018181436s
Sep 21 16:12:02.437: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027083141s
STEP: Saw pod success
Sep 21 16:12:02.437: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep 21 16:12:02.445: INFO: Trying to get logs from node 10.189.39.109 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 21 16:12:02.526: INFO: Waiting for pod pod-host-path-test to disappear
Sep 21 16:12:02.534: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:12:02.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-6529" for this suite.
Sep 21 16:12:08.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:12:08.904: INFO: namespace hostpath-6529 deletion completed in 6.356266592s

• [SLOW TEST:10.746 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:12:08.907: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8229
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:12:15.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8229" for this suite.
Sep 21 16:12:23.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:12:23.520: INFO: namespace job-8229 deletion completed in 8.348956635s

• [SLOW TEST:14.613 seconds]
[sig-apps] Job
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:12:23.521: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-71
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-46397a2b-8baa-4402-91d1-a09cf917ef2d
STEP: Creating a pod to test consume configMaps
Sep 21 16:12:23.780: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d339633-7bcb-4e79-a44c-f052c996127a" in namespace "configmap-71" to be "success or failure"
Sep 21 16:12:23.790: INFO: Pod "pod-configmaps-7d339633-7bcb-4e79-a44c-f052c996127a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.585172ms
Sep 21 16:12:25.800: INFO: Pod "pod-configmaps-7d339633-7bcb-4e79-a44c-f052c996127a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019632157s
Sep 21 16:12:27.809: INFO: Pod "pod-configmaps-7d339633-7bcb-4e79-a44c-f052c996127a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028774922s
STEP: Saw pod success
Sep 21 16:12:27.809: INFO: Pod "pod-configmaps-7d339633-7bcb-4e79-a44c-f052c996127a" satisfied condition "success or failure"
Sep 21 16:12:27.818: INFO: Trying to get logs from node 10.189.39.109 pod pod-configmaps-7d339633-7bcb-4e79-a44c-f052c996127a container configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 16:12:27.865: INFO: Waiting for pod pod-configmaps-7d339633-7bcb-4e79-a44c-f052c996127a to disappear
Sep 21 16:12:27.873: INFO: Pod pod-configmaps-7d339633-7bcb-4e79-a44c-f052c996127a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:12:27.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-71" for this suite.
Sep 21 16:12:33.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:12:34.225: INFO: namespace configmap-71 deletion completed in 6.336357975s

• [SLOW TEST:10.704 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:12:34.225: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3074
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3074.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3074.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3074.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3074.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3074.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3074.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 16:12:38.645: INFO: DNS probes using dns-3074/dns-test-6513d5d3-545a-4b2e-b729-f15235c20d98 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:12:38.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3074" for this suite.
Sep 21 16:12:44.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:12:45.056: INFO: namespace dns-3074 deletion completed in 6.370940772s

• [SLOW TEST:10.831 seconds]
[sig-network] DNS
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:12:45.056: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6090
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Sep 21 16:12:45.310: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:13:02.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6090" for this suite.
Sep 21 16:13:08.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:13:09.311: INFO: namespace crd-publish-openapi-6090 deletion completed in 6.386444476s

• [SLOW TEST:24.255 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:13:09.311: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5072
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-xm8fs in namespace proxy-5072
I0921 16:13:09.584218      24 runners.go:184] Created replication controller with name: proxy-service-xm8fs, namespace: proxy-5072, replica count: 1
I0921 16:13:10.634856      24 runners.go:184] proxy-service-xm8fs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0921 16:13:11.635071      24 runners.go:184] proxy-service-xm8fs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0921 16:13:12.635309      24 runners.go:184] proxy-service-xm8fs Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 16:13:12.645: INFO: setup took 3.094466882s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 21 16:13:12.668: INFO: (0) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 22.494917ms)
Sep 21 16:13:12.669: INFO: (0) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 22.7802ms)
Sep 21 16:13:12.669: INFO: (0) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 23.112363ms)
Sep 21 16:13:12.669: INFO: (0) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 23.561105ms)
Sep 21 16:13:12.670: INFO: (0) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 24.143871ms)
Sep 21 16:13:12.670: INFO: (0) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 24.259009ms)
Sep 21 16:13:12.670: INFO: (0) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 24.335517ms)
Sep 21 16:13:12.676: INFO: (0) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 30.425347ms)
Sep 21 16:13:12.676: INFO: (0) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 30.334689ms)
Sep 21 16:13:12.676: INFO: (0) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 30.511973ms)
Sep 21 16:13:12.676: INFO: (0) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 30.313774ms)
Sep 21 16:13:12.687: INFO: (0) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 41.929622ms)
Sep 21 16:13:12.687: INFO: (0) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 41.549441ms)
Sep 21 16:13:12.689: INFO: (0) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 42.86423ms)
Sep 21 16:13:12.690: INFO: (0) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 43.827086ms)
Sep 21 16:13:12.690: INFO: (0) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 43.802455ms)
Sep 21 16:13:12.705: INFO: (1) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 14.555251ms)
Sep 21 16:13:12.705: INFO: (1) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 14.413842ms)
Sep 21 16:13:12.706: INFO: (1) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 15.520325ms)
Sep 21 16:13:12.706: INFO: (1) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 15.713707ms)
Sep 21 16:13:12.706: INFO: (1) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 15.830996ms)
Sep 21 16:13:12.706: INFO: (1) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 15.872898ms)
Sep 21 16:13:12.706: INFO: (1) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 16.596894ms)
Sep 21 16:13:12.707: INFO: (1) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 16.605206ms)
Sep 21 16:13:12.707: INFO: (1) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 16.904784ms)
Sep 21 16:13:12.707: INFO: (1) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 16.803156ms)
Sep 21 16:13:12.710: INFO: (1) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 20.125564ms)
Sep 21 16:13:12.715: INFO: (1) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 24.573567ms)
Sep 21 16:13:12.716: INFO: (1) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 26.380662ms)
Sep 21 16:13:12.717: INFO: (1) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 26.156218ms)
Sep 21 16:13:12.717: INFO: (1) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 27.296483ms)
Sep 21 16:13:12.718: INFO: (1) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 27.462196ms)
Sep 21 16:13:12.744: INFO: (2) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 26.629603ms)
Sep 21 16:13:12.745: INFO: (2) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 26.70241ms)
Sep 21 16:13:12.745: INFO: (2) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 26.996002ms)
Sep 21 16:13:12.745: INFO: (2) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 26.748474ms)
Sep 21 16:13:12.746: INFO: (2) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 27.758169ms)
Sep 21 16:13:12.746: INFO: (2) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 27.522584ms)
Sep 21 16:13:12.746: INFO: (2) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 28.330783ms)
Sep 21 16:13:12.747: INFO: (2) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 28.841649ms)
Sep 21 16:13:12.747: INFO: (2) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 28.746749ms)
Sep 21 16:13:12.747: INFO: (2) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 29.236154ms)
Sep 21 16:13:12.749: INFO: (2) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 30.454411ms)
Sep 21 16:13:12.750: INFO: (2) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 31.988928ms)
Sep 21 16:13:12.751: INFO: (2) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 33.220489ms)
Sep 21 16:13:12.757: INFO: (2) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 38.613082ms)
Sep 21 16:13:12.757: INFO: (2) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 39.05607ms)
Sep 21 16:13:12.757: INFO: (2) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 39.293786ms)
Sep 21 16:13:12.770: INFO: (3) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 12.802506ms)
Sep 21 16:13:12.773: INFO: (3) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 15.085576ms)
Sep 21 16:13:12.773: INFO: (3) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 15.164736ms)
Sep 21 16:13:12.773: INFO: (3) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 15.548644ms)
Sep 21 16:13:12.773: INFO: (3) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 15.779331ms)
Sep 21 16:13:12.774: INFO: (3) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 16.192404ms)
Sep 21 16:13:12.774: INFO: (3) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 16.235537ms)
Sep 21 16:13:12.774: INFO: (3) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 16.364566ms)
Sep 21 16:13:12.774: INFO: (3) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 16.473823ms)
Sep 21 16:13:12.774: INFO: (3) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 16.569635ms)
Sep 21 16:13:12.778: INFO: (3) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 20.545103ms)
Sep 21 16:13:12.782: INFO: (3) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 24.609955ms)
Sep 21 16:13:12.784: INFO: (3) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 25.993712ms)
Sep 21 16:13:12.784: INFO: (3) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 26.490054ms)
Sep 21 16:13:12.784: INFO: (3) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 26.593784ms)
Sep 21 16:13:12.784: INFO: (3) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 26.726794ms)
Sep 21 16:13:12.799: INFO: (4) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 14.487558ms)
Sep 21 16:13:12.799: INFO: (4) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 14.700162ms)
Sep 21 16:13:12.799: INFO: (4) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 14.441342ms)
Sep 21 16:13:12.800: INFO: (4) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 14.757288ms)
Sep 21 16:13:12.800: INFO: (4) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 15.513019ms)
Sep 21 16:13:12.801: INFO: (4) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 15.829712ms)
Sep 21 16:13:12.801: INFO: (4) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 16.02264ms)
Sep 21 16:13:12.801: INFO: (4) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 16.238608ms)
Sep 21 16:13:12.802: INFO: (4) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 16.861678ms)
Sep 21 16:13:12.802: INFO: (4) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 16.928299ms)
Sep 21 16:13:12.802: INFO: (4) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 17.362373ms)
Sep 21 16:13:12.809: INFO: (4) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 23.821804ms)
Sep 21 16:13:12.810: INFO: (4) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 25.639733ms)
Sep 21 16:13:12.810: INFO: (4) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 25.542746ms)
Sep 21 16:13:12.811: INFO: (4) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 25.681074ms)
Sep 21 16:13:12.811: INFO: (4) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 26.102863ms)
Sep 21 16:13:12.824: INFO: (5) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 12.659245ms)
Sep 21 16:13:12.825: INFO: (5) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 13.551374ms)
Sep 21 16:13:12.826: INFO: (5) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 13.629423ms)
Sep 21 16:13:12.826: INFO: (5) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 14.437151ms)
Sep 21 16:13:12.826: INFO: (5) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 14.245495ms)
Sep 21 16:13:12.826: INFO: (5) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 15.075005ms)
Sep 21 16:13:12.827: INFO: (5) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 15.288518ms)
Sep 21 16:13:12.827: INFO: (5) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 15.145668ms)
Sep 21 16:13:12.827: INFO: (5) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 15.825555ms)
Sep 21 16:13:12.827: INFO: (5) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 15.672796ms)
Sep 21 16:13:12.828: INFO: (5) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 17.285447ms)
Sep 21 16:13:12.833: INFO: (5) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 21.478773ms)
Sep 21 16:13:12.834: INFO: (5) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 22.452177ms)
Sep 21 16:13:12.836: INFO: (5) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 23.565695ms)
Sep 21 16:13:12.836: INFO: (5) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 23.87699ms)
Sep 21 16:13:12.836: INFO: (5) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 23.829325ms)
Sep 21 16:13:12.849: INFO: (6) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 13.618913ms)
Sep 21 16:13:12.850: INFO: (6) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 14.259845ms)
Sep 21 16:13:12.851: INFO: (6) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 14.504371ms)
Sep 21 16:13:12.851: INFO: (6) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 14.696513ms)
Sep 21 16:13:12.851: INFO: (6) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 14.869693ms)
Sep 21 16:13:12.851: INFO: (6) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 15.204824ms)
Sep 21 16:13:12.852: INFO: (6) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 15.848891ms)
Sep 21 16:13:12.852: INFO: (6) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 15.81191ms)
Sep 21 16:13:12.852: INFO: (6) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 15.92793ms)
Sep 21 16:13:12.852: INFO: (6) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 15.974769ms)
Sep 21 16:13:12.856: INFO: (6) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 19.829445ms)
Sep 21 16:13:12.859: INFO: (6) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 22.88688ms)
Sep 21 16:13:12.861: INFO: (6) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 25.00931ms)
Sep 21 16:13:12.861: INFO: (6) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 25.104683ms)
Sep 21 16:13:12.861: INFO: (6) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 25.302827ms)
Sep 21 16:13:12.862: INFO: (6) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 25.418072ms)
Sep 21 16:13:12.875: INFO: (7) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 13.812266ms)
Sep 21 16:13:12.877: INFO: (7) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 14.225548ms)
Sep 21 16:13:12.877: INFO: (7) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 15.378805ms)
Sep 21 16:13:12.878: INFO: (7) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 15.611228ms)
Sep 21 16:13:12.878: INFO: (7) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 15.413593ms)
Sep 21 16:13:12.878: INFO: (7) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 15.200273ms)
Sep 21 16:13:12.879: INFO: (7) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 15.392719ms)
Sep 21 16:13:12.879: INFO: (7) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 16.600529ms)
Sep 21 16:13:12.880: INFO: (7) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 17.711003ms)
Sep 21 16:13:12.880: INFO: (7) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 18.138561ms)
Sep 21 16:13:12.886: INFO: (7) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 23.917915ms)
Sep 21 16:13:12.888: INFO: (7) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 24.810926ms)
Sep 21 16:13:12.890: INFO: (7) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 27.587552ms)
Sep 21 16:13:12.890: INFO: (7) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 27.72723ms)
Sep 21 16:13:12.891: INFO: (7) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 27.332056ms)
Sep 21 16:13:12.891: INFO: (7) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 28.561962ms)
Sep 21 16:13:12.911: INFO: (8) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 19.841338ms)
Sep 21 16:13:12.911: INFO: (8) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 19.287384ms)
Sep 21 16:13:12.911: INFO: (8) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 19.469707ms)
Sep 21 16:13:12.911: INFO: (8) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 19.401124ms)
Sep 21 16:13:12.911: INFO: (8) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 20.153674ms)
Sep 21 16:13:12.911: INFO: (8) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 18.978417ms)
Sep 21 16:13:12.911: INFO: (8) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 18.902817ms)
Sep 21 16:13:12.915: INFO: (8) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 23.493611ms)
Sep 21 16:13:12.915: INFO: (8) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 24.07232ms)
Sep 21 16:13:12.915: INFO: (8) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 24.179017ms)
Sep 21 16:13:12.916: INFO: (8) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 23.708061ms)
Sep 21 16:13:12.918: INFO: (8) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 27.382384ms)
Sep 21 16:13:12.918: INFO: (8) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 26.74901ms)
Sep 21 16:13:12.918: INFO: (8) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 26.337406ms)
Sep 21 16:13:12.919: INFO: (8) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 27.460295ms)
Sep 21 16:13:12.920: INFO: (8) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 28.622169ms)
Sep 21 16:13:12.932: INFO: (9) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 12.138847ms)
Sep 21 16:13:12.934: INFO: (9) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 13.267001ms)
Sep 21 16:13:12.934: INFO: (9) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 13.108677ms)
Sep 21 16:13:12.934: INFO: (9) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 13.230208ms)
Sep 21 16:13:12.934: INFO: (9) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 13.45747ms)
Sep 21 16:13:12.934: INFO: (9) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 13.330478ms)
Sep 21 16:13:12.934: INFO: (9) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 13.172576ms)
Sep 21 16:13:12.934: INFO: (9) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 13.949493ms)
Sep 21 16:13:12.935: INFO: (9) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 14.011373ms)
Sep 21 16:13:12.935: INFO: (9) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 13.971357ms)
Sep 21 16:13:12.936: INFO: (9) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 15.390014ms)
Sep 21 16:13:12.940: INFO: (9) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 19.240182ms)
Sep 21 16:13:12.942: INFO: (9) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 21.269883ms)
Sep 21 16:13:12.944: INFO: (9) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 23.794668ms)
Sep 21 16:13:12.945: INFO: (9) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 24.117745ms)
Sep 21 16:13:12.945: INFO: (9) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 24.061187ms)
Sep 21 16:13:12.960: INFO: (10) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 14.862482ms)
Sep 21 16:13:12.962: INFO: (10) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 17.008887ms)
Sep 21 16:13:12.962: INFO: (10) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 17.668311ms)
Sep 21 16:13:12.963: INFO: (10) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 17.794866ms)
Sep 21 16:13:12.963: INFO: (10) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 18.332167ms)
Sep 21 16:13:12.963: INFO: (10) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 18.220009ms)
Sep 21 16:13:12.964: INFO: (10) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 18.937945ms)
Sep 21 16:13:12.964: INFO: (10) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 18.88873ms)
Sep 21 16:13:12.965: INFO: (10) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 20.038959ms)
Sep 21 16:13:12.966: INFO: (10) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 20.989822ms)
Sep 21 16:13:12.968: INFO: (10) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 23.651126ms)
Sep 21 16:13:12.968: INFO: (10) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 23.579558ms)
Sep 21 16:13:12.969: INFO: (10) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 23.862881ms)
Sep 21 16:13:12.969: INFO: (10) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 24.224192ms)
Sep 21 16:13:12.969: INFO: (10) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 24.026352ms)
Sep 21 16:13:12.970: INFO: (10) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 24.834121ms)
Sep 21 16:13:12.983: INFO: (11) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 12.952866ms)
Sep 21 16:13:12.985: INFO: (11) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 14.237156ms)
Sep 21 16:13:12.985: INFO: (11) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 14.362526ms)
Sep 21 16:13:12.985: INFO: (11) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 14.122198ms)
Sep 21 16:13:12.987: INFO: (11) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 16.034038ms)
Sep 21 16:13:12.987: INFO: (11) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 16.403153ms)
Sep 21 16:13:12.989: INFO: (11) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 17.852228ms)
Sep 21 16:13:12.989: INFO: (11) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 18.314997ms)
Sep 21 16:13:12.990: INFO: (11) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 18.374302ms)
Sep 21 16:13:12.990: INFO: (11) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 18.97656ms)
Sep 21 16:13:12.990: INFO: (11) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 19.730349ms)
Sep 21 16:13:12.993: INFO: (11) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 21.579795ms)
Sep 21 16:13:12.994: INFO: (11) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 22.755541ms)
Sep 21 16:13:12.994: INFO: (11) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 23.181221ms)
Sep 21 16:13:12.994: INFO: (11) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 23.141724ms)
Sep 21 16:13:12.994: INFO: (11) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 23.968679ms)
Sep 21 16:13:13.008: INFO: (12) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 13.26933ms)
Sep 21 16:13:13.011: INFO: (12) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 16.738715ms)
Sep 21 16:13:13.012: INFO: (12) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 17.154378ms)
Sep 21 16:13:13.012: INFO: (12) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 17.310136ms)
Sep 21 16:13:13.012: INFO: (12) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 17.097195ms)
Sep 21 16:13:13.012: INFO: (12) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 17.219065ms)
Sep 21 16:13:13.012: INFO: (12) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 17.331236ms)
Sep 21 16:13:13.012: INFO: (12) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 17.666535ms)
Sep 21 16:13:13.013: INFO: (12) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 17.740226ms)
Sep 21 16:13:13.013: INFO: (12) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 17.911286ms)
Sep 21 16:13:13.016: INFO: (12) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 21.2666ms)
Sep 21 16:13:13.017: INFO: (12) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 22.41514ms)
Sep 21 16:13:13.020: INFO: (12) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 25.02217ms)
Sep 21 16:13:13.020: INFO: (12) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 25.113651ms)
Sep 21 16:13:13.020: INFO: (12) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 25.357957ms)
Sep 21 16:13:13.021: INFO: (12) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 25.804387ms)
Sep 21 16:13:13.035: INFO: (13) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 13.858139ms)
Sep 21 16:13:13.036: INFO: (13) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 15.035174ms)
Sep 21 16:13:13.036: INFO: (13) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 14.861752ms)
Sep 21 16:13:13.038: INFO: (13) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 16.957919ms)
Sep 21 16:13:13.039: INFO: (13) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 17.561294ms)
Sep 21 16:13:13.039: INFO: (13) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 18.172911ms)
Sep 21 16:13:13.040: INFO: (13) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 18.704005ms)
Sep 21 16:13:13.040: INFO: (13) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 19.49912ms)
Sep 21 16:13:13.042: INFO: (13) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 21.016198ms)
Sep 21 16:13:13.042: INFO: (13) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 21.499634ms)
Sep 21 16:13:13.042: INFO: (13) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 21.41048ms)
Sep 21 16:13:13.045: INFO: (13) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 23.77838ms)
Sep 21 16:13:13.046: INFO: (13) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 25.350872ms)
Sep 21 16:13:13.047: INFO: (13) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 25.795803ms)
Sep 21 16:13:13.047: INFO: (13) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 26.413265ms)
Sep 21 16:13:13.051: INFO: (13) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 30.005817ms)
Sep 21 16:13:13.066: INFO: (14) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 14.785025ms)
Sep 21 16:13:13.066: INFO: (14) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 14.95049ms)
Sep 21 16:13:13.066: INFO: (14) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 15.137217ms)
Sep 21 16:13:13.067: INFO: (14) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 14.921837ms)
Sep 21 16:13:13.067: INFO: (14) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 15.341641ms)
Sep 21 16:13:13.068: INFO: (14) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 16.182026ms)
Sep 21 16:13:13.068: INFO: (14) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 16.276716ms)
Sep 21 16:13:13.068: INFO: (14) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 16.725432ms)
Sep 21 16:13:13.071: INFO: (14) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 19.314751ms)
Sep 21 16:13:13.071: INFO: (14) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 19.390209ms)
Sep 21 16:13:13.071: INFO: (14) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 20.30782ms)
Sep 21 16:13:13.073: INFO: (14) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 22.392337ms)
Sep 21 16:13:13.075: INFO: (14) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 23.336647ms)
Sep 21 16:13:13.075: INFO: (14) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 23.651477ms)
Sep 21 16:13:13.075: INFO: (14) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 24.164851ms)
Sep 21 16:13:13.076: INFO: (14) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 24.09703ms)
Sep 21 16:13:13.088: INFO: (15) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 11.976189ms)
Sep 21 16:13:13.090: INFO: (15) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 13.446426ms)
Sep 21 16:13:13.091: INFO: (15) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 13.642254ms)
Sep 21 16:13:13.091: INFO: (15) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 15.309422ms)
Sep 21 16:13:13.091: INFO: (15) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 14.382119ms)
Sep 21 16:13:13.091: INFO: (15) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 14.320661ms)
Sep 21 16:13:13.092: INFO: (15) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 15.195145ms)
Sep 21 16:13:13.092: INFO: (15) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 15.966431ms)
Sep 21 16:13:13.092: INFO: (15) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 16.142382ms)
Sep 21 16:13:13.093: INFO: (15) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 17.009828ms)
Sep 21 16:13:13.104: INFO: (15) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 27.326685ms)
Sep 21 16:13:13.104: INFO: (15) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 27.227556ms)
Sep 21 16:13:13.104: INFO: (15) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 26.908927ms)
Sep 21 16:13:13.104: INFO: (15) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 26.795262ms)
Sep 21 16:13:13.104: INFO: (15) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 26.616344ms)
Sep 21 16:13:13.104: INFO: (15) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 26.657039ms)
Sep 21 16:13:13.120: INFO: (16) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 16.053166ms)
Sep 21 16:13:13.121: INFO: (16) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 16.45197ms)
Sep 21 16:13:13.121: INFO: (16) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 16.669306ms)
Sep 21 16:13:13.121: INFO: (16) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 17.484435ms)
Sep 21 16:13:13.122: INFO: (16) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 17.74275ms)
Sep 21 16:13:13.122: INFO: (16) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 17.5595ms)
Sep 21 16:13:13.123: INFO: (16) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 18.431547ms)
Sep 21 16:13:13.123: INFO: (16) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 18.612451ms)
Sep 21 16:13:13.123: INFO: (16) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 19.078638ms)
Sep 21 16:13:13.125: INFO: (16) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 20.511328ms)
Sep 21 16:13:13.125: INFO: (16) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 20.74329ms)
Sep 21 16:13:13.125: INFO: (16) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 21.429569ms)
Sep 21 16:13:13.126: INFO: (16) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 21.780737ms)
Sep 21 16:13:13.126: INFO: (16) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 22.211446ms)
Sep 21 16:13:13.127: INFO: (16) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 22.700436ms)
Sep 21 16:13:13.127: INFO: (16) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 23.139291ms)
Sep 21 16:13:13.140: INFO: (17) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 12.700746ms)
Sep 21 16:13:13.142: INFO: (17) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 14.131212ms)
Sep 21 16:13:13.142: INFO: (17) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 14.162823ms)
Sep 21 16:13:13.142: INFO: (17) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 14.882303ms)
Sep 21 16:13:13.143: INFO: (17) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 15.605974ms)
Sep 21 16:13:13.143: INFO: (17) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 15.8599ms)
Sep 21 16:13:13.143: INFO: (17) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 16.00981ms)
Sep 21 16:13:13.144: INFO: (17) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 16.223884ms)
Sep 21 16:13:13.144: INFO: (17) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 16.330471ms)
Sep 21 16:13:13.144: INFO: (17) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 16.562846ms)
Sep 21 16:13:13.147: INFO: (17) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 20.220635ms)
Sep 21 16:13:13.147: INFO: (17) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 19.95336ms)
Sep 21 16:13:13.149: INFO: (17) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 21.273742ms)
Sep 21 16:13:13.149: INFO: (17) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 21.733986ms)
Sep 21 16:13:13.149: INFO: (17) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 21.818912ms)
Sep 21 16:13:13.149: INFO: (17) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 21.916596ms)
Sep 21 16:13:13.163: INFO: (18) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 13.969161ms)
Sep 21 16:13:13.164: INFO: (18) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 14.022916ms)
Sep 21 16:13:13.164: INFO: (18) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 14.330738ms)
Sep 21 16:13:13.164: INFO: (18) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 14.303119ms)
Sep 21 16:13:13.165: INFO: (18) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 15.011211ms)
Sep 21 16:13:13.166: INFO: (18) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 16.710217ms)
Sep 21 16:13:13.166: INFO: (18) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 16.762739ms)
Sep 21 16:13:13.166: INFO: (18) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 16.839811ms)
Sep 21 16:13:13.166: INFO: (18) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 16.520782ms)
Sep 21 16:13:13.166: INFO: (18) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 16.804173ms)
Sep 21 16:13:13.170: INFO: (18) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 19.778107ms)
Sep 21 16:13:13.172: INFO: (18) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 22.603487ms)
Sep 21 16:13:13.175: INFO: (18) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 25.702824ms)
Sep 21 16:13:13.176: INFO: (18) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 25.67546ms)
Sep 21 16:13:13.176: INFO: (18) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 25.650626ms)
Sep 21 16:13:13.176: INFO: (18) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 25.985232ms)
Sep 21 16:13:13.190: INFO: (19) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx/proxy/rewriteme">test</a> (200; 13.947452ms)
Sep 21 16:13:13.192: INFO: (19) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:443/proxy/tlsrewritem... (200; 15.692735ms)
Sep 21 16:13:13.192: INFO: (19) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 16.097633ms)
Sep 21 16:13:13.193: INFO: (19) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:162/proxy/: bar (200; 17.039301ms)
Sep 21 16:13:13.193: INFO: (19) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 16.43431ms)
Sep 21 16:13:13.193: INFO: (19) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">test<... (200; 17.183692ms)
Sep 21 16:13:13.194: INFO: (19) /api/v1/namespaces/proxy-5072/pods/proxy-service-xm8fs-lhkhx:160/proxy/: foo (200; 17.183277ms)
Sep 21 16:13:13.194: INFO: (19) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:462/proxy/: tls qux (200; 18.303333ms)
Sep 21 16:13:13.196: INFO: (19) /api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5072/pods/http:proxy-service-xm8fs-lhkhx:1080/proxy/rewriteme">... (200; 19.703974ms)
Sep 21 16:13:13.196: INFO: (19) /api/v1/namespaces/proxy-5072/pods/https:proxy-service-xm8fs-lhkhx:460/proxy/: tls baz (200; 19.718022ms)
Sep 21 16:13:13.196: INFO: (19) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname1/proxy/: tls baz (200; 20.496961ms)
Sep 21 16:13:13.198: INFO: (19) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname2/proxy/: bar (200; 21.690724ms)
Sep 21 16:13:13.200: INFO: (19) /api/v1/namespaces/proxy-5072/services/https:proxy-service-xm8fs:tlsportname2/proxy/: tls qux (200; 23.437538ms)
Sep 21 16:13:13.201: INFO: (19) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname1/proxy/: foo (200; 24.362611ms)
Sep 21 16:13:13.202: INFO: (19) /api/v1/namespaces/proxy-5072/services/http:proxy-service-xm8fs:portname1/proxy/: foo (200; 25.490751ms)
Sep 21 16:13:13.202: INFO: (19) /api/v1/namespaces/proxy-5072/services/proxy-service-xm8fs:portname2/proxy/: bar (200; 26.004517ms)
STEP: deleting ReplicationController proxy-service-xm8fs in namespace proxy-5072, will wait for the garbage collector to delete the pods
Sep 21 16:13:13.284: INFO: Deleting ReplicationController proxy-service-xm8fs took: 21.625358ms
Sep 21 16:13:13.584: INFO: Terminating ReplicationController proxy-service-xm8fs pods took: 300.230082ms
[AfterEach] version v1
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:13:21.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5072" for this suite.
Sep 21 16:13:27.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:13:28.187: INFO: namespace proxy-5072 deletion completed in 6.388180861s

• [SLOW TEST:18.876 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:13:28.187: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8719
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 21 16:13:28.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-8719'
Sep 21 16:13:28.603: INFO: stderr: ""
Sep 21 16:13:28.603: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Sep 21 16:13:28.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete pods e2e-test-httpd-pod --namespace=kubectl-8719'
Sep 21 16:13:41.718: INFO: stderr: ""
Sep 21 16:13:41.718: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:13:41.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8719" for this suite.
Sep 21 16:13:47.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:13:48.107: INFO: namespace kubectl-8719 deletion completed in 6.373441888s

• [SLOW TEST:19.920 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:13:48.107: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5326
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-264fb81a-d584-493b-a56d-51a236236c79
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:13:48.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5326" for this suite.
Sep 21 16:13:54.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:13:54.739: INFO: namespace secrets-5326 deletion completed in 6.347681525s

• [SLOW TEST:6.632 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:13:54.740: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6676
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0921 16:13:56.132022      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 21 16:13:56.132: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:13:56.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6676" for this suite.
Sep 21 16:14:04.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:14:04.507: INFO: namespace gc-6676 deletion completed in 8.358329694s

• [SLOW TEST:9.767 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:14:04.508: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-599
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 16:14:04.773: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4803729e-d5ee-436f-9106-09f748c1ce16" in namespace "downward-api-599" to be "success or failure"
Sep 21 16:14:04.784: INFO: Pod "downwardapi-volume-4803729e-d5ee-436f-9106-09f748c1ce16": Phase="Pending", Reason="", readiness=false. Elapsed: 11.01805ms
Sep 21 16:14:06.801: INFO: Pod "downwardapi-volume-4803729e-d5ee-436f-9106-09f748c1ce16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02853957s
STEP: Saw pod success
Sep 21 16:14:06.801: INFO: Pod "downwardapi-volume-4803729e-d5ee-436f-9106-09f748c1ce16" satisfied condition "success or failure"
Sep 21 16:14:06.811: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-4803729e-d5ee-436f-9106-09f748c1ce16 container client-container: <nil>
STEP: delete the pod
Sep 21 16:14:06.878: INFO: Waiting for pod downwardapi-volume-4803729e-d5ee-436f-9106-09f748c1ce16 to disappear
Sep 21 16:14:06.886: INFO: Pod downwardapi-volume-4803729e-d5ee-436f-9106-09f748c1ce16 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:14:06.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-599" for this suite.
Sep 21 16:14:12.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:14:13.241: INFO: namespace downward-api-599 deletion completed in 6.333756134s

• [SLOW TEST:8.734 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:14:13.242: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1775
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1775.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1775.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 16:14:17.556: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:17.570: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:17.584: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:17.598: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:17.643: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:17.657: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:17.671: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:17.683: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:17.711: INFO: Lookups using dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local]

Sep 21 16:14:22.726: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:22.738: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:22.752: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:22.764: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:22.805: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:22.819: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:22.833: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:22.847: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:22.875: INFO: Lookups using dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local]

Sep 21 16:14:27.728: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:27.742: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:27.756: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:27.769: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:27.813: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:27.826: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:27.840: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:27.853: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:27.882: INFO: Lookups using dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local]

Sep 21 16:14:32.726: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:32.739: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:32.755: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:32.771: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:32.810: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:32.823: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:32.837: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:32.851: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:32.878: INFO: Lookups using dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local]

Sep 21 16:14:37.726: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:37.741: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:37.755: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:37.768: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:37.808: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:37.824: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:37.838: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:37.852: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:37.877: INFO: Lookups using dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local]

Sep 21 16:14:42.725: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:42.737: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:42.751: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:42.765: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:42.803: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:42.816: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:42.828: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:42.841: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local from pod dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2: the server could not find the requested resource (get pods dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2)
Sep 21 16:14:42.866: INFO: Lookups using dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1775.svc.cluster.local jessie_udp@dns-test-service-2.dns-1775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1775.svc.cluster.local]

Sep 21 16:14:47.895: INFO: DNS probes using dns-1775/dns-test-36daa778-6412-4afb-8d8b-4f097586d8d2 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:14:47.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1775" for this suite.
Sep 21 16:14:56.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:14:56.337: INFO: namespace dns-1775 deletion completed in 8.362064966s

• [SLOW TEST:43.095 seconds]
[sig-network] DNS
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:14:56.337: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9947
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 21 16:14:56.577: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 21 16:14:56.630: INFO: Waiting for terminating namespaces to be deleted...
Sep 21 16:14:56.640: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.107 before test
Sep 21 16:14:56.706: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-wl754 from kube-system started at 2020-09-21 15:34:03 +0000 UTC (4 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 16:14:56.706: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 16:14:56.706: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 16:14:56.706: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 16:14:56.706: INFO: catalog-operator-67cbc5d959-dq2t6 from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container catalog-operator ready: true, restart count 0
Sep 21 16:14:56.706: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pk8wt from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 16:14:56.706: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 16:14:56.706: INFO: ibm-keepalived-watcher-zkkcm from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 16:14:56.706: INFO: dashboard-metrics-scraper-76756886dc-mkkzv from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 21 16:14:56.706: INFO: ibm-storage-watcher-69664bb666-tt4h6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Sep 21 16:14:56.706: INFO: vpn-79845b6f9d-jkrfr from kube-system started at 2020-09-21 13:20:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container vpn ready: true, restart count 0
Sep 21 16:14:56.706: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-99989 from ibm-system started at 2020-09-21 15:34:03 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
Sep 21 16:14:56.706: INFO: ibm-master-proxy-static-10.189.39.107 from kube-system started at 2020-09-21 13:10:54 +0000 UTC (2 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 16:14:56.706: INFO: 	Container pause ready: true, restart count 0
Sep 21 16:14:56.706: INFO: kubernetes-dashboard-5977b5969-2nxvq from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 21 16:14:56.706: INFO: sonobuoy-e2e-job-6e9ba11f9ded426e from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container e2e ready: true, restart count 0
Sep 21 16:14:56.706: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 16:14:56.706: INFO: metrics-server-c86549c5-x7xfd from kube-system started at 2020-09-21 13:11:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container metrics-server ready: true, restart count 0
Sep 21 16:14:56.706: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Sep 21 16:14:56.706: INFO: coredns-autoscaler-65c89858bf-nbnlc from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container autoscaler ready: true, restart count 0
Sep 21 16:14:56.706: INFO: ibm-file-plugin-75656db994-jw4r2 from kube-system started at 2020-09-21 13:11:19 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Sep 21 16:14:56.706: INFO: coredns-55db5d97fb-x5w82 from kube-system started at 2020-09-21 13:20:46 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container coredns ready: true, restart count 0
Sep 21 16:14:56.706: INFO: calico-node-bsqdv from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 16:14:56.706: INFO: olm-operator-6f74dfc868-pmh8h from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container olm-operator ready: true, restart count 0
Sep 21 16:14:56.706: INFO: calico-kube-controllers-66c5f69b5f-cbmg6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.706: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 21 16:14:56.706: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.109 before test
Sep 21 16:14:56.739: INFO: addon-catalog-source-zchlp from ibm-system started at 2020-09-21 13:13:49 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.739: INFO: 	Container configmap-registry-server ready: true, restart count 0
Sep 21 16:14:56.739: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pgfzj from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:14:56.739: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 16:14:56.739: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 16:14:56.739: INFO: ibm-master-proxy-static-10.189.39.109 from kube-system started at 2020-09-21 13:12:01 +0000 UTC (2 container statuses recorded)
Sep 21 16:14:56.739: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 16:14:56.739: INFO: 	Container pause ready: true, restart count 0
Sep 21 16:14:56.739: INFO: calico-node-pplqw from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.739: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 16:14:56.739: INFO: ibm-keepalived-watcher-fb29r from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.739: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 16:14:56.739: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.114 before test
Sep 21 16:14:56.788: INFO: ibm-master-proxy-static-10.189.39.114 from kube-system started at 2020-09-21 13:11:38 +0000 UTC (2 container statuses recorded)
Sep 21 16:14:56.788: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 16:14:56.788: INFO: 	Container pause ready: true, restart count 0
Sep 21 16:14:56.788: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-kgtrl from kube-system started at 2020-09-21 13:25:35 +0000 UTC (4 container statuses recorded)
Sep 21 16:14:56.788: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 16:14:56.788: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 16:14:56.788: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 16:14:56.788: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 16:14:56.788: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-ntgzw from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:14:56.788: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 16:14:56.788: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 16:14:56.788: INFO: calico-node-xtntd from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.788: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 16:14:56.788: INFO: ibm-keepalived-watcher-4r8qr from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.788: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 16:14:56.788: INFO: coredns-55db5d97fb-z9cdn from kube-system started at 2020-09-21 13:20:47 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.788: INFO: 	Container coredns ready: true, restart count 0
Sep 21 16:14:56.788: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-pp552 from ibm-system started at 2020-09-21 13:18:25 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.788: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
Sep 21 16:14:56.788: INFO: sonobuoy from sonobuoy started at 2020-09-21 14:34:24 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.788: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 21 16:14:56.788: INFO: coredns-55db5d97fb-wkf29 from kube-system started at 2020-09-21 15:39:03 +0000 UTC (1 container statuses recorded)
Sep 21 16:14:56.788: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6e650e48-5ce2-4e1c-a637-80016d236bbc 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-6e650e48-5ce2-4e1c-a637-80016d236bbc off the node 10.189.39.109
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6e650e48-5ce2-4e1c-a637-80016d236bbc
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:15:09.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9947" for this suite.
Sep 21 16:15:25.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:15:25.385: INFO: namespace sched-pred-9947 deletion completed in 16.337055733s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:29.048 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:15:25.385: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3181
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 21 16:15:25.650: INFO: Waiting up to 5m0s for pod "pod-308b61c6-6381-4d93-a76d-57be13c9e031" in namespace "emptydir-3181" to be "success or failure"
Sep 21 16:15:25.660: INFO: Pod "pod-308b61c6-6381-4d93-a76d-57be13c9e031": Phase="Pending", Reason="", readiness=false. Elapsed: 9.492286ms
Sep 21 16:15:27.670: INFO: Pod "pod-308b61c6-6381-4d93-a76d-57be13c9e031": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02022155s
Sep 21 16:15:29.681: INFO: Pod "pod-308b61c6-6381-4d93-a76d-57be13c9e031": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031283216s
STEP: Saw pod success
Sep 21 16:15:29.681: INFO: Pod "pod-308b61c6-6381-4d93-a76d-57be13c9e031" satisfied condition "success or failure"
Sep 21 16:15:29.690: INFO: Trying to get logs from node 10.189.39.109 pod pod-308b61c6-6381-4d93-a76d-57be13c9e031 container test-container: <nil>
STEP: delete the pod
Sep 21 16:15:29.737: INFO: Waiting for pod pod-308b61c6-6381-4d93-a76d-57be13c9e031 to disappear
Sep 21 16:15:29.745: INFO: Pod pod-308b61c6-6381-4d93-a76d-57be13c9e031 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:15:29.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3181" for this suite.
Sep 21 16:15:35.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:15:36.099: INFO: namespace emptydir-3181 deletion completed in 6.341020133s

• [SLOW TEST:10.714 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:15:36.099: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 21 16:15:38.396: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:15:38.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6782" for this suite.
Sep 21 16:15:44.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:15:44.795: INFO: namespace container-runtime-6782 deletion completed in 6.352392684s

• [SLOW TEST:8.696 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:15:44.796: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:15:48.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2510" for this suite.
Sep 21 16:16:18.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:16:18.500: INFO: namespace replication-controller-2510 deletion completed in 30.349170828s

• [SLOW TEST:33.705 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:16:18.501: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-979
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:16:24.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-979" for this suite.
Sep 21 16:16:30.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:16:30.541: INFO: namespace watch-979 deletion completed in 6.417991741s

• [SLOW TEST:12.040 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:16:30.541: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 16:16:30.818: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf46817f-0479-4280-b0d9-a72a664fa461" in namespace "projected-8829" to be "success or failure"
Sep 21 16:16:30.828: INFO: Pod "downwardapi-volume-bf46817f-0479-4280-b0d9-a72a664fa461": Phase="Pending", Reason="", readiness=false. Elapsed: 10.202786ms
Sep 21 16:16:32.841: INFO: Pod "downwardapi-volume-bf46817f-0479-4280-b0d9-a72a664fa461": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022722895s
Sep 21 16:16:34.854: INFO: Pod "downwardapi-volume-bf46817f-0479-4280-b0d9-a72a664fa461": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035800899s
STEP: Saw pod success
Sep 21 16:16:34.854: INFO: Pod "downwardapi-volume-bf46817f-0479-4280-b0d9-a72a664fa461" satisfied condition "success or failure"
Sep 21 16:16:34.865: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-bf46817f-0479-4280-b0d9-a72a664fa461 container client-container: <nil>
STEP: delete the pod
Sep 21 16:16:34.921: INFO: Waiting for pod downwardapi-volume-bf46817f-0479-4280-b0d9-a72a664fa461 to disappear
Sep 21 16:16:34.930: INFO: Pod downwardapi-volume-bf46817f-0479-4280-b0d9-a72a664fa461 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:16:34.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8829" for this suite.
Sep 21 16:16:40.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:16:41.504: INFO: namespace projected-8829 deletion completed in 6.558926203s

• [SLOW TEST:10.963 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:16:41.505: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-4851
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4851, will wait for the garbage collector to delete the pods
Sep 21 16:16:45.854: INFO: Deleting Job.batch foo took: 25.227098ms
Sep 21 16:16:46.155: INFO: Terminating Job.batch foo pods took: 300.485214ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:17:22.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4851" for this suite.
Sep 21 16:17:28.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:17:28.432: INFO: namespace job-4851 deletion completed in 6.34299568s

• [SLOW TEST:46.928 seconds]
[sig-apps] Job
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:17:28.432: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 21 16:17:28.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-6633'
Sep 21 16:17:28.754: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 21 16:17:28.754: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Sep 21 16:17:28.769: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-jx5tx]
Sep 21 16:17:28.769: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-jx5tx" in namespace "kubectl-6633" to be "running and ready"
Sep 21 16:17:28.778: INFO: Pod "e2e-test-httpd-rc-jx5tx": Phase="Pending", Reason="", readiness=false. Elapsed: 9.094381ms
Sep 21 16:17:30.789: INFO: Pod "e2e-test-httpd-rc-jx5tx": Phase="Running", Reason="", readiness=true. Elapsed: 2.019310621s
Sep 21 16:17:30.789: INFO: Pod "e2e-test-httpd-rc-jx5tx" satisfied condition "running and ready"
Sep 21 16:17:30.789: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-jx5tx]
Sep 21 16:17:30.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 logs rc/e2e-test-httpd-rc --namespace=kubectl-6633'
Sep 21 16:17:30.922: INFO: stderr: ""
Sep 21 16:17:30.922: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.195.251. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.195.251. Set the 'ServerName' directive globally to suppress this message\n[Mon Sep 21 16:17:30.119614 2020] [mpm_event:notice] [pid 1:tid 139758575278952] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Sep 21 16:17:30.119676 2020] [core:notice] [pid 1:tid 139758575278952] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Sep 21 16:17:30.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete rc e2e-test-httpd-rc --namespace=kubectl-6633'
Sep 21 16:17:31.021: INFO: stderr: ""
Sep 21 16:17:31.021: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:17:31.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6633" for this suite.
Sep 21 16:17:37.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:17:37.366: INFO: namespace kubectl-6633 deletion completed in 6.329353072s

• [SLOW TEST:8.933 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:17:37.366: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9476
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:17:37.614: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:17:38.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9476" for this suite.
Sep 21 16:17:44.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:17:44.537: INFO: namespace custom-resource-definition-9476 deletion completed in 6.358897242s

• [SLOW TEST:7.171 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:17:44.537: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3845
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 16:17:45.179: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 16:17:47.207: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301865, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301865, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301865, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736301865, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 16:17:50.239: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:17:50.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3845" for this suite.
Sep 21 16:17:56.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:17:56.758: INFO: namespace webhook-3845 deletion completed in 6.334936954s
STEP: Destroying namespace "webhook-3845-markers" for this suite.
Sep 21 16:18:02.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:18:03.142: INFO: namespace webhook-3845-markers deletion completed in 6.383678865s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.650 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:18:03.191: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 21 16:18:03.449: INFO: Waiting up to 5m0s for pod "downward-api-46b976dd-ab82-4d0e-ad85-ef67e06414b9" in namespace "downward-api-576" to be "success or failure"
Sep 21 16:18:03.458: INFO: Pod "downward-api-46b976dd-ab82-4d0e-ad85-ef67e06414b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.17199ms
Sep 21 16:18:05.469: INFO: Pod "downward-api-46b976dd-ab82-4d0e-ad85-ef67e06414b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01955265s
Sep 21 16:18:07.477: INFO: Pod "downward-api-46b976dd-ab82-4d0e-ad85-ef67e06414b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028368016s
STEP: Saw pod success
Sep 21 16:18:07.478: INFO: Pod "downward-api-46b976dd-ab82-4d0e-ad85-ef67e06414b9" satisfied condition "success or failure"
Sep 21 16:18:07.486: INFO: Trying to get logs from node 10.189.39.109 pod downward-api-46b976dd-ab82-4d0e-ad85-ef67e06414b9 container dapi-container: <nil>
STEP: delete the pod
Sep 21 16:18:07.533: INFO: Waiting for pod downward-api-46b976dd-ab82-4d0e-ad85-ef67e06414b9 to disappear
Sep 21 16:18:07.541: INFO: Pod downward-api-46b976dd-ab82-4d0e-ad85-ef67e06414b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:18:07.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-576" for this suite.
Sep 21 16:18:13.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:18:13.900: INFO: namespace downward-api-576 deletion completed in 6.346148248s

• [SLOW TEST:10.709 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:18:13.900: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-627
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-1ddcc321-5223-46bc-a60d-939f7f712b3c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1ddcc321-5223-46bc-a60d-939f7f712b3c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:19:27.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-627" for this suite.
Sep 21 16:19:43.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:19:43.484: INFO: namespace configmap-627 deletion completed in 16.368017036s

• [SLOW TEST:89.584 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:19:43.487: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6256
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:19:43.795: INFO: (0) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 36.255051ms)
Sep 21 16:19:43.809: INFO: (1) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.760997ms)
Sep 21 16:19:43.822: INFO: (2) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.999083ms)
Sep 21 16:19:43.834: INFO: (3) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.665189ms)
Sep 21 16:19:43.852: INFO: (4) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.020048ms)
Sep 21 16:19:43.867: INFO: (5) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.147254ms)
Sep 21 16:19:43.883: INFO: (6) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.15851ms)
Sep 21 16:19:43.896: INFO: (7) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.617528ms)
Sep 21 16:19:43.910: INFO: (8) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.356974ms)
Sep 21 16:19:43.924: INFO: (9) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.042032ms)
Sep 21 16:19:43.937: INFO: (10) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.318899ms)
Sep 21 16:19:43.953: INFO: (11) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.999906ms)
Sep 21 16:19:43.966: INFO: (12) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.767415ms)
Sep 21 16:19:43.986: INFO: (13) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.274099ms)
Sep 21 16:19:44.000: INFO: (14) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.330765ms)
Sep 21 16:19:44.014: INFO: (15) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.053785ms)
Sep 21 16:19:44.028: INFO: (16) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.136527ms)
Sep 21 16:19:44.041: INFO: (17) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 12.976174ms)
Sep 21 16:19:44.055: INFO: (18) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.452555ms)
Sep 21 16:19:44.072: INFO: (19) /api/v1/nodes/10.189.39.107/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.438045ms)
[AfterEach] version v1
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:19:44.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6256" for this suite.
Sep 21 16:19:50.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:19:50.433: INFO: namespace proxy-6256 deletion completed in 6.348327496s

• [SLOW TEST:6.947 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:19:50.434: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3764
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:19:50.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3764" for this suite.
Sep 21 16:20:02.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:20:03.088: INFO: namespace kubelet-test-3764 deletion completed in 12.352518967s

• [SLOW TEST:12.654 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:20:03.090: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-fef2b88b-00c1-404e-a6f2-3b23026724ff
STEP: Creating a pod to test consume configMaps
Sep 21 16:20:03.366: INFO: Waiting up to 5m0s for pod "pod-configmaps-e942a28d-6019-4c9b-977d-7fb5f97880e3" in namespace "configmap-9064" to be "success or failure"
Sep 21 16:20:03.378: INFO: Pod "pod-configmaps-e942a28d-6019-4c9b-977d-7fb5f97880e3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.502354ms
Sep 21 16:20:05.390: INFO: Pod "pod-configmaps-e942a28d-6019-4c9b-977d-7fb5f97880e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023943201s
STEP: Saw pod success
Sep 21 16:20:05.390: INFO: Pod "pod-configmaps-e942a28d-6019-4c9b-977d-7fb5f97880e3" satisfied condition "success or failure"
Sep 21 16:20:05.399: INFO: Trying to get logs from node 10.189.39.109 pod pod-configmaps-e942a28d-6019-4c9b-977d-7fb5f97880e3 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 16:20:05.444: INFO: Waiting for pod pod-configmaps-e942a28d-6019-4c9b-977d-7fb5f97880e3 to disappear
Sep 21 16:20:05.453: INFO: Pod pod-configmaps-e942a28d-6019-4c9b-977d-7fb5f97880e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:20:05.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9064" for this suite.
Sep 21 16:20:11.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:20:11.807: INFO: namespace configmap-9064 deletion completed in 6.337759714s

• [SLOW TEST:8.717 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:20:11.807: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 21 16:20:12.055: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 21 16:20:12.096: INFO: Waiting for terminating namespaces to be deleted...
Sep 21 16:20:12.107: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.107 before test
Sep 21 16:20:12.156: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pk8wt from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 16:20:12.156: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 16:20:12.156: INFO: ibm-keepalived-watcher-zkkcm from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 16:20:12.156: INFO: dashboard-metrics-scraper-76756886dc-mkkzv from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 21 16:20:12.156: INFO: ibm-storage-watcher-69664bb666-tt4h6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Sep 21 16:20:12.156: INFO: vpn-79845b6f9d-jkrfr from kube-system started at 2020-09-21 13:20:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container vpn ready: true, restart count 0
Sep 21 16:20:12.156: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-99989 from ibm-system started at 2020-09-21 15:34:03 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
Sep 21 16:20:12.156: INFO: ibm-master-proxy-static-10.189.39.107 from kube-system started at 2020-09-21 13:10:54 +0000 UTC (2 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 16:20:12.156: INFO: 	Container pause ready: true, restart count 0
Sep 21 16:20:12.156: INFO: kubernetes-dashboard-5977b5969-2nxvq from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 21 16:20:12.156: INFO: sonobuoy-e2e-job-6e9ba11f9ded426e from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container e2e ready: true, restart count 0
Sep 21 16:20:12.156: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 16:20:12.156: INFO: metrics-server-c86549c5-x7xfd from kube-system started at 2020-09-21 13:11:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container metrics-server ready: true, restart count 0
Sep 21 16:20:12.156: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Sep 21 16:20:12.156: INFO: coredns-autoscaler-65c89858bf-nbnlc from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container autoscaler ready: true, restart count 0
Sep 21 16:20:12.156: INFO: ibm-file-plugin-75656db994-jw4r2 from kube-system started at 2020-09-21 13:11:19 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Sep 21 16:20:12.156: INFO: coredns-55db5d97fb-x5w82 from kube-system started at 2020-09-21 13:20:46 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container coredns ready: true, restart count 0
Sep 21 16:20:12.156: INFO: calico-node-bsqdv from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 16:20:12.156: INFO: olm-operator-6f74dfc868-pmh8h from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container olm-operator ready: true, restart count 0
Sep 21 16:20:12.156: INFO: calico-kube-controllers-66c5f69b5f-cbmg6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 21 16:20:12.156: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-wl754 from kube-system started at 2020-09-21 15:34:03 +0000 UTC (4 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 16:20:12.156: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 16:20:12.156: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 16:20:12.156: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 16:20:12.156: INFO: catalog-operator-67cbc5d959-dq2t6 from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.156: INFO: 	Container catalog-operator ready: true, restart count 0
Sep 21 16:20:12.156: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.109 before test
Sep 21 16:20:12.184: INFO: ibm-keepalived-watcher-fb29r from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.184: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 16:20:12.184: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pgfzj from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:20:12.184: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 16:20:12.184: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 16:20:12.184: INFO: addon-catalog-source-zchlp from ibm-system started at 2020-09-21 13:13:49 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.184: INFO: 	Container configmap-registry-server ready: true, restart count 0
Sep 21 16:20:12.184: INFO: ibm-master-proxy-static-10.189.39.109 from kube-system started at 2020-09-21 13:12:01 +0000 UTC (2 container statuses recorded)
Sep 21 16:20:12.184: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 16:20:12.184: INFO: 	Container pause ready: true, restart count 0
Sep 21 16:20:12.184: INFO: calico-node-pplqw from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.184: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 16:20:12.184: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.114 before test
Sep 21 16:20:12.237: INFO: calico-node-xtntd from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.237: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 16:20:12.237: INFO: ibm-keepalived-watcher-4r8qr from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.237: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 16:20:12.237: INFO: coredns-55db5d97fb-z9cdn from kube-system started at 2020-09-21 13:20:47 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.237: INFO: 	Container coredns ready: true, restart count 0
Sep 21 16:20:12.237: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-pp552 from ibm-system started at 2020-09-21 13:18:25 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.237: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
Sep 21 16:20:12.237: INFO: sonobuoy from sonobuoy started at 2020-09-21 14:34:24 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.237: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 21 16:20:12.237: INFO: coredns-55db5d97fb-wkf29 from kube-system started at 2020-09-21 15:39:03 +0000 UTC (1 container statuses recorded)
Sep 21 16:20:12.237: INFO: 	Container coredns ready: true, restart count 0
Sep 21 16:20:12.237: INFO: ibm-master-proxy-static-10.189.39.114 from kube-system started at 2020-09-21 13:11:38 +0000 UTC (2 container statuses recorded)
Sep 21 16:20:12.237: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 16:20:12.237: INFO: 	Container pause ready: true, restart count 0
Sep 21 16:20:12.237: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-kgtrl from kube-system started at 2020-09-21 13:25:35 +0000 UTC (4 container statuses recorded)
Sep 21 16:20:12.238: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 16:20:12.238: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 16:20:12.238: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 16:20:12.238: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 16:20:12.238: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-ntgzw from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:20:12.238: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 16:20:12.238: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1636d8e8e08e93a2], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:20:13.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9687" for this suite.
Sep 21 16:20:19.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:20:19.673: INFO: namespace sched-pred-9687 deletion completed in 6.356582314s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.866 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:20:19.674: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-187
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:20:19.933: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 21 16:20:24.943: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 21 16:20:24.943: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 21 16:20:24.989: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-187 /apis/apps/v1/namespaces/deployment-187/deployments/test-cleanup-deployment 3bbb9519-20d9-4bfe-bc2e-9e03ab2be01f 42465 1 2020-09-21 16:20:24 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003965ff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Sep 21 16:20:24.999: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Sep 21 16:20:24.999: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep 21 16:20:24.999: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-187 /apis/apps/v1/namespaces/deployment-187/replicasets/test-cleanup-controller 7e881ea8-5b58-4510-aec8-e5dba28e16b3 42466 1 2020-09-21 16:20:19 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 3bbb9519-20d9-4bfe-bc2e-9e03ab2be01f 0xc006340367 0xc006340368}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0063403c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 21 16:20:25.007: INFO: Pod "test-cleanup-controller-g7km2" is available:
&Pod{ObjectMeta:{test-cleanup-controller-g7km2 test-cleanup-controller- deployment-187 /api/v1/namespaces/deployment-187/pods/test-cleanup-controller-g7km2 40a5ed39-f4bb-4d67-aca4-4e24f6dddb2c 42458 0 2020-09-21 16:20:19 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-controller 7e881ea8-5b58-4510-aec8-e5dba28e16b3 0xc0020b06b7 0xc0020b06b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7ld5p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7ld5p,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7ld5p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 16:20:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 16:20:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 16:20:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 16:20:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:172.30.195.254,StartTime:2020-09-21 16:20:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-21 16:20:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://31f01f93ca14adac224a6ca4a632654056e3936ee88c93e14b25e85a2c502496,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.195.254,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:20:25.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-187" for this suite.
Sep 21 16:20:31.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:20:31.415: INFO: namespace deployment-187 deletion completed in 6.386982522s

• [SLOW TEST:11.741 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:20:31.415: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5365
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:20:31.690: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-eaac75eb-db11-441c-9770-9770c5ed145d" in namespace "security-context-test-5365" to be "success or failure"
Sep 21 16:20:31.699: INFO: Pod "busybox-readonly-false-eaac75eb-db11-441c-9770-9770c5ed145d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.870579ms
Sep 21 16:20:33.709: INFO: Pod "busybox-readonly-false-eaac75eb-db11-441c-9770-9770c5ed145d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019004898s
Sep 21 16:20:35.721: INFO: Pod "busybox-readonly-false-eaac75eb-db11-441c-9770-9770c5ed145d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031356399s
Sep 21 16:20:35.721: INFO: Pod "busybox-readonly-false-eaac75eb-db11-441c-9770-9770c5ed145d" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:20:35.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5365" for this suite.
Sep 21 16:20:41.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:20:42.337: INFO: namespace security-context-test-5365 deletion completed in 6.603814529s

• [SLOW TEST:10.922 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:20:42.338: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-283
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:20:58.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-283" for this suite.
Sep 21 16:21:04.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:21:05.012: INFO: namespace resourcequota-283 deletion completed in 6.329301768s

• [SLOW TEST:22.674 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:21:05.014: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-135
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:21:21.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-135" for this suite.
Sep 21 16:21:27.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:21:27.815: INFO: namespace resourcequota-135 deletion completed in 6.335538718s

• [SLOW TEST:22.801 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:21:27.815: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6152
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 16:21:28.436: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 16:21:30.461: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736302088, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736302088, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736302088, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736302088, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 16:21:33.492: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:21:43.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6152" for this suite.
Sep 21 16:21:52.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:21:52.385: INFO: namespace webhook-6152 deletion completed in 8.572127394s
STEP: Destroying namespace "webhook-6152-markers" for this suite.
Sep 21 16:21:58.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:21:58.728: INFO: namespace webhook-6152-markers deletion completed in 6.343416708s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.958 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:21:58.774: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6067
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:22:06.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6067" for this suite.
Sep 21 16:22:12.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:22:12.407: INFO: namespace resourcequota-6067 deletion completed in 6.360561587s

• [SLOW TEST:13.633 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:22:12.407: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6681
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Sep 21 16:22:43.242: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0921 16:22:43.242582      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:22:43.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6681" for this suite.
Sep 21 16:22:51.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:22:51.593: INFO: namespace gc-6681 deletion completed in 8.335778276s

• [SLOW TEST:39.186 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:22:51.594: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:22:51.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9376" for this suite.
Sep 21 16:23:03.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:23:04.258: INFO: namespace pods-9376 deletion completed in 12.377316368s

• [SLOW TEST:12.665 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:23:04.259: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3561
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-7dfba704-15a5-426b-959b-5ffbc4579ca6
STEP: Creating a pod to test consume secrets
Sep 21 16:23:04.531: INFO: Waiting up to 5m0s for pod "pod-secrets-c6628e5a-289c-4d61-8a2c-908ec6c371f8" in namespace "secrets-3561" to be "success or failure"
Sep 21 16:23:04.544: INFO: Pod "pod-secrets-c6628e5a-289c-4d61-8a2c-908ec6c371f8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.05653ms
Sep 21 16:23:06.553: INFO: Pod "pod-secrets-c6628e5a-289c-4d61-8a2c-908ec6c371f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022146879s
Sep 21 16:23:08.563: INFO: Pod "pod-secrets-c6628e5a-289c-4d61-8a2c-908ec6c371f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031789105s
STEP: Saw pod success
Sep 21 16:23:08.563: INFO: Pod "pod-secrets-c6628e5a-289c-4d61-8a2c-908ec6c371f8" satisfied condition "success or failure"
Sep 21 16:23:08.571: INFO: Trying to get logs from node 10.189.39.109 pod pod-secrets-c6628e5a-289c-4d61-8a2c-908ec6c371f8 container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 16:23:08.650: INFO: Waiting for pod pod-secrets-c6628e5a-289c-4d61-8a2c-908ec6c371f8 to disappear
Sep 21 16:23:08.658: INFO: Pod pod-secrets-c6628e5a-289c-4d61-8a2c-908ec6c371f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:23:08.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3561" for this suite.
Sep 21 16:23:14.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:23:15.024: INFO: namespace secrets-3561 deletion completed in 6.351420768s

• [SLOW TEST:10.765 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:23:15.024: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1427
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Sep 21 16:23:19.336: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-744630836 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep 21 16:23:34.441: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:23:34.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1427" for this suite.
Sep 21 16:23:40.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:23:40.855: INFO: namespace pods-1427 deletion completed in 6.391024374s

• [SLOW TEST:25.830 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:23:40.856: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6595
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-efaf4743-a196-41af-9ecd-da1a4196f3c0
STEP: Creating a pod to test consume configMaps
Sep 21 16:23:41.178: INFO: Waiting up to 5m0s for pod "pod-configmaps-c64f90b0-f233-4055-9f80-6f27309c05a6" in namespace "configmap-6595" to be "success or failure"
Sep 21 16:23:41.191: INFO: Pod "pod-configmaps-c64f90b0-f233-4055-9f80-6f27309c05a6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.225293ms
Sep 21 16:23:43.202: INFO: Pod "pod-configmaps-c64f90b0-f233-4055-9f80-6f27309c05a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024084699s
STEP: Saw pod success
Sep 21 16:23:43.202: INFO: Pod "pod-configmaps-c64f90b0-f233-4055-9f80-6f27309c05a6" satisfied condition "success or failure"
Sep 21 16:23:43.210: INFO: Trying to get logs from node 10.189.39.109 pod pod-configmaps-c64f90b0-f233-4055-9f80-6f27309c05a6 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 16:23:43.261: INFO: Waiting for pod pod-configmaps-c64f90b0-f233-4055-9f80-6f27309c05a6 to disappear
Sep 21 16:23:43.268: INFO: Pod pod-configmaps-c64f90b0-f233-4055-9f80-6f27309c05a6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:23:43.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6595" for this suite.
Sep 21 16:23:49.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:23:49.628: INFO: namespace configmap-6595 deletion completed in 6.347778469s

• [SLOW TEST:8.773 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:23:49.629: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-422bc7e4-15f3-46de-bb5d-7a746b8c2a87
STEP: Creating a pod to test consume secrets
Sep 21 16:23:49.906: INFO: Waiting up to 5m0s for pod "pod-secrets-d591dcc7-d09f-445d-97d0-87e8d4766333" in namespace "secrets-9270" to be "success or failure"
Sep 21 16:23:49.915: INFO: Pod "pod-secrets-d591dcc7-d09f-445d-97d0-87e8d4766333": Phase="Pending", Reason="", readiness=false. Elapsed: 8.572672ms
Sep 21 16:23:51.925: INFO: Pod "pod-secrets-d591dcc7-d09f-445d-97d0-87e8d4766333": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018881696s
STEP: Saw pod success
Sep 21 16:23:51.925: INFO: Pod "pod-secrets-d591dcc7-d09f-445d-97d0-87e8d4766333" satisfied condition "success or failure"
Sep 21 16:23:51.933: INFO: Trying to get logs from node 10.189.39.109 pod pod-secrets-d591dcc7-d09f-445d-97d0-87e8d4766333 container secret-env-test: <nil>
STEP: delete the pod
Sep 21 16:23:51.982: INFO: Waiting for pod pod-secrets-d591dcc7-d09f-445d-97d0-87e8d4766333 to disappear
Sep 21 16:23:51.990: INFO: Pod pod-secrets-d591dcc7-d09f-445d-97d0-87e8d4766333 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:23:51.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9270" for this suite.
Sep 21 16:23:58.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:23:58.351: INFO: namespace secrets-9270 deletion completed in 6.346984505s

• [SLOW TEST:8.723 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:23:58.352: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 16:23:58.624: INFO: Waiting up to 5m0s for pod "downwardapi-volume-842cc7b5-9ce0-4809-ad9b-814d537db88c" in namespace "projected-7168" to be "success or failure"
Sep 21 16:23:58.631: INFO: Pod "downwardapi-volume-842cc7b5-9ce0-4809-ad9b-814d537db88c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.522046ms
Sep 21 16:24:00.640: INFO: Pod "downwardapi-volume-842cc7b5-9ce0-4809-ad9b-814d537db88c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016681018s
Sep 21 16:24:02.651: INFO: Pod "downwardapi-volume-842cc7b5-9ce0-4809-ad9b-814d537db88c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02695628s
STEP: Saw pod success
Sep 21 16:24:02.651: INFO: Pod "downwardapi-volume-842cc7b5-9ce0-4809-ad9b-814d537db88c" satisfied condition "success or failure"
Sep 21 16:24:02.661: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-842cc7b5-9ce0-4809-ad9b-814d537db88c container client-container: <nil>
STEP: delete the pod
Sep 21 16:24:02.711: INFO: Waiting for pod downwardapi-volume-842cc7b5-9ce0-4809-ad9b-814d537db88c to disappear
Sep 21 16:24:02.719: INFO: Pod downwardapi-volume-842cc7b5-9ce0-4809-ad9b-814d537db88c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:24:02.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7168" for this suite.
Sep 21 16:24:08.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:24:09.110: INFO: namespace projected-7168 deletion completed in 6.377204149s

• [SLOW TEST:10.758 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:24:09.110: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5033
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:25:09.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5033" for this suite.
Sep 21 16:25:39.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:25:39.743: INFO: namespace container-probe-5033 deletion completed in 30.344635194s

• [SLOW TEST:90.633 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:25:39.744: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3092
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:25:44.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3092" for this suite.
Sep 21 16:26:34.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:26:34.467: INFO: namespace kubelet-test-3092 deletion completed in 50.338085249s

• [SLOW TEST:54.723 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:26:34.467: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 21 16:26:36.770: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:26:36.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3380" for this suite.
Sep 21 16:26:42.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:26:43.148: INFO: namespace container-runtime-3380 deletion completed in 6.330522203s

• [SLOW TEST:8.681 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:26:43.149: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7685
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 21 16:26:43.443: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 21 16:26:43.484: INFO: Waiting for terminating namespaces to be deleted...
Sep 21 16:26:43.494: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.107 before test
Sep 21 16:26:43.554: INFO: calico-node-bsqdv from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 16:26:43.554: INFO: ibm-file-plugin-75656db994-jw4r2 from kube-system started at 2020-09-21 13:11:19 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Sep 21 16:26:43.554: INFO: coredns-55db5d97fb-x5w82 from kube-system started at 2020-09-21 13:20:46 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container coredns ready: true, restart count 0
Sep 21 16:26:43.554: INFO: calico-kube-controllers-66c5f69b5f-cbmg6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 21 16:26:43.554: INFO: olm-operator-6f74dfc868-pmh8h from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container olm-operator ready: true, restart count 0
Sep 21 16:26:43.554: INFO: catalog-operator-67cbc5d959-dq2t6 from ibm-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container catalog-operator ready: true, restart count 0
Sep 21 16:26:43.554: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-wl754 from kube-system started at 2020-09-21 15:34:03 +0000 UTC (4 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 16:26:43.554: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 16:26:43.554: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 16:26:43.554: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 16:26:43.554: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pk8wt from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 16:26:43.554: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 16:26:43.554: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-99989 from ibm-system started at 2020-09-21 15:34:03 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
Sep 21 16:26:43.554: INFO: ibm-master-proxy-static-10.189.39.107 from kube-system started at 2020-09-21 13:10:54 +0000 UTC (2 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 16:26:43.554: INFO: 	Container pause ready: true, restart count 0
Sep 21 16:26:43.554: INFO: ibm-keepalived-watcher-zkkcm from kube-system started at 2020-09-21 13:11:00 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 16:26:43.554: INFO: dashboard-metrics-scraper-76756886dc-mkkzv from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 21 16:26:43.554: INFO: ibm-storage-watcher-69664bb666-tt4h6 from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Sep 21 16:26:43.554: INFO: vpn-79845b6f9d-jkrfr from kube-system started at 2020-09-21 13:20:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container vpn ready: true, restart count 0
Sep 21 16:26:43.554: INFO: coredns-autoscaler-65c89858bf-nbnlc from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container autoscaler ready: true, restart count 0
Sep 21 16:26:43.554: INFO: kubernetes-dashboard-5977b5969-2nxvq from kube-system started at 2020-09-21 13:11:10 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 21 16:26:43.554: INFO: sonobuoy-e2e-job-6e9ba11f9ded426e from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container e2e ready: true, restart count 0
Sep 21 16:26:43.554: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 21 16:26:43.554: INFO: metrics-server-c86549c5-x7xfd from kube-system started at 2020-09-21 13:11:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:26:43.554: INFO: 	Container metrics-server ready: true, restart count 0
Sep 21 16:26:43.554: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Sep 21 16:26:43.554: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.109 before test
Sep 21 16:26:43.593: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-pgfzj from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:26:43.593: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 16:26:43.593: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 16:26:43.593: INFO: addon-catalog-source-zchlp from ibm-system started at 2020-09-21 13:13:49 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.593: INFO: 	Container configmap-registry-server ready: true, restart count 0
Sep 21 16:26:43.593: INFO: ibm-master-proxy-static-10.189.39.109 from kube-system started at 2020-09-21 13:12:01 +0000 UTC (2 container statuses recorded)
Sep 21 16:26:43.593: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 16:26:43.593: INFO: 	Container pause ready: true, restart count 0
Sep 21 16:26:43.593: INFO: calico-node-pplqw from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.593: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 16:26:43.593: INFO: ibm-keepalived-watcher-fb29r from kube-system started at 2020-09-21 13:12:14 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.593: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 16:26:43.593: INFO: 
Logging pods the kubelet thinks is on node 10.189.39.114 before test
Sep 21 16:26:43.647: INFO: public-crbtka5icw0n6mlk4u6bag-alb1-6ddbb7d5cc-kgtrl from kube-system started at 2020-09-21 13:25:35 +0000 UTC (4 container statuses recorded)
Sep 21 16:26:43.647: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Sep 21 16:26:43.647: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Sep 21 16:26:43.647: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Sep 21 16:26:43.647: INFO: 	Container nginx-ingress ready: true, restart count 0
Sep 21 16:26:43.647: INFO: sonobuoy-systemd-logs-daemon-set-cbcdd74578e04fb7-ntgzw from sonobuoy started at 2020-09-21 14:34:29 +0000 UTC (2 container statuses recorded)
Sep 21 16:26:43.647: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 21 16:26:43.647: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 21 16:26:43.647: INFO: ibm-master-proxy-static-10.189.39.114 from kube-system started at 2020-09-21 13:11:38 +0000 UTC (2 container statuses recorded)
Sep 21 16:26:43.647: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Sep 21 16:26:43.648: INFO: 	Container pause ready: true, restart count 0
Sep 21 16:26:43.648: INFO: ibm-keepalived-watcher-4r8qr from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.648: INFO: 	Container keepalived-watcher ready: true, restart count 0
Sep 21 16:26:43.648: INFO: coredns-55db5d97fb-z9cdn from kube-system started at 2020-09-21 13:20:47 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.648: INFO: 	Container coredns ready: true, restart count 0
Sep 21 16:26:43.648: INFO: calico-node-xtntd from kube-system started at 2020-09-21 13:11:50 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.648: INFO: 	Container calico-node ready: true, restart count 0
Sep 21 16:26:43.648: INFO: sonobuoy from sonobuoy started at 2020-09-21 14:34:24 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.648: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 21 16:26:43.648: INFO: coredns-55db5d97fb-wkf29 from kube-system started at 2020-09-21 15:39:03 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.648: INFO: 	Container coredns ready: true, restart count 0
Sep 21 16:26:43.648: INFO: ibm-cloud-provider-ip-169-63-175-234-749787685c-pp552 from ibm-system started at 2020-09-21 13:18:25 +0000 UTC (1 container statuses recorded)
Sep 21 16:26:43.648: INFO: 	Container ibm-cloud-provider-ip-169-63-175-234 ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ab4cd7bf-7700-4005-91c8-e5b6ad939420 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-ab4cd7bf-7700-4005-91c8-e5b6ad939420 off the node 10.189.39.109
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ab4cd7bf-7700-4005-91c8-e5b6ad939420
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:31:47.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7685" for this suite.
Sep 21 16:32:03.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:32:04.266: INFO: namespace sched-pred-7685 deletion completed in 16.393938714s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:321.117 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:32:04.269: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1036
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Sep 21 16:32:04.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-1036'
Sep 21 16:32:04.804: INFO: stderr: ""
Sep 21 16:32:04.804: INFO: stdout: "pod/pause created\n"
Sep 21 16:32:04.804: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 21 16:32:04.804: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1036" to be "running and ready"
Sep 21 16:32:04.815: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.70705ms
Sep 21 16:32:06.823: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.01983863s
Sep 21 16:32:06.823: INFO: Pod "pause" satisfied condition "running and ready"
Sep 21 16:32:06.824: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 21 16:32:06.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 label pods pause testing-label=testing-label-value --namespace=kubectl-1036'
Sep 21 16:32:06.921: INFO: stderr: ""
Sep 21 16:32:06.921: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 21 16:32:06.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pod pause -L testing-label --namespace=kubectl-1036'
Sep 21 16:32:07.010: INFO: stderr: ""
Sep 21 16:32:07.010: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 21 16:32:07.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 label pods pause testing-label- --namespace=kubectl-1036'
Sep 21 16:32:07.102: INFO: stderr: ""
Sep 21 16:32:07.102: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 21 16:32:07.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pod pause -L testing-label --namespace=kubectl-1036'
Sep 21 16:32:07.185: INFO: stderr: ""
Sep 21 16:32:07.185: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Sep 21 16:32:07.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete --grace-period=0 --force -f - --namespace=kubectl-1036'
Sep 21 16:32:07.279: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 16:32:07.279: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 21 16:32:07.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get rc,svc -l name=pause --no-headers --namespace=kubectl-1036'
Sep 21 16:32:07.372: INFO: stderr: "No resources found in kubectl-1036 namespace.\n"
Sep 21 16:32:07.372: INFO: stdout: ""
Sep 21 16:32:07.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -l name=pause --namespace=kubectl-1036 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 21 16:32:07.447: INFO: stderr: ""
Sep 21 16:32:07.447: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:32:07.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1036" for this suite.
Sep 21 16:32:13.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:32:13.826: INFO: namespace kubectl-1036 deletion completed in 6.361045828s

• [SLOW TEST:9.557 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:32:13.827: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7298
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Sep 21 16:32:14.092: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:32:29.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7298" for this suite.
Sep 21 16:32:35.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:32:36.265: INFO: namespace crd-publish-openapi-7298 deletion completed in 6.338212803s

• [SLOW TEST:22.438 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:32:36.265: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1881
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-5b941cb8-3e6f-40a2-a224-633b27206bed
STEP: Creating a pod to test consume secrets
Sep 21 16:32:36.523: INFO: Waiting up to 5m0s for pod "pod-secrets-54a6973b-847b-47b4-a7d3-fb332384b24b" in namespace "secrets-1881" to be "success or failure"
Sep 21 16:32:36.531: INFO: Pod "pod-secrets-54a6973b-847b-47b4-a7d3-fb332384b24b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.181314ms
Sep 21 16:32:38.540: INFO: Pod "pod-secrets-54a6973b-847b-47b4-a7d3-fb332384b24b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017244381s
STEP: Saw pod success
Sep 21 16:32:38.540: INFO: Pod "pod-secrets-54a6973b-847b-47b4-a7d3-fb332384b24b" satisfied condition "success or failure"
Sep 21 16:32:38.549: INFO: Trying to get logs from node 10.189.39.109 pod pod-secrets-54a6973b-847b-47b4-a7d3-fb332384b24b container secret-volume-test: <nil>
STEP: delete the pod
Sep 21 16:32:38.631: INFO: Waiting for pod pod-secrets-54a6973b-847b-47b4-a7d3-fb332384b24b to disappear
Sep 21 16:32:38.638: INFO: Pod pod-secrets-54a6973b-847b-47b4-a7d3-fb332384b24b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:32:38.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1881" for this suite.
Sep 21 16:32:44.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:32:44.997: INFO: namespace secrets-1881 deletion completed in 6.346062284s

• [SLOW TEST:8.732 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:32:44.997: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1122
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1122.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1122.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1122.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1122.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1122.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1122.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 16:32:49.422: INFO: DNS probes using dns-1122/dns-test-62f3f354-25e3-450c-98a2-62bbbe6b763b succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:32:49.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1122" for this suite.
Sep 21 16:32:55.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:32:55.848: INFO: namespace dns-1122 deletion completed in 6.336462928s

• [SLOW TEST:10.851 seconds]
[sig-network] DNS
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:32:55.849: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-7188
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:32:56.099: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:32:56.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7188" for this suite.
Sep 21 16:33:02.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:33:02.573: INFO: namespace custom-resource-definition-7188 deletion completed in 6.378482362s

• [SLOW TEST:6.724 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:33:02.574: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:33:02.819: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 21 16:33:04.895: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:33:05.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2240" for this suite.
Sep 21 16:33:13.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:33:14.280: INFO: namespace replication-controller-2240 deletion completed in 8.355215877s

• [SLOW TEST:11.707 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:33:14.281: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1706.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1706.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 16:33:18.612: INFO: DNS probes using dns-test-421b5d6d-daf9-4748-af0a-07122d3a31e3 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1706.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1706.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 16:33:20.722: INFO: File wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:20.738: INFO: File jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:20.738: INFO: Lookups using dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 failed for: [wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local]

Sep 21 16:33:25.753: INFO: File wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:25.786: INFO: File jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:25.786: INFO: Lookups using dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 failed for: [wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local]

Sep 21 16:33:30.755: INFO: File wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:30.778: INFO: File jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:30.778: INFO: Lookups using dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 failed for: [wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local]

Sep 21 16:33:35.753: INFO: File wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:35.777: INFO: File jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:35.777: INFO: Lookups using dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 failed for: [wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local]

Sep 21 16:33:40.759: INFO: File wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:40.774: INFO: File jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:40.774: INFO: Lookups using dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 failed for: [wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local]

Sep 21 16:33:45.753: INFO: File wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:45.781: INFO: File jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local from pod  dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 21 16:33:45.781: INFO: Lookups using dns-1706/dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 failed for: [wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local]

Sep 21 16:33:50.768: INFO: DNS probes using dns-test-72af59f3-65e9-4955-9823-bc96f3cb9335 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1706.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1706.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1706.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1706.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 21 16:33:54.929: INFO: DNS probes using dns-test-1c3c955a-b843-4101-a2ba-e347551b4619 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:33:54.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1706" for this suite.
Sep 21 16:34:03.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:34:03.377: INFO: namespace dns-1706 deletion completed in 8.370112429s

• [SLOW TEST:49.097 seconds]
[sig-network] DNS
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:34:03.378: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-569
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:34:03.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-569" for this suite.
Sep 21 16:34:09.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:34:10.071: INFO: namespace resourcequota-569 deletion completed in 6.330575638s

• [SLOW TEST:6.693 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:34:10.071: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1056
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1056
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-1056
I0921 16:34:10.399890      24 runners.go:184] Created replication controller with name: externalname-service, namespace: services-1056, replica count: 2
Sep 21 16:34:13.450: INFO: Creating new exec pod
I0921 16:34:13.450324      24 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 21 16:34:16.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-1056 execpodxj7dn -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 21 16:34:16.767: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 21 16:34:16.767: INFO: stdout: ""
Sep 21 16:34:16.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-1056 execpodxj7dn -- /bin/sh -x -c nc -zv -t -w 2 172.21.209.58 80'
Sep 21 16:34:17.002: INFO: stderr: "+ nc -zv -t -w 2 172.21.209.58 80\nConnection to 172.21.209.58 80 port [tcp/http] succeeded!\n"
Sep 21 16:34:17.002: INFO: stdout: ""
Sep 21 16:34:17.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-1056 execpodxj7dn -- /bin/sh -x -c nc -zv -t -w 2 10.189.39.107 31215'
Sep 21 16:34:17.279: INFO: stderr: "+ nc -zv -t -w 2 10.189.39.107 31215\nConnection to 10.189.39.107 31215 port [tcp/31215] succeeded!\n"
Sep 21 16:34:17.279: INFO: stdout: ""
Sep 21 16:34:17.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-1056 execpodxj7dn -- /bin/sh -x -c nc -zv -t -w 2 10.189.39.109 31215'
Sep 21 16:34:17.529: INFO: stderr: "+ nc -zv -t -w 2 10.189.39.109 31215\nConnection to 10.189.39.109 31215 port [tcp/31215] succeeded!\n"
Sep 21 16:34:17.529: INFO: stdout: ""
Sep 21 16:34:17.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-1056 execpodxj7dn -- /bin/sh -x -c nc -zv -t -w 2 169.60.73.248 31215'
Sep 21 16:34:17.778: INFO: stderr: "+ nc -zv -t -w 2 169.60.73.248 31215\nConnection to 169.60.73.248 31215 port [tcp/31215] succeeded!\n"
Sep 21 16:34:17.778: INFO: stdout: ""
Sep 21 16:34:17.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 exec --namespace=services-1056 execpodxj7dn -- /bin/sh -x -c nc -zv -t -w 2 169.60.73.249 31215'
Sep 21 16:34:18.077: INFO: stderr: "+ nc -zv -t -w 2 169.60.73.249 31215\nConnection to 169.60.73.249 31215 port [tcp/31215] succeeded!\n"
Sep 21 16:34:18.077: INFO: stdout: ""
Sep 21 16:34:18.077: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:34:18.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1056" for this suite.
Sep 21 16:34:26.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:34:26.491: INFO: namespace services-1056 deletion completed in 8.330192561s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.420 seconds]
[sig-network] Services
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:34:26.492: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 21 16:34:32.824: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0921 16:34:32.824362      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 21 16:34:32.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6341" for this suite.
Sep 21 16:34:40.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:34:41.192: INFO: namespace gc-6341 deletion completed in 8.352914116s

• [SLOW TEST:14.701 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:34:41.193: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5035
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Sep 21 16:34:41.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-5035'
Sep 21 16:34:41.740: INFO: stderr: ""
Sep 21 16:34:41.740: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 21 16:34:41.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5035'
Sep 21 16:34:41.823: INFO: stderr: ""
Sep 21 16:34:41.823: INFO: stdout: "update-demo-nautilus-srxt7 update-demo-nautilus-tdnfq "
Sep 21 16:34:41.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-srxt7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5035'
Sep 21 16:34:41.904: INFO: stderr: ""
Sep 21 16:34:41.904: INFO: stdout: ""
Sep 21 16:34:41.904: INFO: update-demo-nautilus-srxt7 is created but not running
Sep 21 16:34:46.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5035'
Sep 21 16:34:46.985: INFO: stderr: ""
Sep 21 16:34:46.985: INFO: stdout: "update-demo-nautilus-srxt7 update-demo-nautilus-tdnfq "
Sep 21 16:34:46.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-srxt7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5035'
Sep 21 16:34:47.080: INFO: stderr: ""
Sep 21 16:34:47.080: INFO: stdout: "true"
Sep 21 16:34:47.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-srxt7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5035'
Sep 21 16:34:47.167: INFO: stderr: ""
Sep 21 16:34:47.167: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 16:34:47.167: INFO: validating pod update-demo-nautilus-srxt7
Sep 21 16:34:47.190: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 16:34:47.190: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 16:34:47.190: INFO: update-demo-nautilus-srxt7 is verified up and running
Sep 21 16:34:47.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-tdnfq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5035'
Sep 21 16:34:47.264: INFO: stderr: ""
Sep 21 16:34:47.264: INFO: stdout: "true"
Sep 21 16:34:47.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods update-demo-nautilus-tdnfq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5035'
Sep 21 16:34:47.344: INFO: stderr: ""
Sep 21 16:34:47.344: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 21 16:34:47.344: INFO: validating pod update-demo-nautilus-tdnfq
Sep 21 16:34:47.362: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 21 16:34:47.362: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 21 16:34:47.362: INFO: update-demo-nautilus-tdnfq is verified up and running
STEP: using delete to clean up resources
Sep 21 16:34:47.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete --grace-period=0 --force -f - --namespace=kubectl-5035'
Sep 21 16:34:47.449: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 16:34:47.449: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 21 16:34:47.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5035'
Sep 21 16:34:47.539: INFO: stderr: "No resources found in kubectl-5035 namespace.\n"
Sep 21 16:34:47.539: INFO: stdout: ""
Sep 21 16:34:47.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -l name=update-demo --namespace=kubectl-5035 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 21 16:34:47.612: INFO: stderr: ""
Sep 21 16:34:47.612: INFO: stdout: "update-demo-nautilus-srxt7\nupdate-demo-nautilus-tdnfq\n"
Sep 21 16:34:48.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5035'
Sep 21 16:34:48.217: INFO: stderr: "No resources found in kubectl-5035 namespace.\n"
Sep 21 16:34:48.217: INFO: stdout: ""
Sep 21 16:34:48.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 get pods -l name=update-demo --namespace=kubectl-5035 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 21 16:34:48.305: INFO: stderr: ""
Sep 21 16:34:48.305: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:34:48.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5035" for this suite.
Sep 21 16:35:00.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:35:00.685: INFO: namespace kubectl-5035 deletion completed in 12.365565606s

• [SLOW TEST:19.492 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:35:00.685: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-d20cac83-381a-46a6-bf03-525acea1c519
STEP: Creating a pod to test consume configMaps
Sep 21 16:35:00.960: INFO: Waiting up to 5m0s for pod "pod-configmaps-b9f9a724-28c4-482d-9197-98899b54a476" in namespace "configmap-8124" to be "success or failure"
Sep 21 16:35:00.970: INFO: Pod "pod-configmaps-b9f9a724-28c4-482d-9197-98899b54a476": Phase="Pending", Reason="", readiness=false. Elapsed: 10.139545ms
Sep 21 16:35:02.979: INFO: Pod "pod-configmaps-b9f9a724-28c4-482d-9197-98899b54a476": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019532878s
Sep 21 16:35:04.989: INFO: Pod "pod-configmaps-b9f9a724-28c4-482d-9197-98899b54a476": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029468904s
STEP: Saw pod success
Sep 21 16:35:04.989: INFO: Pod "pod-configmaps-b9f9a724-28c4-482d-9197-98899b54a476" satisfied condition "success or failure"
Sep 21 16:35:04.998: INFO: Trying to get logs from node 10.189.39.109 pod pod-configmaps-b9f9a724-28c4-482d-9197-98899b54a476 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 16:35:05.069: INFO: Waiting for pod pod-configmaps-b9f9a724-28c4-482d-9197-98899b54a476 to disappear
Sep 21 16:35:05.087: INFO: Pod pod-configmaps-b9f9a724-28c4-482d-9197-98899b54a476 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:35:05.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8124" for this suite.
Sep 21 16:35:11.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:35:11.442: INFO: namespace configmap-8124 deletion completed in 6.342482611s

• [SLOW TEST:10.757 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:35:11.443: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-6432
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:35:11.691: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Creating first CR 
Sep 21 16:35:12.333: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-21T16:35:12Z generation:1 name:name1 resourceVersion:45421 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:28ed1d8e-c441-4ad4-b2d8-da106645f253] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Sep 21 16:35:22.343: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-21T16:35:22Z generation:1 name:name2 resourceVersion:45434 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:e499372e-0c2d-4b94-addf-1ce889dee4c9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Sep 21 16:35:32.357: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-21T16:35:12Z generation:2 name:name1 resourceVersion:45448 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:28ed1d8e-c441-4ad4-b2d8-da106645f253] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Sep 21 16:35:42.369: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-21T16:35:22Z generation:2 name:name2 resourceVersion:45462 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:e499372e-0c2d-4b94-addf-1ce889dee4c9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Sep 21 16:35:52.394: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-21T16:35:12Z generation:2 name:name1 resourceVersion:45478 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:28ed1d8e-c441-4ad4-b2d8-da106645f253] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Sep 21 16:36:02.417: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-21T16:35:22Z generation:2 name:name2 resourceVersion:45492 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:e499372e-0c2d-4b94-addf-1ce889dee4c9] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:36:12.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-6432" for this suite.
Sep 21 16:36:19.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:36:19.354: INFO: namespace crd-watch-6432 deletion completed in 6.392797525s

• [SLOW TEST:67.912 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:36:19.355: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1253
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-1253
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1253 to expose endpoints map[]
Sep 21 16:36:19.642: INFO: Get endpoints failed (12.487662ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep 21 16:36:20.658: INFO: successfully validated that service endpoint-test2 in namespace services-1253 exposes endpoints map[] (1.027726945s elapsed)
STEP: Creating pod pod1 in namespace services-1253
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1253 to expose endpoints map[pod1:[80]]
Sep 21 16:36:22.741: INFO: successfully validated that service endpoint-test2 in namespace services-1253 exposes endpoints map[pod1:[80]] (2.063541916s elapsed)
STEP: Creating pod pod2 in namespace services-1253
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1253 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 21 16:36:24.841: INFO: successfully validated that service endpoint-test2 in namespace services-1253 exposes endpoints map[pod1:[80] pod2:[80]] (2.086460344s elapsed)
STEP: Deleting pod pod1 in namespace services-1253
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1253 to expose endpoints map[pod2:[80]]
Sep 21 16:36:24.877: INFO: successfully validated that service endpoint-test2 in namespace services-1253 exposes endpoints map[pod2:[80]] (19.82927ms elapsed)
STEP: Deleting pod pod2 in namespace services-1253
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1253 to expose endpoints map[]
Sep 21 16:36:25.914: INFO: successfully validated that service endpoint-test2 in namespace services-1253 exposes endpoints map[] (1.024439506s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:36:25.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1253" for this suite.
Sep 21 16:36:34.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:36:34.326: INFO: namespace services-1253 deletion completed in 8.343791776s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:14.971 seconds]
[sig-network] Services
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:36:34.327: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9642
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 21 16:36:34.646: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9642 /api/v1/namespaces/watch-9642/configmaps/e2e-watch-test-resource-version 040328e5-c543-4db8-b150-d5fb69a06d6d 45627 0 2020-09-21 16:36:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 21 16:36:34.646: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9642 /api/v1/namespaces/watch-9642/configmaps/e2e-watch-test-resource-version 040328e5-c543-4db8-b150-d5fb69a06d6d 45628 0 2020-09-21 16:36:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:36:34.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9642" for this suite.
Sep 21 16:36:40.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:36:41.015: INFO: namespace watch-9642 deletion completed in 6.356876123s

• [SLOW TEST:6.688 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:36:41.016: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8849
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Sep 21 16:36:41.262: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 16:36:44.257: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:36:55.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8849" for this suite.
Sep 21 16:37:01.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:37:02.231: INFO: namespace crd-publish-openapi-8849 deletion completed in 6.628008503s

• [SLOW TEST:21.215 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:37:02.232: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 16:37:03.034: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Sep 21 16:37:05.063: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303023, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303023, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303023, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303023, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 16:37:08.094: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:37:08.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4060" for this suite.
Sep 21 16:37:14.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:37:14.685: INFO: namespace webhook-4060 deletion completed in 6.342854219s
STEP: Destroying namespace "webhook-4060-markers" for this suite.
Sep 21 16:37:20.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:37:21.098: INFO: namespace webhook-4060-markers deletion completed in 6.412598758s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.910 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:37:21.143: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 21 16:37:21.433: INFO: Waiting up to 5m0s for pod "downwardapi-volume-582beeea-8b0e-46ba-a335-70950302f854" in namespace "downward-api-7804" to be "success or failure"
Sep 21 16:37:21.443: INFO: Pod "downwardapi-volume-582beeea-8b0e-46ba-a335-70950302f854": Phase="Pending", Reason="", readiness=false. Elapsed: 9.891734ms
Sep 21 16:37:23.453: INFO: Pod "downwardapi-volume-582beeea-8b0e-46ba-a335-70950302f854": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019565948s
Sep 21 16:37:25.462: INFO: Pod "downwardapi-volume-582beeea-8b0e-46ba-a335-70950302f854": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028528656s
STEP: Saw pod success
Sep 21 16:37:25.462: INFO: Pod "downwardapi-volume-582beeea-8b0e-46ba-a335-70950302f854" satisfied condition "success or failure"
Sep 21 16:37:25.471: INFO: Trying to get logs from node 10.189.39.109 pod downwardapi-volume-582beeea-8b0e-46ba-a335-70950302f854 container client-container: <nil>
STEP: delete the pod
Sep 21 16:37:25.541: INFO: Waiting for pod downwardapi-volume-582beeea-8b0e-46ba-a335-70950302f854 to disappear
Sep 21 16:37:25.549: INFO: Pod downwardapi-volume-582beeea-8b0e-46ba-a335-70950302f854 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:37:25.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7804" for this suite.
Sep 21 16:37:31.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:37:32.211: INFO: namespace downward-api-7804 deletion completed in 6.635037173s

• [SLOW TEST:11.068 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:37:32.211: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-3357
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Sep 21 16:37:32.485: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Sep 21 16:37:32.985: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep 21 16:37:35.081: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303052, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 16:37:37.089: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303052, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 16:37:39.092: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303052, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 16:37:41.091: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303052, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 16:37:43.093: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303053, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303052, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 21 16:37:46.981: INFO: Waited 1.876354304s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:37:47.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3357" for this suite.
Sep 21 16:37:53.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:37:53.960: INFO: namespace aggregator-3357 deletion completed in 6.410278674s

• [SLOW TEST:21.749 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:37:53.960: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9446
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-9446
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9446 to expose endpoints map[]
Sep 21 16:37:54.246: INFO: successfully validated that service multi-endpoint-test in namespace services-9446 exposes endpoints map[] (14.282303ms elapsed)
STEP: Creating pod pod1 in namespace services-9446
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9446 to expose endpoints map[pod1:[100]]
Sep 21 16:37:56.328: INFO: successfully validated that service multi-endpoint-test in namespace services-9446 exposes endpoints map[pod1:[100]] (2.060722497s elapsed)
STEP: Creating pod pod2 in namespace services-9446
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9446 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 21 16:37:58.428: INFO: successfully validated that service multi-endpoint-test in namespace services-9446 exposes endpoints map[pod1:[100] pod2:[101]] (2.08809341s elapsed)
STEP: Deleting pod pod1 in namespace services-9446
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9446 to expose endpoints map[pod2:[101]]
Sep 21 16:37:59.479: INFO: successfully validated that service multi-endpoint-test in namespace services-9446 exposes endpoints map[pod2:[101]] (1.036356016s elapsed)
STEP: Deleting pod pod2 in namespace services-9446
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9446 to expose endpoints map[]
Sep 21 16:38:00.531: INFO: successfully validated that service multi-endpoint-test in namespace services-9446 exposes endpoints map[] (1.037289093s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:38:00.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9446" for this suite.
Sep 21 16:38:30.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:38:30.956: INFO: namespace services-9446 deletion completed in 30.343915535s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:36.997 seconds]
[sig-network] Services
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:38:30.960: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1970
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Sep 21 16:38:31.192: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep 21 16:38:31.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-1970'
Sep 21 16:38:31.420: INFO: stderr: ""
Sep 21 16:38:31.420: INFO: stdout: "service/redis-slave created\n"
Sep 21 16:38:31.420: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep 21 16:38:31.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-1970'
Sep 21 16:38:31.567: INFO: stderr: ""
Sep 21 16:38:31.567: INFO: stdout: "service/redis-master created\n"
Sep 21 16:38:31.567: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 21 16:38:31.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-1970'
Sep 21 16:38:31.927: INFO: stderr: ""
Sep 21 16:38:31.927: INFO: stdout: "service/frontend created\n"
Sep 21 16:38:31.927: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep 21 16:38:31.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-1970'
Sep 21 16:38:32.150: INFO: stderr: ""
Sep 21 16:38:32.150: INFO: stdout: "deployment.apps/frontend created\n"
Sep 21 16:38:32.150: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 21 16:38:32.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-1970'
Sep 21 16:38:32.309: INFO: stderr: ""
Sep 21 16:38:32.310: INFO: stdout: "deployment.apps/redis-master created\n"
Sep 21 16:38:32.311: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep 21 16:38:32.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 create -f - --namespace=kubectl-1970'
Sep 21 16:38:32.472: INFO: stderr: ""
Sep 21 16:38:32.472: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep 21 16:38:32.472: INFO: Waiting for all frontend pods to be Running.
Sep 21 16:38:47.523: INFO: Waiting for frontend to serve content.
Sep 21 16:38:47.559: INFO: Trying to add a new entry to the guestbook.
Sep 21 16:38:47.594: INFO: Verifying that added entry can be retrieved.
Sep 21 16:38:47.642: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 21 16:38:52.681: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 21 16:38:57.713: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 21 16:39:02.745: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 21 16:39:07.783: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 21 16:39:12.823: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 21 16:39:17.857: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 21 16:39:22.899: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 21 16:39:27.936: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 21 16:39:32.970: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Sep 21 16:39:38.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete --grace-period=0 --force -f - --namespace=kubectl-1970'
Sep 21 16:39:38.153: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 16:39:38.153: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 16:39:38.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete --grace-period=0 --force -f - --namespace=kubectl-1970'
Sep 21 16:39:38.317: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 16:39:38.317: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 16:39:38.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete --grace-period=0 --force -f - --namespace=kubectl-1970'
Sep 21 16:39:38.465: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 16:39:38.465: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 16:39:38.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete --grace-period=0 --force -f - --namespace=kubectl-1970'
Sep 21 16:39:38.571: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 16:39:38.571: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 16:39:38.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete --grace-period=0 --force -f - --namespace=kubectl-1970'
Sep 21 16:39:38.668: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 16:39:38.668: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 21 16:39:38.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 delete --grace-period=0 --force -f - --namespace=kubectl-1970'
Sep 21 16:39:38.775: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 21 16:39:38.775: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:39:38.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1970" for this suite.
Sep 21 16:40:08.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:40:09.176: INFO: namespace kubectl-1970 deletion completed in 30.384696898s

• [SLOW TEST:98.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:40:09.176: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4397
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Sep 21 16:40:09.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-744630836 api-versions'
Sep 21 16:40:09.510: INFO: stderr: ""
Sep 21 16:40:09.510: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\noperators.coreos.com/v1\noperators.coreos.com/v1alpha1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:40:09.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4397" for this suite.
Sep 21 16:40:15.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:40:15.868: INFO: namespace kubectl-4397 deletion completed in 6.340001329s

• [SLOW TEST:6.692 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:40:15.869: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1204
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Sep 21 16:40:20.193: INFO: Pod pod-hostip-a035bea4-b1fc-4f64-b612-e657b3e0b3ac has hostIP: 10.189.39.109
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:40:20.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1204" for this suite.
Sep 21 16:40:50.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:40:50.605: INFO: namespace pods-1204 deletion completed in 30.394278161s

• [SLOW TEST:34.736 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:40:50.605: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:40:50.864: INFO: Creating deployment "test-recreate-deployment"
Sep 21 16:40:50.876: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 21 16:40:50.895: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 21 16:40:52.914: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 21 16:40:52.921: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 21 16:40:52.938: INFO: Updating deployment test-recreate-deployment
Sep 21 16:40:52.938: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 21 16:40:53.104: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-3556 /apis/apps/v1/namespaces/deployment-3556/deployments/test-recreate-deployment 8b6b3957-9806-4ebd-ad8b-d46a895ea923 46640 2 2020-09-21 16:40:50 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004bcdee8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-09-21 16:40:53 +0000 UTC,LastTransitionTime:2020-09-21 16:40:53 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-09-21 16:40:53 +0000 UTC,LastTransitionTime:2020-09-21 16:40:50 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Sep 21 16:40:53.113: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-3556 /apis/apps/v1/namespaces/deployment-3556/replicasets/test-recreate-deployment-5f94c574ff 6926add7-7573-4b06-9a29-821499d9ed24 46638 1 2020-09-21 16:40:53 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 8b6b3957-9806-4ebd-ad8b-d46a895ea923 0xc004955517 0xc004955518}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004955578 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 16:40:53.113: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 21 16:40:53.113: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-3556 /apis/apps/v1/namespaces/deployment-3556/replicasets/test-recreate-deployment-68fc85c7bb bf33d3b1-2c6c-4e2e-bef1-4b69978245f8 46629 2 2020-09-21 16:40:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 8b6b3957-9806-4ebd-ad8b-d46a895ea923 0xc0049555e7 0xc0049555e8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004955648 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 21 16:40:53.124: INFO: Pod "test-recreate-deployment-5f94c574ff-4k4rl" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-4k4rl test-recreate-deployment-5f94c574ff- deployment-3556 /api/v1/namespaces/deployment-3556/pods/test-recreate-deployment-5f94c574ff-4k4rl 6f4283bc-ebac-4d3d-9fc9-61c620656060 46641 0 2020-09-21 16:40:53 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 6926add7-7573-4b06-9a29-821499d9ed24 0xc004955ab7 0xc004955ab8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-87hs2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-87hs2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-87hs2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.189.39.109,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 16:40:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 16:40:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 16:40:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-21 16:40:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.189.39.109,PodIP:,StartTime:2020-09-21 16:40:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:40:53.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3556" for this suite.
Sep 21 16:40:59.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:40:59.500: INFO: namespace deployment-3556 deletion completed in 6.35572237s

• [SLOW TEST:8.895 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:40:59.500: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3549
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 21 16:40:59.843: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 21 16:40:59.861: INFO: Number of nodes with available pods: 0
Sep 21 16:40:59.861: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 21 16:40:59.904: INFO: Number of nodes with available pods: 0
Sep 21 16:40:59.904: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:00.914: INFO: Number of nodes with available pods: 0
Sep 21 16:41:00.914: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:01.914: INFO: Number of nodes with available pods: 1
Sep 21 16:41:01.914: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 21 16:41:01.955: INFO: Number of nodes with available pods: 1
Sep 21 16:41:01.955: INFO: Number of running nodes: 0, number of available pods: 1
Sep 21 16:41:02.965: INFO: Number of nodes with available pods: 0
Sep 21 16:41:02.965: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 21 16:41:02.997: INFO: Number of nodes with available pods: 0
Sep 21 16:41:02.997: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:04.006: INFO: Number of nodes with available pods: 0
Sep 21 16:41:04.006: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:05.007: INFO: Number of nodes with available pods: 0
Sep 21 16:41:05.007: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:06.007: INFO: Number of nodes with available pods: 0
Sep 21 16:41:06.007: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:07.008: INFO: Number of nodes with available pods: 0
Sep 21 16:41:07.008: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:08.008: INFO: Number of nodes with available pods: 0
Sep 21 16:41:08.008: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:09.007: INFO: Number of nodes with available pods: 0
Sep 21 16:41:09.007: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:10.007: INFO: Number of nodes with available pods: 0
Sep 21 16:41:10.007: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:11.007: INFO: Number of nodes with available pods: 0
Sep 21 16:41:11.007: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:12.006: INFO: Number of nodes with available pods: 0
Sep 21 16:41:12.006: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:13.006: INFO: Number of nodes with available pods: 0
Sep 21 16:41:13.006: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:14.010: INFO: Number of nodes with available pods: 0
Sep 21 16:41:14.010: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:15.009: INFO: Number of nodes with available pods: 0
Sep 21 16:41:15.009: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:41:16.008: INFO: Number of nodes with available pods: 1
Sep 21 16:41:16.008: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3549, will wait for the garbage collector to delete the pods
Sep 21 16:41:16.111: INFO: Deleting DaemonSet.extensions daemon-set took: 25.224682ms
Sep 21 16:41:16.411: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.34294ms
Sep 21 16:41:24.320: INFO: Number of nodes with available pods: 0
Sep 21 16:41:24.320: INFO: Number of running nodes: 0, number of available pods: 0
Sep 21 16:41:24.327: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3549/daemonsets","resourceVersion":"46790"},"items":null}

Sep 21 16:41:24.335: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3549/pods","resourceVersion":"46790"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:41:24.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3549" for this suite.
Sep 21 16:41:30.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:41:30.747: INFO: namespace daemonsets-3549 deletion completed in 6.343787878s

• [SLOW TEST:31.247 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:41:30.748: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6890
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 21 16:41:31.462: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 21 16:41:33.486: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303291, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303291, loc:(*time.Location)(0x78ac9c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303291, loc:(*time.Location)(0x78ac9c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63736303291, loc:(*time.Location)(0x78ac9c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 21 16:41:36.524: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:41:36.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6890" for this suite.
Sep 21 16:41:48.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:41:49.010: INFO: namespace webhook-6890 deletion completed in 12.333002289s
STEP: Destroying namespace "webhook-6890-markers" for this suite.
Sep 21 16:41:55.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:41:55.360: INFO: namespace webhook-6890-markers deletion completed in 6.350168713s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.659 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:41:55.407: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4961
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4961
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 21 16:41:55.643: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 21 16:42:15.856: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.195.241 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4961 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 16:42:15.856: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 16:42:17.020: INFO: Found all expected endpoints: [netserver-0]
Sep 21 16:42:17.028: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.21.2 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4961 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 16:42:17.028: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 16:42:18.148: INFO: Found all expected endpoints: [netserver-1]
Sep 21 16:42:18.158: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.185.205 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4961 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 21 16:42:18.158: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
Sep 21 16:42:19.295: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:42:19.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4961" for this suite.
Sep 21 16:42:31.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:42:31.658: INFO: namespace pod-network-test-4961 deletion completed in 12.349385067s

• [SLOW TEST:36.252 seconds]
[sig-network] Networking
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:42:31.658: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4094
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-9ac23bb9-e91e-47d7-a3fe-90aaecabb1f6
STEP: Creating a pod to test consume configMaps
Sep 21 16:42:31.927: INFO: Waiting up to 5m0s for pod "pod-configmaps-21986ed5-e780-49a3-8cc7-0ce6f4927976" in namespace "configmap-4094" to be "success or failure"
Sep 21 16:42:31.937: INFO: Pod "pod-configmaps-21986ed5-e780-49a3-8cc7-0ce6f4927976": Phase="Pending", Reason="", readiness=false. Elapsed: 9.360128ms
Sep 21 16:42:33.950: INFO: Pod "pod-configmaps-21986ed5-e780-49a3-8cc7-0ce6f4927976": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022392378s
STEP: Saw pod success
Sep 21 16:42:33.950: INFO: Pod "pod-configmaps-21986ed5-e780-49a3-8cc7-0ce6f4927976" satisfied condition "success or failure"
Sep 21 16:42:33.958: INFO: Trying to get logs from node 10.189.39.109 pod pod-configmaps-21986ed5-e780-49a3-8cc7-0ce6f4927976 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 21 16:42:34.047: INFO: Waiting for pod pod-configmaps-21986ed5-e780-49a3-8cc7-0ce6f4927976 to disappear
Sep 21 16:42:34.056: INFO: Pod pod-configmaps-21986ed5-e780-49a3-8cc7-0ce6f4927976 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:42:34.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4094" for this suite.
Sep 21 16:42:40.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:42:40.427: INFO: namespace configmap-4094 deletion completed in 6.355668211s

• [SLOW TEST:8.768 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:42:40.427: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8205
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:42:40.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8205" for this suite.
Sep 21 16:42:46.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:42:47.045: INFO: namespace services-8205 deletion completed in 6.344445278s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.618 seconds]
[sig-network] Services
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:42:47.045: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7364
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 21 16:42:47.301: INFO: Waiting up to 5m0s for pod "downward-api-505c3ddd-0e68-4f19-9ac9-5772b7c28032" in namespace "downward-api-7364" to be "success or failure"
Sep 21 16:42:47.317: INFO: Pod "downward-api-505c3ddd-0e68-4f19-9ac9-5772b7c28032": Phase="Pending", Reason="", readiness=false. Elapsed: 16.160581ms
Sep 21 16:42:49.331: INFO: Pod "downward-api-505c3ddd-0e68-4f19-9ac9-5772b7c28032": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029933021s
STEP: Saw pod success
Sep 21 16:42:49.331: INFO: Pod "downward-api-505c3ddd-0e68-4f19-9ac9-5772b7c28032" satisfied condition "success or failure"
Sep 21 16:42:49.340: INFO: Trying to get logs from node 10.189.39.109 pod downward-api-505c3ddd-0e68-4f19-9ac9-5772b7c28032 container dapi-container: <nil>
STEP: delete the pod
Sep 21 16:42:49.389: INFO: Waiting for pod downward-api-505c3ddd-0e68-4f19-9ac9-5772b7c28032 to disappear
Sep 21 16:42:49.399: INFO: Pod downward-api-505c3ddd-0e68-4f19-9ac9-5772b7c28032 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:42:49.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7364" for this suite.
Sep 21 16:42:55.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:42:55.740: INFO: namespace downward-api-7364 deletion completed in 6.322986615s

• [SLOW TEST:8.694 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:42:55.740: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Sep 21 16:42:56.068: INFO: Waiting up to 5m0s for pod "client-containers-b9b6e9d4-af8b-48e3-833c-323f7c9e2ee8" in namespace "containers-9394" to be "success or failure"
Sep 21 16:42:56.079: INFO: Pod "client-containers-b9b6e9d4-af8b-48e3-833c-323f7c9e2ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.333689ms
Sep 21 16:42:58.089: INFO: Pod "client-containers-b9b6e9d4-af8b-48e3-833c-323f7c9e2ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021070417s
STEP: Saw pod success
Sep 21 16:42:58.089: INFO: Pod "client-containers-b9b6e9d4-af8b-48e3-833c-323f7c9e2ee8" satisfied condition "success or failure"
Sep 21 16:42:58.099: INFO: Trying to get logs from node 10.189.39.109 pod client-containers-b9b6e9d4-af8b-48e3-833c-323f7c9e2ee8 container test-container: <nil>
STEP: delete the pod
Sep 21 16:42:58.157: INFO: Waiting for pod client-containers-b9b6e9d4-af8b-48e3-833c-323f7c9e2ee8 to disappear
Sep 21 16:42:58.165: INFO: Pod client-containers-b9b6e9d4-af8b-48e3-833c-323f7c9e2ee8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:42:58.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9394" for this suite.
Sep 21 16:43:04.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:43:04.591: INFO: namespace containers-9394 deletion completed in 6.412012085s

• [SLOW TEST:8.851 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:43:04.593: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4735
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 21 16:43:04.865: INFO: Waiting up to 5m0s for pod "pod-4e6cf214-ba1f-4d38-8da9-07c58c534e88" in namespace "emptydir-4735" to be "success or failure"
Sep 21 16:43:04.881: INFO: Pod "pod-4e6cf214-ba1f-4d38-8da9-07c58c534e88": Phase="Pending", Reason="", readiness=false. Elapsed: 16.029956ms
Sep 21 16:43:06.891: INFO: Pod "pod-4e6cf214-ba1f-4d38-8da9-07c58c534e88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025794799s
Sep 21 16:43:08.901: INFO: Pod "pod-4e6cf214-ba1f-4d38-8da9-07c58c534e88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035728283s
STEP: Saw pod success
Sep 21 16:43:08.901: INFO: Pod "pod-4e6cf214-ba1f-4d38-8da9-07c58c534e88" satisfied condition "success or failure"
Sep 21 16:43:08.909: INFO: Trying to get logs from node 10.189.39.109 pod pod-4e6cf214-ba1f-4d38-8da9-07c58c534e88 container test-container: <nil>
STEP: delete the pod
Sep 21 16:43:08.965: INFO: Waiting for pod pod-4e6cf214-ba1f-4d38-8da9-07c58c534e88 to disappear
Sep 21 16:43:08.973: INFO: Pod pod-4e6cf214-ba1f-4d38-8da9-07c58c534e88 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:43:08.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4735" for this suite.
Sep 21 16:43:15.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:43:15.332: INFO: namespace emptydir-4735 deletion completed in 6.346931607s

• [SLOW TEST:10.739 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 21 16:43:15.333: INFO: >>> kubeConfig: /tmp/kubeconfig-744630836
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6425
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 21 16:43:15.684: INFO: Number of nodes with available pods: 0
Sep 21 16:43:15.684: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:43:16.706: INFO: Number of nodes with available pods: 0
Sep 21 16:43:16.706: INFO: Node 10.189.39.107 is running more than one daemon pod
Sep 21 16:43:17.722: INFO: Number of nodes with available pods: 2
Sep 21 16:43:17.722: INFO: Node 10.189.39.109 is running more than one daemon pod
Sep 21 16:43:18.706: INFO: Number of nodes with available pods: 3
Sep 21 16:43:18.706: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 21 16:43:18.770: INFO: Number of nodes with available pods: 2
Sep 21 16:43:18.770: INFO: Node 10.189.39.109 is running more than one daemon pod
Sep 21 16:43:19.794: INFO: Number of nodes with available pods: 2
Sep 21 16:43:19.794: INFO: Node 10.189.39.109 is running more than one daemon pod
Sep 21 16:43:20.799: INFO: Number of nodes with available pods: 2
Sep 21 16:43:20.799: INFO: Node 10.189.39.109 is running more than one daemon pod
Sep 21 16:43:21.803: INFO: Number of nodes with available pods: 3
Sep 21 16:43:21.803: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6425, will wait for the garbage collector to delete the pods
Sep 21 16:43:21.911: INFO: Deleting DaemonSet.extensions daemon-set took: 20.918686ms
Sep 21 16:43:22.211: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.293221ms
Sep 21 16:43:34.326: INFO: Number of nodes with available pods: 0
Sep 21 16:43:34.326: INFO: Number of running nodes: 0, number of available pods: 0
Sep 21 16:43:34.335: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6425/daemonsets","resourceVersion":"47456"},"items":null}

Sep 21 16:43:34.342: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6425/pods","resourceVersion":"47456"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 21 16:43:34.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6425" for this suite.
Sep 21 16:43:42.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 21 16:43:42.762: INFO: namespace daemonsets-6425 deletion completed in 8.365682655s

• [SLOW TEST:27.429 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.15-rc.0.27+5ee4e161ecc8bd/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSep 21 16:43:42.762: INFO: Running AfterSuite actions on all nodes
Sep 21 16:43:42.762: INFO: Running AfterSuite actions on node 1
Sep 21 16:43:42.762: INFO: Skipping dumping logs from cluster

Ran 276 of 4847 Specs in 7734.726 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4571 Skipped
PASS

Ginkgo ran 1 suite in 2h8m55.945935658s
Test Suite Passed
