I0916 01:52:48.636116      26 test_context.go:410] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-120268828
I0916 01:52:48.636138      26 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0916 01:52:48.636267      26 e2e.go:124] Starting e2e run "b1f91db0-52c3-4003-b04f-370f6e20f8cb" on Ginkgo node 1
{"msg":"Test Suite starting","total":277,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1600221167 - Will randomize all specs
Will run 277 of 4992 specs

Sep 16 01:52:48.655: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 01:52:48.658: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 16 01:52:48.670: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 16 01:52:48.691: INFO: 3 / 3 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 16 01:52:48.691: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Sep 16 01:52:48.691: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 16 01:52:48.696: INFO: e2e test version: v1.18.8
Sep 16 01:52:48.697: INFO: kube-apiserver version: v1.18.8
Sep 16 01:52:48.697: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 01:52:48.700: INFO: Cluster IP family: ipv4
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:52:48.700: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
Sep 16 01:52:48.717: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 16 01:52:48.721: INFO: Waiting up to 5m0s for pod "downward-api-1e8d2140-bf50-4cf5-8c65-4125bdb88f15" in namespace "downward-api-1346" to be "Succeeded or Failed"
Sep 16 01:52:48.723: INFO: Pod "downward-api-1e8d2140-bf50-4cf5-8c65-4125bdb88f15": Phase="Pending", Reason="", readiness=false. Elapsed: 1.438619ms
Sep 16 01:52:50.725: INFO: Pod "downward-api-1e8d2140-bf50-4cf5-8c65-4125bdb88f15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003937023s
Sep 16 01:52:52.728: INFO: Pod "downward-api-1e8d2140-bf50-4cf5-8c65-4125bdb88f15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0062477s
STEP: Saw pod success
Sep 16 01:52:52.728: INFO: Pod "downward-api-1e8d2140-bf50-4cf5-8c65-4125bdb88f15" satisfied condition "Succeeded or Failed"
Sep 16 01:52:52.729: INFO: Trying to get logs from node 192.168.4.87 pod downward-api-1e8d2140-bf50-4cf5-8c65-4125bdb88f15 container dapi-container: <nil>
STEP: delete the pod
Sep 16 01:52:52.752: INFO: Waiting for pod downward-api-1e8d2140-bf50-4cf5-8c65-4125bdb88f15 to disappear
Sep 16 01:52:52.754: INFO: Pod downward-api-1e8d2140-bf50-4cf5-8c65-4125bdb88f15 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:52:52.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1346" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":277,"completed":1,"skipped":0,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:52:52.759: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-98ba2147-1868-4fd0-b42e-e0c5a04fd547
STEP: Creating a pod to test consume secrets
Sep 16 01:52:52.788: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-eb6be4b2-ca23-4ecc-b15c-afbb60c04570" in namespace "projected-2602" to be "Succeeded or Failed"
Sep 16 01:52:52.789: INFO: Pod "pod-projected-secrets-eb6be4b2-ca23-4ecc-b15c-afbb60c04570": Phase="Pending", Reason="", readiness=false. Elapsed: 1.199669ms
Sep 16 01:52:54.792: INFO: Pod "pod-projected-secrets-eb6be4b2-ca23-4ecc-b15c-afbb60c04570": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003791316s
Sep 16 01:52:56.794: INFO: Pod "pod-projected-secrets-eb6be4b2-ca23-4ecc-b15c-afbb60c04570": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006198988s
STEP: Saw pod success
Sep 16 01:52:56.794: INFO: Pod "pod-projected-secrets-eb6be4b2-ca23-4ecc-b15c-afbb60c04570" satisfied condition "Succeeded or Failed"
Sep 16 01:52:56.796: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-secrets-eb6be4b2-ca23-4ecc-b15c-afbb60c04570 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 16 01:52:56.805: INFO: Waiting for pod pod-projected-secrets-eb6be4b2-ca23-4ecc-b15c-afbb60c04570 to disappear
Sep 16 01:52:56.806: INFO: Pod pod-projected-secrets-eb6be4b2-ca23-4ecc-b15c-afbb60c04570 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:52:56.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2602" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":2,"skipped":6,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:52:56.811: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 01:52:56.828: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 16 01:52:58.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-2965 create -f -'
Sep 16 01:53:00.954: INFO: stderr: ""
Sep 16 01:53:00.954: INFO: stdout: "e2e-test-crd-publish-openapi-7968-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 16 01:53:00.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-2965 delete e2e-test-crd-publish-openapi-7968-crds test-cr'
Sep 16 01:53:01.027: INFO: stderr: ""
Sep 16 01:53:01.027: INFO: stdout: "e2e-test-crd-publish-openapi-7968-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Sep 16 01:53:01.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-2965 apply -f -'
Sep 16 01:53:01.270: INFO: stderr: ""
Sep 16 01:53:01.270: INFO: stdout: "e2e-test-crd-publish-openapi-7968-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 16 01:53:01.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-2965 delete e2e-test-crd-publish-openapi-7968-crds test-cr'
Sep 16 01:53:01.342: INFO: stderr: ""
Sep 16 01:53:01.342: INFO: stdout: "e2e-test-crd-publish-openapi-7968-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 16 01:53:01.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 explain e2e-test-crd-publish-openapi-7968-crds'
Sep 16 01:53:01.558: INFO: stderr: ""
Sep 16 01:53:01.558: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7968-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:53:03.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2965" for this suite.

• [SLOW TEST:6.779 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":277,"completed":3,"skipped":26,"failed":0}
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:03.589: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 16 01:53:03.610: INFO: Waiting up to 5m0s for pod "downward-api-779162b3-98a1-4c25-bc6e-6f85cc38a4fa" in namespace "downward-api-9317" to be "Succeeded or Failed"
Sep 16 01:53:03.612: INFO: Pod "downward-api-779162b3-98a1-4c25-bc6e-6f85cc38a4fa": Phase="Pending", Reason="", readiness=false. Elapsed: 1.418241ms
Sep 16 01:53:05.614: INFO: Pod "downward-api-779162b3-98a1-4c25-bc6e-6f85cc38a4fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003869476s
Sep 16 01:53:07.617: INFO: Pod "downward-api-779162b3-98a1-4c25-bc6e-6f85cc38a4fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006731977s
STEP: Saw pod success
Sep 16 01:53:07.617: INFO: Pod "downward-api-779162b3-98a1-4c25-bc6e-6f85cc38a4fa" satisfied condition "Succeeded or Failed"
Sep 16 01:53:07.619: INFO: Trying to get logs from node 192.168.4.87 pod downward-api-779162b3-98a1-4c25-bc6e-6f85cc38a4fa container dapi-container: <nil>
STEP: delete the pod
Sep 16 01:53:07.629: INFO: Waiting for pod downward-api-779162b3-98a1-4c25-bc6e-6f85cc38a4fa to disappear
Sep 16 01:53:07.631: INFO: Pod downward-api-779162b3-98a1-4c25-bc6e-6f85cc38a4fa no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:53:07.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9317" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":277,"completed":4,"skipped":26,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:07.635: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 16 01:53:12.166: INFO: Successfully updated pod "pod-update-activedeadlineseconds-33f92c70-4c54-4693-9c05-1c65414393e9"
Sep 16 01:53:12.166: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-33f92c70-4c54-4693-9c05-1c65414393e9" in namespace "pods-1480" to be "terminated due to deadline exceeded"
Sep 16 01:53:12.168: INFO: Pod "pod-update-activedeadlineseconds-33f92c70-4c54-4693-9c05-1c65414393e9": Phase="Running", Reason="", readiness=true. Elapsed: 2.312841ms
Sep 16 01:53:14.170: INFO: Pod "pod-update-activedeadlineseconds-33f92c70-4c54-4693-9c05-1c65414393e9": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.004074302s
Sep 16 01:53:14.170: INFO: Pod "pod-update-activedeadlineseconds-33f92c70-4c54-4693-9c05-1c65414393e9" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:53:14.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1480" for this suite.

• [SLOW TEST:6.543 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":277,"completed":5,"skipped":55,"failed":0}
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:14.179: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 16 01:53:18.710: INFO: Successfully updated pod "pod-update-f92277a8-4d86-4978-ae21-de47e1c6290c"
STEP: verifying the updated pod is in kubernetes
Sep 16 01:53:18.713: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:53:18.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1023" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":277,"completed":6,"skipped":59,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:18.719: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:53:18.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9153" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":277,"completed":7,"skipped":77,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:18.744: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-5bdd85d8-c687-44bb-896b-8cca1b9f218e
STEP: Creating secret with name s-test-opt-upd-985b85f4-3058-4258-9bb1-e91ab40c2b9f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5bdd85d8-c687-44bb-896b-8cca1b9f218e
STEP: Updating secret s-test-opt-upd-985b85f4-3058-4258-9bb1-e91ab40c2b9f
STEP: Creating secret with name s-test-opt-create-fa371e54-f8cf-4e2d-b180-1174b4dab1d8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:53:26.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6141" for this suite.

• [SLOW TEST:8.073 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":8,"skipped":96,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:26.817: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 16 01:53:26.836: INFO: Waiting up to 5m0s for pod "pod-7e3a6a13-f7b5-4347-bb18-f5ad750ba3c3" in namespace "emptydir-912" to be "Succeeded or Failed"
Sep 16 01:53:26.838: INFO: Pod "pod-7e3a6a13-f7b5-4347-bb18-f5ad750ba3c3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.256581ms
Sep 16 01:53:28.839: INFO: Pod "pod-7e3a6a13-f7b5-4347-bb18-f5ad750ba3c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003005896s
Sep 16 01:53:30.842: INFO: Pod "pod-7e3a6a13-f7b5-4347-bb18-f5ad750ba3c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005297277s
STEP: Saw pod success
Sep 16 01:53:30.842: INFO: Pod "pod-7e3a6a13-f7b5-4347-bb18-f5ad750ba3c3" satisfied condition "Succeeded or Failed"
Sep 16 01:53:30.843: INFO: Trying to get logs from node 192.168.4.86 pod pod-7e3a6a13-f7b5-4347-bb18-f5ad750ba3c3 container test-container: <nil>
STEP: delete the pod
Sep 16 01:53:30.855: INFO: Waiting for pod pod-7e3a6a13-f7b5-4347-bb18-f5ad750ba3c3 to disappear
Sep 16 01:53:30.856: INFO: Pod pod-7e3a6a13-f7b5-4347-bb18-f5ad750ba3c3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:53:30.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-912" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":9,"skipped":115,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:30.861: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Sep 16 01:53:30.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-3882'
Sep 16 01:53:31.188: INFO: stderr: ""
Sep 16 01:53:31.188: INFO: stdout: "pod/pause created\n"
Sep 16 01:53:31.189: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 16 01:53:31.189: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3882" to be "running and ready"
Sep 16 01:53:31.190: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 1.420574ms
Sep 16 01:53:33.192: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003459266s
Sep 16 01:53:35.194: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.005215368s
Sep 16 01:53:35.194: INFO: Pod "pause" satisfied condition "running and ready"
Sep 16 01:53:35.194: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 16 01:53:35.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 label pods pause testing-label=testing-label-value --namespace=kubectl-3882'
Sep 16 01:53:35.270: INFO: stderr: ""
Sep 16 01:53:35.270: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 16 01:53:35.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pod pause -L testing-label --namespace=kubectl-3882'
Sep 16 01:53:35.337: INFO: stderr: ""
Sep 16 01:53:35.337: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 16 01:53:35.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 label pods pause testing-label- --namespace=kubectl-3882'
Sep 16 01:53:35.411: INFO: stderr: ""
Sep 16 01:53:35.411: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 16 01:53:35.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pod pause -L testing-label --namespace=kubectl-3882'
Sep 16 01:53:35.485: INFO: stderr: ""
Sep 16 01:53:35.485: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Sep 16 01:53:35.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete --grace-period=0 --force -f - --namespace=kubectl-3882'
Sep 16 01:53:35.577: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 16 01:53:35.577: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 16 01:53:35.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get rc,svc -l name=pause --no-headers --namespace=kubectl-3882'
Sep 16 01:53:35.676: INFO: stderr: "No resources found in kubectl-3882 namespace.\n"
Sep 16 01:53:35.676: INFO: stdout: ""
Sep 16 01:53:35.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -l name=pause --namespace=kubectl-3882 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 16 01:53:35.751: INFO: stderr: ""
Sep 16 01:53:35.751: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:53:35.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3882" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":277,"completed":10,"skipped":141,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:35.757: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 16 01:53:45.814: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
W0916 01:53:45.814679      26 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 16 01:53:45.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9209" for this suite.

• [SLOW TEST:10.061 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":277,"completed":11,"skipped":165,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:45.819: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6136.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6136.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6136.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6136.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6136.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6136.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 16 01:53:51.887: INFO: DNS probes using dns-6136/dns-test-4938d96c-1587-4c54-a09a-ddec09b8c67b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:53:51.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6136" for this suite.

• [SLOW TEST:6.078 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":277,"completed":12,"skipped":207,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:53:51.897: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 01:53:52.619: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 01:53:54.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818032, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818032, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818032, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818032, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 01:53:56.627: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818032, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818032, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818032, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818032, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 01:53:59.631: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 01:53:59.633: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:54:00.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3530" for this suite.
STEP: Destroying namespace "webhook-3530-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.855 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":277,"completed":13,"skipped":297,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:54:00.753: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 16 01:54:00.775: INFO: Waiting up to 5m0s for pod "pod-a52b7867-13d8-477c-97ae-3e31bf595688" in namespace "emptydir-6855" to be "Succeeded or Failed"
Sep 16 01:54:00.777: INFO: Pod "pod-a52b7867-13d8-477c-97ae-3e31bf595688": Phase="Pending", Reason="", readiness=false. Elapsed: 1.662273ms
Sep 16 01:54:02.779: INFO: Pod "pod-a52b7867-13d8-477c-97ae-3e31bf595688": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003580612s
Sep 16 01:54:04.781: INFO: Pod "pod-a52b7867-13d8-477c-97ae-3e31bf595688": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005889226s
STEP: Saw pod success
Sep 16 01:54:04.781: INFO: Pod "pod-a52b7867-13d8-477c-97ae-3e31bf595688" satisfied condition "Succeeded or Failed"
Sep 16 01:54:04.782: INFO: Trying to get logs from node 192.168.4.87 pod pod-a52b7867-13d8-477c-97ae-3e31bf595688 container test-container: <nil>
STEP: delete the pod
Sep 16 01:54:04.793: INFO: Waiting for pod pod-a52b7867-13d8-477c-97ae-3e31bf595688 to disappear
Sep 16 01:54:04.795: INFO: Pod pod-a52b7867-13d8-477c-97ae-3e31bf595688 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:54:04.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6855" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":14,"skipped":341,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:54:04.800: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 01:54:04.817: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 16 01:54:04.821: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 16 01:54:09.823: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 16 01:54:09.823: INFO: Creating deployment "test-rolling-update-deployment"
Sep 16 01:54:09.825: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 16 01:54:09.828: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 16 01:54:11.832: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 16 01:54:11.833: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818049, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818049, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818049, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735818049, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 01:54:13.836: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 16 01:54:13.841: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4179 /apis/apps/v1/namespaces/deployment-4179/deployments/test-rolling-update-deployment 193ec433-eb7a-4cdb-8627-c59b31f2b417 6079 1 2020-09-16 01:54:09 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-09-16 01:54:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-16 01:54:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0025ef428 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-09-16 01:54:09 +0000 UTC,LastTransitionTime:2020-09-16 01:54:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-09-16 01:54:12 +0000 UTC,LastTransitionTime:2020-09-16 01:54:09 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 16 01:54:13.843: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-4179 /apis/apps/v1/namespaces/deployment-4179/replicasets/test-rolling-update-deployment-59d5cb45c7 5940112c-3a2b-45b3-a620-c7e2cf0fa353 6068 1 2020-09-16 01:54:09 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 193ec433-eb7a-4cdb-8627-c59b31f2b417 0xc0025855e7 0xc0025855e8}] []  [{kube-controller-manager Update apps/v1 2020-09-16 01:54:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 51 101 99 52 51 51 45 101 98 55 97 45 52 99 100 98 45 56 54 50 55 45 99 53 57 98 51 49 102 50 98 52 49 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0025856d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 16 01:54:13.843: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 16 01:54:13.843: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4179 /apis/apps/v1/namespaces/deployment-4179/replicasets/test-rolling-update-controller 9296b33d-8f5a-4cd5-8577-fda4bf5c4add 6077 2 2020-09-16 01:54:04 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 193ec433-eb7a-4cdb-8627-c59b31f2b417 0xc0025854df 0xc0025854f0}] []  [{e2e.test Update apps/v1 2020-09-16 01:54:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-16 01:54:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 51 101 99 52 51 51 45 101 98 55 97 45 52 99 100 98 45 56 54 50 55 45 99 53 57 98 51 49 102 50 98 52 49 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002585588 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 16 01:54:13.845: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-x472w" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-x472w test-rolling-update-deployment-59d5cb45c7- deployment-4179 /api/v1/namespaces/deployment-4179/pods/test-rolling-update-deployment-59d5cb45c7-x472w b11b65d6-46db-4bb5-856e-c372e095cecf 6067 0 2020-09-16 01:54:09 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 5940112c-3a2b-45b3-a620-c7e2cf0fa353 0xc002585dc7 0xc002585dc8}] []  [{kube-controller-manager Update v1 2020-09-16 01:54:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 57 52 48 49 49 50 99 45 51 97 50 98 45 52 53 98 51 45 97 54 50 48 45 99 55 101 50 99 102 48 102 97 51 53 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 01:54:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 48 52 46 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-kjvnd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-kjvnd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-kjvnd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 01:54:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 01:54:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 01:54:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 01:54:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:172.151.104.21,StartTime:2020-09-16 01:54:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 01:54:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:reg.mg.hcbss/devcke/agnhost:2.12,ImageID:docker-pullable://reg.mg.hcbss/devcke/agnhost@sha256:1dfec5637a7010d6c0955c26f0a752266fa2646ed2bf8e6ad745cdcfcb611db8,ContainerID:docker://e0eaaa394068c46c8adbb7be5fc03112c175e9cc29c141a210333d07ecefb5cb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.104.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:54:13.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4179" for this suite.

• [SLOW TEST:9.050 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":15,"skipped":348,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:54:13.850: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 01:54:13.865: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 16 01:54:17.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-2414 create -f -'
Sep 16 01:54:20.416: INFO: stderr: ""
Sep 16 01:54:20.416: INFO: stdout: "e2e-test-crd-publish-openapi-1035-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 16 01:54:20.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-2414 delete e2e-test-crd-publish-openapi-1035-crds test-cr'
Sep 16 01:54:20.488: INFO: stderr: ""
Sep 16 01:54:20.488: INFO: stdout: "e2e-test-crd-publish-openapi-1035-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Sep 16 01:54:20.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-2414 apply -f -'
Sep 16 01:54:20.739: INFO: stderr: ""
Sep 16 01:54:20.739: INFO: stdout: "e2e-test-crd-publish-openapi-1035-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 16 01:54:20.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-2414 delete e2e-test-crd-publish-openapi-1035-crds test-cr'
Sep 16 01:54:20.818: INFO: stderr: ""
Sep 16 01:54:20.818: INFO: stdout: "e2e-test-crd-publish-openapi-1035-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Sep 16 01:54:20.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 explain e2e-test-crd-publish-openapi-1035-crds'
Sep 16 01:54:21.055: INFO: stderr: ""
Sep 16 01:54:21.055: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1035-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:54:23.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2414" for this suite.

• [SLOW TEST:9.264 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":277,"completed":16,"skipped":364,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:54:23.114: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-zz4p
STEP: Creating a pod to test atomic-volume-subpath
Sep 16 01:54:23.136: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-zz4p" in namespace "subpath-7105" to be "Succeeded or Failed"
Sep 16 01:54:23.137: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Pending", Reason="", readiness=false. Elapsed: 1.196161ms
Sep 16 01:54:25.139: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003275419s
Sep 16 01:54:27.141: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 4.005559199s
Sep 16 01:54:29.144: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 6.007769949s
Sep 16 01:54:31.145: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 8.009588335s
Sep 16 01:54:33.148: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 10.011869768s
Sep 16 01:54:35.150: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 12.014175809s
Sep 16 01:54:37.152: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 14.016410472s
Sep 16 01:54:39.154: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 16.018554152s
Sep 16 01:54:41.156: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 18.020533385s
Sep 16 01:54:43.159: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 20.022917154s
Sep 16 01:54:45.161: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Running", Reason="", readiness=true. Elapsed: 22.025227481s
Sep 16 01:54:47.163: INFO: Pod "pod-subpath-test-downwardapi-zz4p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.027508845s
STEP: Saw pod success
Sep 16 01:54:47.163: INFO: Pod "pod-subpath-test-downwardapi-zz4p" satisfied condition "Succeeded or Failed"
Sep 16 01:54:47.165: INFO: Trying to get logs from node 192.168.4.87 pod pod-subpath-test-downwardapi-zz4p container test-container-subpath-downwardapi-zz4p: <nil>
STEP: delete the pod
Sep 16 01:54:47.177: INFO: Waiting for pod pod-subpath-test-downwardapi-zz4p to disappear
Sep 16 01:54:47.178: INFO: Pod pod-subpath-test-downwardapi-zz4p no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-zz4p
Sep 16 01:54:47.178: INFO: Deleting pod "pod-subpath-test-downwardapi-zz4p" in namespace "subpath-7105"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:54:47.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7105" for this suite.

• [SLOW TEST:24.070 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":277,"completed":17,"skipped":367,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:54:47.184: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:55:01.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4400" for this suite.

• [SLOW TEST:14.025 seconds]
[sig-apps] Job
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":277,"completed":18,"skipped":389,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:55:01.210: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-3bdca43b-3f7b-47f0-b5ac-4f91ffe4ab1b in namespace container-probe-6557
Sep 16 01:55:05.235: INFO: Started pod test-webserver-3bdca43b-3f7b-47f0-b5ac-4f91ffe4ab1b in namespace container-probe-6557
STEP: checking the pod's current state and verifying that restartCount is present
Sep 16 01:55:05.236: INFO: Initial restart count of pod test-webserver-3bdca43b-3f7b-47f0-b5ac-4f91ffe4ab1b is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:59:05.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6557" for this suite.

• [SLOW TEST:244.304 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":19,"skipped":451,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:59:05.515: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:59:10.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6360" for this suite.

• [SLOW TEST:5.304 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":277,"completed":20,"skipped":474,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:59:10.819: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Sep 16 01:59:15.349: INFO: Successfully updated pod "adopt-release-l54ml"
STEP: Checking that the Job readopts the Pod
Sep 16 01:59:15.349: INFO: Waiting up to 15m0s for pod "adopt-release-l54ml" in namespace "job-2898" to be "adopted"
Sep 16 01:59:15.353: INFO: Pod "adopt-release-l54ml": Phase="Running", Reason="", readiness=true. Elapsed: 4.249296ms
Sep 16 01:59:17.355: INFO: Pod "adopt-release-l54ml": Phase="Running", Reason="", readiness=true. Elapsed: 2.006511443s
Sep 16 01:59:17.355: INFO: Pod "adopt-release-l54ml" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Sep 16 01:59:17.861: INFO: Successfully updated pod "adopt-release-l54ml"
STEP: Checking that the Job releases the Pod
Sep 16 01:59:17.861: INFO: Waiting up to 15m0s for pod "adopt-release-l54ml" in namespace "job-2898" to be "released"
Sep 16 01:59:17.863: INFO: Pod "adopt-release-l54ml": Phase="Running", Reason="", readiness=true. Elapsed: 1.542505ms
Sep 16 01:59:19.865: INFO: Pod "adopt-release-l54ml": Phase="Running", Reason="", readiness=true. Elapsed: 2.003855344s
Sep 16 01:59:19.865: INFO: Pod "adopt-release-l54ml" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:59:19.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2898" for this suite.

• [SLOW TEST:9.051 seconds]
[sig-apps] Job
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":277,"completed":21,"skipped":496,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:59:19.870: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Sep 16 01:59:19.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 cluster-info'
Sep 16 01:59:19.964: INFO: stderr: ""
Sep 16 01:59:19.964: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://11.254.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://11.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://11.254.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 01:59:19.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8891" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":277,"completed":22,"skipped":504,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 01:59:19.970: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 16 01:59:20.226: INFO: Pod name wrapped-volume-race-8589032b-dd87-44bf-99a4-06df2757b5c9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8589032b-dd87-44bf-99a4-06df2757b5c9 in namespace emptydir-wrapper-2645, will wait for the garbage collector to delete the pods
Sep 16 01:59:38.342: INFO: Deleting ReplicationController wrapped-volume-race-8589032b-dd87-44bf-99a4-06df2757b5c9 took: 3.433084ms
Sep 16 01:59:38.443: INFO: Terminating ReplicationController wrapped-volume-race-8589032b-dd87-44bf-99a4-06df2757b5c9 pods took: 100.136536ms
STEP: Creating RC which spawns configmap-volume pods
Sep 16 01:59:50.653: INFO: Pod name wrapped-volume-race-55270e39-290e-4fb2-ab1c-480e70264cd8: Found 0 pods out of 5
Sep 16 01:59:55.659: INFO: Pod name wrapped-volume-race-55270e39-290e-4fb2-ab1c-480e70264cd8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-55270e39-290e-4fb2-ab1c-480e70264cd8 in namespace emptydir-wrapper-2645, will wait for the garbage collector to delete the pods
Sep 16 02:00:09.727: INFO: Deleting ReplicationController wrapped-volume-race-55270e39-290e-4fb2-ab1c-480e70264cd8 took: 3.687378ms
Sep 16 02:00:10.127: INFO: Terminating ReplicationController wrapped-volume-race-55270e39-290e-4fb2-ab1c-480e70264cd8 pods took: 400.200389ms
STEP: Creating RC which spawns configmap-volume pods
Sep 16 02:00:20.638: INFO: Pod name wrapped-volume-race-6c5d4b0a-8612-415e-94b9-2739e263baf3: Found 0 pods out of 5
Sep 16 02:00:25.642: INFO: Pod name wrapped-volume-race-6c5d4b0a-8612-415e-94b9-2739e263baf3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6c5d4b0a-8612-415e-94b9-2739e263baf3 in namespace emptydir-wrapper-2645, will wait for the garbage collector to delete the pods
Sep 16 02:00:39.713: INFO: Deleting ReplicationController wrapped-volume-race-6c5d4b0a-8612-415e-94b9-2739e263baf3 took: 3.418689ms
Sep 16 02:00:40.114: INFO: Terminating ReplicationController wrapped-volume-race-6c5d4b0a-8612-415e-94b9-2739e263baf3 pods took: 400.211012ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:00:50.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2645" for this suite.

• [SLOW TEST:90.783 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":277,"completed":23,"skipped":517,"failed":0}
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:00:50.753: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:00:55.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9068" for this suite.

• [SLOW TEST:5.040 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":277,"completed":24,"skipped":518,"failed":0}
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:00:55.793: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 16 02:00:55.812: INFO: Waiting up to 5m0s for pod "pod-663cf435-70c2-4376-a3ec-5948b6ee39a3" in namespace "emptydir-6539" to be "Succeeded or Failed"
Sep 16 02:00:55.813: INFO: Pod "pod-663cf435-70c2-4376-a3ec-5948b6ee39a3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.453135ms
Sep 16 02:00:57.816: INFO: Pod "pod-663cf435-70c2-4376-a3ec-5948b6ee39a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004000108s
Sep 16 02:00:59.818: INFO: Pod "pod-663cf435-70c2-4376-a3ec-5948b6ee39a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006326068s
STEP: Saw pod success
Sep 16 02:00:59.818: INFO: Pod "pod-663cf435-70c2-4376-a3ec-5948b6ee39a3" satisfied condition "Succeeded or Failed"
Sep 16 02:00:59.819: INFO: Trying to get logs from node 192.168.4.87 pod pod-663cf435-70c2-4376-a3ec-5948b6ee39a3 container test-container: <nil>
STEP: delete the pod
Sep 16 02:00:59.835: INFO: Waiting for pod pod-663cf435-70c2-4376-a3ec-5948b6ee39a3 to disappear
Sep 16 02:00:59.836: INFO: Pod pod-663cf435-70c2-4376-a3ec-5948b6ee39a3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:00:59.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6539" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":25,"skipped":518,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:00:59.841: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:00:59.856: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:01:00.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4576" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":277,"completed":26,"skipped":525,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:01:00.974: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5155
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Sep 16 02:01:00.996: INFO: Found 0 stateful pods, waiting for 3
Sep 16 02:01:10.999: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:01:10.999: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:01:10.999: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:01:11.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-5155 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:01:11.297: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:01:11.297: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:01:11.297: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 16 02:01:21.320: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 16 02:01:31.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-5155 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:01:31.503: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 16 02:01:31.503: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 16 02:01:31.503: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 16 02:01:41.515: INFO: Waiting for StatefulSet statefulset-5155/ss2 to complete update
Sep 16 02:01:41.515: INFO: Waiting for Pod statefulset-5155/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 16 02:01:41.515: INFO: Waiting for Pod statefulset-5155/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 16 02:01:51.519: INFO: Waiting for StatefulSet statefulset-5155/ss2 to complete update
Sep 16 02:01:51.519: INFO: Waiting for Pod statefulset-5155/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 16 02:02:01.519: INFO: Waiting for StatefulSet statefulset-5155/ss2 to complete update
STEP: Rolling back to a previous revision
Sep 16 02:02:11.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-5155 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:02:11.716: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:02:11.716: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:02:11.716: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 16 02:02:21.738: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 16 02:02:31.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-5155 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:02:31.935: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 16 02:02:31.935: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 16 02:02:31.935: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 16 02:02:51.946: INFO: Waiting for StatefulSet statefulset-5155/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 16 02:03:01.951: INFO: Deleting all statefulset in ns statefulset-5155
Sep 16 02:03:01.952: INFO: Scaling statefulset ss2 to 0
Sep 16 02:03:21.961: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 02:03:21.962: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:03:21.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5155" for this suite.

• [SLOW TEST:141.000 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":277,"completed":27,"skipped":545,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:03:21.974: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-3374fb4c-9b5f-40a4-adba-396d5bbffbb5 in namespace container-probe-2734
Sep 16 02:03:26.000: INFO: Started pod busybox-3374fb4c-9b5f-40a4-adba-396d5bbffbb5 in namespace container-probe-2734
STEP: checking the pod's current state and verifying that restartCount is present
Sep 16 02:03:26.002: INFO: Initial restart count of pod busybox-3374fb4c-9b5f-40a4-adba-396d5bbffbb5 is 0
Sep 16 02:04:20.068: INFO: Restart count of pod container-probe-2734/busybox-3374fb4c-9b5f-40a4-adba-396d5bbffbb5 is now 1 (54.066147647s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:04:20.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2734" for this suite.

• [SLOW TEST:58.102 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":28,"skipped":546,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:04:20.077: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 16 02:04:24.618: INFO: Successfully updated pod "labelsupdateb0b2e4a6-4f0c-4aea-946f-d92151b30d48"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:04:26.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7553" for this suite.

• [SLOW TEST:6.559 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":29,"skipped":556,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:04:26.636: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 16 02:04:26.655: INFO: Waiting up to 5m0s for pod "pod-4cef877c-2603-4733-8272-99e510c53a08" in namespace "emptydir-6561" to be "Succeeded or Failed"
Sep 16 02:04:26.656: INFO: Pod "pod-4cef877c-2603-4733-8272-99e510c53a08": Phase="Pending", Reason="", readiness=false. Elapsed: 1.398237ms
Sep 16 02:04:28.658: INFO: Pod "pod-4cef877c-2603-4733-8272-99e510c53a08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003685845s
Sep 16 02:04:30.661: INFO: Pod "pod-4cef877c-2603-4733-8272-99e510c53a08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006092455s
STEP: Saw pod success
Sep 16 02:04:30.661: INFO: Pod "pod-4cef877c-2603-4733-8272-99e510c53a08" satisfied condition "Succeeded or Failed"
Sep 16 02:04:30.663: INFO: Trying to get logs from node 192.168.4.87 pod pod-4cef877c-2603-4733-8272-99e510c53a08 container test-container: <nil>
STEP: delete the pod
Sep 16 02:04:30.671: INFO: Waiting for pod pod-4cef877c-2603-4733-8272-99e510c53a08 to disappear
Sep 16 02:04:30.673: INFO: Pod pod-4cef877c-2603-4733-8272-99e510c53a08 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:04:30.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6561" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":30,"skipped":572,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:04:30.678: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-59b5a0d6-da35-4d4b-bb2c-5e79265b050e
STEP: Creating a pod to test consume configMaps
Sep 16 02:04:30.698: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec5bf735-9418-480b-b26c-23bf3f187f11" in namespace "configmap-1203" to be "Succeeded or Failed"
Sep 16 02:04:30.699: INFO: Pod "pod-configmaps-ec5bf735-9418-480b-b26c-23bf3f187f11": Phase="Pending", Reason="", readiness=false. Elapsed: 1.225892ms
Sep 16 02:04:32.701: INFO: Pod "pod-configmaps-ec5bf735-9418-480b-b26c-23bf3f187f11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003630081s
Sep 16 02:04:34.704: INFO: Pod "pod-configmaps-ec5bf735-9418-480b-b26c-23bf3f187f11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006085821s
STEP: Saw pod success
Sep 16 02:04:34.704: INFO: Pod "pod-configmaps-ec5bf735-9418-480b-b26c-23bf3f187f11" satisfied condition "Succeeded or Failed"
Sep 16 02:04:34.705: INFO: Trying to get logs from node 192.168.4.87 pod pod-configmaps-ec5bf735-9418-480b-b26c-23bf3f187f11 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:04:34.715: INFO: Waiting for pod pod-configmaps-ec5bf735-9418-480b-b26c-23bf3f187f11 to disappear
Sep 16 02:04:34.717: INFO: Pod pod-configmaps-ec5bf735-9418-480b-b26c-23bf3f187f11 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:04:34.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1203" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":31,"skipped":645,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:04:34.721: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Sep 16 02:04:34.737: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Sep 16 02:04:46.545: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:04:48.583: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:05:00.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2396" for this suite.

• [SLOW TEST:26.146 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":277,"completed":32,"skipped":667,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:05:00.867: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6574.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6574.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6574.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6574.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6574.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6574.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 16 02:05:04.906: INFO: DNS probes using dns-6574/dns-test-a2d9d4c5-05f0-4c60-8662-7b2c99d4f8fe succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:05:04.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6574" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":277,"completed":33,"skipped":676,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:05:04.920: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Sep 16 02:05:04.935: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:05:08.510: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:05:22.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9846" for this suite.

• [SLOW TEST:17.310 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":277,"completed":34,"skipped":692,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:05:22.230: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:05:39.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9298" for this suite.

• [SLOW TEST:17.043 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":277,"completed":35,"skipped":693,"failed":0}
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:05:39.273: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-4573
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4573
STEP: Creating statefulset with conflicting port in namespace statefulset-4573
STEP: Waiting until pod test-pod will start running in namespace statefulset-4573
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4573
Sep 16 02:05:43.302: INFO: Observed stateful pod in namespace: statefulset-4573, name: ss-0, uid: 7a7fe30f-4890-4794-8a70-6073c7dc7156, status phase: Pending. Waiting for statefulset controller to delete.
Sep 16 02:05:43.701: INFO: Observed stateful pod in namespace: statefulset-4573, name: ss-0, uid: 7a7fe30f-4890-4794-8a70-6073c7dc7156, status phase: Failed. Waiting for statefulset controller to delete.
Sep 16 02:05:43.704: INFO: Observed stateful pod in namespace: statefulset-4573, name: ss-0, uid: 7a7fe30f-4890-4794-8a70-6073c7dc7156, status phase: Failed. Waiting for statefulset controller to delete.
Sep 16 02:05:43.706: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4573
STEP: Removing pod with conflicting port in namespace statefulset-4573
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4573 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 16 02:05:47.716: INFO: Deleting all statefulset in ns statefulset-4573
Sep 16 02:05:47.718: INFO: Scaling statefulset ss to 0
Sep 16 02:05:57.726: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 02:05:57.728: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:05:57.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4573" for this suite.

• [SLOW TEST:18.465 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":277,"completed":36,"skipped":697,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:05:57.739: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:05:57.757: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:05:58.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9720" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":277,"completed":37,"skipped":734,"failed":0}
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:05:58.772: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-ed420b53-bf46-4f02-ace1-cf6b2e6c72d0
Sep 16 02:05:58.791: INFO: Pod name my-hostname-basic-ed420b53-bf46-4f02-ace1-cf6b2e6c72d0: Found 0 pods out of 1
Sep 16 02:06:03.793: INFO: Pod name my-hostname-basic-ed420b53-bf46-4f02-ace1-cf6b2e6c72d0: Found 1 pods out of 1
Sep 16 02:06:03.793: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ed420b53-bf46-4f02-ace1-cf6b2e6c72d0" are running
Sep 16 02:06:03.794: INFO: Pod "my-hostname-basic-ed420b53-bf46-4f02-ace1-cf6b2e6c72d0-9k5q5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-16 02:05:58 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-16 02:06:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-16 02:06:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-16 02:05:58 +0000 UTC Reason: Message:}])
Sep 16 02:06:03.794: INFO: Trying to dial the pod
Sep 16 02:06:08.800: INFO: Controller my-hostname-basic-ed420b53-bf46-4f02-ace1-cf6b2e6c72d0: Got expected result from replica 1 [my-hostname-basic-ed420b53-bf46-4f02-ace1-cf6b2e6c72d0-9k5q5]: "my-hostname-basic-ed420b53-bf46-4f02-ace1-cf6b2e6c72d0-9k5q5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:08.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9549" for this suite.

• [SLOW TEST:10.033 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":38,"skipped":735,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:08.805: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-8399/secret-test-9da88d55-e4a6-4208-9e75-21369ac3ccd6
STEP: Creating a pod to test consume secrets
Sep 16 02:06:08.825: INFO: Waiting up to 5m0s for pod "pod-configmaps-f9326d2e-6fc0-4732-b063-d5ca977af86e" in namespace "secrets-8399" to be "Succeeded or Failed"
Sep 16 02:06:08.826: INFO: Pod "pod-configmaps-f9326d2e-6fc0-4732-b063-d5ca977af86e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.209266ms
Sep 16 02:06:10.829: INFO: Pod "pod-configmaps-f9326d2e-6fc0-4732-b063-d5ca977af86e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003676525s
Sep 16 02:06:12.830: INFO: Pod "pod-configmaps-f9326d2e-6fc0-4732-b063-d5ca977af86e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005378219s
STEP: Saw pod success
Sep 16 02:06:12.830: INFO: Pod "pod-configmaps-f9326d2e-6fc0-4732-b063-d5ca977af86e" satisfied condition "Succeeded or Failed"
Sep 16 02:06:12.832: INFO: Trying to get logs from node 192.168.4.87 pod pod-configmaps-f9326d2e-6fc0-4732-b063-d5ca977af86e container env-test: <nil>
STEP: delete the pod
Sep 16 02:06:12.845: INFO: Waiting for pod pod-configmaps-f9326d2e-6fc0-4732-b063-d5ca977af86e to disappear
Sep 16 02:06:12.846: INFO: Pod pod-configmaps-f9326d2e-6fc0-4732-b063-d5ca977af86e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:12.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8399" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":39,"skipped":751,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:12.851: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Sep 16 02:06:12.869: INFO: Waiting up to 5m0s for pod "client-containers-3a66eae2-936a-48f4-86c0-542efc576cb2" in namespace "containers-7802" to be "Succeeded or Failed"
Sep 16 02:06:12.871: INFO: Pod "client-containers-3a66eae2-936a-48f4-86c0-542efc576cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.54392ms
Sep 16 02:06:14.873: INFO: Pod "client-containers-3a66eae2-936a-48f4-86c0-542efc576cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003819867s
Sep 16 02:06:16.876: INFO: Pod "client-containers-3a66eae2-936a-48f4-86c0-542efc576cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006121528s
Sep 16 02:06:18.878: INFO: Pod "client-containers-3a66eae2-936a-48f4-86c0-542efc576cb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008560871s
STEP: Saw pod success
Sep 16 02:06:18.878: INFO: Pod "client-containers-3a66eae2-936a-48f4-86c0-542efc576cb2" satisfied condition "Succeeded or Failed"
Sep 16 02:06:18.880: INFO: Trying to get logs from node 192.168.4.87 pod client-containers-3a66eae2-936a-48f4-86c0-542efc576cb2 container test-container: <nil>
STEP: delete the pod
Sep 16 02:06:18.889: INFO: Waiting for pod client-containers-3a66eae2-936a-48f4-86c0-542efc576cb2 to disappear
Sep 16 02:06:18.891: INFO: Pod client-containers-3a66eae2-936a-48f4-86c0-542efc576cb2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:18.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7802" for this suite.

• [SLOW TEST:6.044 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":277,"completed":40,"skipped":766,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:18.895: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:06:18.918: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-05cc9de3-07cd-4dfa-a065-0f4c7afabe2e" in namespace "security-context-test-8009" to be "Succeeded or Failed"
Sep 16 02:06:18.919: INFO: Pod "busybox-privileged-false-05cc9de3-07cd-4dfa-a065-0f4c7afabe2e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.678825ms
Sep 16 02:06:20.921: INFO: Pod "busybox-privileged-false-05cc9de3-07cd-4dfa-a065-0f4c7afabe2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003610982s
Sep 16 02:06:22.924: INFO: Pod "busybox-privileged-false-05cc9de3-07cd-4dfa-a065-0f4c7afabe2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006042617s
Sep 16 02:06:22.924: INFO: Pod "busybox-privileged-false-05cc9de3-07cd-4dfa-a065-0f4c7afabe2e" satisfied condition "Succeeded or Failed"
Sep 16 02:06:22.929: INFO: Got logs for pod "busybox-privileged-false-05cc9de3-07cd-4dfa-a065-0f4c7afabe2e": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:22.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8009" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":41,"skipped":819,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:22.934: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 16 02:06:22.953: INFO: Waiting up to 5m0s for pod "downward-api-ddeb3bed-5a84-41c6-9f0f-bbdcb33e10f9" in namespace "downward-api-3764" to be "Succeeded or Failed"
Sep 16 02:06:22.955: INFO: Pod "downward-api-ddeb3bed-5a84-41c6-9f0f-bbdcb33e10f9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.494606ms
Sep 16 02:06:24.957: INFO: Pod "downward-api-ddeb3bed-5a84-41c6-9f0f-bbdcb33e10f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003766988s
Sep 16 02:06:26.960: INFO: Pod "downward-api-ddeb3bed-5a84-41c6-9f0f-bbdcb33e10f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006916149s
STEP: Saw pod success
Sep 16 02:06:26.960: INFO: Pod "downward-api-ddeb3bed-5a84-41c6-9f0f-bbdcb33e10f9" satisfied condition "Succeeded or Failed"
Sep 16 02:06:26.962: INFO: Trying to get logs from node 192.168.4.87 pod downward-api-ddeb3bed-5a84-41c6-9f0f-bbdcb33e10f9 container dapi-container: <nil>
STEP: delete the pod
Sep 16 02:06:26.973: INFO: Waiting for pod downward-api-ddeb3bed-5a84-41c6-9f0f-bbdcb33e10f9 to disappear
Sep 16 02:06:26.975: INFO: Pod downward-api-ddeb3bed-5a84-41c6-9f0f-bbdcb33e10f9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:26.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3764" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":277,"completed":42,"skipped":886,"failed":0}
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:26.980: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 16 02:06:27.002: INFO: Waiting up to 5m0s for pod "downward-api-0f5df039-977a-437c-9e09-90bb5b0071a8" in namespace "downward-api-735" to be "Succeeded or Failed"
Sep 16 02:06:27.003: INFO: Pod "downward-api-0f5df039-977a-437c-9e09-90bb5b0071a8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.513633ms
Sep 16 02:06:29.005: INFO: Pod "downward-api-0f5df039-977a-437c-9e09-90bb5b0071a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003447926s
Sep 16 02:06:31.008: INFO: Pod "downward-api-0f5df039-977a-437c-9e09-90bb5b0071a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005827705s
STEP: Saw pod success
Sep 16 02:06:31.008: INFO: Pod "downward-api-0f5df039-977a-437c-9e09-90bb5b0071a8" satisfied condition "Succeeded or Failed"
Sep 16 02:06:31.009: INFO: Trying to get logs from node 192.168.4.87 pod downward-api-0f5df039-977a-437c-9e09-90bb5b0071a8 container dapi-container: <nil>
STEP: delete the pod
Sep 16 02:06:31.019: INFO: Waiting for pod downward-api-0f5df039-977a-437c-9e09-90bb5b0071a8 to disappear
Sep 16 02:06:31.020: INFO: Pod downward-api-0f5df039-977a-437c-9e09-90bb5b0071a8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:31.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-735" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":277,"completed":43,"skipped":893,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:31.025: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Sep 16 02:06:31.043: INFO: Waiting up to 5m0s for pod "client-containers-efd06971-ae71-464a-8a2b-e9fd4583b293" in namespace "containers-5145" to be "Succeeded or Failed"
Sep 16 02:06:31.044: INFO: Pod "client-containers-efd06971-ae71-464a-8a2b-e9fd4583b293": Phase="Pending", Reason="", readiness=false. Elapsed: 1.268167ms
Sep 16 02:06:33.046: INFO: Pod "client-containers-efd06971-ae71-464a-8a2b-e9fd4583b293": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003063348s
Sep 16 02:06:35.048: INFO: Pod "client-containers-efd06971-ae71-464a-8a2b-e9fd4583b293": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005329422s
STEP: Saw pod success
Sep 16 02:06:35.048: INFO: Pod "client-containers-efd06971-ae71-464a-8a2b-e9fd4583b293" satisfied condition "Succeeded or Failed"
Sep 16 02:06:35.050: INFO: Trying to get logs from node 192.168.4.87 pod client-containers-efd06971-ae71-464a-8a2b-e9fd4583b293 container test-container: <nil>
STEP: delete the pod
Sep 16 02:06:35.058: INFO: Waiting for pod client-containers-efd06971-ae71-464a-8a2b-e9fd4583b293 to disappear
Sep 16 02:06:35.059: INFO: Pod client-containers-efd06971-ae71-464a-8a2b-e9fd4583b293 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:35.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5145" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":277,"completed":44,"skipped":901,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:35.064: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-fab1f682-53c0-4713-bd63-02026c18d730
STEP: Creating a pod to test consume configMaps
Sep 16 02:06:35.085: INFO: Waiting up to 5m0s for pod "pod-configmaps-3881b93a-979a-4e77-bc69-241a19f19aea" in namespace "configmap-4637" to be "Succeeded or Failed"
Sep 16 02:06:35.087: INFO: Pod "pod-configmaps-3881b93a-979a-4e77-bc69-241a19f19aea": Phase="Pending", Reason="", readiness=false. Elapsed: 1.90668ms
Sep 16 02:06:37.089: INFO: Pod "pod-configmaps-3881b93a-979a-4e77-bc69-241a19f19aea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00430515s
Sep 16 02:06:39.092: INFO: Pod "pod-configmaps-3881b93a-979a-4e77-bc69-241a19f19aea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007011419s
STEP: Saw pod success
Sep 16 02:06:39.092: INFO: Pod "pod-configmaps-3881b93a-979a-4e77-bc69-241a19f19aea" satisfied condition "Succeeded or Failed"
Sep 16 02:06:39.093: INFO: Trying to get logs from node 192.168.4.87 pod pod-configmaps-3881b93a-979a-4e77-bc69-241a19f19aea container configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:06:39.104: INFO: Waiting for pod pod-configmaps-3881b93a-979a-4e77-bc69-241a19f19aea to disappear
Sep 16 02:06:39.105: INFO: Pod pod-configmaps-3881b93a-979a-4e77-bc69-241a19f19aea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:39.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4637" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":45,"skipped":932,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:39.110: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:43.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1795" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":277,"completed":46,"skipped":993,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:43.137: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:47.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2533" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":277,"completed":47,"skipped":1000,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:47.177: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:06:47.196: INFO: Waiting up to 5m0s for pod "busybox-user-65534-a514f151-46a8-485a-acf7-edd2d27f9914" in namespace "security-context-test-754" to be "Succeeded or Failed"
Sep 16 02:06:47.197: INFO: Pod "busybox-user-65534-a514f151-46a8-485a-acf7-edd2d27f9914": Phase="Pending", Reason="", readiness=false. Elapsed: 1.226906ms
Sep 16 02:06:49.199: INFO: Pod "busybox-user-65534-a514f151-46a8-485a-acf7-edd2d27f9914": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003470157s
Sep 16 02:06:51.202: INFO: Pod "busybox-user-65534-a514f151-46a8-485a-acf7-edd2d27f9914": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006131661s
Sep 16 02:06:51.202: INFO: Pod "busybox-user-65534-a514f151-46a8-485a-acf7-edd2d27f9914" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:06:51.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-754" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":48,"skipped":1008,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:06:51.207: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:06:51.222: INFO: Creating deployment "webserver-deployment"
Sep 16 02:06:51.225: INFO: Waiting for observed generation 1
Sep 16 02:06:53.228: INFO: Waiting for all required pods to come up
Sep 16 02:06:53.230: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 16 02:07:01.235: INFO: Waiting for deployment "webserver-deployment" to complete
Sep 16 02:07:01.238: INFO: Updating deployment "webserver-deployment" with a non-existent image
Sep 16 02:07:01.243: INFO: Updating deployment webserver-deployment
Sep 16 02:07:01.243: INFO: Waiting for observed generation 2
Sep 16 02:07:03.246: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 16 02:07:03.247: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 16 02:07:03.249: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 16 02:07:03.253: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 16 02:07:03.253: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 16 02:07:03.254: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 16 02:07:03.256: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Sep 16 02:07:03.256: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Sep 16 02:07:03.260: INFO: Updating deployment webserver-deployment
Sep 16 02:07:03.260: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Sep 16 02:07:03.262: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 16 02:07:03.263: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 16 02:07:05.268: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2506 /apis/apps/v1/namespaces/deployment-2506/deployments/webserver-deployment 25f937b2-dac1-4b88-b509-1205d30e4f5c 11053 3 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0054763b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-09-16 02:07:03 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-09-16 02:07:03 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Sep 16 02:07:05.270: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-2506 /apis/apps/v1/namespaces/deployment-2506/replicasets/webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 11047 3 2020-09-16 02:07:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 25f937b2-dac1-4b88-b509-1205d30e4f5c 0xc005476887 0xc005476888}] []  [{kube-controller-manager Update apps/v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 53 102 57 51 55 98 50 45 100 97 99 49 45 52 98 56 56 45 98 53 48 57 45 49 50 48 53 100 51 48 101 52 102 53 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005476908 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 16 02:07:05.270: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Sep 16 02:07:05.271: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-2506 /apis/apps/v1/namespaces/deployment-2506/replicasets/webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 11045 3 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 25f937b2-dac1-4b88-b509-1205d30e4f5c 0xc005476967 0xc005476968}] []  [{kube-controller-manager Update apps/v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 53 102 57 51 55 98 50 45 100 97 99 49 45 52 98 56 56 45 98 53 48 57 45 49 50 48 53 100 51 48 101 52 102 53 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0054769d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Sep 16 02:07:05.275: INFO: Pod "webserver-deployment-6676bcd6d4-62c46" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-62c46 webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-62c46 69ef217f-6d72-4ff9-a4ae-4da4ad895b7f 10965 0 2020-09-16 02:07:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bae27 0xc0054bae28}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.275: INFO: Pod "webserver-deployment-6676bcd6d4-8bmc2" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-8bmc2 webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-8bmc2 f5d82f90-34df-42b9-bfdc-7c665df1e424 10972 0 2020-09-16 02:07:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bafd7 0xc0054bafd8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.275: INFO: Pod "webserver-deployment-6676bcd6d4-98pxh" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-98pxh webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-98pxh 9500ea36-2e7e-4010-a9b8-dd67229940ef 11085 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bb187 0xc0054bb188}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.275: INFO: Pod "webserver-deployment-6676bcd6d4-fs9dm" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-fs9dm webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-fs9dm ef9c1a78-82e7-4b17-9a5b-8fee72c8bf0f 11076 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bb347 0xc0054bb348}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.275: INFO: Pod "webserver-deployment-6676bcd6d4-kq8f9" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-kq8f9 webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-kq8f9 9015dd03-8138-47fc-8f05-bb6facc0e19d 11095 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bb4f7 0xc0054bb4f8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.276: INFO: Pod "webserver-deployment-6676bcd6d4-lf8vm" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-lf8vm webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-lf8vm bc0534ee-bdb4-40f5-9a3d-42a49e1cd945 11043 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bb6a7 0xc0054bb6a8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.276: INFO: Pod "webserver-deployment-6676bcd6d4-mlp42" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-mlp42 webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-mlp42 2732aa8e-a023-4741-85f5-bb225d7d7733 11067 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bb7e0 0xc0054bb7e1}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.276: INFO: Pod "webserver-deployment-6676bcd6d4-pbknf" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-pbknf webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-pbknf d43608ed-5f50-4b5e-97b6-fd6426dc88c2 11097 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bb987 0xc0054bb988}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.276: INFO: Pod "webserver-deployment-6676bcd6d4-rc7bt" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-rc7bt webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-rc7bt e7fca8e7-4984-4a06-a124-12f129c4b600 10967 0 2020-09-16 02:07:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bbb47 0xc0054bbb48}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.276: INFO: Pod "webserver-deployment-6676bcd6d4-tzv5x" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-tzv5x webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-tzv5x 96f043a5-a261-4ee7-83de-d91751b0500b 10971 0 2020-09-16 02:07:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bbcf7 0xc0054bbcf8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.277: INFO: Pod "webserver-deployment-6676bcd6d4-w7jmb" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-w7jmb webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-w7jmb 571de5d8-687b-435c-9dfe-62777a0e7506 11077 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc0054bbea7 0xc0054bbea8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.277: INFO: Pod "webserver-deployment-6676bcd6d4-x2mxt" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-x2mxt webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-x2mxt 09e3111d-cb85-4bec-8c84-1536d38432b3 10966 0 2020-09-16 02:07:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc005424057 0xc005424058}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:01 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.277: INFO: Pod "webserver-deployment-6676bcd6d4-x95ck" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-x95ck webserver-deployment-6676bcd6d4- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-6676bcd6d4-x95ck ca206f5f-b703-4fcf-9016-6ddcf0d4cb85 11071 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 48daacf3-12be-49cc-b034-aee81d159880 0xc005424207 0xc005424208}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 56 100 97 97 99 102 51 45 49 50 98 101 45 52 57 99 99 45 98 48 51 52 45 97 101 101 56 49 100 49 53 57 56 56 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.277: INFO: Pod "webserver-deployment-84855cf797-2v26l" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-2v26l webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-2v26l b9fa6bd4-920b-4d02-912d-740ca9c171c3 10882 0 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc0054243b7 0xc0054243b8}] []  [{kube-controller-manager Update v1 2020-09-16 02:06:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:06:58 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 54 54 46 49 54 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:172.151.166.165,StartTime:2020-09-16 02:06:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 02:06:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://ec86aac763767bd307184166d2dc97a7a3619d340856417ad525717e1bd18346,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.166.165,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.277: INFO: Pod "webserver-deployment-84855cf797-5wml9" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-5wml9 webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-5wml9 dc58e7fe-1266-42b2-9a6b-55ea467f9038 11075 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005424567 0xc005424568}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.278: INFO: Pod "webserver-deployment-84855cf797-6p9c2" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6p9c2 webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-6p9c2 fa24ff9f-07bd-424e-96b0-e8c9e4f5d025 10909 0 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc0054246f7 0xc0054246f8}] []  [{kube-controller-manager Update v1 2020-09-16 02:06:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:06:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 54 54 46 49 54 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:172.151.166.166,StartTime:2020-09-16 02:06:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 02:06:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://e7b08622713d2804213a6b8457d478099500b9de27878c1c53bf7102fc148ab7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.166.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.278: INFO: Pod "webserver-deployment-84855cf797-6rvpn" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6rvpn webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-6rvpn fe3a6d55-3f3e-46fa-bdcb-104aeb27efe2 11083 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc0054248a7 0xc0054248a8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.278: INFO: Pod "webserver-deployment-84855cf797-77dgb" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-77dgb webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-77dgb b2310d74-48a3-4bd1-b021-172814604318 11100 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005424a37 0xc005424a38}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.278: INFO: Pod "webserver-deployment-84855cf797-7wtqd" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-7wtqd webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-7wtqd e2203bd0-6890-496c-9134-1bda744dfa9b 11070 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005424bc7 0xc005424bc8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.278: INFO: Pod "webserver-deployment-84855cf797-b68j7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-b68j7 webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-b68j7 05241871-b7af-4290-a3cf-9067f84cb361 11073 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005424d57 0xc005424d58}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.279: INFO: Pod "webserver-deployment-84855cf797-fx78g" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-fx78g webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-fx78g a41a3918-2fc9-410e-a6d6-47be8eaccbfe 11079 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005424ee7 0xc005424ee8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.279: INFO: Pod "webserver-deployment-84855cf797-fxsxp" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-fxsxp webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-fxsxp 9409f907-0eca-409e-bd5c-518797acffa8 11096 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005425087 0xc005425088}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.279: INFO: Pod "webserver-deployment-84855cf797-gff9d" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-gff9d webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-gff9d 79a513b6-6b80-4c65-a52c-1dd4c8fcc144 10900 0 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005425217 0xc005425218}] []  [{kube-controller-manager Update v1 2020-09-16 02:06:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:06:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 54 54 46 49 54 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:172.151.166.168,StartTime:2020-09-16 02:06:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 02:06:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://27099fbb8d34c8e96c4f1a91891ccb84dbfa2e945fe295b1520f88e3aef28daa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.166.168,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.279: INFO: Pod "webserver-deployment-84855cf797-jn9cg" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-jn9cg webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-jn9cg efb2cfb4-afcc-4e06-8fce-89dc563498d2 10893 0 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc0054253c7 0xc0054253c8}] []  [{kube-controller-manager Update v1 2020-09-16 02:06:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:06:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 48 52 46 53 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:172.151.104.56,StartTime:2020-09-16 02:06:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 02:06:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://0894dba1682f2b3f87a230d34f2b06f33cce611795d2b1ab02e0f0588c1aaf30,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.104.56,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.279: INFO: Pod "webserver-deployment-84855cf797-m2hqs" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-m2hqs webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-m2hqs 48a24bba-e7af-4e88-bd52-830fd26e22d8 11098 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005425587 0xc005425588}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.280: INFO: Pod "webserver-deployment-84855cf797-mhlwm" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-mhlwm webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-mhlwm 9755695b-6211-4ec3-b4b3-a3e7cff0fbfa 10896 0 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005425717 0xc005425718}] []  [{kube-controller-manager Update v1 2020-09-16 02:06:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:06:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 48 52 46 53 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:172.151.104.57,StartTime:2020-09-16 02:06:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 02:06:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://114dc3e2a58aa1825fa20712d8c5050d42212d2808baa7665c14e155ea1361a3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.104.57,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.280: INFO: Pod "webserver-deployment-84855cf797-ngxzt" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-ngxzt webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-ngxzt 842a61c6-d8f4-4d50-a27c-0d252d305f6b 11099 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc0054258c7 0xc0054258c8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.280: INFO: Pod "webserver-deployment-84855cf797-rh4lk" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rh4lk webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-rh4lk 6c88f1ce-1e22-4705-9578-6c6952f53d3c 10902 0 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005425a57 0xc005425a58}] []  [{kube-controller-manager Update v1 2020-09-16 02:06:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:06:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 54 54 46 49 54 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:172.151.166.167,StartTime:2020-09-16 02:06:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 02:06:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://b620d2974ec70ddac4e0b0db410e7d14e8eae947a7a6e6805ab7f95adfd32c04,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.166.167,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.280: INFO: Pod "webserver-deployment-84855cf797-rjrkj" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rjrkj webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-rjrkj 97fe4cd2-2c9f-4972-ba7a-dddb41af0aba 10906 0 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005425c07 0xc005425c08}] []  [{kube-controller-manager Update v1 2020-09-16 02:06:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:06:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 54 54 46 49 54 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:172.151.166.164,StartTime:2020-09-16 02:06:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 02:06:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://5ce6fac1767057823f58012c3dce8ea76f53b83bdb4a2769bdff65fb606a3d21,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.166.164,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.281: INFO: Pod "webserver-deployment-84855cf797-tc9jf" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-tc9jf webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-tc9jf 39df0051-4f86-4568-aa03-76ee81e17df8 11058 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005425db7 0xc005425db8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.281: INFO: Pod "webserver-deployment-84855cf797-z8rrx" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-z8rrx webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-z8rrx 1e24e7b4-500b-4fb1-8f52-d367713bfbc3 10890 0 2020-09-16 02:06:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc005425f47 0xc005425f48}] []  [{kube-controller-manager Update v1 2020-09-16 02:06:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:06:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 48 52 46 54 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:06:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:172.151.104.60,StartTime:2020-09-16 02:06:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 02:06:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://4981d5d85357cb38f5992158a0afaa0d4e4342374f76f2f848afc5db0e85518d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.104.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.281: INFO: Pod "webserver-deployment-84855cf797-zhbzq" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-zhbzq webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-zhbzq 94d71ef6-f05b-401b-89aa-f5b02d1e625a 11072 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc0027d60f7 0xc0027d60f8}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.86,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.86,PodIP:,StartTime:2020-09-16 02:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:07:05.281: INFO: Pod "webserver-deployment-84855cf797-zzjcb" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-zzjcb webserver-deployment-84855cf797- deployment-2506 /api/v1/namespaces/deployment-2506/pods/webserver-deployment-84855cf797-zzjcb 715aad77-a549-4729-83a6-033898997cd4 11038 0 2020-09-16 02:07:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1bd0d22f-6fbd-430f-91a4-61933cdc2416 0xc0027d6287 0xc0027d6288}] []  [{kube-controller-manager Update v1 2020-09-16 02:07:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 100 48 100 50 50 102 45 54 102 98 100 45 52 51 48 102 45 57 49 97 52 45 54 49 57 51 51 99 100 99 50 52 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cf6n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cf6n4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cf6n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:07:05.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2506" for this suite.

• [SLOW TEST:14.081 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":277,"completed":49,"skipped":1051,"failed":0}
SSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:07:05.288: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:07:05.307: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc" in namespace "security-context-test-7377" to be "Succeeded or Failed"
Sep 16 02:07:05.308: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.199123ms
Sep 16 02:07:07.311: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003697519s
Sep 16 02:07:09.313: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005996713s
Sep 16 02:07:11.316: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008342224s
Sep 16 02:07:13.318: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010649749s
Sep 16 02:07:15.320: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012723214s
Sep 16 02:07:17.322: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.015123375s
Sep 16 02:07:19.325: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.017275384s
Sep 16 02:07:21.327: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 16.019573909s
Sep 16 02:07:23.329: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 18.021534356s
Sep 16 02:07:25.331: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 20.023498723s
Sep 16 02:07:27.333: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Pending", Reason="", readiness=false. Elapsed: 22.025957403s
Sep 16 02:07:29.335: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.028242084s
Sep 16 02:07:29.336: INFO: Pod "busybox-readonly-false-ab25e48a-3232-474b-bf6c-734dc5bdc4cc" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:07:29.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7377" for this suite.

• [SLOW TEST:24.052 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:166
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":277,"completed":50,"skipped":1057,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:07:29.340: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:07:40.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6585" for this suite.

• [SLOW TEST:11.049 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":277,"completed":51,"skipped":1091,"failed":0}
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:07:40.389: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-1c7a6888-5a37-4061-9352-a32062fc4945
STEP: Creating a pod to test consume configMaps
Sep 16 02:07:40.410: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2b20aa2c-d17c-4c07-85c6-44abd349b7ae" in namespace "projected-1855" to be "Succeeded or Failed"
Sep 16 02:07:40.411: INFO: Pod "pod-projected-configmaps-2b20aa2c-d17c-4c07-85c6-44abd349b7ae": Phase="Pending", Reason="", readiness=false. Elapsed: 1.36131ms
Sep 16 02:07:42.414: INFO: Pod "pod-projected-configmaps-2b20aa2c-d17c-4c07-85c6-44abd349b7ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003825168s
Sep 16 02:07:44.416: INFO: Pod "pod-projected-configmaps-2b20aa2c-d17c-4c07-85c6-44abd349b7ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006158825s
STEP: Saw pod success
Sep 16 02:07:44.416: INFO: Pod "pod-projected-configmaps-2b20aa2c-d17c-4c07-85c6-44abd349b7ae" satisfied condition "Succeeded or Failed"
Sep 16 02:07:44.418: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-configmaps-2b20aa2c-d17c-4c07-85c6-44abd349b7ae container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:07:44.427: INFO: Waiting for pod pod-projected-configmaps-2b20aa2c-d17c-4c07-85c6-44abd349b7ae to disappear
Sep 16 02:07:44.428: INFO: Pod pod-projected-configmaps-2b20aa2c-d17c-4c07-85c6-44abd349b7ae no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:07:44.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1855" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":52,"skipped":1093,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:07:44.432: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-5ee475a1-aae4-468d-93bb-828cf9ea64e8
STEP: Creating a pod to test consume configMaps
Sep 16 02:07:44.453: INFO: Waiting up to 5m0s for pod "pod-configmaps-9a862edf-56d9-40f5-b594-e2b355708c0d" in namespace "configmap-7896" to be "Succeeded or Failed"
Sep 16 02:07:44.454: INFO: Pod "pod-configmaps-9a862edf-56d9-40f5-b594-e2b355708c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.300355ms
Sep 16 02:07:46.456: INFO: Pod "pod-configmaps-9a862edf-56d9-40f5-b594-e2b355708c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003788143s
Sep 16 02:07:48.459: INFO: Pod "pod-configmaps-9a862edf-56d9-40f5-b594-e2b355708c0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00614873s
STEP: Saw pod success
Sep 16 02:07:48.459: INFO: Pod "pod-configmaps-9a862edf-56d9-40f5-b594-e2b355708c0d" satisfied condition "Succeeded or Failed"
Sep 16 02:07:48.460: INFO: Trying to get logs from node 192.168.4.87 pod pod-configmaps-9a862edf-56d9-40f5-b594-e2b355708c0d container configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:07:48.469: INFO: Waiting for pod pod-configmaps-9a862edf-56d9-40f5-b594-e2b355708c0d to disappear
Sep 16 02:07:48.471: INFO: Pod pod-configmaps-9a862edf-56d9-40f5-b594-e2b355708c0d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:07:48.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7896" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":53,"skipped":1099,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:07:48.476: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 16 02:07:48.496: INFO: Waiting up to 5m0s for pod "pod-c35c4308-d497-4fff-8d15-15bd31be340d" in namespace "emptydir-9069" to be "Succeeded or Failed"
Sep 16 02:07:48.498: INFO: Pod "pod-c35c4308-d497-4fff-8d15-15bd31be340d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.338701ms
Sep 16 02:07:50.500: INFO: Pod "pod-c35c4308-d497-4fff-8d15-15bd31be340d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003659487s
Sep 16 02:07:52.502: INFO: Pod "pod-c35c4308-d497-4fff-8d15-15bd31be340d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005864757s
STEP: Saw pod success
Sep 16 02:07:52.502: INFO: Pod "pod-c35c4308-d497-4fff-8d15-15bd31be340d" satisfied condition "Succeeded or Failed"
Sep 16 02:07:52.503: INFO: Trying to get logs from node 192.168.4.87 pod pod-c35c4308-d497-4fff-8d15-15bd31be340d container test-container: <nil>
STEP: delete the pod
Sep 16 02:07:52.512: INFO: Waiting for pod pod-c35c4308-d497-4fff-8d15-15bd31be340d to disappear
Sep 16 02:07:52.513: INFO: Pod pod-c35c4308-d497-4fff-8d15-15bd31be340d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:07:52.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9069" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":54,"skipped":1139,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:07:52.519: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Sep 16 02:07:52.538: INFO: Waiting up to 5m0s for pod "var-expansion-8a6d1c97-36cb-403c-b897-9ea558a679ed" in namespace "var-expansion-4768" to be "Succeeded or Failed"
Sep 16 02:07:52.540: INFO: Pod "var-expansion-8a6d1c97-36cb-403c-b897-9ea558a679ed": Phase="Pending", Reason="", readiness=false. Elapsed: 1.390402ms
Sep 16 02:07:54.542: INFO: Pod "var-expansion-8a6d1c97-36cb-403c-b897-9ea558a679ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003935239s
Sep 16 02:07:56.544: INFO: Pod "var-expansion-8a6d1c97-36cb-403c-b897-9ea558a679ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006334017s
STEP: Saw pod success
Sep 16 02:07:56.544: INFO: Pod "var-expansion-8a6d1c97-36cb-403c-b897-9ea558a679ed" satisfied condition "Succeeded or Failed"
Sep 16 02:07:56.546: INFO: Trying to get logs from node 192.168.4.87 pod var-expansion-8a6d1c97-36cb-403c-b897-9ea558a679ed container dapi-container: <nil>
STEP: delete the pod
Sep 16 02:07:56.555: INFO: Waiting for pod var-expansion-8a6d1c97-36cb-403c-b897-9ea558a679ed to disappear
Sep 16 02:07:56.556: INFO: Pod var-expansion-8a6d1c97-36cb-403c-b897-9ea558a679ed no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:07:56.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4768" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":277,"completed":55,"skipped":1205,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:07:56.561: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-49788dee-c8dd-4fc0-8176-80c74f997431
STEP: Creating secret with name secret-projected-all-test-volume-75a4c434-8b97-4dd3-89e3-dce1a293e791
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 16 02:07:56.583: INFO: Waiting up to 5m0s for pod "projected-volume-38881cd2-461e-44b5-bf5a-9ac8c39f6407" in namespace "projected-2870" to be "Succeeded or Failed"
Sep 16 02:07:56.584: INFO: Pod "projected-volume-38881cd2-461e-44b5-bf5a-9ac8c39f6407": Phase="Pending", Reason="", readiness=false. Elapsed: 1.3053ms
Sep 16 02:07:58.587: INFO: Pod "projected-volume-38881cd2-461e-44b5-bf5a-9ac8c39f6407": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00372575s
Sep 16 02:08:00.589: INFO: Pod "projected-volume-38881cd2-461e-44b5-bf5a-9ac8c39f6407": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006241007s
STEP: Saw pod success
Sep 16 02:08:00.589: INFO: Pod "projected-volume-38881cd2-461e-44b5-bf5a-9ac8c39f6407" satisfied condition "Succeeded or Failed"
Sep 16 02:08:00.591: INFO: Trying to get logs from node 192.168.4.87 pod projected-volume-38881cd2-461e-44b5-bf5a-9ac8c39f6407 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 16 02:08:00.601: INFO: Waiting for pod projected-volume-38881cd2-461e-44b5-bf5a-9ac8c39f6407 to disappear
Sep 16 02:08:00.602: INFO: Pod projected-volume-38881cd2-461e-44b5-bf5a-9ac8c39f6407 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:08:00.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2870" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":277,"completed":56,"skipped":1210,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:08:00.607: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Sep 16 02:08:01.645: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0916 02:08:01.645113      26 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:08:01.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8354" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":277,"completed":57,"skipped":1211,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:08:01.649: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:08:01.667: INFO: Creating ReplicaSet my-hostname-basic-50d98228-2b89-49d0-bdd7-bcf3e2085d75
Sep 16 02:08:01.671: INFO: Pod name my-hostname-basic-50d98228-2b89-49d0-bdd7-bcf3e2085d75: Found 0 pods out of 1
Sep 16 02:08:06.673: INFO: Pod name my-hostname-basic-50d98228-2b89-49d0-bdd7-bcf3e2085d75: Found 1 pods out of 1
Sep 16 02:08:06.673: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-50d98228-2b89-49d0-bdd7-bcf3e2085d75" is running
Sep 16 02:08:06.674: INFO: Pod "my-hostname-basic-50d98228-2b89-49d0-bdd7-bcf3e2085d75-js9pw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-16 02:08:01 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-16 02:08:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-16 02:08:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-16 02:08:01 +0000 UTC Reason: Message:}])
Sep 16 02:08:06.674: INFO: Trying to dial the pod
Sep 16 02:08:11.681: INFO: Controller my-hostname-basic-50d98228-2b89-49d0-bdd7-bcf3e2085d75: Got expected result from replica 1 [my-hostname-basic-50d98228-2b89-49d0-bdd7-bcf3e2085d75-js9pw]: "my-hostname-basic-50d98228-2b89-49d0-bdd7-bcf3e2085d75-js9pw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:08:11.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9098" for this suite.

• [SLOW TEST:10.038 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":58,"skipped":1249,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:08:11.687: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 16 02:08:19.723: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 16 02:08:19.725: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 16 02:08:21.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 16 02:08:21.727: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 16 02:08:23.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 16 02:08:23.727: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 16 02:08:25.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 16 02:08:25.727: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 16 02:08:27.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 16 02:08:27.727: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 16 02:08:29.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 16 02:08:29.727: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 16 02:08:31.725: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 16 02:08:31.727: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:08:31.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5392" for this suite.

• [SLOW TEST:20.050 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":277,"completed":59,"skipped":1257,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:08:31.737: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 16 02:08:36.272: INFO: Successfully updated pod "labelsupdate72854e45-8970-4103-963e-249532058777"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:08:38.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3328" for this suite.

• [SLOW TEST:6.555 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":60,"skipped":1259,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:08:38.293: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-55d9f76b-516e-440d-864e-c409eeb07d14 in namespace container-probe-4166
Sep 16 02:08:42.314: INFO: Started pod liveness-55d9f76b-516e-440d-864e-c409eeb07d14 in namespace container-probe-4166
STEP: checking the pod's current state and verifying that restartCount is present
Sep 16 02:08:42.315: INFO: Initial restart count of pod liveness-55d9f76b-516e-440d-864e-c409eeb07d14 is 0
Sep 16 02:08:54.329: INFO: Restart count of pod container-probe-4166/liveness-55d9f76b-516e-440d-864e-c409eeb07d14 is now 1 (12.013152864s elapsed)
Sep 16 02:09:14.353: INFO: Restart count of pod container-probe-4166/liveness-55d9f76b-516e-440d-864e-c409eeb07d14 is now 2 (32.037945157s elapsed)
Sep 16 02:09:34.376: INFO: Restart count of pod container-probe-4166/liveness-55d9f76b-516e-440d-864e-c409eeb07d14 is now 3 (52.060589615s elapsed)
Sep 16 02:09:54.398: INFO: Restart count of pod container-probe-4166/liveness-55d9f76b-516e-440d-864e-c409eeb07d14 is now 4 (1m12.082620576s elapsed)
Sep 16 02:10:56.471: INFO: Restart count of pod container-probe-4166/liveness-55d9f76b-516e-440d-864e-c409eeb07d14 is now 5 (2m14.155259456s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:10:56.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4166" for this suite.

• [SLOW TEST:138.187 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":277,"completed":61,"skipped":1292,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:10:56.480: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Sep 16 02:11:36.511: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0916 02:11:36.511623      26 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:11:36.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2233" for this suite.

• [SLOW TEST:40.039 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":277,"completed":62,"skipped":1298,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:11:36.520: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Sep 16 02:11:36.543: INFO: Waiting up to 5m0s for pod "var-expansion-8fcdef57-c751-4007-8ed9-3c88f16ac55b" in namespace "var-expansion-4184" to be "Succeeded or Failed"
Sep 16 02:11:36.544: INFO: Pod "var-expansion-8fcdef57-c751-4007-8ed9-3c88f16ac55b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.358033ms
Sep 16 02:11:38.547: INFO: Pod "var-expansion-8fcdef57-c751-4007-8ed9-3c88f16ac55b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00421954s
Sep 16 02:11:40.549: INFO: Pod "var-expansion-8fcdef57-c751-4007-8ed9-3c88f16ac55b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006586918s
STEP: Saw pod success
Sep 16 02:11:40.549: INFO: Pod "var-expansion-8fcdef57-c751-4007-8ed9-3c88f16ac55b" satisfied condition "Succeeded or Failed"
Sep 16 02:11:40.551: INFO: Trying to get logs from node 192.168.4.87 pod var-expansion-8fcdef57-c751-4007-8ed9-3c88f16ac55b container dapi-container: <nil>
STEP: delete the pod
Sep 16 02:11:40.576: INFO: Waiting for pod var-expansion-8fcdef57-c751-4007-8ed9-3c88f16ac55b to disappear
Sep 16 02:11:40.578: INFO: Pod var-expansion-8fcdef57-c751-4007-8ed9-3c88f16ac55b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:11:40.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4184" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":277,"completed":63,"skipped":1319,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:11:40.582: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-47fa5616-e542-4292-915c-8e7d16cea580
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:11:40.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-919" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":277,"completed":64,"skipped":1323,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:11:40.603: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 16 02:11:40.622: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:11:58.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5929" for this suite.

• [SLOW TEST:18.208 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":277,"completed":65,"skipped":1345,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:11:58.812: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-6227
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 16 02:11:58.827: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 16 02:11:58.839: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:12:00.841: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:12:02.841: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:12:04.842: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:12:06.841: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:12:08.841: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:12:10.841: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:12:12.840: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:12:14.841: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:12:16.840: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:12:18.841: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 16 02:12:18.844: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 16 02:12:22.857: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.151.166.179 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6227 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:12:22.857: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:12:24.033: INFO: Found all expected endpoints: [netserver-0]
Sep 16 02:12:24.035: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.151.104.23 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6227 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:12:24.035: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:12:25.157: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:12:25.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6227" for this suite.

• [SLOW TEST:26.350 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":66,"skipped":1375,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:12:25.161: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-8dfdd835-510d-4988-a2db-c34d1b8b91e5
STEP: Creating secret with name s-test-opt-upd-fc67d91c-b2b1-4c30-abf5-9f565f1f1c1f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8dfdd835-510d-4988-a2db-c34d1b8b91e5
STEP: Updating secret s-test-opt-upd-fc67d91c-b2b1-4c30-abf5-9f565f1f1c1f
STEP: Creating secret with name s-test-opt-create-38cf7cf5-472e-4f5d-aed9-f504eb7df4f6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:12:33.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7612" for this suite.

• [SLOW TEST:8.079 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":67,"skipped":1381,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:12:33.241: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2617.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2617.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2617.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2617.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 16 02:12:39.272: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.274: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.276: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-2617.svc.cluster.local from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.278: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-2617.svc.cluster.local from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.280: INFO: Unable to read wheezy_udp@PodARecord from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.281: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.283: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.285: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.287: INFO: Unable to read jessie_udp@dns-test-service-2.dns-2617.svc.cluster.local from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.289: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-2617.svc.cluster.local from pod dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462: the server could not find the requested resource (get pods dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462)
Sep 16 02:12:39.293: INFO: Lookups using dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local wheezy_udp@dns-test-service-2.dns-2617.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-2617.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2617.svc.cluster.local jessie_udp@dns-test-service-2.dns-2617.svc.cluster.local jessie_tcp@dns-test-service-2.dns-2617.svc.cluster.local]

Sep 16 02:12:44.313: INFO: DNS probes using dns-2617/dns-test-b1e6bdcd-9960-42ad-a1ba-db16da100462 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:12:44.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2617" for this suite.

• [SLOW TEST:11.087 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":277,"completed":68,"skipped":1383,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:12:44.328: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9643
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9643
STEP: creating replication controller externalsvc in namespace services-9643
I0916 02:12:44.355281      26 runners.go:190] Created replication controller with name: externalsvc, namespace: services-9643, replica count: 2
I0916 02:12:47.405627      26 runners.go:190] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0916 02:12:50.405827      26 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Sep 16 02:12:50.416: INFO: Creating new exec pod
Sep 16 02:12:54.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-9643 execpod4tpb4 -- /bin/sh -x -c nslookup nodeport-service'
Sep 16 02:12:56.654: INFO: stderr: "+ nslookup nodeport-service\n"
Sep 16 02:12:56.654: INFO: stdout: "Server:\t\t11.254.0.10\nAddress:\t11.254.0.10#53\n\nnodeport-service.services-9643.svc.cluster.local\tcanonical name = externalsvc.services-9643.svc.cluster.local.\nName:\texternalsvc.services-9643.svc.cluster.local\nAddress: 11.254.128.145\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9643, will wait for the garbage collector to delete the pods
Sep 16 02:12:56.710: INFO: Deleting ReplicationController externalsvc took: 3.022893ms
Sep 16 02:12:56.810: INFO: Terminating ReplicationController externalsvc pods took: 100.146244ms
Sep 16 02:13:10.617: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:13:10.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9643" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:26.300 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":277,"completed":69,"skipped":1419,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:13:10.628: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 16 02:13:10.650: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-a f43a34d6-b97d-492c-a474-47e3afaef0cf 13364 0 2020-09-16 02:13:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:13:10.650: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-a f43a34d6-b97d-492c-a474-47e3afaef0cf 13364 0 2020-09-16 02:13:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 16 02:13:20.655: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-a f43a34d6-b97d-492c-a474-47e3afaef0cf 13417 0 2020-09-16 02:13:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:13:20.655: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-a f43a34d6-b97d-492c-a474-47e3afaef0cf 13417 0 2020-09-16 02:13:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 16 02:13:30.659: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-a f43a34d6-b97d-492c-a474-47e3afaef0cf 13441 0 2020-09-16 02:13:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:13:30.660: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-a f43a34d6-b97d-492c-a474-47e3afaef0cf 13441 0 2020-09-16 02:13:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 16 02:13:40.663: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-a f43a34d6-b97d-492c-a474-47e3afaef0cf 13465 0 2020-09-16 02:13:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:13:40.664: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-a f43a34d6-b97d-492c-a474-47e3afaef0cf 13465 0 2020-09-16 02:13:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 16 02:13:50.668: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-b 1b4aca3f-e3f6-4e0e-b8af-c5ae06079f01 13489 0 2020-09-16 02:13:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:13:50.668: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-b 1b4aca3f-e3f6-4e0e-b8af-c5ae06079f01 13489 0 2020-09-16 02:13:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 16 02:14:00.672: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-b 1b4aca3f-e3f6-4e0e-b8af-c5ae06079f01 13513 0 2020-09-16 02:13:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:14:00.672: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1789 /api/v1/namespaces/watch-1789/configmaps/e2e-watch-test-configmap-b 1b4aca3f-e3f6-4e0e-b8af-c5ae06079f01 13513 0 2020-09-16 02:13:50 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-16 02:13:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:14:10.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1789" for this suite.

• [SLOW TEST:60.050 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":277,"completed":70,"skipped":1420,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:14:10.678: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-9fe5cc94-9ea3-4656-aa3d-4fa522e504fd
STEP: Creating a pod to test consume configMaps
Sep 16 02:14:10.699: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3e27533f-eb9c-4426-9b78-c09527bcf749" in namespace "projected-8942" to be "Succeeded or Failed"
Sep 16 02:14:10.700: INFO: Pod "pod-projected-configmaps-3e27533f-eb9c-4426-9b78-c09527bcf749": Phase="Pending", Reason="", readiness=false. Elapsed: 1.352474ms
Sep 16 02:14:12.702: INFO: Pod "pod-projected-configmaps-3e27533f-eb9c-4426-9b78-c09527bcf749": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003663533s
Sep 16 02:14:14.705: INFO: Pod "pod-projected-configmaps-3e27533f-eb9c-4426-9b78-c09527bcf749": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006377682s
STEP: Saw pod success
Sep 16 02:14:14.705: INFO: Pod "pod-projected-configmaps-3e27533f-eb9c-4426-9b78-c09527bcf749" satisfied condition "Succeeded or Failed"
Sep 16 02:14:14.707: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-configmaps-3e27533f-eb9c-4426-9b78-c09527bcf749 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:14:14.723: INFO: Waiting for pod pod-projected-configmaps-3e27533f-eb9c-4426-9b78-c09527bcf749 to disappear
Sep 16 02:14:14.724: INFO: Pod pod-projected-configmaps-3e27533f-eb9c-4426-9b78-c09527bcf749 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:14:14.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8942" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":71,"skipped":1424,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:14:14.729: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-02289e20-7075-4768-921c-310bb5ae45c9
STEP: Creating a pod to test consume secrets
Sep 16 02:14:14.750: INFO: Waiting up to 5m0s for pod "pod-secrets-14a695f1-0edc-470f-96ca-19e6066db10a" in namespace "secrets-3778" to be "Succeeded or Failed"
Sep 16 02:14:14.752: INFO: Pod "pod-secrets-14a695f1-0edc-470f-96ca-19e6066db10a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.390216ms
Sep 16 02:14:16.761: INFO: Pod "pod-secrets-14a695f1-0edc-470f-96ca-19e6066db10a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010546116s
Sep 16 02:14:18.764: INFO: Pod "pod-secrets-14a695f1-0edc-470f-96ca-19e6066db10a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013359525s
STEP: Saw pod success
Sep 16 02:14:18.764: INFO: Pod "pod-secrets-14a695f1-0edc-470f-96ca-19e6066db10a" satisfied condition "Succeeded or Failed"
Sep 16 02:14:18.765: INFO: Trying to get logs from node 192.168.4.87 pod pod-secrets-14a695f1-0edc-470f-96ca-19e6066db10a container secret-env-test: <nil>
STEP: delete the pod
Sep 16 02:14:18.775: INFO: Waiting for pod pod-secrets-14a695f1-0edc-470f-96ca-19e6066db10a to disappear
Sep 16 02:14:18.777: INFO: Pod pod-secrets-14a695f1-0edc-470f-96ca-19e6066db10a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:14:18.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3778" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":277,"completed":72,"skipped":1453,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:14:18.781: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:14:19.856: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Sep 16 02:14:21.862: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819259, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819259, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819259, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819259, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:14:24.867: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:14:24.869: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:14:26.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6018" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:7.254 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":277,"completed":73,"skipped":1456,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:14:26.035: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Sep 16 02:14:26.051: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-120268828 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:14:26.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1671" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":277,"completed":74,"skipped":1477,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:14:26.133: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Sep 16 02:14:26.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-9599'
Sep 16 02:14:26.493: INFO: stderr: ""
Sep 16 02:14:26.493: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Sep 16 02:14:27.496: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:14:27.496: INFO: Found 0 / 1
Sep 16 02:14:28.496: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:14:28.496: INFO: Found 0 / 1
Sep 16 02:14:29.495: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:14:29.496: INFO: Found 1 / 1
Sep 16 02:14:29.496: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 16 02:14:29.497: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:14:29.497: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 16 02:14:29.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 patch pod agnhost-master-t6966 --namespace=kubectl-9599 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 16 02:14:29.567: INFO: stderr: ""
Sep 16 02:14:29.567: INFO: stdout: "pod/agnhost-master-t6966 patched\n"
STEP: checking annotations
Sep 16 02:14:29.569: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:14:29.569: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:14:29.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9599" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":277,"completed":75,"skipped":1487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:14:29.574: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-9066
STEP: creating replication controller nodeport-test in namespace services-9066
I0916 02:14:29.596778      26 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-9066, replica count: 2
I0916 02:14:32.647117      26 runners.go:190] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 16 02:14:35.647: INFO: Creating new exec pod
I0916 02:14:35.647336      26 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 16 02:14:40.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-9066 execpodlchn4 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Sep 16 02:14:40.833: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Sep 16 02:14:40.833: INFO: stdout: ""
Sep 16 02:14:40.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-9066 execpodlchn4 -- /bin/sh -x -c nc -zv -t -w 2 11.254.1.23 80'
Sep 16 02:14:41.010: INFO: stderr: "+ nc -zv -t -w 2 11.254.1.23 80\nConnection to 11.254.1.23 80 port [tcp/http] succeeded!\n"
Sep 16 02:14:41.010: INFO: stdout: ""
Sep 16 02:14:41.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-9066 execpodlchn4 -- /bin/sh -x -c nc -zv -t -w 2 192.168.4.86 30905'
Sep 16 02:14:41.187: INFO: stderr: "+ nc -zv -t -w 2 192.168.4.86 30905\nConnection to 192.168.4.86 30905 port [tcp/30905] succeeded!\n"
Sep 16 02:14:41.187: INFO: stdout: ""
Sep 16 02:14:41.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-9066 execpodlchn4 -- /bin/sh -x -c nc -zv -t -w 2 192.168.4.87 30905'
Sep 16 02:14:41.366: INFO: stderr: "+ nc -zv -t -w 2 192.168.4.87 30905\nConnection to 192.168.4.87 30905 port [tcp/30905] succeeded!\n"
Sep 16 02:14:41.366: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:14:41.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9066" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:11.798 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":277,"completed":76,"skipped":1510,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:14:41.372: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 16 02:14:41.393: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 16 02:14:41.400: INFO: Waiting for terminating namespaces to be deleted...
Sep 16 02:14:41.402: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.86 before test
Sep 16 02:14:41.414: INFO: ckecsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep 16 02:14:41.414: INFO: cke-lvmcsi-nf9cd from cke-storage started at 2020-09-16 01:25:20 +0000 UTC (2 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 02:14:41.414: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:14:41.414: INFO: ckecsi-runc-jq25h from cke-storage started at 2020-09-16 01:25:30 +0000 UTC (2 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 02:14:41.414: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:14:41.414: INFO: sonobuoy from sonobuoy started at 2020-09-16 01:52:42 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 16 02:14:41.414: INFO: calico-kube-controllers-97dc579d-s2z7r from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 16 02:14:41.414: INFO: sonobuoy-e2e-job-a58be685376b45c9 from sonobuoy started at 2020-09-16 01:52:44 +0000 UTC (2 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container e2e ready: true, restart count 0
Sep 16 02:14:41.414: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 16 02:14:41.414: INFO: nodeport-test-lsp4s from services-9066 started at 2020-09-16 02:14:29 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container nodeport-test ready: true, restart count 0
Sep 16 02:14:41.414: INFO: coredns-75587db8b6-vlztj from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container coredns ready: true, restart count 0
Sep 16 02:14:41.414: INFO: ckecsi-attacher-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep 16 02:14:41.414: INFO: kubernetes-dashboard-7d464dfc59-d5sxx from kubernetes-dashboard started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.414: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 16 02:14:41.414: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.87 before test
Sep 16 02:14:41.419: INFO: ckecsi-runc-2x2tv from cke-storage started at 2020-09-16 01:25:29 +0000 UTC (2 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 02:14:41.419: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:14:41.419: INFO: ckecsi-attacher-1 from cke-storage started at 2020-09-16 01:26:22 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep 16 02:14:41.419: INFO: cke-lvmcsi-q44bw from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (2 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 02:14:41.419: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:14:41.419: INFO: cke-lvmcsi-resizer-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container csi-lvm-resizer ready: true, restart count 0
Sep 16 02:14:41.419: INFO: ckecsi-provisioner-1 from cke-storage started at 2020-09-16 01:26:19 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep 16 02:14:41.419: INFO: nodeport-test-br5jt from services-9066 started at 2020-09-16 02:14:29 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container nodeport-test ready: true, restart count 0
Sep 16 02:14:41.419: INFO: agnhost-master-t6966 from kubectl-9599 started at 2020-09-16 02:14:26 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container agnhost-master ready: false, restart count 0
Sep 16 02:14:41.419: INFO: cke-lvmcsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container csi-provisioner ready: true, restart count 1
Sep 16 02:14:41.419: INFO: dashboard-metrics-scraper-6fb76cb999-qld2q from kubernetes-dashboard started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 16 02:14:41.419: INFO: metrics-server-cf7f9ccc5-jcnlg from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container metrics-server ready: true, restart count 0
Sep 16 02:14:41.419: INFO: execpodlchn4 from services-9066 started at 2020-09-16 02:14:35 +0000 UTC (1 container statuses recorded)
Sep 16 02:14:41.419: INFO: 	Container agnhost-pause ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.163521de574a7706], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:14:42.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-620" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":277,"completed":77,"skipped":1535,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:14:42.436: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:14:42.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8068" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":277,"completed":78,"skipped":1546,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:14:42.456: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-lrh5
STEP: Creating a pod to test atomic-volume-subpath
Sep 16 02:14:42.477: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lrh5" in namespace "subpath-1828" to be "Succeeded or Failed"
Sep 16 02:14:42.478: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.178057ms
Sep 16 02:14:44.480: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003046487s
Sep 16 02:14:46.482: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 4.005097584s
Sep 16 02:14:48.484: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 6.007739166s
Sep 16 02:14:50.487: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 8.010657387s
Sep 16 02:14:52.490: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 10.012967931s
Sep 16 02:14:54.492: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 12.015371125s
Sep 16 02:14:56.494: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 14.017671219s
Sep 16 02:14:58.497: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 16.019947446s
Sep 16 02:15:00.499: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 18.022375627s
Sep 16 02:15:02.501: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 20.024687434s
Sep 16 02:15:04.504: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Running", Reason="", readiness=true. Elapsed: 22.027170188s
Sep 16 02:15:06.506: INFO: Pod "pod-subpath-test-configmap-lrh5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.029417831s
STEP: Saw pod success
Sep 16 02:15:06.506: INFO: Pod "pod-subpath-test-configmap-lrh5" satisfied condition "Succeeded or Failed"
Sep 16 02:15:06.507: INFO: Trying to get logs from node 192.168.4.86 pod pod-subpath-test-configmap-lrh5 container test-container-subpath-configmap-lrh5: <nil>
STEP: delete the pod
Sep 16 02:15:06.516: INFO: Waiting for pod pod-subpath-test-configmap-lrh5 to disappear
Sep 16 02:15:06.518: INFO: Pod pod-subpath-test-configmap-lrh5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lrh5
Sep 16 02:15:06.518: INFO: Deleting pod "pod-subpath-test-configmap-lrh5" in namespace "subpath-1828"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:15:06.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1828" for this suite.

• [SLOW TEST:24.067 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":277,"completed":79,"skipped":1553,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:15:06.524: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:15:06.538: INFO: Creating deployment "test-recreate-deployment"
Sep 16 02:15:06.540: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 16 02:15:06.543: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 16 02:15:08.547: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 16 02:15:08.548: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819306, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819306, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819306, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819306, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 02:15:10.550: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 16 02:15:10.557: INFO: Updating deployment test-recreate-deployment
Sep 16 02:15:10.557: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 16 02:15:10.584: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4222 /apis/apps/v1/namespaces/deployment-4222/deployments/test-recreate-deployment 589f6782-a14e-4d86-85ec-94eb1045b3ca 14106 2 2020-09-16 02:15:06 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-09-16 02:15:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-16 02:15:10 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002d910e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-09-16 02:15:10 +0000 UTC,LastTransitionTime:2020-09-16 02:15:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-09-16 02:15:10 +0000 UTC,LastTransitionTime:2020-09-16 02:15:06 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Sep 16 02:15:10.586: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-4222 /apis/apps/v1/namespaces/deployment-4222/replicasets/test-recreate-deployment-d5667d9c7 1b944996-b3db-4c12-9c17-1cb20ea61585 14104 1 2020-09-16 02:15:10 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 589f6782-a14e-4d86-85ec-94eb1045b3ca 0xc002d91700 0xc002d91701}] []  [{kube-controller-manager Update apps/v1 2020-09-16 02:15:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 56 57 102 54 55 56 50 45 97 49 52 101 45 52 100 56 54 45 56 53 101 99 45 57 52 101 98 49 48 52 53 98 51 99 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002d91778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 16 02:15:10.586: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 16 02:15:10.587: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-4222 /apis/apps/v1/namespaces/deployment-4222/replicasets/test-recreate-deployment-74d98b5f7c 31c76fcf-bd21-4cdc-ad86-e978ee6f88c6 14094 2 2020-09-16 02:15:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 589f6782-a14e-4d86-85ec-94eb1045b3ca 0xc002d91607 0xc002d91608}] []  [{kube-controller-manager Update apps/v1 2020-09-16 02:15:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 56 57 102 54 55 56 50 45 97 49 52 101 45 52 100 56 54 45 56 53 101 99 45 57 52 101 98 49 48 52 53 98 51 99 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002d91698 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 16 02:15:10.589: INFO: Pod "test-recreate-deployment-d5667d9c7-dpsb6" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-dpsb6 test-recreate-deployment-d5667d9c7- deployment-4222 /api/v1/namespaces/deployment-4222/pods/test-recreate-deployment-d5667d9c7-dpsb6 17688016-815f-442b-9d77-09e0b7db99bc 14102 0 2020-09-16 02:15:10 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 1b944996-b3db-4c12-9c17-1cb20ea61585 0xc002d91c90 0xc002d91c91}] []  [{kube-controller-manager Update v1 2020-09-16 02:15:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 57 52 52 57 57 54 45 98 51 100 98 45 52 99 49 50 45 57 99 49 55 45 49 99 98 50 48 101 97 54 49 53 56 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fdzfj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fdzfj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fdzfj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:15:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:15:10.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4222" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":80,"skipped":1596,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:15:10.594: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8500.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8500.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8500.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8500.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 16 02:15:16.626: INFO: DNS probes using dns-test-51ba766d-8acb-4d6c-b6ec-88bd34409340 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8500.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8500.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8500.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8500.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 16 02:15:22.652: INFO: DNS probes using dns-test-83bc8579-ad46-4c59-a635-69d3c170cc63 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8500.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8500.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8500.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8500.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 16 02:15:28.678: INFO: DNS probes using dns-test-b76c0ee2-7486-44e9-86fc-1ada66262b9e succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:15:28.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8500" for this suite.

• [SLOW TEST:18.097 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":277,"completed":81,"skipped":1607,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:15:28.692: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:15:28.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-09a7358f-ee32-4882-8005-ad40cbaeb7c9" in namespace "downward-api-7418" to be "Succeeded or Failed"
Sep 16 02:15:28.716: INFO: Pod "downwardapi-volume-09a7358f-ee32-4882-8005-ad40cbaeb7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.66639ms
Sep 16 02:15:30.718: INFO: Pod "downwardapi-volume-09a7358f-ee32-4882-8005-ad40cbaeb7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004063352s
Sep 16 02:15:32.720: INFO: Pod "downwardapi-volume-09a7358f-ee32-4882-8005-ad40cbaeb7c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006090861s
STEP: Saw pod success
Sep 16 02:15:32.720: INFO: Pod "downwardapi-volume-09a7358f-ee32-4882-8005-ad40cbaeb7c9" satisfied condition "Succeeded or Failed"
Sep 16 02:15:32.722: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-09a7358f-ee32-4882-8005-ad40cbaeb7c9 container client-container: <nil>
STEP: delete the pod
Sep 16 02:15:32.730: INFO: Waiting for pod downwardapi-volume-09a7358f-ee32-4882-8005-ad40cbaeb7c9 to disappear
Sep 16 02:15:32.732: INFO: Pod downwardapi-volume-09a7358f-ee32-4882-8005-ad40cbaeb7c9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:15:32.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7418" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":277,"completed":82,"skipped":1609,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:15:32.736: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-0093ec0f-6e60-4a09-a276-3d01cf188cd9
STEP: Creating a pod to test consume secrets
Sep 16 02:15:32.755: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-240391e7-8b9b-40f4-9188-1629a4bed178" in namespace "projected-398" to be "Succeeded or Failed"
Sep 16 02:15:32.757: INFO: Pod "pod-projected-secrets-240391e7-8b9b-40f4-9188-1629a4bed178": Phase="Pending", Reason="", readiness=false. Elapsed: 1.132518ms
Sep 16 02:15:34.759: INFO: Pod "pod-projected-secrets-240391e7-8b9b-40f4-9188-1629a4bed178": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003282671s
Sep 16 02:15:36.761: INFO: Pod "pod-projected-secrets-240391e7-8b9b-40f4-9188-1629a4bed178": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005653162s
STEP: Saw pod success
Sep 16 02:15:36.761: INFO: Pod "pod-projected-secrets-240391e7-8b9b-40f4-9188-1629a4bed178" satisfied condition "Succeeded or Failed"
Sep 16 02:15:36.763: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-secrets-240391e7-8b9b-40f4-9188-1629a4bed178 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 16 02:15:36.772: INFO: Waiting for pod pod-projected-secrets-240391e7-8b9b-40f4-9188-1629a4bed178 to disappear
Sep 16 02:15:36.773: INFO: Pod pod-projected-secrets-240391e7-8b9b-40f4-9188-1629a4bed178 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:15:36.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-398" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":83,"skipped":1616,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:15:36.778: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5409.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5409.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5409.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5409.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5409.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5409.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5409.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5409.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5409.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5409.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5409.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 183.17.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.17.183_udp@PTR;check="$$(dig +tcp +noall +answer +search 183.17.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.17.183_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5409.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5409.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5409.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5409.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5409.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5409.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5409.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5409.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5409.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5409.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5409.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 183.17.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.17.183_udp@PTR;check="$$(dig +tcp +noall +answer +search 183.17.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.17.183_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 16 02:15:42.811: INFO: Unable to read wheezy_udp@dns-test-service.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.812: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.814: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.816: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.817: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.819: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.821: INFO: Unable to read wheezy_udp@PodARecord from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.822: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.827: INFO: Unable to read jessie_udp@dns-test-service.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.829: INFO: Unable to read jessie_tcp@dns-test-service.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.830: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.832: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local from pod dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9: the server could not find the requested resource (get pods dns-test-f78f41b9-013a-4884-ad14-e427489441c9)
Sep 16 02:15:42.841: INFO: Lookups using dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9 failed for: [wheezy_udp@dns-test-service.dns-5409.svc.cluster.local wheezy_tcp@dns-test-service.dns-5409.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local wheezy_udp@_http._tcp.test-service-2.dns-5409.svc.cluster.local wheezy_tcp@_http._tcp.test-service-2.dns-5409.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-5409.svc.cluster.local jessie_tcp@dns-test-service.dns-5409.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5409.svc.cluster.local]

Sep 16 02:15:47.875: INFO: DNS probes using dns-5409/dns-test-f78f41b9-013a-4884-ad14-e427489441c9 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:15:47.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5409" for this suite.

• [SLOW TEST:11.121 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":277,"completed":84,"skipped":1632,"failed":0}
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:15:47.899: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-6810
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 16 02:15:47.915: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 16 02:15:47.928: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:15:49.930: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:15:51.930: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:15:53.930: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:15:55.930: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:15:57.930: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:15:59.930: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:16:01.930: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:16:03.930: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 16 02:16:03.933: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 16 02:16:07.947: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.151.166.184:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6810 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:16:07.947: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:16:08.061: INFO: Found all expected endpoints: [netserver-0]
Sep 16 02:16:08.063: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.151.104.43:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6810 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:16:08.063: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:16:08.167: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:08.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6810" for this suite.

• [SLOW TEST:20.273 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":85,"skipped":1635,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:08.172: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-dc711be4-26aa-4e7d-b8ac-99db740cd3c4
STEP: Creating configMap with name cm-test-opt-upd-9e4ee84b-6720-4f84-8df9-05f5fc3026c2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-dc711be4-26aa-4e7d-b8ac-99db740cd3c4
STEP: Updating configmap cm-test-opt-upd-9e4ee84b-6720-4f84-8df9-05f5fc3026c2
STEP: Creating configMap with name cm-test-opt-create-ba06c59e-0594-4d9a-8af3-d5a57887f827
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:16.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9206" for this suite.

• [SLOW TEST:8.080 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":86,"skipped":1650,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:16.252: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 16 02:16:16.271: INFO: Waiting up to 5m0s for pod "downward-api-c7ed1807-8074-429d-9ce8-84060d8ed089" in namespace "downward-api-623" to be "Succeeded or Failed"
Sep 16 02:16:16.272: INFO: Pod "downward-api-c7ed1807-8074-429d-9ce8-84060d8ed089": Phase="Pending", Reason="", readiness=false. Elapsed: 1.355138ms
Sep 16 02:16:18.275: INFO: Pod "downward-api-c7ed1807-8074-429d-9ce8-84060d8ed089": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003664802s
Sep 16 02:16:20.277: INFO: Pod "downward-api-c7ed1807-8074-429d-9ce8-84060d8ed089": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006136945s
STEP: Saw pod success
Sep 16 02:16:20.277: INFO: Pod "downward-api-c7ed1807-8074-429d-9ce8-84060d8ed089" satisfied condition "Succeeded or Failed"
Sep 16 02:16:20.279: INFO: Trying to get logs from node 192.168.4.86 pod downward-api-c7ed1807-8074-429d-9ce8-84060d8ed089 container dapi-container: <nil>
STEP: delete the pod
Sep 16 02:16:20.289: INFO: Waiting for pod downward-api-c7ed1807-8074-429d-9ce8-84060d8ed089 to disappear
Sep 16 02:16:20.290: INFO: Pod downward-api-c7ed1807-8074-429d-9ce8-84060d8ed089 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:20.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-623" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":277,"completed":87,"skipped":1670,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:20.311: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:24.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9248" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":88,"skipped":1683,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:24.348: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-56311cde-34fc-4486-bc17-ac70c0e863ab
STEP: Creating a pod to test consume configMaps
Sep 16 02:16:24.371: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a20b1a9c-ca03-4cb7-ac7b-56b06796466f" in namespace "projected-7125" to be "Succeeded or Failed"
Sep 16 02:16:24.373: INFO: Pod "pod-projected-configmaps-a20b1a9c-ca03-4cb7-ac7b-56b06796466f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.300403ms
Sep 16 02:16:26.374: INFO: Pod "pod-projected-configmaps-a20b1a9c-ca03-4cb7-ac7b-56b06796466f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002964615s
Sep 16 02:16:28.377: INFO: Pod "pod-projected-configmaps-a20b1a9c-ca03-4cb7-ac7b-56b06796466f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005734295s
STEP: Saw pod success
Sep 16 02:16:28.377: INFO: Pod "pod-projected-configmaps-a20b1a9c-ca03-4cb7-ac7b-56b06796466f" satisfied condition "Succeeded or Failed"
Sep 16 02:16:28.379: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-configmaps-a20b1a9c-ca03-4cb7-ac7b-56b06796466f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:16:28.390: INFO: Waiting for pod pod-projected-configmaps-a20b1a9c-ca03-4cb7-ac7b-56b06796466f to disappear
Sep 16 02:16:28.391: INFO: Pod pod-projected-configmaps-a20b1a9c-ca03-4cb7-ac7b-56b06796466f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:28.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7125" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":89,"skipped":1686,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:28.397: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:16:28.969: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 02:16:30.974: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819388, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819388, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819388, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819388, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 02:16:32.977: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819388, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819388, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819388, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819388, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:16:35.981: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:35.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2804" for this suite.
STEP: Destroying namespace "webhook-2804-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.615 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":277,"completed":90,"skipped":1709,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:36.012: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:16:36.035: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 16 02:16:41.036: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 16 02:16:41.037: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 16 02:16:41.045: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-5535 /apis/apps/v1/namespaces/deployment-5535/deployments/test-cleanup-deployment 29d28747-f8a8-4a42-8867-9e30e773dc2b 14984 1 2020-09-16 02:16:41 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2020-09-16 02:16:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00534eef8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Sep 16 02:16:41.047: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Sep 16 02:16:41.047: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep 16 02:16:41.047: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-5535 /apis/apps/v1/namespaces/deployment-5535/replicasets/test-cleanup-controller 10d4df3b-df60-4d93-95f8-7effe0bc69f6 14987 1 2020-09-16 02:16:36 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 29d28747-f8a8-4a42-8867-9e30e773dc2b 0xc00534f307 0xc00534f308}] []  [{e2e.test Update apps/v1 2020-09-16 02:16:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-16 02:16:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 57 100 50 56 55 52 55 45 102 56 97 56 45 52 97 52 50 45 56 56 54 55 45 57 101 51 48 101 55 55 51 100 99 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00534f3a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 16 02:16:41.050: INFO: Pod "test-cleanup-controller-pmgwp" is available:
&Pod{ObjectMeta:{test-cleanup-controller-pmgwp test-cleanup-controller- deployment-5535 /api/v1/namespaces/deployment-5535/pods/test-cleanup-controller-pmgwp 3675ec42-5fd8-4088-9b79-af409b284a65 14967 0 2020-09-16 02:16:36 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 10d4df3b-df60-4d93-95f8-7effe0bc69f6 0xc00534f737 0xc00534f738}] []  [{kube-controller-manager Update v1 2020-09-16 02:16:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 48 100 52 100 102 51 98 45 100 102 54 48 45 52 100 57 51 45 57 53 102 56 45 55 101 102 102 101 48 98 99 54 57 102 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 02:16:39 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 48 52 46 52 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lm4sg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lm4sg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lm4sg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:16:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:16:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:16:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 02:16:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:172.151.104.48,StartTime:2020-09-16 02:16:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 02:16:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://60a6f23c019079a30015d7721491c2c1ce23c854b41dbc7d53e726d660740193,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.104.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:41.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5535" for this suite.

• [SLOW TEST:5.043 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":277,"completed":91,"skipped":1722,"failed":0}
SSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:41.056: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-8987
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8987
STEP: Deleting pre-stop pod
Sep 16 02:16:54.091: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:54.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8987" for this suite.

• [SLOW TEST:13.043 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":277,"completed":92,"skipped":1727,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:54.099: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Sep 16 02:16:54.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 api-versions'
Sep 16 02:16:54.281: INFO: stderr: ""
Sep 16 02:16:54.281: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:54.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5079" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":277,"completed":93,"skipped":1731,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:54.286: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-aea311aa-404d-4f73-9b1d-eb14982ad66c
STEP: Creating a pod to test consume secrets
Sep 16 02:16:54.309: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-796df32c-4739-430c-b2e1-a09fa961b694" in namespace "projected-6353" to be "Succeeded or Failed"
Sep 16 02:16:54.310: INFO: Pod "pod-projected-secrets-796df32c-4739-430c-b2e1-a09fa961b694": Phase="Pending", Reason="", readiness=false. Elapsed: 1.239477ms
Sep 16 02:16:56.312: INFO: Pod "pod-projected-secrets-796df32c-4739-430c-b2e1-a09fa961b694": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003439662s
Sep 16 02:16:58.314: INFO: Pod "pod-projected-secrets-796df32c-4739-430c-b2e1-a09fa961b694": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005879143s
STEP: Saw pod success
Sep 16 02:16:58.314: INFO: Pod "pod-projected-secrets-796df32c-4739-430c-b2e1-a09fa961b694" satisfied condition "Succeeded or Failed"
Sep 16 02:16:58.316: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-secrets-796df32c-4739-430c-b2e1-a09fa961b694 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 16 02:16:58.326: INFO: Waiting for pod pod-projected-secrets-796df32c-4739-430c-b2e1-a09fa961b694 to disappear
Sep 16 02:16:58.328: INFO: Pod pod-projected-secrets-796df32c-4739-430c-b2e1-a09fa961b694 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:16:58.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6353" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":94,"skipped":1737,"failed":0}
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:16:58.332: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 16 02:16:58.347: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:17:04.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8470" for this suite.

• [SLOW TEST:5.826 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":277,"completed":95,"skipped":1744,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:17:04.158: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:17:04.183: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 16 02:17:04.190: INFO: Number of nodes with available pods: 0
Sep 16 02:17:04.190: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:17:05.195: INFO: Number of nodes with available pods: 0
Sep 16 02:17:05.195: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:17:06.195: INFO: Number of nodes with available pods: 0
Sep 16 02:17:06.195: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:17:07.194: INFO: Number of nodes with available pods: 0
Sep 16 02:17:07.194: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:17:08.194: INFO: Number of nodes with available pods: 2
Sep 16 02:17:08.194: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 16 02:17:08.216: INFO: Wrong image for pod: daemon-set-57hkg. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:08.216: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:09.221: INFO: Wrong image for pod: daemon-set-57hkg. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:09.221: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:10.222: INFO: Wrong image for pod: daemon-set-57hkg. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:10.222: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:11.221: INFO: Wrong image for pod: daemon-set-57hkg. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:11.221: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:12.221: INFO: Wrong image for pod: daemon-set-57hkg. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:12.221: INFO: Pod daemon-set-57hkg is not available
Sep 16 02:17:12.221: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:13.222: INFO: Wrong image for pod: daemon-set-57hkg. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:13.222: INFO: Pod daemon-set-57hkg is not available
Sep 16 02:17:13.222: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:14.222: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:14.222: INFO: Pod daemon-set-624p2 is not available
Sep 16 02:17:15.222: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:15.222: INFO: Pod daemon-set-624p2 is not available
Sep 16 02:17:16.222: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:17.222: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:18.222: INFO: Wrong image for pod: daemon-set-5hzn2. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 16 02:17:18.222: INFO: Pod daemon-set-5hzn2 is not available
Sep 16 02:17:19.222: INFO: Pod daemon-set-5gh6r is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 16 02:17:19.227: INFO: Number of nodes with available pods: 1
Sep 16 02:17:19.227: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:17:20.233: INFO: Number of nodes with available pods: 1
Sep 16 02:17:20.233: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:17:21.232: INFO: Number of nodes with available pods: 2
Sep 16 02:17:21.232: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6006, will wait for the garbage collector to delete the pods
Sep 16 02:17:21.295: INFO: Deleting DaemonSet.extensions daemon-set took: 3.606208ms
Sep 16 02:17:21.696: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.190249ms
Sep 16 02:17:30.597: INFO: Number of nodes with available pods: 0
Sep 16 02:17:30.597: INFO: Number of running nodes: 0, number of available pods: 0
Sep 16 02:17:30.599: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6006/daemonsets","resourceVersion":"15438"},"items":null}

Sep 16 02:17:30.600: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6006/pods","resourceVersion":"15438"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:17:30.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6006" for this suite.

• [SLOW TEST:26.452 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":277,"completed":96,"skipped":1764,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:17:30.611: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:17:30.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2103" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":277,"completed":97,"skipped":1782,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:17:30.642: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:17:31.192: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Sep 16 02:17:33.197: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819451, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819451, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819451, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819451, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:17:36.205: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:17:36.207: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:17:37.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5478" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:6.622 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":277,"completed":98,"skipped":1796,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:17:37.265: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:17:37.286: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Sep 16 02:17:40.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-4661 create -f -'
Sep 16 02:17:43.107: INFO: stderr: ""
Sep 16 02:17:43.107: INFO: stdout: "e2e-test-crd-publish-openapi-2684-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 16 02:17:43.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-4661 delete e2e-test-crd-publish-openapi-2684-crds test-foo'
Sep 16 02:17:43.178: INFO: stderr: ""
Sep 16 02:17:43.178: INFO: stdout: "e2e-test-crd-publish-openapi-2684-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Sep 16 02:17:43.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-4661 apply -f -'
Sep 16 02:17:43.429: INFO: stderr: ""
Sep 16 02:17:43.429: INFO: stdout: "e2e-test-crd-publish-openapi-2684-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 16 02:17:43.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-4661 delete e2e-test-crd-publish-openapi-2684-crds test-foo'
Sep 16 02:17:43.502: INFO: stderr: ""
Sep 16 02:17:43.502: INFO: stdout: "e2e-test-crd-publish-openapi-2684-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Sep 16 02:17:43.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-4661 create -f -'
Sep 16 02:17:43.728: INFO: rc: 1
Sep 16 02:17:43.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-4661 apply -f -'
Sep 16 02:17:43.976: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Sep 16 02:17:43.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-4661 create -f -'
Sep 16 02:17:44.202: INFO: rc: 1
Sep 16 02:17:44.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-4661 apply -f -'
Sep 16 02:17:44.426: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Sep 16 02:17:44.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 explain e2e-test-crd-publish-openapi-2684-crds'
Sep 16 02:17:44.652: INFO: stderr: ""
Sep 16 02:17:44.652: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2684-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Sep 16 02:17:44.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 explain e2e-test-crd-publish-openapi-2684-crds.metadata'
Sep 16 02:17:44.896: INFO: stderr: ""
Sep 16 02:17:44.896: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2684-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Sep 16 02:17:44.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 explain e2e-test-crd-publish-openapi-2684-crds.spec'
Sep 16 02:17:45.107: INFO: stderr: ""
Sep 16 02:17:45.107: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2684-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Sep 16 02:17:45.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 explain e2e-test-crd-publish-openapi-2684-crds.spec.bars'
Sep 16 02:17:45.331: INFO: stderr: ""
Sep 16 02:17:45.331: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2684-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Sep 16 02:17:45.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 explain e2e-test-crd-publish-openapi-2684-crds.spec.bars2'
Sep 16 02:17:45.554: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:17:47.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4661" for this suite.

• [SLOW TEST:10.289 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":277,"completed":99,"skipped":1818,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:17:47.554: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:17:51.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5900" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":277,"completed":100,"skipped":1843,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:17:51.592: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:17:51.948: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Sep 16 02:17:53.954: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819471, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819471, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819471, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819471, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:17:56.960: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:17:56.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1809" for this suite.
STEP: Destroying namespace "webhook-1809-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.429 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":277,"completed":101,"skipped":1867,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:17:57.021: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:17:57.043: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c068cf28-d542-4053-aaa0-29bfd9879c5f" in namespace "projected-1243" to be "Succeeded or Failed"
Sep 16 02:17:57.044: INFO: Pod "downwardapi-volume-c068cf28-d542-4053-aaa0-29bfd9879c5f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.637181ms
Sep 16 02:17:59.047: INFO: Pod "downwardapi-volume-c068cf28-d542-4053-aaa0-29bfd9879c5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004082848s
Sep 16 02:18:01.050: INFO: Pod "downwardapi-volume-c068cf28-d542-4053-aaa0-29bfd9879c5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006775764s
STEP: Saw pod success
Sep 16 02:18:01.050: INFO: Pod "downwardapi-volume-c068cf28-d542-4053-aaa0-29bfd9879c5f" satisfied condition "Succeeded or Failed"
Sep 16 02:18:01.051: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-c068cf28-d542-4053-aaa0-29bfd9879c5f container client-container: <nil>
STEP: delete the pod
Sep 16 02:18:01.062: INFO: Waiting for pod downwardapi-volume-c068cf28-d542-4053-aaa0-29bfd9879c5f to disappear
Sep 16 02:18:01.064: INFO: Pod downwardapi-volume-c068cf28-d542-4053-aaa0-29bfd9879c5f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:18:01.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1243" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":102,"skipped":1879,"failed":0}
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:18:01.069: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 16 02:18:05.106: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:18:05.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8873" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":103,"skipped":1882,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:18:05.120: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:18:05.632: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 02:18:07.637: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819485, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819485, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819485, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819485, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 02:18:09.640: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819485, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819485, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819485, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819485, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:18:12.644: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:18:12.647: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6698-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:18:13.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5595" for this suite.
STEP: Destroying namespace "webhook-5595-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.630 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":277,"completed":104,"skipped":1923,"failed":0}
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:18:13.750: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-918a11d7-94df-4cb6-a22a-e50eaaad3e7a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-918a11d7-94df-4cb6-a22a-e50eaaad3e7a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:19:32.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6540" for this suite.

• [SLOW TEST:78.279 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":105,"skipped":1923,"failed":0}
SSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:19:32.029: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:19:32.044: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:19:36.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2782" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":277,"completed":106,"skipped":1927,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:19:36.161: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:19:36.179: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2145ef2-fff2-4b57-87af-bb35c5d2bb1a" in namespace "downward-api-1179" to be "Succeeded or Failed"
Sep 16 02:19:36.181: INFO: Pod "downwardapi-volume-d2145ef2-fff2-4b57-87af-bb35c5d2bb1a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.647089ms
Sep 16 02:19:38.183: INFO: Pod "downwardapi-volume-d2145ef2-fff2-4b57-87af-bb35c5d2bb1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003693901s
Sep 16 02:19:40.185: INFO: Pod "downwardapi-volume-d2145ef2-fff2-4b57-87af-bb35c5d2bb1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006026065s
STEP: Saw pod success
Sep 16 02:19:40.185: INFO: Pod "downwardapi-volume-d2145ef2-fff2-4b57-87af-bb35c5d2bb1a" satisfied condition "Succeeded or Failed"
Sep 16 02:19:40.187: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-d2145ef2-fff2-4b57-87af-bb35c5d2bb1a container client-container: <nil>
STEP: delete the pod
Sep 16 02:19:40.197: INFO: Waiting for pod downwardapi-volume-d2145ef2-fff2-4b57-87af-bb35c5d2bb1a to disappear
Sep 16 02:19:40.199: INFO: Pod downwardapi-volume-d2145ef2-fff2-4b57-87af-bb35c5d2bb1a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:19:40.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1179" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":107,"skipped":1936,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:19:40.204: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:19:53.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6140" for this suite.

• [SLOW TEST:13.051 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":277,"completed":108,"skipped":1941,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:19:53.255: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Sep 16 02:20:03.285: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0916 02:20:03.285872      26 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:20:03.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7887" for this suite.

• [SLOW TEST:10.034 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":277,"completed":109,"skipped":1954,"failed":0}
SSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:20:03.290: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-9d77a9f9-6ff0-41cd-9760-2e81ede2bced
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:20:07.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1416" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":110,"skipped":1958,"failed":0}
S
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:20:07.332: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-a05d920c-d903-42ee-8728-39887e2bd066
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:20:07.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8382" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":277,"completed":111,"skipped":1959,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:20:07.355: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:20:07.374: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f475721a-7294-4592-a1f5-7d03ac02dc8f" in namespace "projected-9470" to be "Succeeded or Failed"
Sep 16 02:20:07.375: INFO: Pod "downwardapi-volume-f475721a-7294-4592-a1f5-7d03ac02dc8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.315897ms
Sep 16 02:20:09.378: INFO: Pod "downwardapi-volume-f475721a-7294-4592-a1f5-7d03ac02dc8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003703747s
Sep 16 02:20:11.380: INFO: Pod "downwardapi-volume-f475721a-7294-4592-a1f5-7d03ac02dc8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005974459s
STEP: Saw pod success
Sep 16 02:20:11.380: INFO: Pod "downwardapi-volume-f475721a-7294-4592-a1f5-7d03ac02dc8f" satisfied condition "Succeeded or Failed"
Sep 16 02:20:11.381: INFO: Trying to get logs from node 192.168.4.86 pod downwardapi-volume-f475721a-7294-4592-a1f5-7d03ac02dc8f container client-container: <nil>
STEP: delete the pod
Sep 16 02:20:11.395: INFO: Waiting for pod downwardapi-volume-f475721a-7294-4592-a1f5-7d03ac02dc8f to disappear
Sep 16 02:20:11.397: INFO: Pod downwardapi-volume-f475721a-7294-4592-a1f5-7d03ac02dc8f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:20:11.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9470" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":112,"skipped":1967,"failed":0}
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:20:11.401: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-8275
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 16 02:20:11.419: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 16 02:20:11.431: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:20:13.433: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:20:15.432: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:20:17.432: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:20:19.432: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:20:21.433: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:20:23.433: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:20:25.433: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:20:27.433: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:20:29.433: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 16 02:20:29.436: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 16 02:20:33.446: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.151.104.9:8080/dial?request=hostname&protocol=http&host=172.151.166.191&port=8080&tries=1'] Namespace:pod-network-test-8275 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:20:33.446: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:20:33.559: INFO: Waiting for responses: map[]
Sep 16 02:20:33.561: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.151.104.9:8080/dial?request=hostname&protocol=http&host=172.151.104.8&port=8080&tries=1'] Namespace:pod-network-test-8275 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:20:33.561: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:20:33.669: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:20:33.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8275" for this suite.

• [SLOW TEST:22.274 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":277,"completed":113,"skipped":1968,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:20:33.675: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:20:33.693: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:20:37.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4090" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":277,"completed":114,"skipped":1970,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:20:37.720: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:20:37.739: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:20:39.742: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:20:41.741: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:20:43.741: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Running (Ready = false)
Sep 16 02:20:45.741: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Running (Ready = false)
Sep 16 02:20:47.742: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Running (Ready = false)
Sep 16 02:20:49.742: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Running (Ready = false)
Sep 16 02:20:51.741: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Running (Ready = false)
Sep 16 02:20:53.742: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Running (Ready = false)
Sep 16 02:20:55.742: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Running (Ready = false)
Sep 16 02:20:57.741: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Running (Ready = false)
Sep 16 02:20:59.741: INFO: The status of Pod test-webserver-af8ec5a6-4f35-4203-b1ec-0ab34e7f3b10 is Running (Ready = true)
Sep 16 02:20:59.743: INFO: Container started at 2020-09-16 02:20:41 +0000 UTC, pod became ready at 2020-09-16 02:20:57 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:20:59.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4664" for this suite.

• [SLOW TEST:22.028 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":277,"completed":115,"skipped":1991,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:20:59.747: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Sep 16 02:21:03.772: INFO: Pod pod-hostip-78254965-39f2-4e8f-ad6b-0a5ff599e0b2 has hostIP: 192.168.4.86
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:21:03.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2422" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":277,"completed":116,"skipped":2006,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:21:03.777: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:21:03.798: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37caa380-992d-4d09-b871-87fb00fc08a0" in namespace "projected-5841" to be "Succeeded or Failed"
Sep 16 02:21:03.799: INFO: Pod "downwardapi-volume-37caa380-992d-4d09-b871-87fb00fc08a0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.545508ms
Sep 16 02:21:05.802: INFO: Pod "downwardapi-volume-37caa380-992d-4d09-b871-87fb00fc08a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003959522s
Sep 16 02:21:07.804: INFO: Pod "downwardapi-volume-37caa380-992d-4d09-b871-87fb00fc08a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006402145s
STEP: Saw pod success
Sep 16 02:21:07.804: INFO: Pod "downwardapi-volume-37caa380-992d-4d09-b871-87fb00fc08a0" satisfied condition "Succeeded or Failed"
Sep 16 02:21:07.806: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-37caa380-992d-4d09-b871-87fb00fc08a0 container client-container: <nil>
STEP: delete the pod
Sep 16 02:21:07.816: INFO: Waiting for pod downwardapi-volume-37caa380-992d-4d09-b871-87fb00fc08a0 to disappear
Sep 16 02:21:07.817: INFO: Pod downwardapi-volume-37caa380-992d-4d09-b871-87fb00fc08a0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:21:07.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5841" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":117,"skipped":2117,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:21:07.821: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-86caabf1-1f94-4d1b-8f70-5dcda791fd33
STEP: Creating a pod to test consume secrets
Sep 16 02:21:07.842: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8182f238-a816-4386-88bf-18339518e319" in namespace "projected-2755" to be "Succeeded or Failed"
Sep 16 02:21:07.843: INFO: Pod "pod-projected-secrets-8182f238-a816-4386-88bf-18339518e319": Phase="Pending", Reason="", readiness=false. Elapsed: 1.291665ms
Sep 16 02:21:09.845: INFO: Pod "pod-projected-secrets-8182f238-a816-4386-88bf-18339518e319": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003059227s
Sep 16 02:21:11.847: INFO: Pod "pod-projected-secrets-8182f238-a816-4386-88bf-18339518e319": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005121779s
STEP: Saw pod success
Sep 16 02:21:11.847: INFO: Pod "pod-projected-secrets-8182f238-a816-4386-88bf-18339518e319" satisfied condition "Succeeded or Failed"
Sep 16 02:21:11.848: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-secrets-8182f238-a816-4386-88bf-18339518e319 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 16 02:21:11.857: INFO: Waiting for pod pod-projected-secrets-8182f238-a816-4386-88bf-18339518e319 to disappear
Sep 16 02:21:11.858: INFO: Pod pod-projected-secrets-8182f238-a816-4386-88bf-18339518e319 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:21:11.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2755" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":118,"skipped":2118,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:21:11.862: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:21:11.880: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50d0e526-4e9f-464e-968b-689c3e088ff1" in namespace "projected-5319" to be "Succeeded or Failed"
Sep 16 02:21:11.881: INFO: Pod "downwardapi-volume-50d0e526-4e9f-464e-968b-689c3e088ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.296302ms
Sep 16 02:21:13.883: INFO: Pod "downwardapi-volume-50d0e526-4e9f-464e-968b-689c3e088ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002951585s
Sep 16 02:21:15.885: INFO: Pod "downwardapi-volume-50d0e526-4e9f-464e-968b-689c3e088ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005255083s
STEP: Saw pod success
Sep 16 02:21:15.885: INFO: Pod "downwardapi-volume-50d0e526-4e9f-464e-968b-689c3e088ff1" satisfied condition "Succeeded or Failed"
Sep 16 02:21:15.887: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-50d0e526-4e9f-464e-968b-689c3e088ff1 container client-container: <nil>
STEP: delete the pod
Sep 16 02:21:15.896: INFO: Waiting for pod downwardapi-volume-50d0e526-4e9f-464e-968b-689c3e088ff1 to disappear
Sep 16 02:21:15.897: INFO: Pod downwardapi-volume-50d0e526-4e9f-464e-968b-689c3e088ff1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:21:15.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5319" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":277,"completed":119,"skipped":2120,"failed":0}

------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:21:15.901: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Sep 16 02:21:15.917: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:21:32.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2365" for this suite.

• [SLOW TEST:16.381 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":277,"completed":120,"skipped":2120,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:21:32.283: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-1e9a4028-673e-4c13-8974-8fa516641eba
STEP: Creating a pod to test consume secrets
Sep 16 02:21:32.304: INFO: Waiting up to 5m0s for pod "pod-secrets-4cc5f029-93d1-4dad-8292-4c6d63bf6819" in namespace "secrets-2733" to be "Succeeded or Failed"
Sep 16 02:21:32.306: INFO: Pod "pod-secrets-4cc5f029-93d1-4dad-8292-4c6d63bf6819": Phase="Pending", Reason="", readiness=false. Elapsed: 1.525836ms
Sep 16 02:21:34.308: INFO: Pod "pod-secrets-4cc5f029-93d1-4dad-8292-4c6d63bf6819": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003853951s
Sep 16 02:21:36.311: INFO: Pod "pod-secrets-4cc5f029-93d1-4dad-8292-4c6d63bf6819": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006162394s
STEP: Saw pod success
Sep 16 02:21:36.311: INFO: Pod "pod-secrets-4cc5f029-93d1-4dad-8292-4c6d63bf6819" satisfied condition "Succeeded or Failed"
Sep 16 02:21:36.312: INFO: Trying to get logs from node 192.168.4.87 pod pod-secrets-4cc5f029-93d1-4dad-8292-4c6d63bf6819 container secret-volume-test: <nil>
STEP: delete the pod
Sep 16 02:21:36.321: INFO: Waiting for pod pod-secrets-4cc5f029-93d1-4dad-8292-4c6d63bf6819 to disappear
Sep 16 02:21:36.323: INFO: Pod pod-secrets-4cc5f029-93d1-4dad-8292-4c6d63bf6819 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:21:36.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2733" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":121,"skipped":2125,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:21:36.327: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 16 02:21:36.346: INFO: Waiting up to 5m0s for pod "pod-b2a87e70-6ba7-4dc8-a42a-3375fd7b2856" in namespace "emptydir-3994" to be "Succeeded or Failed"
Sep 16 02:21:36.347: INFO: Pod "pod-b2a87e70-6ba7-4dc8-a42a-3375fd7b2856": Phase="Pending", Reason="", readiness=false. Elapsed: 1.182229ms
Sep 16 02:21:38.349: INFO: Pod "pod-b2a87e70-6ba7-4dc8-a42a-3375fd7b2856": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003235204s
Sep 16 02:21:40.351: INFO: Pod "pod-b2a87e70-6ba7-4dc8-a42a-3375fd7b2856": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005432497s
STEP: Saw pod success
Sep 16 02:21:40.351: INFO: Pod "pod-b2a87e70-6ba7-4dc8-a42a-3375fd7b2856" satisfied condition "Succeeded or Failed"
Sep 16 02:21:40.353: INFO: Trying to get logs from node 192.168.4.87 pod pod-b2a87e70-6ba7-4dc8-a42a-3375fd7b2856 container test-container: <nil>
STEP: delete the pod
Sep 16 02:21:40.362: INFO: Waiting for pod pod-b2a87e70-6ba7-4dc8-a42a-3375fd7b2856 to disappear
Sep 16 02:21:40.363: INFO: Pod pod-b2a87e70-6ba7-4dc8-a42a-3375fd7b2856 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:21:40.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3994" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":122,"skipped":2130,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:21:40.368: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-3197
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 16 02:21:40.382: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 16 02:21:40.393: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:21:42.395: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:21:44.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:21:46.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:21:48.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:21:50.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:21:52.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:21:54.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:21:56.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:21:58.395: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 16 02:22:00.395: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 16 02:22:00.398: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 16 02:22:04.410: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.151.104.20:8080/dial?request=hostname&protocol=udp&host=172.151.166.134&port=8081&tries=1'] Namespace:pod-network-test-3197 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:22:04.410: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:22:04.510: INFO: Waiting for responses: map[]
Sep 16 02:22:04.512: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.151.104.20:8080/dial?request=hostname&protocol=udp&host=172.151.104.22&port=8081&tries=1'] Namespace:pod-network-test-3197 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:22:04.512: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:22:04.616: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:22:04.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3197" for this suite.

• [SLOW TEST:24.253 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":277,"completed":123,"skipped":2147,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:22:04.621: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:22:05.078: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 02:22:07.084: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819725, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819725, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819725, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735819725, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:22:10.091: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Sep 16 02:22:10.103: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:22:10.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7513" for this suite.
STEP: Destroying namespace "webhook-7513-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.511 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":277,"completed":124,"skipped":2157,"failed":0}
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:22:10.133: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 16 02:22:14.164: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:22:14.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1460" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":125,"skipped":2162,"failed":0}

------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:22:14.174: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:23:14.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4" for this suite.

• [SLOW TEST:60.027 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":277,"completed":126,"skipped":2162,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:23:14.201: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-9563
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-9563
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9563
Sep 16 02:23:14.222: INFO: Found 0 stateful pods, waiting for 1
Sep 16 02:23:24.225: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 16 02:23:24.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:23:24.441: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:23:24.441: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:23:24.441: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 16 02:23:24.443: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 16 02:23:34.446: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 16 02:23:34.446: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 02:23:34.453: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:23:34.453: INFO: ss-0  192.168.4.87  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:23:34.453: INFO: 
Sep 16 02:23:34.453: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 16 02:23:35.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998280446s
Sep 16 02:23:36.458: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.996275953s
Sep 16 02:23:37.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.993407828s
Sep 16 02:23:38.463: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.990969006s
Sep 16 02:23:39.466: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.988601787s
Sep 16 02:23:40.468: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.985950519s
Sep 16 02:23:41.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.983302098s
Sep 16 02:23:42.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.980390094s
Sep 16 02:23:43.477: INFO: Verifying statefulset ss doesn't scale past 3 for another 977.567935ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9563
Sep 16 02:23:44.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:23:44.649: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 16 02:23:44.649: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 16 02:23:44.649: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 16 02:23:44.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:23:44.825: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 16 02:23:44.825: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 16 02:23:44.825: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 16 02:23:44.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:23:44.995: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 16 02:23:44.995: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 16 02:23:44.995: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 16 02:23:44.997: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:23:44.997: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:23:44.997: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 16 02:23:44.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:23:45.163: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:23:45.163: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:23:45.163: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 16 02:23:45.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:23:45.374: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:23:45.374: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:23:45.374: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 16 02:23:45.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:23:45.570: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:23:45.570: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:23:45.570: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 16 02:23:45.570: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 02:23:45.572: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 16 02:23:55.576: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 16 02:23:55.576: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 16 02:23:55.576: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 16 02:23:55.582: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:23:55.582: INFO: ss-0  192.168.4.87  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:23:55.582: INFO: ss-1  192.168.4.86  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:23:55.582: INFO: ss-2  192.168.4.87  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:23:55.582: INFO: 
Sep 16 02:23:55.582: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 16 02:23:56.585: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:23:56.585: INFO: ss-0  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:23:56.585: INFO: ss-1  192.168.4.86  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:23:56.585: INFO: ss-2  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:23:56.585: INFO: 
Sep 16 02:23:56.585: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 16 02:23:57.588: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:23:57.588: INFO: ss-0  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:23:57.588: INFO: ss-1  192.168.4.86  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:23:57.588: INFO: ss-2  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:23:57.588: INFO: 
Sep 16 02:23:57.588: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 16 02:23:58.591: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:23:58.591: INFO: ss-0  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:23:58.591: INFO: ss-1  192.168.4.86  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:23:58.591: INFO: ss-2  192.168.4.87  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:23:58.591: INFO: 
Sep 16 02:23:58.591: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 16 02:23:59.594: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:23:59.594: INFO: ss-0  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:23:59.594: INFO: ss-2  192.168.4.87  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:23:59.594: INFO: 
Sep 16 02:23:59.594: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 16 02:24:00.597: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:24:00.597: INFO: ss-0  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:24:00.597: INFO: ss-2  192.168.4.87  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:24:00.597: INFO: 
Sep 16 02:24:00.597: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 16 02:24:01.600: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:24:01.600: INFO: ss-0  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:24:01.600: INFO: ss-2  192.168.4.87  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:24:01.600: INFO: 
Sep 16 02:24:01.600: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 16 02:24:02.602: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:24:02.602: INFO: ss-0  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:24:02.603: INFO: ss-2  192.168.4.87  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:24:02.603: INFO: 
Sep 16 02:24:02.603: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 16 02:24:03.605: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:24:03.605: INFO: ss-0  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:24:03.605: INFO: ss-2  192.168.4.87  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:24:03.605: INFO: 
Sep 16 02:24:03.605: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 16 02:24:04.608: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Sep 16 02:24:04.608: INFO: ss-0  192.168.4.87  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:14 +0000 UTC  }]
Sep 16 02:24:04.608: INFO: ss-2  192.168.4.87  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-16 02:23:34 +0000 UTC  }]
Sep 16 02:24:04.608: INFO: 
Sep 16 02:24:04.608: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9563
Sep 16 02:24:05.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:24:05.704: INFO: rc: 1
Sep 16 02:24:05.704: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Sep 16 02:24:15.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:24:15.777: INFO: rc: 1
Sep 16 02:24:15.777: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:24:25.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:24:25.847: INFO: rc: 1
Sep 16 02:24:25.847: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:24:35.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:24:35.917: INFO: rc: 1
Sep 16 02:24:35.917: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:24:45.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:24:45.988: INFO: rc: 1
Sep 16 02:24:45.988: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:24:55.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:24:56.062: INFO: rc: 1
Sep 16 02:24:56.062: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:25:06.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:25:06.132: INFO: rc: 1
Sep 16 02:25:06.132: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:25:16.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:25:16.204: INFO: rc: 1
Sep 16 02:25:16.204: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:25:26.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:25:26.278: INFO: rc: 1
Sep 16 02:25:26.278: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:25:36.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:25:36.352: INFO: rc: 1
Sep 16 02:25:36.352: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:25:46.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:25:46.422: INFO: rc: 1
Sep 16 02:25:46.422: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:25:56.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:25:56.500: INFO: rc: 1
Sep 16 02:25:56.500: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:26:06.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:26:06.570: INFO: rc: 1
Sep 16 02:26:06.570: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:26:16.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:26:16.640: INFO: rc: 1
Sep 16 02:26:16.640: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:26:26.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:26:26.710: INFO: rc: 1
Sep 16 02:26:26.710: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:26:36.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:26:36.779: INFO: rc: 1
Sep 16 02:26:36.779: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:26:46.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:26:46.854: INFO: rc: 1
Sep 16 02:26:46.854: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:26:56.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:26:56.932: INFO: rc: 1
Sep 16 02:26:56.932: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:27:06.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:27:07.002: INFO: rc: 1
Sep 16 02:27:07.002: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:27:17.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:27:17.075: INFO: rc: 1
Sep 16 02:27:17.075: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:27:27.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:27:27.155: INFO: rc: 1
Sep 16 02:27:27.155: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:27:37.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:27:37.226: INFO: rc: 1
Sep 16 02:27:37.226: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:27:47.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:27:49.045: INFO: rc: 1
Sep 16 02:27:49.045: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:27:59.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:27:59.118: INFO: rc: 1
Sep 16 02:27:59.118: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:28:09.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:28:09.189: INFO: rc: 1
Sep 16 02:28:09.189: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:28:19.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:28:19.259: INFO: rc: 1
Sep 16 02:28:19.259: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:28:29.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:28:29.329: INFO: rc: 1
Sep 16 02:28:29.329: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:28:39.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:28:39.398: INFO: rc: 1
Sep 16 02:28:39.398: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:28:49.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:28:49.469: INFO: rc: 1
Sep 16 02:28:49.470: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:28:59.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:28:59.540: INFO: rc: 1
Sep 16 02:28:59.540: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 16 02:29:09.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-9563 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:29:09.614: INFO: rc: 1
Sep 16 02:29:09.614: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Sep 16 02:29:09.614: INFO: Scaling statefulset ss to 0
Sep 16 02:29:09.620: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 16 02:29:09.621: INFO: Deleting all statefulset in ns statefulset-9563
Sep 16 02:29:09.622: INFO: Scaling statefulset ss to 0
Sep 16 02:29:09.627: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 02:29:09.628: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:29:09.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9563" for this suite.

• [SLOW TEST:355.439 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":277,"completed":127,"skipped":2180,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:29:09.640: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-5737cd2a-af3a-4b93-95d8-bf4d71e6c828
STEP: Creating a pod to test consume secrets
Sep 16 02:29:09.661: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-38f7cb59-95ab-4e7e-9efd-9bfe876b5b80" in namespace "projected-844" to be "Succeeded or Failed"
Sep 16 02:29:09.662: INFO: Pod "pod-projected-secrets-38f7cb59-95ab-4e7e-9efd-9bfe876b5b80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.311846ms
Sep 16 02:29:11.665: INFO: Pod "pod-projected-secrets-38f7cb59-95ab-4e7e-9efd-9bfe876b5b80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003737163s
Sep 16 02:29:13.667: INFO: Pod "pod-projected-secrets-38f7cb59-95ab-4e7e-9efd-9bfe876b5b80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006252744s
STEP: Saw pod success
Sep 16 02:29:13.667: INFO: Pod "pod-projected-secrets-38f7cb59-95ab-4e7e-9efd-9bfe876b5b80" satisfied condition "Succeeded or Failed"
Sep 16 02:29:13.669: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-secrets-38f7cb59-95ab-4e7e-9efd-9bfe876b5b80 container secret-volume-test: <nil>
STEP: delete the pod
Sep 16 02:29:13.684: INFO: Waiting for pod pod-projected-secrets-38f7cb59-95ab-4e7e-9efd-9bfe876b5b80 to disappear
Sep 16 02:29:13.686: INFO: Pod pod-projected-secrets-38f7cb59-95ab-4e7e-9efd-9bfe876b5b80 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:29:13.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-844" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":128,"skipped":2189,"failed":0}
SSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:29:13.691: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 16 02:29:13.709: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 16 02:29:18.711: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:29:19.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3338" for this suite.

• [SLOW TEST:6.033 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":277,"completed":129,"skipped":2193,"failed":0}
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:29:19.724: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:29:25.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2008" for this suite.
STEP: Destroying namespace "nsdeletetest-5884" for this suite.
Sep 16 02:29:25.788: INFO: Namespace nsdeletetest-5884 was already deleted
STEP: Destroying namespace "nsdeletetest-682" for this suite.

• [SLOW TEST:6.066 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":277,"completed":130,"skipped":2195,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:29:25.790: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 16 02:29:35.821: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:35.821: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:35.912: INFO: Exec stderr: ""
Sep 16 02:29:35.912: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:35.912: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:36.003: INFO: Exec stderr: ""
Sep 16 02:29:36.003: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:36.003: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:36.111: INFO: Exec stderr: ""
Sep 16 02:29:36.111: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:36.111: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:36.207: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 16 02:29:36.207: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:36.207: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:36.299: INFO: Exec stderr: ""
Sep 16 02:29:36.299: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:36.299: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:36.386: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 16 02:29:36.386: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:36.386: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:36.477: INFO: Exec stderr: ""
Sep 16 02:29:36.477: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:36.477: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:36.569: INFO: Exec stderr: ""
Sep 16 02:29:36.569: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:36.569: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:36.674: INFO: Exec stderr: ""
Sep 16 02:29:36.674: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4221 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:29:36.674: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:29:36.771: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:29:36.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4221" for this suite.

• [SLOW TEST:10.986 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":131,"skipped":2220,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:29:36.777: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:29:40.813: INFO: Waiting up to 5m0s for pod "client-envvars-6b14760a-f790-458d-982a-2dea5a5f9e60" in namespace "pods-9883" to be "Succeeded or Failed"
Sep 16 02:29:40.815: INFO: Pod "client-envvars-6b14760a-f790-458d-982a-2dea5a5f9e60": Phase="Pending", Reason="", readiness=false. Elapsed: 1.755882ms
Sep 16 02:29:42.817: INFO: Pod "client-envvars-6b14760a-f790-458d-982a-2dea5a5f9e60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004235051s
Sep 16 02:29:44.819: INFO: Pod "client-envvars-6b14760a-f790-458d-982a-2dea5a5f9e60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006508094s
STEP: Saw pod success
Sep 16 02:29:44.819: INFO: Pod "client-envvars-6b14760a-f790-458d-982a-2dea5a5f9e60" satisfied condition "Succeeded or Failed"
Sep 16 02:29:44.821: INFO: Trying to get logs from node 192.168.4.86 pod client-envvars-6b14760a-f790-458d-982a-2dea5a5f9e60 container env3cont: <nil>
STEP: delete the pod
Sep 16 02:29:44.835: INFO: Waiting for pod client-envvars-6b14760a-f790-458d-982a-2dea5a5f9e60 to disappear
Sep 16 02:29:44.837: INFO: Pod client-envvars-6b14760a-f790-458d-982a-2dea5a5f9e60 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:29:44.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9883" for this suite.

• [SLOW TEST:8.067 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":277,"completed":132,"skipped":2306,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:29:44.845: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:29:45.320: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 02:29:47.325: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820185, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820185, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820185, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820185, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:29:50.331: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:30:00.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9673" for this suite.
STEP: Destroying namespace "webhook-9673-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.628 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":277,"completed":133,"skipped":2349,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:30:00.473: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:30:00.490: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9850
I0916 02:30:00.501051      26 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9850, replica count: 1
I0916 02:30:01.551386      26 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0916 02:30:02.551565      26 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0916 02:30:03.551717      26 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 16 02:30:03.656: INFO: Created: latency-svc-hdzqj
Sep 16 02:30:03.659: INFO: Got endpoints: latency-svc-hdzqj [7.39158ms]
Sep 16 02:30:03.663: INFO: Created: latency-svc-dnd67
Sep 16 02:30:03.665: INFO: Got endpoints: latency-svc-dnd67 [6.017827ms]
Sep 16 02:30:03.666: INFO: Created: latency-svc-d9lfw
Sep 16 02:30:03.668: INFO: Got endpoints: latency-svc-d9lfw [8.452289ms]
Sep 16 02:30:03.668: INFO: Created: latency-svc-hwc7z
Sep 16 02:30:03.669: INFO: Created: latency-svc-22qm4
Sep 16 02:30:03.669: INFO: Got endpoints: latency-svc-hwc7z [10.571899ms]
Sep 16 02:30:03.671: INFO: Created: latency-svc-jpvj5
Sep 16 02:30:03.672: INFO: Got endpoints: latency-svc-22qm4 [12.658708ms]
Sep 16 02:30:03.673: INFO: Created: latency-svc-g4h2g
Sep 16 02:30:03.673: INFO: Got endpoints: latency-svc-jpvj5 [14.023959ms]
Sep 16 02:30:03.675: INFO: Created: latency-svc-g5rt6
Sep 16 02:30:03.675: INFO: Got endpoints: latency-svc-g4h2g [15.814314ms]
Sep 16 02:30:03.678: INFO: Created: latency-svc-nfj5x
Sep 16 02:30:03.678: INFO: Got endpoints: latency-svc-g5rt6 [19.018149ms]
Sep 16 02:30:03.679: INFO: Created: latency-svc-wpwlb
Sep 16 02:30:03.681: INFO: Created: latency-svc-fzz8t
Sep 16 02:30:03.681: INFO: Got endpoints: latency-svc-nfj5x [22.238653ms]
Sep 16 02:30:03.681: INFO: Got endpoints: latency-svc-wpwlb [22.227595ms]
Sep 16 02:30:03.683: INFO: Got endpoints: latency-svc-fzz8t [23.676284ms]
Sep 16 02:30:03.684: INFO: Created: latency-svc-679qd
Sep 16 02:30:03.686: INFO: Got endpoints: latency-svc-679qd [26.511383ms]
Sep 16 02:30:03.686: INFO: Created: latency-svc-j8rxj
Sep 16 02:30:03.687: INFO: Created: latency-svc-xqrfs
Sep 16 02:30:03.688: INFO: Got endpoints: latency-svc-j8rxj [28.467581ms]
Sep 16 02:30:03.689: INFO: Created: latency-svc-lvqjj
Sep 16 02:30:03.689: INFO: Got endpoints: latency-svc-xqrfs [29.950552ms]
Sep 16 02:30:03.691: INFO: Got endpoints: latency-svc-lvqjj [31.596679ms]
Sep 16 02:30:03.692: INFO: Created: latency-svc-4jv4l
Sep 16 02:30:03.693: INFO: Got endpoints: latency-svc-4jv4l [33.615641ms]
Sep 16 02:30:03.693: INFO: Created: latency-svc-vjgcp
Sep 16 02:30:03.695: INFO: Created: latency-svc-s59tl
Sep 16 02:30:03.696: INFO: Got endpoints: latency-svc-vjgcp [31.053177ms]
Sep 16 02:30:03.698: INFO: Created: latency-svc-tlc4q
Sep 16 02:30:03.698: INFO: Got endpoints: latency-svc-s59tl [30.459373ms]
Sep 16 02:30:03.699: INFO: Created: latency-svc-vqdd6
Sep 16 02:30:03.700: INFO: Got endpoints: latency-svc-tlc4q [30.241751ms]
Sep 16 02:30:03.701: INFO: Got endpoints: latency-svc-vqdd6 [29.348724ms]
Sep 16 02:30:03.701: INFO: Created: latency-svc-kbdvc
Sep 16 02:30:03.703: INFO: Created: latency-svc-x5zkq
Sep 16 02:30:03.703: INFO: Got endpoints: latency-svc-kbdvc [29.824044ms]
Sep 16 02:30:03.704: INFO: Got endpoints: latency-svc-x5zkq [29.47683ms]
Sep 16 02:30:03.705: INFO: Created: latency-svc-8sb4l
Sep 16 02:30:03.707: INFO: Got endpoints: latency-svc-8sb4l [28.777684ms]
Sep 16 02:30:03.708: INFO: Created: latency-svc-ngzdl
Sep 16 02:30:03.709: INFO: Created: latency-svc-z6tkt
Sep 16 02:30:03.709: INFO: Got endpoints: latency-svc-ngzdl [27.780644ms]
Sep 16 02:30:03.710: INFO: Got endpoints: latency-svc-z6tkt [29.005045ms]
Sep 16 02:30:03.712: INFO: Created: latency-svc-m5d4x
Sep 16 02:30:03.713: INFO: Created: latency-svc-t2gqk
Sep 16 02:30:03.713: INFO: Got endpoints: latency-svc-m5d4x [30.623975ms]
Sep 16 02:30:03.715: INFO: Created: latency-svc-v4px5
Sep 16 02:30:03.715: INFO: Got endpoints: latency-svc-t2gqk [29.585395ms]
Sep 16 02:30:03.716: INFO: Created: latency-svc-d7q8x
Sep 16 02:30:03.717: INFO: Got endpoints: latency-svc-v4px5 [29.348527ms]
Sep 16 02:30:03.719: INFO: Got endpoints: latency-svc-d7q8x [29.508239ms]
Sep 16 02:30:03.719: INFO: Created: latency-svc-q65sv
Sep 16 02:30:03.720: INFO: Got endpoints: latency-svc-q65sv [29.058903ms]
Sep 16 02:30:03.720: INFO: Created: latency-svc-d7vms
Sep 16 02:30:03.722: INFO: Got endpoints: latency-svc-d7vms [29.122658ms]
Sep 16 02:30:03.722: INFO: Created: latency-svc-hm5vm
Sep 16 02:30:03.723: INFO: Created: latency-svc-2gj7h
Sep 16 02:30:03.725: INFO: Created: latency-svc-8dr5g
Sep 16 02:30:03.726: INFO: Created: latency-svc-wgd22
Sep 16 02:30:03.728: INFO: Created: latency-svc-7jq2f
Sep 16 02:30:03.729: INFO: Created: latency-svc-lfhx4
Sep 16 02:30:03.730: INFO: Created: latency-svc-n77sw
Sep 16 02:30:03.732: INFO: Created: latency-svc-29xxl
Sep 16 02:30:03.733: INFO: Created: latency-svc-vmqhg
Sep 16 02:30:03.736: INFO: Created: latency-svc-vlv6q
Sep 16 02:30:03.737: INFO: Created: latency-svc-w59j4
Sep 16 02:30:03.739: INFO: Created: latency-svc-hjnhg
Sep 16 02:30:03.740: INFO: Created: latency-svc-jlb6r
Sep 16 02:30:03.741: INFO: Created: latency-svc-95gcj
Sep 16 02:30:03.743: INFO: Created: latency-svc-tbj5j
Sep 16 02:30:03.758: INFO: Got endpoints: latency-svc-hm5vm [61.742426ms]
Sep 16 02:30:03.761: INFO: Created: latency-svc-nc5qn
Sep 16 02:30:03.808: INFO: Got endpoints: latency-svc-2gj7h [110.248844ms]
Sep 16 02:30:03.812: INFO: Created: latency-svc-ng9tk
Sep 16 02:30:03.859: INFO: Got endpoints: latency-svc-8dr5g [158.866049ms]
Sep 16 02:30:03.863: INFO: Created: latency-svc-wfgff
Sep 16 02:30:03.908: INFO: Got endpoints: latency-svc-wgd22 [207.514595ms]
Sep 16 02:30:03.912: INFO: Created: latency-svc-hksp9
Sep 16 02:30:03.958: INFO: Got endpoints: latency-svc-7jq2f [255.469494ms]
Sep 16 02:30:03.963: INFO: Created: latency-svc-klrjx
Sep 16 02:30:04.009: INFO: Got endpoints: latency-svc-lfhx4 [304.230491ms]
Sep 16 02:30:04.015: INFO: Created: latency-svc-gznbm
Sep 16 02:30:04.059: INFO: Got endpoints: latency-svc-n77sw [351.687732ms]
Sep 16 02:30:04.063: INFO: Created: latency-svc-h7686
Sep 16 02:30:04.109: INFO: Got endpoints: latency-svc-29xxl [399.427914ms]
Sep 16 02:30:04.113: INFO: Created: latency-svc-wxqwg
Sep 16 02:30:04.159: INFO: Got endpoints: latency-svc-vmqhg [448.216556ms]
Sep 16 02:30:04.163: INFO: Created: latency-svc-bw2zp
Sep 16 02:30:04.209: INFO: Got endpoints: latency-svc-vlv6q [495.27897ms]
Sep 16 02:30:04.213: INFO: Created: latency-svc-n2hqs
Sep 16 02:30:04.259: INFO: Got endpoints: latency-svc-w59j4 [543.390687ms]
Sep 16 02:30:04.263: INFO: Created: latency-svc-f4qtk
Sep 16 02:30:04.309: INFO: Got endpoints: latency-svc-hjnhg [591.589666ms]
Sep 16 02:30:04.313: INFO: Created: latency-svc-dj4v6
Sep 16 02:30:04.358: INFO: Got endpoints: latency-svc-jlb6r [639.72141ms]
Sep 16 02:30:04.363: INFO: Created: latency-svc-wx4dg
Sep 16 02:30:04.408: INFO: Got endpoints: latency-svc-95gcj [688.382824ms]
Sep 16 02:30:04.413: INFO: Created: latency-svc-z259w
Sep 16 02:30:04.459: INFO: Got endpoints: latency-svc-tbj5j [736.984683ms]
Sep 16 02:30:04.463: INFO: Created: latency-svc-b899f
Sep 16 02:30:04.509: INFO: Got endpoints: latency-svc-nc5qn [750.818329ms]
Sep 16 02:30:04.513: INFO: Created: latency-svc-m7gx8
Sep 16 02:30:04.559: INFO: Got endpoints: latency-svc-ng9tk [750.306327ms]
Sep 16 02:30:04.562: INFO: Created: latency-svc-9s79q
Sep 16 02:30:04.609: INFO: Got endpoints: latency-svc-wfgff [750.342421ms]
Sep 16 02:30:04.614: INFO: Created: latency-svc-dnlxx
Sep 16 02:30:04.659: INFO: Got endpoints: latency-svc-hksp9 [750.347491ms]
Sep 16 02:30:04.663: INFO: Created: latency-svc-g5g2g
Sep 16 02:30:04.709: INFO: Got endpoints: latency-svc-klrjx [750.563556ms]
Sep 16 02:30:04.714: INFO: Created: latency-svc-5djfl
Sep 16 02:30:04.759: INFO: Got endpoints: latency-svc-gznbm [750.03822ms]
Sep 16 02:30:04.763: INFO: Created: latency-svc-nvtg4
Sep 16 02:30:04.809: INFO: Got endpoints: latency-svc-h7686 [750.233983ms]
Sep 16 02:30:04.813: INFO: Created: latency-svc-ch784
Sep 16 02:30:04.859: INFO: Got endpoints: latency-svc-wxqwg [750.829866ms]
Sep 16 02:30:04.864: INFO: Created: latency-svc-d648z
Sep 16 02:30:04.909: INFO: Got endpoints: latency-svc-bw2zp [750.224229ms]
Sep 16 02:30:04.913: INFO: Created: latency-svc-pbh22
Sep 16 02:30:04.959: INFO: Got endpoints: latency-svc-n2hqs [749.891136ms]
Sep 16 02:30:04.963: INFO: Created: latency-svc-ghtvt
Sep 16 02:30:05.009: INFO: Got endpoints: latency-svc-f4qtk [750.050407ms]
Sep 16 02:30:05.013: INFO: Created: latency-svc-dxjkq
Sep 16 02:30:05.058: INFO: Got endpoints: latency-svc-dj4v6 [749.927435ms]
Sep 16 02:30:05.062: INFO: Created: latency-svc-926cz
Sep 16 02:30:05.109: INFO: Got endpoints: latency-svc-wx4dg [750.41287ms]
Sep 16 02:30:05.113: INFO: Created: latency-svc-kdrfw
Sep 16 02:30:05.159: INFO: Got endpoints: latency-svc-z259w [750.328622ms]
Sep 16 02:30:05.162: INFO: Created: latency-svc-wrtm7
Sep 16 02:30:05.208: INFO: Got endpoints: latency-svc-b899f [749.640723ms]
Sep 16 02:30:05.212: INFO: Created: latency-svc-qfhp5
Sep 16 02:30:05.258: INFO: Got endpoints: latency-svc-m7gx8 [749.761236ms]
Sep 16 02:30:05.262: INFO: Created: latency-svc-8msbt
Sep 16 02:30:05.308: INFO: Got endpoints: latency-svc-9s79q [749.351712ms]
Sep 16 02:30:05.312: INFO: Created: latency-svc-mrxnc
Sep 16 02:30:05.358: INFO: Got endpoints: latency-svc-dnlxx [749.113023ms]
Sep 16 02:30:05.362: INFO: Created: latency-svc-d4s2h
Sep 16 02:30:05.408: INFO: Got endpoints: latency-svc-g5g2g [749.171972ms]
Sep 16 02:30:05.412: INFO: Created: latency-svc-8tqr6
Sep 16 02:30:05.458: INFO: Got endpoints: latency-svc-5djfl [749.144989ms]
Sep 16 02:30:05.464: INFO: Created: latency-svc-sgp56
Sep 16 02:30:05.508: INFO: Got endpoints: latency-svc-nvtg4 [749.570101ms]
Sep 16 02:30:05.513: INFO: Created: latency-svc-5f2zc
Sep 16 02:30:05.558: INFO: Got endpoints: latency-svc-ch784 [748.956538ms]
Sep 16 02:30:05.562: INFO: Created: latency-svc-bbcsq
Sep 16 02:30:05.609: INFO: Got endpoints: latency-svc-d648z [749.058539ms]
Sep 16 02:30:05.613: INFO: Created: latency-svc-52v8c
Sep 16 02:30:05.659: INFO: Got endpoints: latency-svc-pbh22 [749.673407ms]
Sep 16 02:30:05.663: INFO: Created: latency-svc-6dd7k
Sep 16 02:30:05.708: INFO: Got endpoints: latency-svc-ghtvt [749.525803ms]
Sep 16 02:30:05.712: INFO: Created: latency-svc-8k4rb
Sep 16 02:30:05.758: INFO: Got endpoints: latency-svc-dxjkq [749.493712ms]
Sep 16 02:30:05.762: INFO: Created: latency-svc-kwfxm
Sep 16 02:30:05.808: INFO: Got endpoints: latency-svc-926cz [749.76502ms]
Sep 16 02:30:05.812: INFO: Created: latency-svc-8ghwv
Sep 16 02:30:05.858: INFO: Got endpoints: latency-svc-kdrfw [749.015864ms]
Sep 16 02:30:05.861: INFO: Created: latency-svc-bqqfz
Sep 16 02:30:05.908: INFO: Got endpoints: latency-svc-wrtm7 [749.762566ms]
Sep 16 02:30:05.912: INFO: Created: latency-svc-hbgct
Sep 16 02:30:05.958: INFO: Got endpoints: latency-svc-qfhp5 [749.472108ms]
Sep 16 02:30:05.962: INFO: Created: latency-svc-dssjv
Sep 16 02:30:06.008: INFO: Got endpoints: latency-svc-8msbt [749.593067ms]
Sep 16 02:30:06.012: INFO: Created: latency-svc-f4rst
Sep 16 02:30:06.058: INFO: Got endpoints: latency-svc-mrxnc [750.428555ms]
Sep 16 02:30:06.062: INFO: Created: latency-svc-vk5nk
Sep 16 02:30:06.109: INFO: Got endpoints: latency-svc-d4s2h [750.407508ms]
Sep 16 02:30:06.113: INFO: Created: latency-svc-6zjth
Sep 16 02:30:06.159: INFO: Got endpoints: latency-svc-8tqr6 [750.528666ms]
Sep 16 02:30:06.163: INFO: Created: latency-svc-lqpl4
Sep 16 02:30:06.209: INFO: Got endpoints: latency-svc-sgp56 [750.364811ms]
Sep 16 02:30:06.213: INFO: Created: latency-svc-zzhrh
Sep 16 02:30:06.259: INFO: Got endpoints: latency-svc-5f2zc [750.234593ms]
Sep 16 02:30:06.262: INFO: Created: latency-svc-ltmwc
Sep 16 02:30:06.308: INFO: Got endpoints: latency-svc-bbcsq [750.497493ms]
Sep 16 02:30:06.312: INFO: Created: latency-svc-9bw2l
Sep 16 02:30:06.358: INFO: Got endpoints: latency-svc-52v8c [749.728416ms]
Sep 16 02:30:06.362: INFO: Created: latency-svc-ndgjx
Sep 16 02:30:06.409: INFO: Got endpoints: latency-svc-6dd7k [750.178122ms]
Sep 16 02:30:06.414: INFO: Created: latency-svc-f8xlq
Sep 16 02:30:06.459: INFO: Got endpoints: latency-svc-8k4rb [750.437867ms]
Sep 16 02:30:06.464: INFO: Created: latency-svc-mhbph
Sep 16 02:30:06.509: INFO: Got endpoints: latency-svc-kwfxm [750.564929ms]
Sep 16 02:30:06.513: INFO: Created: latency-svc-qlzqp
Sep 16 02:30:06.561: INFO: Got endpoints: latency-svc-8ghwv [752.520783ms]
Sep 16 02:30:06.565: INFO: Created: latency-svc-7fwpc
Sep 16 02:30:06.608: INFO: Got endpoints: latency-svc-bqqfz [750.51805ms]
Sep 16 02:30:06.612: INFO: Created: latency-svc-s54fb
Sep 16 02:30:06.659: INFO: Got endpoints: latency-svc-hbgct [750.794907ms]
Sep 16 02:30:06.666: INFO: Created: latency-svc-xhfcv
Sep 16 02:30:06.709: INFO: Got endpoints: latency-svc-dssjv [750.688871ms]
Sep 16 02:30:06.714: INFO: Created: latency-svc-t62fw
Sep 16 02:30:06.758: INFO: Got endpoints: latency-svc-f4rst [750.368186ms]
Sep 16 02:30:06.763: INFO: Created: latency-svc-kf458
Sep 16 02:30:06.809: INFO: Got endpoints: latency-svc-vk5nk [750.486704ms]
Sep 16 02:30:06.816: INFO: Created: latency-svc-26gf9
Sep 16 02:30:06.859: INFO: Got endpoints: latency-svc-6zjth [749.961576ms]
Sep 16 02:30:06.863: INFO: Created: latency-svc-cgkx5
Sep 16 02:30:06.909: INFO: Got endpoints: latency-svc-lqpl4 [749.98981ms]
Sep 16 02:30:06.913: INFO: Created: latency-svc-ctm5j
Sep 16 02:30:06.959: INFO: Got endpoints: latency-svc-zzhrh [750.015728ms]
Sep 16 02:30:06.962: INFO: Created: latency-svc-hp6l9
Sep 16 02:30:07.008: INFO: Got endpoints: latency-svc-ltmwc [749.908292ms]
Sep 16 02:30:07.013: INFO: Created: latency-svc-ph4pd
Sep 16 02:30:07.059: INFO: Got endpoints: latency-svc-9bw2l [750.359947ms]
Sep 16 02:30:07.063: INFO: Created: latency-svc-7mkdl
Sep 16 02:30:07.109: INFO: Got endpoints: latency-svc-ndgjx [750.246299ms]
Sep 16 02:30:07.113: INFO: Created: latency-svc-mrfnc
Sep 16 02:30:07.158: INFO: Got endpoints: latency-svc-f8xlq [749.602031ms]
Sep 16 02:30:07.163: INFO: Created: latency-svc-8kxcv
Sep 16 02:30:07.209: INFO: Got endpoints: latency-svc-mhbph [749.790059ms]
Sep 16 02:30:07.213: INFO: Created: latency-svc-hqh9h
Sep 16 02:30:07.258: INFO: Got endpoints: latency-svc-qlzqp [749.615556ms]
Sep 16 02:30:07.263: INFO: Created: latency-svc-7sc6p
Sep 16 02:30:07.309: INFO: Got endpoints: latency-svc-7fwpc [747.678044ms]
Sep 16 02:30:07.313: INFO: Created: latency-svc-mchgp
Sep 16 02:30:07.359: INFO: Got endpoints: latency-svc-s54fb [750.201785ms]
Sep 16 02:30:07.367: INFO: Created: latency-svc-q89xs
Sep 16 02:30:07.408: INFO: Got endpoints: latency-svc-xhfcv [748.917862ms]
Sep 16 02:30:07.412: INFO: Created: latency-svc-pqfcv
Sep 16 02:30:07.459: INFO: Got endpoints: latency-svc-t62fw [749.794248ms]
Sep 16 02:30:07.463: INFO: Created: latency-svc-7v9kr
Sep 16 02:30:07.509: INFO: Got endpoints: latency-svc-kf458 [750.083269ms]
Sep 16 02:30:07.513: INFO: Created: latency-svc-s5mdp
Sep 16 02:30:07.559: INFO: Got endpoints: latency-svc-26gf9 [749.591145ms]
Sep 16 02:30:07.563: INFO: Created: latency-svc-db7b4
Sep 16 02:30:07.608: INFO: Got endpoints: latency-svc-cgkx5 [749.861323ms]
Sep 16 02:30:07.613: INFO: Created: latency-svc-hjxxn
Sep 16 02:30:07.659: INFO: Got endpoints: latency-svc-ctm5j [749.936945ms]
Sep 16 02:30:07.663: INFO: Created: latency-svc-ngkp2
Sep 16 02:30:07.709: INFO: Got endpoints: latency-svc-hp6l9 [750.024169ms]
Sep 16 02:30:07.713: INFO: Created: latency-svc-trfmt
Sep 16 02:30:07.758: INFO: Got endpoints: latency-svc-ph4pd [749.781301ms]
Sep 16 02:30:07.763: INFO: Created: latency-svc-89rzp
Sep 16 02:30:07.808: INFO: Got endpoints: latency-svc-7mkdl [749.512337ms]
Sep 16 02:30:07.812: INFO: Created: latency-svc-24m75
Sep 16 02:30:07.858: INFO: Got endpoints: latency-svc-mrfnc [749.606529ms]
Sep 16 02:30:07.863: INFO: Created: latency-svc-2gg6v
Sep 16 02:30:07.909: INFO: Got endpoints: latency-svc-8kxcv [750.098371ms]
Sep 16 02:30:07.913: INFO: Created: latency-svc-tcx4v
Sep 16 02:30:07.958: INFO: Got endpoints: latency-svc-hqh9h [749.804727ms]
Sep 16 02:30:07.963: INFO: Created: latency-svc-gjlbn
Sep 16 02:30:08.008: INFO: Got endpoints: latency-svc-7sc6p [749.855367ms]
Sep 16 02:30:08.013: INFO: Created: latency-svc-fspnl
Sep 16 02:30:08.058: INFO: Got endpoints: latency-svc-mchgp [749.242137ms]
Sep 16 02:30:08.062: INFO: Created: latency-svc-74tjl
Sep 16 02:30:08.109: INFO: Got endpoints: latency-svc-q89xs [750.128556ms]
Sep 16 02:30:08.113: INFO: Created: latency-svc-8dpms
Sep 16 02:30:08.158: INFO: Got endpoints: latency-svc-pqfcv [749.833091ms]
Sep 16 02:30:08.162: INFO: Created: latency-svc-2jp4d
Sep 16 02:30:08.208: INFO: Got endpoints: latency-svc-7v9kr [749.339124ms]
Sep 16 02:30:08.212: INFO: Created: latency-svc-jhknn
Sep 16 02:30:08.258: INFO: Got endpoints: latency-svc-s5mdp [749.705805ms]
Sep 16 02:30:08.262: INFO: Created: latency-svc-nnw68
Sep 16 02:30:08.309: INFO: Got endpoints: latency-svc-db7b4 [750.114897ms]
Sep 16 02:30:08.318: INFO: Created: latency-svc-sq8sb
Sep 16 02:30:08.359: INFO: Got endpoints: latency-svc-hjxxn [750.283402ms]
Sep 16 02:30:08.364: INFO: Created: latency-svc-p5p99
Sep 16 02:30:08.409: INFO: Got endpoints: latency-svc-ngkp2 [750.127425ms]
Sep 16 02:30:08.414: INFO: Created: latency-svc-s2wbd
Sep 16 02:30:08.459: INFO: Got endpoints: latency-svc-trfmt [750.676871ms]
Sep 16 02:30:08.464: INFO: Created: latency-svc-64kh5
Sep 16 02:30:08.508: INFO: Got endpoints: latency-svc-89rzp [750.133422ms]
Sep 16 02:30:08.513: INFO: Created: latency-svc-twvr7
Sep 16 02:30:08.559: INFO: Got endpoints: latency-svc-24m75 [750.29609ms]
Sep 16 02:30:08.563: INFO: Created: latency-svc-858fr
Sep 16 02:30:08.609: INFO: Got endpoints: latency-svc-2gg6v [750.838469ms]
Sep 16 02:30:08.616: INFO: Created: latency-svc-fbtvh
Sep 16 02:30:08.659: INFO: Got endpoints: latency-svc-tcx4v [750.083397ms]
Sep 16 02:30:08.664: INFO: Created: latency-svc-tb7b6
Sep 16 02:30:08.709: INFO: Got endpoints: latency-svc-gjlbn [750.710756ms]
Sep 16 02:30:08.719: INFO: Created: latency-svc-ksz5c
Sep 16 02:30:08.760: INFO: Got endpoints: latency-svc-fspnl [751.196798ms]
Sep 16 02:30:08.765: INFO: Created: latency-svc-htth4
Sep 16 02:30:08.809: INFO: Got endpoints: latency-svc-74tjl [751.128779ms]
Sep 16 02:30:08.814: INFO: Created: latency-svc-q9jv4
Sep 16 02:30:08.859: INFO: Got endpoints: latency-svc-8dpms [750.678822ms]
Sep 16 02:30:08.864: INFO: Created: latency-svc-25rvl
Sep 16 02:30:08.909: INFO: Got endpoints: latency-svc-2jp4d [750.61913ms]
Sep 16 02:30:08.913: INFO: Created: latency-svc-g65bx
Sep 16 02:30:08.959: INFO: Got endpoints: latency-svc-jhknn [750.587342ms]
Sep 16 02:30:08.963: INFO: Created: latency-svc-znrpf
Sep 16 02:30:09.009: INFO: Got endpoints: latency-svc-nnw68 [750.321977ms]
Sep 16 02:30:09.013: INFO: Created: latency-svc-5gsjm
Sep 16 02:30:09.058: INFO: Got endpoints: latency-svc-sq8sb [749.509836ms]
Sep 16 02:30:09.063: INFO: Created: latency-svc-k7wqs
Sep 16 02:30:09.109: INFO: Got endpoints: latency-svc-p5p99 [749.945034ms]
Sep 16 02:30:09.113: INFO: Created: latency-svc-l8tc5
Sep 16 02:30:09.159: INFO: Got endpoints: latency-svc-s2wbd [749.825031ms]
Sep 16 02:30:09.167: INFO: Created: latency-svc-r6d27
Sep 16 02:30:09.209: INFO: Got endpoints: latency-svc-64kh5 [749.163124ms]
Sep 16 02:30:09.212: INFO: Created: latency-svc-crlpw
Sep 16 02:30:09.259: INFO: Got endpoints: latency-svc-twvr7 [750.291486ms]
Sep 16 02:30:09.263: INFO: Created: latency-svc-jt7nd
Sep 16 02:30:09.309: INFO: Got endpoints: latency-svc-858fr [750.085323ms]
Sep 16 02:30:09.313: INFO: Created: latency-svc-hslk6
Sep 16 02:30:09.359: INFO: Got endpoints: latency-svc-fbtvh [749.61024ms]
Sep 16 02:30:09.363: INFO: Created: latency-svc-pnlgr
Sep 16 02:30:09.408: INFO: Got endpoints: latency-svc-tb7b6 [749.089048ms]
Sep 16 02:30:09.412: INFO: Created: latency-svc-9bgd4
Sep 16 02:30:09.459: INFO: Got endpoints: latency-svc-ksz5c [749.442533ms]
Sep 16 02:30:09.463: INFO: Created: latency-svc-bhxrw
Sep 16 02:30:09.508: INFO: Got endpoints: latency-svc-htth4 [748.69053ms]
Sep 16 02:30:09.513: INFO: Created: latency-svc-dkbk2
Sep 16 02:30:09.558: INFO: Got endpoints: latency-svc-q9jv4 [749.377667ms]
Sep 16 02:30:09.563: INFO: Created: latency-svc-4xx4g
Sep 16 02:30:09.608: INFO: Got endpoints: latency-svc-25rvl [748.952101ms]
Sep 16 02:30:09.613: INFO: Created: latency-svc-j6chz
Sep 16 02:30:09.658: INFO: Got endpoints: latency-svc-g65bx [749.465236ms]
Sep 16 02:30:09.662: INFO: Created: latency-svc-h9pkh
Sep 16 02:30:09.709: INFO: Got endpoints: latency-svc-znrpf [749.998435ms]
Sep 16 02:30:09.713: INFO: Created: latency-svc-r72ms
Sep 16 02:30:09.759: INFO: Got endpoints: latency-svc-5gsjm [749.97038ms]
Sep 16 02:30:09.763: INFO: Created: latency-svc-mlqg8
Sep 16 02:30:09.809: INFO: Got endpoints: latency-svc-k7wqs [750.526041ms]
Sep 16 02:30:09.813: INFO: Created: latency-svc-nrh77
Sep 16 02:30:09.859: INFO: Got endpoints: latency-svc-l8tc5 [749.901841ms]
Sep 16 02:30:09.864: INFO: Created: latency-svc-ftdsr
Sep 16 02:30:09.909: INFO: Got endpoints: latency-svc-r6d27 [750.061774ms]
Sep 16 02:30:09.913: INFO: Created: latency-svc-bpgbq
Sep 16 02:30:09.959: INFO: Got endpoints: latency-svc-crlpw [750.118156ms]
Sep 16 02:30:09.963: INFO: Created: latency-svc-h6r9c
Sep 16 02:30:10.010: INFO: Got endpoints: latency-svc-jt7nd [751.03378ms]
Sep 16 02:30:10.016: INFO: Created: latency-svc-lpvfj
Sep 16 02:30:10.059: INFO: Got endpoints: latency-svc-hslk6 [749.729145ms]
Sep 16 02:30:10.063: INFO: Created: latency-svc-2dpv2
Sep 16 02:30:10.108: INFO: Got endpoints: latency-svc-pnlgr [749.568718ms]
Sep 16 02:30:10.112: INFO: Created: latency-svc-9czvh
Sep 16 02:30:10.159: INFO: Got endpoints: latency-svc-9bgd4 [750.653313ms]
Sep 16 02:30:10.162: INFO: Created: latency-svc-5kwd9
Sep 16 02:30:10.209: INFO: Got endpoints: latency-svc-bhxrw [749.818923ms]
Sep 16 02:30:10.212: INFO: Created: latency-svc-fhljp
Sep 16 02:30:10.259: INFO: Got endpoints: latency-svc-dkbk2 [750.529964ms]
Sep 16 02:30:10.264: INFO: Created: latency-svc-82sn6
Sep 16 02:30:10.308: INFO: Got endpoints: latency-svc-4xx4g [750.022825ms]
Sep 16 02:30:10.312: INFO: Created: latency-svc-kjb2l
Sep 16 02:30:10.359: INFO: Got endpoints: latency-svc-j6chz [750.513576ms]
Sep 16 02:30:10.363: INFO: Created: latency-svc-6dq7q
Sep 16 02:30:10.409: INFO: Got endpoints: latency-svc-h9pkh [750.459501ms]
Sep 16 02:30:10.413: INFO: Created: latency-svc-cspbv
Sep 16 02:30:10.459: INFO: Got endpoints: latency-svc-r72ms [750.07954ms]
Sep 16 02:30:10.463: INFO: Created: latency-svc-m65sx
Sep 16 02:30:10.509: INFO: Got endpoints: latency-svc-mlqg8 [749.996307ms]
Sep 16 02:30:10.513: INFO: Created: latency-svc-bgwlm
Sep 16 02:30:10.559: INFO: Got endpoints: latency-svc-nrh77 [749.869945ms]
Sep 16 02:30:10.564: INFO: Created: latency-svc-p7c2l
Sep 16 02:30:10.609: INFO: Got endpoints: latency-svc-ftdsr [749.700571ms]
Sep 16 02:30:10.614: INFO: Created: latency-svc-vvwwf
Sep 16 02:30:10.658: INFO: Got endpoints: latency-svc-bpgbq [749.575311ms]
Sep 16 02:30:10.664: INFO: Created: latency-svc-bh2sq
Sep 16 02:30:10.709: INFO: Got endpoints: latency-svc-h6r9c [750.542464ms]
Sep 16 02:30:10.715: INFO: Created: latency-svc-g9fvj
Sep 16 02:30:10.759: INFO: Got endpoints: latency-svc-lpvfj [748.744011ms]
Sep 16 02:30:10.764: INFO: Created: latency-svc-fn8kq
Sep 16 02:30:10.810: INFO: Got endpoints: latency-svc-2dpv2 [751.269026ms]
Sep 16 02:30:10.815: INFO: Created: latency-svc-5969k
Sep 16 02:30:10.859: INFO: Got endpoints: latency-svc-9czvh [750.295723ms]
Sep 16 02:30:10.863: INFO: Created: latency-svc-d85vk
Sep 16 02:30:10.909: INFO: Got endpoints: latency-svc-5kwd9 [749.968679ms]
Sep 16 02:30:10.913: INFO: Created: latency-svc-gp4p6
Sep 16 02:30:10.959: INFO: Got endpoints: latency-svc-fhljp [750.299269ms]
Sep 16 02:30:10.964: INFO: Created: latency-svc-8kh44
Sep 16 02:30:11.009: INFO: Got endpoints: latency-svc-82sn6 [749.627128ms]
Sep 16 02:30:11.013: INFO: Created: latency-svc-gn7sj
Sep 16 02:30:11.058: INFO: Got endpoints: latency-svc-kjb2l [749.468733ms]
Sep 16 02:30:11.062: INFO: Created: latency-svc-fmbtv
Sep 16 02:30:11.108: INFO: Got endpoints: latency-svc-6dq7q [748.884488ms]
Sep 16 02:30:11.113: INFO: Created: latency-svc-v9mrs
Sep 16 02:30:11.158: INFO: Got endpoints: latency-svc-cspbv [749.667681ms]
Sep 16 02:30:11.163: INFO: Created: latency-svc-h8snr
Sep 16 02:30:11.208: INFO: Got endpoints: latency-svc-m65sx [749.74931ms]
Sep 16 02:30:11.213: INFO: Created: latency-svc-5vtvj
Sep 16 02:30:11.258: INFO: Got endpoints: latency-svc-bgwlm [749.644399ms]
Sep 16 02:30:11.263: INFO: Created: latency-svc-w7mcf
Sep 16 02:30:11.309: INFO: Got endpoints: latency-svc-p7c2l [749.630153ms]
Sep 16 02:30:11.313: INFO: Created: latency-svc-lq2sp
Sep 16 02:30:11.359: INFO: Got endpoints: latency-svc-vvwwf [750.026644ms]
Sep 16 02:30:11.363: INFO: Created: latency-svc-j4q4t
Sep 16 02:30:11.409: INFO: Got endpoints: latency-svc-bh2sq [750.068312ms]
Sep 16 02:30:11.413: INFO: Created: latency-svc-f86sf
Sep 16 02:30:11.459: INFO: Got endpoints: latency-svc-g9fvj [749.175166ms]
Sep 16 02:30:11.463: INFO: Created: latency-svc-xgb4c
Sep 16 02:30:11.509: INFO: Got endpoints: latency-svc-fn8kq [749.843515ms]
Sep 16 02:30:11.558: INFO: Got endpoints: latency-svc-5969k [748.533761ms]
Sep 16 02:30:11.609: INFO: Got endpoints: latency-svc-d85vk [749.821848ms]
Sep 16 02:30:11.659: INFO: Got endpoints: latency-svc-gp4p6 [750.04088ms]
Sep 16 02:30:11.709: INFO: Got endpoints: latency-svc-8kh44 [749.671484ms]
Sep 16 02:30:11.759: INFO: Got endpoints: latency-svc-gn7sj [749.902671ms]
Sep 16 02:30:11.809: INFO: Got endpoints: latency-svc-fmbtv [750.647616ms]
Sep 16 02:30:11.858: INFO: Got endpoints: latency-svc-v9mrs [750.511019ms]
Sep 16 02:30:11.909: INFO: Got endpoints: latency-svc-h8snr [750.260442ms]
Sep 16 02:30:11.958: INFO: Got endpoints: latency-svc-5vtvj [749.835511ms]
Sep 16 02:30:12.009: INFO: Got endpoints: latency-svc-w7mcf [750.168803ms]
Sep 16 02:30:12.059: INFO: Got endpoints: latency-svc-lq2sp [749.952426ms]
Sep 16 02:30:12.109: INFO: Got endpoints: latency-svc-j4q4t [750.85368ms]
Sep 16 02:30:12.159: INFO: Got endpoints: latency-svc-f86sf [750.250252ms]
Sep 16 02:30:12.209: INFO: Got endpoints: latency-svc-xgb4c [750.244606ms]
Sep 16 02:30:12.209: INFO: Latencies: [6.017827ms 8.452289ms 10.571899ms 12.658708ms 14.023959ms 15.814314ms 19.018149ms 22.227595ms 22.238653ms 23.676284ms 26.511383ms 27.780644ms 28.467581ms 28.777684ms 29.005045ms 29.058903ms 29.122658ms 29.348527ms 29.348724ms 29.47683ms 29.508239ms 29.585395ms 29.824044ms 29.950552ms 30.241751ms 30.459373ms 30.623975ms 31.053177ms 31.596679ms 33.615641ms 61.742426ms 110.248844ms 158.866049ms 207.514595ms 255.469494ms 304.230491ms 351.687732ms 399.427914ms 448.216556ms 495.27897ms 543.390687ms 591.589666ms 639.72141ms 688.382824ms 736.984683ms 747.678044ms 748.533761ms 748.69053ms 748.744011ms 748.884488ms 748.917862ms 748.952101ms 748.956538ms 749.015864ms 749.058539ms 749.089048ms 749.113023ms 749.144989ms 749.163124ms 749.171972ms 749.175166ms 749.242137ms 749.339124ms 749.351712ms 749.377667ms 749.442533ms 749.465236ms 749.468733ms 749.472108ms 749.493712ms 749.509836ms 749.512337ms 749.525803ms 749.568718ms 749.570101ms 749.575311ms 749.591145ms 749.593067ms 749.602031ms 749.606529ms 749.61024ms 749.615556ms 749.627128ms 749.630153ms 749.640723ms 749.644399ms 749.667681ms 749.671484ms 749.673407ms 749.700571ms 749.705805ms 749.728416ms 749.729145ms 749.74931ms 749.761236ms 749.762566ms 749.76502ms 749.781301ms 749.790059ms 749.794248ms 749.804727ms 749.818923ms 749.821848ms 749.825031ms 749.833091ms 749.835511ms 749.843515ms 749.855367ms 749.861323ms 749.869945ms 749.891136ms 749.901841ms 749.902671ms 749.908292ms 749.927435ms 749.936945ms 749.945034ms 749.952426ms 749.961576ms 749.968679ms 749.97038ms 749.98981ms 749.996307ms 749.998435ms 750.015728ms 750.022825ms 750.024169ms 750.026644ms 750.03822ms 750.04088ms 750.050407ms 750.061774ms 750.068312ms 750.07954ms 750.083269ms 750.083397ms 750.085323ms 750.098371ms 750.114897ms 750.118156ms 750.127425ms 750.128556ms 750.133422ms 750.168803ms 750.178122ms 750.201785ms 750.224229ms 750.233983ms 750.234593ms 750.244606ms 750.246299ms 750.250252ms 750.260442ms 750.283402ms 750.291486ms 750.295723ms 750.29609ms 750.299269ms 750.306327ms 750.321977ms 750.328622ms 750.342421ms 750.347491ms 750.359947ms 750.364811ms 750.368186ms 750.407508ms 750.41287ms 750.428555ms 750.437867ms 750.459501ms 750.486704ms 750.497493ms 750.511019ms 750.513576ms 750.51805ms 750.526041ms 750.528666ms 750.529964ms 750.542464ms 750.563556ms 750.564929ms 750.587342ms 750.61913ms 750.647616ms 750.653313ms 750.676871ms 750.678822ms 750.688871ms 750.710756ms 750.794907ms 750.818329ms 750.829866ms 750.838469ms 750.85368ms 751.03378ms 751.128779ms 751.196798ms 751.269026ms 752.520783ms]
Sep 16 02:30:12.209: INFO: 50 %ile: 749.804727ms
Sep 16 02:30:12.209: INFO: 90 %ile: 750.563556ms
Sep 16 02:30:12.209: INFO: 99 %ile: 751.269026ms
Sep 16 02:30:12.209: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:30:12.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9850" for this suite.

• [SLOW TEST:11.741 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":277,"completed":134,"skipped":2358,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:30:12.215: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:30:12.558: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 02:30:14.564: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820212, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820212, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820212, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820212, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 02:30:16.566: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820212, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820212, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820212, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820212, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:30:19.571: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Sep 16 02:30:20.571: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Sep 16 02:30:21.571: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Sep 16 02:30:22.571: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Sep 16 02:30:23.571: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Sep 16 02:30:24.571: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:30:24.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3457" for this suite.
STEP: Destroying namespace "webhook-3457-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:12.444 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":277,"completed":135,"skipped":2367,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:30:24.659: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-9c3c27ca-50e7-4bcc-8d0c-5e9a641b1af3 in namespace container-probe-5541
Sep 16 02:30:28.686: INFO: Started pod busybox-9c3c27ca-50e7-4bcc-8d0c-5e9a641b1af3 in namespace container-probe-5541
STEP: checking the pod's current state and verifying that restartCount is present
Sep 16 02:30:28.688: INFO: Initial restart count of pod busybox-9c3c27ca-50e7-4bcc-8d0c-5e9a641b1af3 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:34:28.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5541" for this suite.

• [SLOW TEST:244.328 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":136,"skipped":2384,"failed":0}
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:34:28.987: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:34:45.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1388" for this suite.

• [SLOW TEST:16.048 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":277,"completed":137,"skipped":2384,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:34:45.036: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:34:45.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4330" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":277,"completed":138,"skipped":2397,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:34:45.057: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 16 02:34:45.075: INFO: Waiting up to 5m0s for pod "pod-9abcd7cb-ac5b-4071-aaaf-53f1f12e349e" in namespace "emptydir-1404" to be "Succeeded or Failed"
Sep 16 02:34:45.076: INFO: Pod "pod-9abcd7cb-ac5b-4071-aaaf-53f1f12e349e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.161489ms
Sep 16 02:34:47.079: INFO: Pod "pod-9abcd7cb-ac5b-4071-aaaf-53f1f12e349e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003325615s
Sep 16 02:34:49.081: INFO: Pod "pod-9abcd7cb-ac5b-4071-aaaf-53f1f12e349e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005907603s
STEP: Saw pod success
Sep 16 02:34:49.081: INFO: Pod "pod-9abcd7cb-ac5b-4071-aaaf-53f1f12e349e" satisfied condition "Succeeded or Failed"
Sep 16 02:34:49.083: INFO: Trying to get logs from node 192.168.4.87 pod pod-9abcd7cb-ac5b-4071-aaaf-53f1f12e349e container test-container: <nil>
STEP: delete the pod
Sep 16 02:34:49.098: INFO: Waiting for pod pod-9abcd7cb-ac5b-4071-aaaf-53f1f12e349e to disappear
Sep 16 02:34:49.099: INFO: Pod pod-9abcd7cb-ac5b-4071-aaaf-53f1f12e349e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:34:49.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1404" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":139,"skipped":2405,"failed":0}
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:34:49.104: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 16 02:34:49.123: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:34:55.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8992" for this suite.

• [SLOW TEST:5.986 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":277,"completed":140,"skipped":2410,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:34:55.090: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8604.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8604.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 16 02:35:01.122: INFO: Unable to read wheezy_udp@kubernetes.default.svc.cluster.local from pod dns-8604/dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6: the server could not find the requested resource (get pods dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6)
Sep 16 02:35:01.124: INFO: Unable to read wheezy_tcp@kubernetes.default.svc.cluster.local from pod dns-8604/dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6: the server could not find the requested resource (get pods dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6)
Sep 16 02:35:01.125: INFO: Unable to read wheezy_udp@PodARecord from pod dns-8604/dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6: the server could not find the requested resource (get pods dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6)
Sep 16 02:35:01.127: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-8604/dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6: the server could not find the requested resource (get pods dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6)
Sep 16 02:35:01.134: INFO: Lookups using dns-8604/dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6 failed for: [wheezy_udp@kubernetes.default.svc.cluster.local wheezy_tcp@kubernetes.default.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord]

Sep 16 02:35:06.151: INFO: DNS probes using dns-8604/dns-test-9eed73d5-0cb3-4e2e-8f26-01ddad7b4bd6 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:35:06.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8604" for this suite.

• [SLOW TEST:11.078 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":277,"completed":141,"skipped":2425,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:35:06.168: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 16 02:35:06.200: INFO: Number of nodes with available pods: 0
Sep 16 02:35:06.200: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:07.205: INFO: Number of nodes with available pods: 0
Sep 16 02:35:07.205: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:08.206: INFO: Number of nodes with available pods: 0
Sep 16 02:35:08.206: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:09.205: INFO: Number of nodes with available pods: 0
Sep 16 02:35:09.205: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:10.205: INFO: Number of nodes with available pods: 1
Sep 16 02:35:10.205: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:11.205: INFO: Number of nodes with available pods: 2
Sep 16 02:35:11.205: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 16 02:35:11.217: INFO: Number of nodes with available pods: 1
Sep 16 02:35:11.217: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:12.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:12.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:13.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:13.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:14.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:14.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:15.221: INFO: Number of nodes with available pods: 1
Sep 16 02:35:15.221: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:16.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:16.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:17.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:17.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:18.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:18.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:19.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:19.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:20.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:20.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:21.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:21.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:22.222: INFO: Number of nodes with available pods: 1
Sep 16 02:35:22.222: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 02:35:23.222: INFO: Number of nodes with available pods: 2
Sep 16 02:35:23.222: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1865, will wait for the garbage collector to delete the pods
Sep 16 02:35:23.280: INFO: Deleting DaemonSet.extensions daemon-set took: 4.007682ms
Sep 16 02:35:23.680: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.1945ms
Sep 16 02:35:28.882: INFO: Number of nodes with available pods: 0
Sep 16 02:35:28.882: INFO: Number of running nodes: 0, number of available pods: 0
Sep 16 02:35:28.884: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1865/daemonsets","resourceVersion":"21952"},"items":null}

Sep 16 02:35:28.885: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1865/pods","resourceVersion":"21952"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:35:28.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1865" for this suite.

• [SLOW TEST:22.728 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":277,"completed":142,"skipped":2437,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:35:28.896: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Sep 16 02:35:28.916: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Sep 16 02:35:28.918: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Sep 16 02:35:28.918: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Sep 16 02:35:28.922: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Sep 16 02:35:28.922: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Sep 16 02:35:28.926: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Sep 16 02:35:28.926: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Sep 16 02:35:35.942: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:35:35.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-2177" for this suite.

• [SLOW TEST:7.054 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":277,"completed":143,"skipped":2471,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:35:35.950: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:35:35.968: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14443fdb-9d2d-4ce5-a6f3-08736f3ee583" in namespace "projected-2480" to be "Succeeded or Failed"
Sep 16 02:35:35.969: INFO: Pod "downwardapi-volume-14443fdb-9d2d-4ce5-a6f3-08736f3ee583": Phase="Pending", Reason="", readiness=false. Elapsed: 1.381675ms
Sep 16 02:35:37.972: INFO: Pod "downwardapi-volume-14443fdb-9d2d-4ce5-a6f3-08736f3ee583": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00371758s
Sep 16 02:35:39.974: INFO: Pod "downwardapi-volume-14443fdb-9d2d-4ce5-a6f3-08736f3ee583": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006102141s
STEP: Saw pod success
Sep 16 02:35:39.974: INFO: Pod "downwardapi-volume-14443fdb-9d2d-4ce5-a6f3-08736f3ee583" satisfied condition "Succeeded or Failed"
Sep 16 02:35:39.976: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-14443fdb-9d2d-4ce5-a6f3-08736f3ee583 container client-container: <nil>
STEP: delete the pod
Sep 16 02:35:39.985: INFO: Waiting for pod downwardapi-volume-14443fdb-9d2d-4ce5-a6f3-08736f3ee583 to disappear
Sep 16 02:35:39.987: INFO: Pod downwardapi-volume-14443fdb-9d2d-4ce5-a6f3-08736f3ee583 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:35:39.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2480" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":144,"skipped":2493,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:35:39.991: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-wfrk
STEP: Creating a pod to test atomic-volume-subpath
Sep 16 02:35:40.025: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wfrk" in namespace "subpath-4600" to be "Succeeded or Failed"
Sep 16 02:35:40.026: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Pending", Reason="", readiness=false. Elapsed: 1.838209ms
Sep 16 02:35:42.029: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004277186s
Sep 16 02:35:44.031: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 4.006638777s
Sep 16 02:35:46.034: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 6.009185215s
Sep 16 02:35:48.036: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 8.011516107s
Sep 16 02:35:50.039: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 10.013974661s
Sep 16 02:35:52.040: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 12.015845958s
Sep 16 02:35:54.043: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 14.018228434s
Sep 16 02:35:56.045: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 16.020489886s
Sep 16 02:35:58.047: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 18.022842198s
Sep 16 02:36:00.050: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 20.025601879s
Sep 16 02:36:02.052: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Running", Reason="", readiness=true. Elapsed: 22.027922678s
Sep 16 02:36:04.055: INFO: Pod "pod-subpath-test-configmap-wfrk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.030279355s
STEP: Saw pod success
Sep 16 02:36:04.055: INFO: Pod "pod-subpath-test-configmap-wfrk" satisfied condition "Succeeded or Failed"
Sep 16 02:36:04.056: INFO: Trying to get logs from node 192.168.4.87 pod pod-subpath-test-configmap-wfrk container test-container-subpath-configmap-wfrk: <nil>
STEP: delete the pod
Sep 16 02:36:04.065: INFO: Waiting for pod pod-subpath-test-configmap-wfrk to disappear
Sep 16 02:36:04.067: INFO: Pod pod-subpath-test-configmap-wfrk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wfrk
Sep 16 02:36:04.067: INFO: Deleting pod "pod-subpath-test-configmap-wfrk" in namespace "subpath-4600"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:36:04.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4600" for this suite.

• [SLOW TEST:24.081 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":277,"completed":145,"skipped":2500,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:36:04.073: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6402 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6402;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6402 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6402;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6402.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6402.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6402.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6402.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6402.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6402.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6402.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6402.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6402.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6402.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6402.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6402.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6402.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 219.81.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.81.219_udp@PTR;check="$$(dig +tcp +noall +answer +search 219.81.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.81.219_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6402 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6402;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6402 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6402;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6402.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6402.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6402.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6402.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6402.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6402.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6402.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6402.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6402.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6402.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6402.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6402.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6402.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 219.81.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.81.219_udp@PTR;check="$$(dig +tcp +noall +answer +search 219.81.254.11.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/11.254.81.219_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 16 02:36:10.111: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.114: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.116: INFO: Unable to read wheezy_udp@dns-test-service.dns-6402 from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.118: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6402 from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.119: INFO: Unable to read wheezy_udp@dns-test-service.dns-6402.svc from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.121: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6402.svc from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.123: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6402.svc from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.125: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6402.svc from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.137: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.138: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.140: INFO: Unable to read jessie_udp@dns-test-service.dns-6402 from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.142: INFO: Unable to read jessie_tcp@dns-test-service.dns-6402 from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.143: INFO: Unable to read jessie_udp@dns-test-service.dns-6402.svc from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.145: INFO: Unable to read jessie_tcp@dns-test-service.dns-6402.svc from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.146: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6402.svc from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.148: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6402.svc from pod dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1: the server could not find the requested resource (get pods dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1)
Sep 16 02:36:10.157: INFO: Lookups using dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6402 wheezy_tcp@dns-test-service.dns-6402 wheezy_udp@dns-test-service.dns-6402.svc wheezy_tcp@dns-test-service.dns-6402.svc wheezy_udp@_http._tcp.dns-test-service.dns-6402.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6402.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6402 jessie_tcp@dns-test-service.dns-6402 jessie_udp@dns-test-service.dns-6402.svc jessie_tcp@dns-test-service.dns-6402.svc jessie_udp@_http._tcp.dns-test-service.dns-6402.svc jessie_tcp@_http._tcp.dns-test-service.dns-6402.svc]

Sep 16 02:36:15.202: INFO: DNS probes using dns-6402/dns-test-bed5dbda-ebab-40bc-b8f4-290706b1e0e1 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:36:15.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6402" for this suite.

• [SLOW TEST:11.154 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":277,"completed":146,"skipped":2516,"failed":0}
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:36:15.227: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 16 02:36:15.244: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 16 02:36:15.250: INFO: Waiting for terminating namespaces to be deleted...
Sep 16 02:36:15.251: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.86 before test
Sep 16 02:36:15.262: INFO: ckecsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.262: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep 16 02:36:15.262: INFO: cke-lvmcsi-nf9cd from cke-storage started at 2020-09-16 01:25:20 +0000 UTC (2 container statuses recorded)
Sep 16 02:36:15.262: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 02:36:15.262: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:36:15.262: INFO: ckecsi-runc-jq25h from cke-storage started at 2020-09-16 01:25:30 +0000 UTC (2 container statuses recorded)
Sep 16 02:36:15.262: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 02:36:15.262: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:36:15.262: INFO: sonobuoy from sonobuoy started at 2020-09-16 01:52:42 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.262: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 16 02:36:15.262: INFO: calico-kube-controllers-97dc579d-s2z7r from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.262: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 16 02:36:15.262: INFO: sonobuoy-e2e-job-a58be685376b45c9 from sonobuoy started at 2020-09-16 01:52:44 +0000 UTC (2 container statuses recorded)
Sep 16 02:36:15.262: INFO: 	Container e2e ready: true, restart count 0
Sep 16 02:36:15.262: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 16 02:36:15.262: INFO: coredns-75587db8b6-vlztj from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.262: INFO: 	Container coredns ready: true, restart count 0
Sep 16 02:36:15.262: INFO: ckecsi-attacher-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.262: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep 16 02:36:15.262: INFO: kubernetes-dashboard-7d464dfc59-d5sxx from kubernetes-dashboard started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.262: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 16 02:36:15.262: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.87 before test
Sep 16 02:36:15.266: INFO: cke-lvmcsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.266: INFO: 	Container csi-provisioner ready: true, restart count 1
Sep 16 02:36:15.266: INFO: dashboard-metrics-scraper-6fb76cb999-qld2q from kubernetes-dashboard started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.266: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 16 02:36:15.266: INFO: metrics-server-cf7f9ccc5-jcnlg from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.266: INFO: 	Container metrics-server ready: true, restart count 0
Sep 16 02:36:15.266: INFO: ckecsi-runc-2x2tv from cke-storage started at 2020-09-16 01:25:29 +0000 UTC (2 container statuses recorded)
Sep 16 02:36:15.266: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 02:36:15.266: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:36:15.266: INFO: ckecsi-attacher-1 from cke-storage started at 2020-09-16 01:26:22 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.266: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep 16 02:36:15.266: INFO: cke-lvmcsi-q44bw from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (2 container statuses recorded)
Sep 16 02:36:15.266: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 02:36:15.266: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:36:15.266: INFO: cke-lvmcsi-resizer-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.266: INFO: 	Container csi-lvm-resizer ready: true, restart count 0
Sep 16 02:36:15.266: INFO: ckecsi-provisioner-1 from cke-storage started at 2020-09-16 01:26:19 +0000 UTC (1 container statuses recorded)
Sep 16 02:36:15.266: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8fbda8fe-c54d-424d-81c3-83b756d5b91f 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-8fbda8fe-c54d-424d-81c3-83b756d5b91f off the node 192.168.4.87
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8fbda8fe-c54d-424d-81c3-83b756d5b91f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:36:31.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1759" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:16.088 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":277,"completed":147,"skipped":2519,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:36:31.316: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-b18b300f-2d78-4ff9-be25-7fb5b6494df6
STEP: Creating a pod to test consume configMaps
Sep 16 02:36:31.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-30b47339-8c61-4cbe-afc5-eb526372fde7" in namespace "configmap-9366" to be "Succeeded or Failed"
Sep 16 02:36:31.338: INFO: Pod "pod-configmaps-30b47339-8c61-4cbe-afc5-eb526372fde7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.31885ms
Sep 16 02:36:33.340: INFO: Pod "pod-configmaps-30b47339-8c61-4cbe-afc5-eb526372fde7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003363425s
Sep 16 02:36:35.343: INFO: Pod "pod-configmaps-30b47339-8c61-4cbe-afc5-eb526372fde7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005718289s
STEP: Saw pod success
Sep 16 02:36:35.343: INFO: Pod "pod-configmaps-30b47339-8c61-4cbe-afc5-eb526372fde7" satisfied condition "Succeeded or Failed"
Sep 16 02:36:35.344: INFO: Trying to get logs from node 192.168.4.86 pod pod-configmaps-30b47339-8c61-4cbe-afc5-eb526372fde7 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:36:35.353: INFO: Waiting for pod pod-configmaps-30b47339-8c61-4cbe-afc5-eb526372fde7 to disappear
Sep 16 02:36:35.354: INFO: Pod pod-configmaps-30b47339-8c61-4cbe-afc5-eb526372fde7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:36:35.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9366" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":148,"skipped":2525,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:36:35.359: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:36:35.375: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 16 02:36:38.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-5315 create -f -'
Sep 16 02:36:41.029: INFO: stderr: ""
Sep 16 02:36:41.029: INFO: stdout: "e2e-test-crd-publish-openapi-8341-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 16 02:36:41.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-5315 delete e2e-test-crd-publish-openapi-8341-crds test-cr'
Sep 16 02:36:41.104: INFO: stderr: ""
Sep 16 02:36:41.104: INFO: stdout: "e2e-test-crd-publish-openapi-8341-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Sep 16 02:36:41.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-5315 apply -f -'
Sep 16 02:36:41.348: INFO: stderr: ""
Sep 16 02:36:41.348: INFO: stdout: "e2e-test-crd-publish-openapi-8341-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 16 02:36:41.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 --namespace=crd-publish-openapi-5315 delete e2e-test-crd-publish-openapi-8341-crds test-cr'
Sep 16 02:36:41.423: INFO: stderr: ""
Sep 16 02:36:41.423: INFO: stdout: "e2e-test-crd-publish-openapi-8341-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 16 02:36:41.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 explain e2e-test-crd-publish-openapi-8341-crds'
Sep 16 02:36:41.681: INFO: stderr: ""
Sep 16 02:36:41.681: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8341-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:36:45.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5315" for this suite.

• [SLOW TEST:9.872 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":277,"completed":149,"skipped":2534,"failed":0}
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:36:45.231: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:36:45.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-784'
Sep 16 02:36:45.528: INFO: stderr: ""
Sep 16 02:36:45.528: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Sep 16 02:36:45.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-784'
Sep 16 02:36:45.791: INFO: stderr: ""
Sep 16 02:36:45.791: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Sep 16 02:36:46.793: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:36:46.793: INFO: Found 0 / 1
Sep 16 02:36:47.793: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:36:47.793: INFO: Found 0 / 1
Sep 16 02:36:48.794: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:36:48.794: INFO: Found 1 / 1
Sep 16 02:36:48.794: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 16 02:36:48.795: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:36:48.795: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 16 02:36:48.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 describe pod agnhost-master-z9lrz --namespace=kubectl-784'
Sep 16 02:36:48.882: INFO: stderr: ""
Sep 16 02:36:48.882: INFO: stdout: "Name:         agnhost-master-z9lrz\nNamespace:    kubectl-784\nPriority:     0\nNode:         192.168.4.86/192.168.4.86\nStart Time:   Wed, 16 Sep 2020 02:36:45 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           172.151.166.140\nIPs:\n  IP:           172.151.166.140\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://41ef1a05aee28c9b605c6e983f1590be1316cb1a8e51d7e2b3f28c0b5da6ff48\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://reg.mg.hcbss/devcke/agnhost@sha256:1dfec5637a7010d6c0955c26f0a752266fa2646ed2bf8e6ad745cdcfcb611db8\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 16 Sep 2020 02:36:48 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-wqmgv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-wqmgv:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-wqmgv\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  3s    default-scheduler      Successfully assigned kubectl-784/agnhost-master-z9lrz to 192.168.4.86\n  Normal  Pulled     1s    kubelet, 192.168.4.86  Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    1s    kubelet, 192.168.4.86  Created container agnhost-master\n  Normal  Started    0s    kubelet, 192.168.4.86  Started container agnhost-master\n"
Sep 16 02:36:48.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 describe rc agnhost-master --namespace=kubectl-784'
Sep 16 02:36:48.969: INFO: stderr: ""
Sep 16 02:36:48.969: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-784\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-master-z9lrz\n"
Sep 16 02:36:48.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 describe service agnhost-master --namespace=kubectl-784'
Sep 16 02:36:49.046: INFO: stderr: ""
Sep 16 02:36:49.046: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-784\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                11.254.221.107\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.151.166.140:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 16 02:36:49.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 describe node 192.168.4.86'
Sep 16 02:36:49.140: INFO: stderr: ""
Sep 16 02:36:49.140: INFO: stdout: "Name:               192.168.4.86\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=192.168.4.86\n                    kubernetes.io/os=linux\n                    runc=1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"cke-lvmcsi\":\"192.168.4.86\",\"ckecsi\":\"192.168.4.86\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 16 Sep 2020 01:25:20 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  192.168.4.86\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 16 Sep 2020 02:36:41 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 16 Sep 2020 02:36:14 +0000   Wed, 16 Sep 2020 01:25:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 16 Sep 2020 02:36:14 +0000   Wed, 16 Sep 2020 01:25:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 16 Sep 2020 02:36:14 +0000   Wed, 16 Sep 2020 01:25:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 16 Sep 2020 02:36:14 +0000   Wed, 16 Sep 2020 01:25:30 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.4.86\n  Hostname:    192.168.4.86\nCapacity:\n  cpu:                24\n  ephemeral-storage:  32896784Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8Gi\n  pods:               110\nAllocatable:\n  cpu:                24\n  ephemeral-storage:  32896784Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7730941120\n  pods:               110\nSystem Info:\n  Machine ID:                 \n  System UUID:                ee4b32b6-d6c8-11e6-9fbe-18ded76a6cca\n  Boot ID:                    dd9250cf-08dc-47b2-895e-1a01dbf5c099\n  Kernel Version:             4.19.8-1.el7.elrepo.x86_64\n  OS Image:                   Alpine Linux v3.11\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://19.3.5\n  Kubelet Version:            v1.18.8\n  Kube-Proxy Version:         v1.18.8\nPodCIDR:                      172.151.1.0/24\nPodCIDRs:                     172.151.1.0/24\nNon-terminated Pods:          (10 in total)\n  Namespace                   Name                                      CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                      ------------  ----------  ---------------  -------------  ---\n  cke-storage                 cke-lvmcsi-nf9cd                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  cke-storage                 ckecsi-attacher-0                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  cke-storage                 ckecsi-provisioner-0                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  cke-storage                 ckecsi-runc-jq25h                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  kube-system                 calico-kube-controllers-97dc579d-s2z7r    0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  kube-system                 coredns-75587db8b6-vlztj                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  kubectl-784                 agnhost-master-z9lrz                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  kubernetes-dashboard        kubernetes-dashboard-7d464dfc59-d5sxx     0 (0%)        0 (0%)      0 (0%)           0 (0%)         71m\n  sonobuoy                    sonobuoy                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\n  sonobuoy                    sonobuoy-e2e-job-a58be685376b45c9         0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests  Limits\n  --------           --------  ------\n  cpu                0 (0%)    0 (0%)\n  memory             0 (0%)    0 (0%)\n  ephemeral-storage  0 (0%)    0 (0%)\n  hugepages-1Gi      0 (0%)    0 (0%)\n  hugepages-2Mi      0 (0%)    0 (0%)\nEvents:              <none>\n"
Sep 16 02:36:49.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 describe namespace kubectl-784'
Sep 16 02:36:49.213: INFO: stderr: ""
Sep 16 02:36:49.213: INFO: stdout: "Name:         kubectl-784\nLabels:       e2e-framework=kubectl\n              e2e-run=b1f91db0-52c3-4003-b04f-370f6e20f8cb\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:36:49.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-784" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":277,"completed":150,"skipped":2534,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:36:49.218: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-ddaa9b5f-6e91-492e-87ec-774f28187668
STEP: Creating configMap with name cm-test-opt-upd-98b9782d-251c-44e5-b8e7-603490a07cbc
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ddaa9b5f-6e91-492e-87ec-774f28187668
STEP: Updating configmap cm-test-opt-upd-98b9782d-251c-44e5-b8e7-603490a07cbc
STEP: Creating configMap with name cm-test-opt-create-730f89da-8a1b-49ba-8a72-2891d60bec8d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:38:09.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4932" for this suite.

• [SLOW TEST:80.309 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":151,"skipped":2535,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:38:09.527: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7563
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-7563
I0916 02:38:09.551896      26 runners.go:190] Created replication controller with name: externalname-service, namespace: services-7563, replica count: 2
I0916 02:38:12.602238      26 runners.go:190] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0916 02:38:15.602403      26 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 16 02:38:15.602: INFO: Creating new exec pod
Sep 16 02:38:20.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-7563 execpodvg6nw -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 16 02:38:20.793: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 16 02:38:20.793: INFO: stdout: ""
Sep 16 02:38:20.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-7563 execpodvg6nw -- /bin/sh -x -c nc -zv -t -w 2 11.254.151.116 80'
Sep 16 02:38:20.965: INFO: stderr: "+ nc -zv -t -w 2 11.254.151.116 80\nConnection to 11.254.151.116 80 port [tcp/http] succeeded!\n"
Sep 16 02:38:20.965: INFO: stdout: ""
Sep 16 02:38:20.965: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:38:20.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7563" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:11.451 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":277,"completed":152,"skipped":2577,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:38:20.978: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-9e83f08b-8add-4065-9e9a-b1ce255b36c3
STEP: Creating a pod to test consume configMaps
Sep 16 02:38:20.998: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff733744-f26d-4bbf-b0c3-0359e5e74299" in namespace "projected-6476" to be "Succeeded or Failed"
Sep 16 02:38:21.000: INFO: Pod "pod-projected-configmaps-ff733744-f26d-4bbf-b0c3-0359e5e74299": Phase="Pending", Reason="", readiness=false. Elapsed: 1.29767ms
Sep 16 02:38:23.002: INFO: Pod "pod-projected-configmaps-ff733744-f26d-4bbf-b0c3-0359e5e74299": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00327329s
Sep 16 02:38:25.004: INFO: Pod "pod-projected-configmaps-ff733744-f26d-4bbf-b0c3-0359e5e74299": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005580031s
STEP: Saw pod success
Sep 16 02:38:25.004: INFO: Pod "pod-projected-configmaps-ff733744-f26d-4bbf-b0c3-0359e5e74299" satisfied condition "Succeeded or Failed"
Sep 16 02:38:25.005: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-configmaps-ff733744-f26d-4bbf-b0c3-0359e5e74299 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:38:25.015: INFO: Waiting for pod pod-projected-configmaps-ff733744-f26d-4bbf-b0c3-0359e5e74299 to disappear
Sep 16 02:38:25.016: INFO: Pod pod-projected-configmaps-ff733744-f26d-4bbf-b0c3-0359e5e74299 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:38:25.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6476" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":153,"skipped":2585,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:38:25.020: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:38:25.956: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 02:38:27.962: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820705, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820705, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820705, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820705, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 02:38:29.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820705, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820705, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820705, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820705, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:38:32.968: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:38:32.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4900" for this suite.
STEP: Destroying namespace "webhook-4900-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.999 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":277,"completed":154,"skipped":2586,"failed":0}
S
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:38:33.019: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Sep 16 02:38:33.041: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 16 02:39:33.054: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:39:33.056: INFO: Starting informer...
STEP: Starting pod...
Sep 16 02:39:33.263: INFO: Pod is running on 192.168.4.87. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Sep 16 02:39:33.275: INFO: Pod wasn't evicted. Proceeding
Sep 16 02:39:33.275: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Sep 16 02:40:48.284: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:40:48.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-9053" for this suite.

• [SLOW TEST:135.269 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":277,"completed":155,"skipped":2587,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:40:48.289: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 16 02:40:48.305: INFO: PodSpec: initContainers in spec.initContainers
Sep 16 02:41:35.929: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-596b6af5-076d-4b6d-879a-eab06953f942", GenerateName:"", Namespace:"init-container-9357", SelfLink:"/api/v1/namespaces/init-container-9357/pods/pod-init-596b6af5-076d-4b6d-879a-eab06953f942", UID:"c7bcce51-c100-4227-9aee-b4ce9c58affe", ResourceVersion:"23771", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63735820848, loc:(*time.Location)(0x7b565c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"305304459"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00100c8e0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00100c900)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00100c920), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00100c940)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-f5jl6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc005b39e00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-f5jl6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-f5jl6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-f5jl6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003588688), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.4.87", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002efa7e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003588720)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003588770)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003588778), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00358877c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820848, loc:(*time.Location)(0x7b565c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820848, loc:(*time.Location)(0x7b565c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820848, loc:(*time.Location)(0x7b565c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735820848, loc:(*time.Location)(0x7b565c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.4.87", PodIP:"172.151.104.53", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.151.104.53"}}, StartTime:(*v1.Time)(0xc00100c960), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002efa8c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002efa930)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://reg.mg.hcbss/devcke/busybox@sha256:cbcde3595079b1f7a6b046e96e7547fe786d5c2c8eba678bc260161bc01b8dbe", ContainerID:"docker://c8056fd88d5f98c73b8d51496be95967a7f2779561665c6ed582b996665bf526", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00100c9a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00100c980), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc00358889f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:41:35.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9357" for this suite.

• [SLOW TEST:47.645 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":277,"completed":156,"skipped":2600,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:41:35.934: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:41:35.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2262" for this suite.
STEP: Destroying namespace "nspatchtest-a2875dd1-b2b4-48b2-bc77-b5e79af615f2-1860" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":277,"completed":157,"skipped":2627,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:41:35.972: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:41:47.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6316" for this suite.

• [SLOW TEST:11.040 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":277,"completed":158,"skipped":2628,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:41:47.012: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 16 02:41:55.060: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 16 02:41:55.061: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 16 02:41:57.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 16 02:41:57.064: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 16 02:41:59.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 16 02:41:59.064: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 16 02:42:01.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 16 02:42:01.064: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 16 02:42:03.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 16 02:42:03.064: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 16 02:42:05.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 16 02:42:05.064: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 16 02:42:07.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 16 02:42:07.064: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 16 02:42:09.061: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 16 02:42:09.064: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:42:09.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9470" for this suite.

• [SLOW TEST:22.056 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":277,"completed":159,"skipped":2644,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:42:09.068: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 16 02:42:09.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-3644'
Sep 16 02:42:09.163: INFO: stderr: ""
Sep 16 02:42:09.163: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Sep 16 02:42:14.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pod e2e-test-httpd-pod --namespace=kubectl-3644 -o json'
Sep 16 02:42:14.284: INFO: stderr: ""
Sep 16 02:42:14.284: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-09-16T02:42:09Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-09-16T02:42:09Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"172.151.104.55\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-09-16T02:42:11Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3644\",\n        \"resourceVersion\": \"23982\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3644/pods/e2e-test-httpd-pod\",\n        \"uid\": \"89993173-49b5-46e7-8a88-70bfae7380cf\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-kqf88\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.4.87\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-kqf88\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-kqf88\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-16T02:42:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-16T02:42:11Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-16T02:42:11Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-16T02:42:09Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://bc2d95c3ae1e02a17391574afa75b0e59cb68acb11c83067107038fdd56a523a\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://reg.mg.hcbss/devcke/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-09-16T02:42:11Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.4.87\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.151.104.55\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.151.104.55\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-09-16T02:42:09Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 16 02:42:14.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 replace -f - --namespace=kubectl-3644'
Sep 16 02:42:14.638: INFO: stderr: ""
Sep 16 02:42:14.638: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Sep 16 02:42:14.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete pods e2e-test-httpd-pod --namespace=kubectl-3644'
Sep 16 02:42:28.810: INFO: stderr: ""
Sep 16 02:42:28.810: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:42:28.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3644" for this suite.

• [SLOW TEST:19.747 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1450
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":277,"completed":160,"skipped":2651,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:42:28.816: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:42:28.835: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e01fcc28-8358-4f7f-bce2-7b92657183b4" in namespace "projected-2211" to be "Succeeded or Failed"
Sep 16 02:42:28.836: INFO: Pod "downwardapi-volume-e01fcc28-8358-4f7f-bce2-7b92657183b4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.298692ms
Sep 16 02:42:30.838: INFO: Pod "downwardapi-volume-e01fcc28-8358-4f7f-bce2-7b92657183b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003731573s
Sep 16 02:42:32.840: INFO: Pod "downwardapi-volume-e01fcc28-8358-4f7f-bce2-7b92657183b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005547046s
STEP: Saw pod success
Sep 16 02:42:32.840: INFO: Pod "downwardapi-volume-e01fcc28-8358-4f7f-bce2-7b92657183b4" satisfied condition "Succeeded or Failed"
Sep 16 02:42:32.842: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-e01fcc28-8358-4f7f-bce2-7b92657183b4 container client-container: <nil>
STEP: delete the pod
Sep 16 02:42:32.850: INFO: Waiting for pod downwardapi-volume-e01fcc28-8358-4f7f-bce2-7b92657183b4 to disappear
Sep 16 02:42:32.852: INFO: Pod downwardapi-volume-e01fcc28-8358-4f7f-bce2-7b92657183b4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:42:32.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2211" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":161,"skipped":2660,"failed":0}

------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:42:32.858: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:42:32.881: INFO: Waiting up to 5m0s for pod "downwardapi-volume-725ce568-26fa-4c5f-bde9-098d48889809" in namespace "downward-api-8120" to be "Succeeded or Failed"
Sep 16 02:42:32.882: INFO: Pod "downwardapi-volume-725ce568-26fa-4c5f-bde9-098d48889809": Phase="Pending", Reason="", readiness=false. Elapsed: 1.52763ms
Sep 16 02:42:34.885: INFO: Pod "downwardapi-volume-725ce568-26fa-4c5f-bde9-098d48889809": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003904179s
Sep 16 02:42:36.887: INFO: Pod "downwardapi-volume-725ce568-26fa-4c5f-bde9-098d48889809": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006333563s
STEP: Saw pod success
Sep 16 02:42:36.887: INFO: Pod "downwardapi-volume-725ce568-26fa-4c5f-bde9-098d48889809" satisfied condition "Succeeded or Failed"
Sep 16 02:42:36.889: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-725ce568-26fa-4c5f-bde9-098d48889809 container client-container: <nil>
STEP: delete the pod
Sep 16 02:42:36.897: INFO: Waiting for pod downwardapi-volume-725ce568-26fa-4c5f-bde9-098d48889809 to disappear
Sep 16 02:42:36.898: INFO: Pod downwardapi-volume-725ce568-26fa-4c5f-bde9-098d48889809 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:42:36.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8120" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":162,"skipped":2660,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:42:36.903: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 16 02:42:36.924: INFO: Waiting up to 5m0s for pod "pod-186c57b7-359c-4c1c-bce6-fc0dca91434f" in namespace "emptydir-211" to be "Succeeded or Failed"
Sep 16 02:42:36.925: INFO: Pod "pod-186c57b7-359c-4c1c-bce6-fc0dca91434f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.337371ms
Sep 16 02:42:38.928: INFO: Pod "pod-186c57b7-359c-4c1c-bce6-fc0dca91434f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003532799s
Sep 16 02:42:40.930: INFO: Pod "pod-186c57b7-359c-4c1c-bce6-fc0dca91434f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006100803s
STEP: Saw pod success
Sep 16 02:42:40.930: INFO: Pod "pod-186c57b7-359c-4c1c-bce6-fc0dca91434f" satisfied condition "Succeeded or Failed"
Sep 16 02:42:40.932: INFO: Trying to get logs from node 192.168.4.87 pod pod-186c57b7-359c-4c1c-bce6-fc0dca91434f container test-container: <nil>
STEP: delete the pod
Sep 16 02:42:40.941: INFO: Waiting for pod pod-186c57b7-359c-4c1c-bce6-fc0dca91434f to disappear
Sep 16 02:42:40.943: INFO: Pod pod-186c57b7-359c-4c1c-bce6-fc0dca91434f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:42:40.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-211" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":163,"skipped":2662,"failed":0}
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:42:40.947: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 16 02:42:40.963: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 16 02:42:40.969: INFO: Waiting for terminating namespaces to be deleted...
Sep 16 02:42:40.970: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.86 before test
Sep 16 02:42:40.982: INFO: cke-lvmcsi-nf9cd from cke-storage started at 2020-09-16 01:25:20 +0000 UTC (2 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 02:42:40.982: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:42:40.982: INFO: ckecsi-runc-jq25h from cke-storage started at 2020-09-16 01:25:30 +0000 UTC (2 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 02:42:40.982: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:42:40.982: INFO: sonobuoy from sonobuoy started at 2020-09-16 01:52:42 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 16 02:42:40.982: INFO: metrics-server-cf7f9ccc5-ddpmv from kube-system started at 2020-09-16 02:39:33 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container metrics-server ready: true, restart count 0
Sep 16 02:42:40.982: INFO: calico-kube-controllers-97dc579d-s2z7r from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 16 02:42:40.982: INFO: sonobuoy-e2e-job-a58be685376b45c9 from sonobuoy started at 2020-09-16 01:52:44 +0000 UTC (2 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container e2e ready: true, restart count 0
Sep 16 02:42:40.982: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 16 02:42:40.982: INFO: coredns-75587db8b6-vlztj from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container coredns ready: true, restart count 0
Sep 16 02:42:40.982: INFO: ckecsi-attacher-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep 16 02:42:40.982: INFO: kubernetes-dashboard-7d464dfc59-d5sxx from kubernetes-dashboard started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 16 02:42:40.982: INFO: ckecsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.982: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep 16 02:42:40.982: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.87 before test
Sep 16 02:42:40.986: INFO: cke-lvmcsi-q44bw from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (2 container statuses recorded)
Sep 16 02:42:40.986: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 02:42:40.986: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:42:40.986: INFO: cke-lvmcsi-resizer-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.986: INFO: 	Container csi-lvm-resizer ready: true, restart count 0
Sep 16 02:42:40.986: INFO: ckecsi-runc-nc5cc from cke-storage started at 2020-09-16 02:39:48 +0000 UTC (2 container statuses recorded)
Sep 16 02:42:40.986: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 02:42:40.986: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 02:42:40.986: INFO: dashboard-metrics-scraper-6fb76cb999-mzs62 from kubernetes-dashboard started at 2020-09-16 02:39:33 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.986: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 16 02:42:40.986: INFO: cke-lvmcsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.986: INFO: 	Container csi-provisioner ready: true, restart count 1
Sep 16 02:42:40.986: INFO: ckecsi-attacher-1 from cke-storage started at 2020-09-16 02:39:48 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.986: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep 16 02:42:40.986: INFO: ckecsi-provisioner-1 from cke-storage started at 2020-09-16 02:39:48 +0000 UTC (1 container statuses recorded)
Sep 16 02:42:40.986: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-98a91821-57a7-4148-b88f-bf16cdaec030 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-98a91821-57a7-4148-b88f-bf16cdaec030 off the node 192.168.4.87
STEP: verifying the node doesn't have the label kubernetes.io/e2e-98a91821-57a7-4148-b88f-bf16cdaec030
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:47:49.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6021" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:308.083 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":277,"completed":164,"skipped":2665,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:47:49.030: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-4v9t
STEP: Creating a pod to test atomic-volume-subpath
Sep 16 02:47:49.052: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4v9t" in namespace "subpath-5354" to be "Succeeded or Failed"
Sep 16 02:47:49.054: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Pending", Reason="", readiness=false. Elapsed: 1.497402ms
Sep 16 02:47:51.056: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003801312s
Sep 16 02:47:53.058: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 4.00609462s
Sep 16 02:47:55.061: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 6.008309612s
Sep 16 02:47:57.063: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 8.010631238s
Sep 16 02:47:59.065: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 10.012949159s
Sep 16 02:48:01.068: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 12.015158931s
Sep 16 02:48:03.070: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 14.017246048s
Sep 16 02:48:05.072: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 16.019581758s
Sep 16 02:48:07.074: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 18.021852443s
Sep 16 02:48:09.077: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 20.024167068s
Sep 16 02:48:11.079: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Running", Reason="", readiness=true. Elapsed: 22.02631107s
Sep 16 02:48:13.082: INFO: Pod "pod-subpath-test-secret-4v9t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.029259986s
STEP: Saw pod success
Sep 16 02:48:13.082: INFO: Pod "pod-subpath-test-secret-4v9t" satisfied condition "Succeeded or Failed"
Sep 16 02:48:13.083: INFO: Trying to get logs from node 192.168.4.87 pod pod-subpath-test-secret-4v9t container test-container-subpath-secret-4v9t: <nil>
STEP: delete the pod
Sep 16 02:48:13.099: INFO: Waiting for pod pod-subpath-test-secret-4v9t to disappear
Sep 16 02:48:13.101: INFO: Pod pod-subpath-test-secret-4v9t no longer exists
STEP: Deleting pod pod-subpath-test-secret-4v9t
Sep 16 02:48:13.101: INFO: Deleting pod "pod-subpath-test-secret-4v9t" in namespace "subpath-5354"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:48:13.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5354" for this suite.

• [SLOW TEST:24.076 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":277,"completed":165,"skipped":2677,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:48:13.107: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 16 02:48:13.130: INFO: Waiting up to 5m0s for pod "pod-11a0736f-2209-4c31-b3a0-cfbffa547644" in namespace "emptydir-7648" to be "Succeeded or Failed"
Sep 16 02:48:13.132: INFO: Pod "pod-11a0736f-2209-4c31-b3a0-cfbffa547644": Phase="Pending", Reason="", readiness=false. Elapsed: 1.314277ms
Sep 16 02:48:15.134: INFO: Pod "pod-11a0736f-2209-4c31-b3a0-cfbffa547644": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003642484s
Sep 16 02:48:17.137: INFO: Pod "pod-11a0736f-2209-4c31-b3a0-cfbffa547644": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006153844s
STEP: Saw pod success
Sep 16 02:48:17.137: INFO: Pod "pod-11a0736f-2209-4c31-b3a0-cfbffa547644" satisfied condition "Succeeded or Failed"
Sep 16 02:48:17.138: INFO: Trying to get logs from node 192.168.4.87 pod pod-11a0736f-2209-4c31-b3a0-cfbffa547644 container test-container: <nil>
STEP: delete the pod
Sep 16 02:48:17.148: INFO: Waiting for pod pod-11a0736f-2209-4c31-b3a0-cfbffa547644 to disappear
Sep 16 02:48:17.149: INFO: Pod pod-11a0736f-2209-4c31-b3a0-cfbffa547644 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:48:17.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7648" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":166,"skipped":2700,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:48:17.154: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:48:17.176: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac2ed7f9-9ba3-4c13-b8a9-72b7fa9f21c5" in namespace "downward-api-8784" to be "Succeeded or Failed"
Sep 16 02:48:17.178: INFO: Pod "downwardapi-volume-ac2ed7f9-9ba3-4c13-b8a9-72b7fa9f21c5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.495427ms
Sep 16 02:48:19.180: INFO: Pod "downwardapi-volume-ac2ed7f9-9ba3-4c13-b8a9-72b7fa9f21c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003567425s
Sep 16 02:48:21.182: INFO: Pod "downwardapi-volume-ac2ed7f9-9ba3-4c13-b8a9-72b7fa9f21c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005936425s
STEP: Saw pod success
Sep 16 02:48:21.182: INFO: Pod "downwardapi-volume-ac2ed7f9-9ba3-4c13-b8a9-72b7fa9f21c5" satisfied condition "Succeeded or Failed"
Sep 16 02:48:21.184: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-ac2ed7f9-9ba3-4c13-b8a9-72b7fa9f21c5 container client-container: <nil>
STEP: delete the pod
Sep 16 02:48:21.193: INFO: Waiting for pod downwardapi-volume-ac2ed7f9-9ba3-4c13-b8a9-72b7fa9f21c5 to disappear
Sep 16 02:48:21.194: INFO: Pod downwardapi-volume-ac2ed7f9-9ba3-4c13-b8a9-72b7fa9f21c5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:48:21.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8784" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":167,"skipped":2725,"failed":0}
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:48:21.199: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-9964/configmap-test-a0987624-4619-49c5-9cbd-f26eece65d01
STEP: Creating a pod to test consume configMaps
Sep 16 02:48:21.221: INFO: Waiting up to 5m0s for pod "pod-configmaps-d580abc4-64a0-445f-94e0-5fe3c3df8a6c" in namespace "configmap-9964" to be "Succeeded or Failed"
Sep 16 02:48:21.223: INFO: Pod "pod-configmaps-d580abc4-64a0-445f-94e0-5fe3c3df8a6c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.461065ms
Sep 16 02:48:23.225: INFO: Pod "pod-configmaps-d580abc4-64a0-445f-94e0-5fe3c3df8a6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003844079s
Sep 16 02:48:25.228: INFO: Pod "pod-configmaps-d580abc4-64a0-445f-94e0-5fe3c3df8a6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006202362s
STEP: Saw pod success
Sep 16 02:48:25.228: INFO: Pod "pod-configmaps-d580abc4-64a0-445f-94e0-5fe3c3df8a6c" satisfied condition "Succeeded or Failed"
Sep 16 02:48:25.229: INFO: Trying to get logs from node 192.168.4.87 pod pod-configmaps-d580abc4-64a0-445f-94e0-5fe3c3df8a6c container env-test: <nil>
STEP: delete the pod
Sep 16 02:48:25.238: INFO: Waiting for pod pod-configmaps-d580abc4-64a0-445f-94e0-5fe3c3df8a6c to disappear
Sep 16 02:48:25.240: INFO: Pod pod-configmaps-d580abc4-64a0-445f-94e0-5fe3c3df8a6c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:48:25.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9964" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":277,"completed":168,"skipped":2726,"failed":0}
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:48:25.244: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-1864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1864 to expose endpoints map[]
Sep 16 02:48:25.263: INFO: Get endpoints failed (1.268312ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep 16 02:48:26.265: INFO: successfully validated that service multi-endpoint-test in namespace services-1864 exposes endpoints map[] (1.003140529s elapsed)
STEP: Creating pod pod1 in namespace services-1864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1864 to expose endpoints map[pod1:[100]]
Sep 16 02:48:29.283: INFO: successfully validated that service multi-endpoint-test in namespace services-1864 exposes endpoints map[pod1:[100]] (3.013740557s elapsed)
STEP: Creating pod pod2 in namespace services-1864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1864 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 16 02:48:32.304: INFO: successfully validated that service multi-endpoint-test in namespace services-1864 exposes endpoints map[pod1:[100] pod2:[101]] (3.017947121s elapsed)
STEP: Deleting pod pod1 in namespace services-1864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1864 to expose endpoints map[pod2:[101]]
Sep 16 02:48:33.315: INFO: successfully validated that service multi-endpoint-test in namespace services-1864 exposes endpoints map[pod2:[101]] (1.007716715s elapsed)
STEP: Deleting pod pod2 in namespace services-1864
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1864 to expose endpoints map[]
Sep 16 02:48:34.321: INFO: successfully validated that service multi-endpoint-test in namespace services-1864 exposes endpoints map[] (1.003817174s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:48:34.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1864" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:9.090 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":277,"completed":169,"skipped":2728,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:48:34.334: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Sep 16 02:48:34.363: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:48:37.923: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:48:50.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4877" for this suite.

• [SLOW TEST:15.786 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":277,"completed":170,"skipped":2740,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:48:50.120: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:48:54.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3496" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":171,"skipped":2761,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:48:54.154: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:49:21.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9610" for this suite.

• [SLOW TEST:27.040 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":277,"completed":172,"skipped":2763,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:49:21.194: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:49:21.213: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:49:27.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3882" for this suite.

• [SLOW TEST:6.124 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":277,"completed":173,"skipped":2791,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:49:27.318: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 16 02:49:27.337: INFO: Waiting up to 5m0s for pod "pod-ad3b820b-8721-4858-bad1-510efd7679d4" in namespace "emptydir-9065" to be "Succeeded or Failed"
Sep 16 02:49:27.339: INFO: Pod "pod-ad3b820b-8721-4858-bad1-510efd7679d4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.31591ms
Sep 16 02:49:29.341: INFO: Pod "pod-ad3b820b-8721-4858-bad1-510efd7679d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003379648s
Sep 16 02:49:31.343: INFO: Pod "pod-ad3b820b-8721-4858-bad1-510efd7679d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005632s
STEP: Saw pod success
Sep 16 02:49:31.343: INFO: Pod "pod-ad3b820b-8721-4858-bad1-510efd7679d4" satisfied condition "Succeeded or Failed"
Sep 16 02:49:31.344: INFO: Trying to get logs from node 192.168.4.87 pod pod-ad3b820b-8721-4858-bad1-510efd7679d4 container test-container: <nil>
STEP: delete the pod
Sep 16 02:49:31.353: INFO: Waiting for pod pod-ad3b820b-8721-4858-bad1-510efd7679d4 to disappear
Sep 16 02:49:31.355: INFO: Pod pod-ad3b820b-8721-4858-bad1-510efd7679d4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:49:31.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9065" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":174,"skipped":2797,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:49:31.359: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:49:31.388: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b8883cb-b3bf-49cc-add2-f7bb35b19042" in namespace "downward-api-6134" to be "Succeeded or Failed"
Sep 16 02:49:31.393: INFO: Pod "downwardapi-volume-8b8883cb-b3bf-49cc-add2-f7bb35b19042": Phase="Pending", Reason="", readiness=false. Elapsed: 4.617986ms
Sep 16 02:49:33.395: INFO: Pod "downwardapi-volume-8b8883cb-b3bf-49cc-add2-f7bb35b19042": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006583849s
Sep 16 02:49:35.397: INFO: Pod "downwardapi-volume-8b8883cb-b3bf-49cc-add2-f7bb35b19042": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008995868s
STEP: Saw pod success
Sep 16 02:49:35.397: INFO: Pod "downwardapi-volume-8b8883cb-b3bf-49cc-add2-f7bb35b19042" satisfied condition "Succeeded or Failed"
Sep 16 02:49:35.399: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-8b8883cb-b3bf-49cc-add2-f7bb35b19042 container client-container: <nil>
STEP: delete the pod
Sep 16 02:49:35.408: INFO: Waiting for pod downwardapi-volume-8b8883cb-b3bf-49cc-add2-f7bb35b19042 to disappear
Sep 16 02:49:35.409: INFO: Pod downwardapi-volume-8b8883cb-b3bf-49cc-add2-f7bb35b19042 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:49:35.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6134" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":175,"skipped":2811,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:49:35.413: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:49:35.767: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 02:49:37.773: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821375, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821375, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821375, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821375, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 02:49:39.775: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821375, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821375, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821375, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821375, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:49:42.779: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:49:42.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9450" for this suite.
STEP: Destroying namespace "webhook-9450-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.408 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":277,"completed":176,"skipped":2816,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:49:42.822: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 16 02:49:42.849: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4362 /api/v1/namespaces/watch-4362/configmaps/e2e-watch-test-resource-version 32aec333-8ecc-43e3-ad7e-ac4ca090bfd5 25754 0 2020-09-16 02:49:42 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-09-16 02:49:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:49:42.849: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4362 /api/v1/namespaces/watch-4362/configmaps/e2e-watch-test-resource-version 32aec333-8ecc-43e3-ad7e-ac4ca090bfd5 25755 0 2020-09-16 02:49:42 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-09-16 02:49:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:49:42.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4362" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":277,"completed":177,"skipped":2827,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:49:42.854: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-8d02f9c0-2cd8-4644-9d39-0786daba64bc
STEP: Creating a pod to test consume configMaps
Sep 16 02:49:42.876: INFO: Waiting up to 5m0s for pod "pod-configmaps-6431ae5c-1b6a-4ff4-b42d-3a1e03a2334f" in namespace "configmap-4478" to be "Succeeded or Failed"
Sep 16 02:49:42.877: INFO: Pod "pod-configmaps-6431ae5c-1b6a-4ff4-b42d-3a1e03a2334f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.325389ms
Sep 16 02:49:44.879: INFO: Pod "pod-configmaps-6431ae5c-1b6a-4ff4-b42d-3a1e03a2334f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003571481s
Sep 16 02:49:46.882: INFO: Pod "pod-configmaps-6431ae5c-1b6a-4ff4-b42d-3a1e03a2334f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006155173s
STEP: Saw pod success
Sep 16 02:49:46.882: INFO: Pod "pod-configmaps-6431ae5c-1b6a-4ff4-b42d-3a1e03a2334f" satisfied condition "Succeeded or Failed"
Sep 16 02:49:46.884: INFO: Trying to get logs from node 192.168.4.87 pod pod-configmaps-6431ae5c-1b6a-4ff4-b42d-3a1e03a2334f container configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:49:46.893: INFO: Waiting for pod pod-configmaps-6431ae5c-1b6a-4ff4-b42d-3a1e03a2334f to disappear
Sep 16 02:49:46.895: INFO: Pod pod-configmaps-6431ae5c-1b6a-4ff4-b42d-3a1e03a2334f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:49:46.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4478" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":178,"skipped":2844,"failed":0}
SS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:49:46.899: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:49:46.915: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 16 02:49:48.931: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:49:49.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3284" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":277,"completed":179,"skipped":2846,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:49:49.939: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 16 02:49:53.979: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:49:53.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6404" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":277,"completed":180,"skipped":2861,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:49:53.990: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Sep 16 02:49:54.005: INFO: namespace kubectl-5042
Sep 16 02:49:54.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-5042'
Sep 16 02:49:57.358: INFO: stderr: ""
Sep 16 02:49:57.358: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Sep 16 02:49:58.361: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:49:58.361: INFO: Found 0 / 1
Sep 16 02:49:59.361: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:49:59.361: INFO: Found 0 / 1
Sep 16 02:50:00.361: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:50:00.361: INFO: Found 1 / 1
Sep 16 02:50:00.361: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 16 02:50:00.362: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 16 02:50:00.362: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 16 02:50:00.362: INFO: wait on agnhost-master startup in kubectl-5042 
Sep 16 02:50:00.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 logs agnhost-master-zl2hw agnhost-master --namespace=kubectl-5042'
Sep 16 02:50:00.441: INFO: stderr: ""
Sep 16 02:50:00.441: INFO: stdout: "Paused\n"
STEP: exposing RC
Sep 16 02:50:00.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5042'
Sep 16 02:50:00.524: INFO: stderr: ""
Sep 16 02:50:00.524: INFO: stdout: "service/rm2 exposed\n"
Sep 16 02:50:00.526: INFO: Service rm2 in namespace kubectl-5042 found.
STEP: exposing service
Sep 16 02:50:02.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5042'
Sep 16 02:50:02.608: INFO: stderr: ""
Sep 16 02:50:02.608: INFO: stdout: "service/rm3 exposed\n"
Sep 16 02:50:02.610: INFO: Service rm3 in namespace kubectl-5042 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:50:04.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5042" for this suite.

• [SLOW TEST:10.628 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1119
    should create services for rc  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":277,"completed":181,"skipped":2920,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:50:04.618: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Sep 16 02:50:04.637: INFO: Waiting up to 5m0s for pod "var-expansion-0e954454-4116-423b-810e-3741ff8338d0" in namespace "var-expansion-266" to be "Succeeded or Failed"
Sep 16 02:50:04.639: INFO: Pod "var-expansion-0e954454-4116-423b-810e-3741ff8338d0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.278462ms
Sep 16 02:50:06.640: INFO: Pod "var-expansion-0e954454-4116-423b-810e-3741ff8338d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003189132s
Sep 16 02:50:08.643: INFO: Pod "var-expansion-0e954454-4116-423b-810e-3741ff8338d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005471794s
STEP: Saw pod success
Sep 16 02:50:08.643: INFO: Pod "var-expansion-0e954454-4116-423b-810e-3741ff8338d0" satisfied condition "Succeeded or Failed"
Sep 16 02:50:08.644: INFO: Trying to get logs from node 192.168.4.87 pod var-expansion-0e954454-4116-423b-810e-3741ff8338d0 container dapi-container: <nil>
STEP: delete the pod
Sep 16 02:50:08.655: INFO: Waiting for pod var-expansion-0e954454-4116-423b-810e-3741ff8338d0 to disappear
Sep 16 02:50:08.656: INFO: Pod var-expansion-0e954454-4116-423b-810e-3741ff8338d0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:50:08.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-266" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":277,"completed":182,"skipped":2938,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:50:08.661: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 16 02:50:13.197: INFO: Successfully updated pod "annotationupdate0abf8607-20e2-46d5-bf6f-28c8d545c1b8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:50:17.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7077" for this suite.

• [SLOW TEST:8.558 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":183,"skipped":2946,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:50:17.220: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-937be857-57e6-4985-936d-71c57349db1f
STEP: Creating a pod to test consume secrets
Sep 16 02:50:17.243: INFO: Waiting up to 5m0s for pod "pod-secrets-7eb95d92-e185-470a-9170-a3143ead7f47" in namespace "secrets-5524" to be "Succeeded or Failed"
Sep 16 02:50:17.244: INFO: Pod "pod-secrets-7eb95d92-e185-470a-9170-a3143ead7f47": Phase="Pending", Reason="", readiness=false. Elapsed: 1.2605ms
Sep 16 02:50:19.246: INFO: Pod "pod-secrets-7eb95d92-e185-470a-9170-a3143ead7f47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00323582s
Sep 16 02:50:21.249: INFO: Pod "pod-secrets-7eb95d92-e185-470a-9170-a3143ead7f47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005676306s
STEP: Saw pod success
Sep 16 02:50:21.249: INFO: Pod "pod-secrets-7eb95d92-e185-470a-9170-a3143ead7f47" satisfied condition "Succeeded or Failed"
Sep 16 02:50:21.250: INFO: Trying to get logs from node 192.168.4.87 pod pod-secrets-7eb95d92-e185-470a-9170-a3143ead7f47 container secret-volume-test: <nil>
STEP: delete the pod
Sep 16 02:50:21.259: INFO: Waiting for pod pod-secrets-7eb95d92-e185-470a-9170-a3143ead7f47 to disappear
Sep 16 02:50:21.260: INFO: Pod pod-secrets-7eb95d92-e185-470a-9170-a3143ead7f47 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:50:21.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5524" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":184,"skipped":2958,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:50:21.266: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 16 02:50:21.286: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:50:28.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3184" for this suite.

• [SLOW TEST:7.026 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":277,"completed":185,"skipped":2986,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:50:28.292: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:50:28.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2781" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":277,"completed":186,"skipped":3037,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:50:28.325: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Sep 16 02:50:28.344: INFO: Created pod &Pod{ObjectMeta:{dns-8276  dns-8276 /api/v1/namespaces/dns-8276/pods/dns-8276 7f0bea28-4dbf-4997-8fba-a1f36f0908e6 26256 0 2020-09-16 02:50:28 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2020-09-16 02:50:28 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h6f9v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h6f9v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h6f9v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 16 02:50:28.346: INFO: The status of Pod dns-8276 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:50:30.348: INFO: The status of Pod dns-8276 is Pending, waiting for it to be Running (with Ready = true)
Sep 16 02:50:32.348: INFO: The status of Pod dns-8276 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Sep 16 02:50:32.348: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8276 PodName:dns-8276 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:50:32.348: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Verifying customized DNS server is configured on pod...
Sep 16 02:50:32.468: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8276 PodName:dns-8276 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 02:50:32.468: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 02:50:32.579: INFO: Deleting pod dns-8276...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:50:32.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8276" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":277,"completed":187,"skipped":3048,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:50:32.590: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-jt6pw in namespace proxy-6651
I0916 02:50:32.613564      26 runners.go:190] Created replication controller with name: proxy-service-jt6pw, namespace: proxy-6651, replica count: 1
I0916 02:50:33.663894      26 runners.go:190] proxy-service-jt6pw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0916 02:50:34.664068      26 runners.go:190] proxy-service-jt6pw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0916 02:50:35.664223      26 runners.go:190] proxy-service-jt6pw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0916 02:50:36.664404      26 runners.go:190] proxy-service-jt6pw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0916 02:50:37.664571      26 runners.go:190] proxy-service-jt6pw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0916 02:50:38.664739      26 runners.go:190] proxy-service-jt6pw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0916 02:50:39.664900      26 runners.go:190] proxy-service-jt6pw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 16 02:50:39.666: INFO: setup took 7.061140375s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 16 02:50:39.670: INFO: (0) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 2.986318ms)
Sep 16 02:50:39.674: INFO: (0) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 7.253712ms)
Sep 16 02:50:39.675: INFO: (0) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 8.241082ms)
Sep 16 02:50:39.675: INFO: (0) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 8.536062ms)
Sep 16 02:50:39.675: INFO: (0) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 8.712003ms)
Sep 16 02:50:39.675: INFO: (0) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 8.763939ms)
Sep 16 02:50:39.675: INFO: (0) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 8.673966ms)
Sep 16 02:50:39.676: INFO: (0) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 8.982807ms)
Sep 16 02:50:39.676: INFO: (0) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 9.235327ms)
Sep 16 02:50:39.676: INFO: (0) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 9.556009ms)
Sep 16 02:50:39.676: INFO: (0) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 9.542021ms)
Sep 16 02:50:39.677: INFO: (0) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 10.256578ms)
Sep 16 02:50:39.677: INFO: (0) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 10.224121ms)
Sep 16 02:50:39.680: INFO: (0) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 13.768274ms)
Sep 16 02:50:39.680: INFO: (0) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 13.707906ms)
Sep 16 02:50:39.682: INFO: (0) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 15.071552ms)
Sep 16 02:50:39.684: INFO: (1) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 2.569864ms)
Sep 16 02:50:39.685: INFO: (1) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.272169ms)
Sep 16 02:50:39.685: INFO: (1) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 3.409038ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 3.759408ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 3.765648ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 3.769423ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 3.883852ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 3.895463ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 4.055585ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 4.092698ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.119404ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.073591ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.037388ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 4.017717ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 4.057366ms)
Sep 16 02:50:39.686: INFO: (1) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 4.144447ms)
Sep 16 02:50:39.689: INFO: (2) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 3.258444ms)
Sep 16 02:50:39.689: INFO: (2) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 3.245731ms)
Sep 16 02:50:39.689: INFO: (2) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 3.288705ms)
Sep 16 02:50:39.689: INFO: (2) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 3.35344ms)
Sep 16 02:50:39.689: INFO: (2) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 3.409893ms)
Sep 16 02:50:39.689: INFO: (2) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 3.336146ms)
Sep 16 02:50:39.689: INFO: (2) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 3.299848ms)
Sep 16 02:50:39.689: INFO: (2) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 3.317563ms)
Sep 16 02:50:39.690: INFO: (2) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.098747ms)
Sep 16 02:50:39.690: INFO: (2) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.17325ms)
Sep 16 02:50:39.690: INFO: (2) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.241333ms)
Sep 16 02:50:39.690: INFO: (2) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 4.227096ms)
Sep 16 02:50:39.690: INFO: (2) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.25105ms)
Sep 16 02:50:39.691: INFO: (2) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 4.685589ms)
Sep 16 02:50:39.691: INFO: (2) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 4.827559ms)
Sep 16 02:50:39.691: INFO: (2) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 4.837905ms)
Sep 16 02:50:39.694: INFO: (3) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 2.985993ms)
Sep 16 02:50:39.694: INFO: (3) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 2.980697ms)
Sep 16 02:50:39.694: INFO: (3) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 3.108239ms)
Sep 16 02:50:39.694: INFO: (3) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 3.271003ms)
Sep 16 02:50:39.694: INFO: (3) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 3.494405ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.615081ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 3.706416ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 3.671467ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 3.800336ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 3.725566ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 3.808845ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 3.782243ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.825672ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.868183ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 3.775907ms)
Sep 16 02:50:39.695: INFO: (3) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 3.900565ms)
Sep 16 02:50:39.702: INFO: (4) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 7.176165ms)
Sep 16 02:50:39.702: INFO: (4) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 7.40349ms)
Sep 16 02:50:39.702: INFO: (4) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 7.378373ms)
Sep 16 02:50:39.702: INFO: (4) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 7.489792ms)
Sep 16 02:50:39.702: INFO: (4) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 7.461909ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 7.793054ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 7.862752ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 7.850996ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 7.890231ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 7.850425ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 7.900937ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 8.06167ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 8.095596ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 8.167051ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 8.182748ms)
Sep 16 02:50:39.703: INFO: (4) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 8.196599ms)
Sep 16 02:50:39.706: INFO: (5) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 3.01904ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.362641ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 3.306357ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 3.442653ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 3.494986ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 3.491396ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 3.571893ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 3.728361ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 3.823691ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 3.774818ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.828659ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 3.868678ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.856685ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.94324ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 3.862506ms)
Sep 16 02:50:39.707: INFO: (5) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 4.096397ms)
Sep 16 02:50:39.710: INFO: (6) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 2.765504ms)
Sep 16 02:50:39.710: INFO: (6) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 2.784202ms)
Sep 16 02:50:39.710: INFO: (6) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 2.938738ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 3.249128ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 3.290991ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 3.328947ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 3.345999ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 3.298481ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.474378ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.702342ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 3.695581ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 3.669168ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 3.650659ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 3.751579ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 3.692339ms)
Sep 16 02:50:39.711: INFO: (6) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.730788ms)
Sep 16 02:50:39.713: INFO: (7) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 1.92549ms)
Sep 16 02:50:39.714: INFO: (7) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 2.82082ms)
Sep 16 02:50:39.714: INFO: (7) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 2.799384ms)
Sep 16 02:50:39.714: INFO: (7) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 3.003817ms)
Sep 16 02:50:39.714: INFO: (7) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 3.07645ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 3.463766ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 3.49769ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.676009ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 3.707479ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 3.655382ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 3.686776ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 3.726448ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 3.731276ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.742609ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.79501ms)
Sep 16 02:50:39.715: INFO: (7) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 3.775277ms)
Sep 16 02:50:39.719: INFO: (8) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 3.83457ms)
Sep 16 02:50:39.719: INFO: (8) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.118202ms)
Sep 16 02:50:39.719: INFO: (8) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 4.133371ms)
Sep 16 02:50:39.720: INFO: (8) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.329188ms)
Sep 16 02:50:39.720: INFO: (8) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.303877ms)
Sep 16 02:50:39.720: INFO: (8) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 4.396511ms)
Sep 16 02:50:39.720: INFO: (8) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.545212ms)
Sep 16 02:50:39.720: INFO: (8) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 4.603689ms)
Sep 16 02:50:39.720: INFO: (8) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 4.64449ms)
Sep 16 02:50:39.720: INFO: (8) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 4.585002ms)
Sep 16 02:50:39.720: INFO: (8) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 4.704269ms)
Sep 16 02:50:39.721: INFO: (8) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 5.719415ms)
Sep 16 02:50:39.721: INFO: (8) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 5.847901ms)
Sep 16 02:50:39.721: INFO: (8) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 5.88823ms)
Sep 16 02:50:39.721: INFO: (8) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 5.864152ms)
Sep 16 02:50:39.721: INFO: (8) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 5.899665ms)
Sep 16 02:50:39.723: INFO: (9) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 1.978535ms)
Sep 16 02:50:39.724: INFO: (9) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 2.986314ms)
Sep 16 02:50:39.724: INFO: (9) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 3.046169ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 3.440182ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 3.804683ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 3.761767ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.844595ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 3.828795ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 3.84816ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 3.823181ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 3.84783ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 4.035903ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.100801ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.074796ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 4.180951ms)
Sep 16 02:50:39.725: INFO: (9) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 4.234833ms)
Sep 16 02:50:39.727: INFO: (10) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 1.933275ms)
Sep 16 02:50:39.729: INFO: (10) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.691741ms)
Sep 16 02:50:39.729: INFO: (10) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.77934ms)
Sep 16 02:50:39.729: INFO: (10) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 3.860631ms)
Sep 16 02:50:39.729: INFO: (10) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 3.855908ms)
Sep 16 02:50:39.730: INFO: (10) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 4.624666ms)
Sep 16 02:50:39.730: INFO: (10) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.590346ms)
Sep 16 02:50:39.730: INFO: (10) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 4.6934ms)
Sep 16 02:50:39.731: INFO: (10) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 5.180368ms)
Sep 16 02:50:39.731: INFO: (10) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 5.214054ms)
Sep 16 02:50:39.731: INFO: (10) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 5.272496ms)
Sep 16 02:50:39.731: INFO: (10) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 5.226855ms)
Sep 16 02:50:39.731: INFO: (10) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 5.275516ms)
Sep 16 02:50:39.731: INFO: (10) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 5.258027ms)
Sep 16 02:50:39.731: INFO: (10) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 5.325261ms)
Sep 16 02:50:39.731: INFO: (10) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 5.295854ms)
Sep 16 02:50:39.734: INFO: (11) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 2.769405ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 3.636506ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 3.693571ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 3.736908ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.677597ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 3.732748ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 4.330275ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 4.356033ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.496617ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 4.493316ms)
Sep 16 02:50:39.735: INFO: (11) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 4.457986ms)
Sep 16 02:50:39.736: INFO: (11) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.544127ms)
Sep 16 02:50:39.736: INFO: (11) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 4.529055ms)
Sep 16 02:50:39.736: INFO: (11) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 4.545438ms)
Sep 16 02:50:39.736: INFO: (11) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 4.53557ms)
Sep 16 02:50:39.736: INFO: (11) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 4.748018ms)
Sep 16 02:50:39.738: INFO: (12) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 1.860029ms)
Sep 16 02:50:39.739: INFO: (12) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.21036ms)
Sep 16 02:50:39.739: INFO: (12) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 3.313033ms)
Sep 16 02:50:39.739: INFO: (12) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 3.538726ms)
Sep 16 02:50:39.740: INFO: (12) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 4.406936ms)
Sep 16 02:50:39.740: INFO: (12) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 4.58505ms)
Sep 16 02:50:39.740: INFO: (12) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 4.499197ms)
Sep 16 02:50:39.740: INFO: (12) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.582904ms)
Sep 16 02:50:39.740: INFO: (12) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 4.510535ms)
Sep 16 02:50:39.740: INFO: (12) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 4.628875ms)
Sep 16 02:50:39.741: INFO: (12) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 4.723669ms)
Sep 16 02:50:39.741: INFO: (12) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 4.810471ms)
Sep 16 02:50:39.741: INFO: (12) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 4.723043ms)
Sep 16 02:50:39.741: INFO: (12) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.836206ms)
Sep 16 02:50:39.741: INFO: (12) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 4.92468ms)
Sep 16 02:50:39.741: INFO: (12) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 4.813641ms)
Sep 16 02:50:39.743: INFO: (13) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 2.339475ms)
Sep 16 02:50:39.743: INFO: (13) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 2.528025ms)
Sep 16 02:50:39.744: INFO: (13) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 3.510739ms)
Sep 16 02:50:39.745: INFO: (13) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.581194ms)
Sep 16 02:50:39.745: INFO: (13) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.63668ms)
Sep 16 02:50:39.745: INFO: (13) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 3.903006ms)
Sep 16 02:50:39.745: INFO: (13) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 3.955757ms)
Sep 16 02:50:39.745: INFO: (13) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 4.197067ms)
Sep 16 02:50:39.745: INFO: (13) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 4.094983ms)
Sep 16 02:50:39.745: INFO: (13) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.157182ms)
Sep 16 02:50:39.745: INFO: (13) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.206345ms)
Sep 16 02:50:39.745: INFO: (13) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 4.354393ms)
Sep 16 02:50:39.746: INFO: (13) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 4.596427ms)
Sep 16 02:50:39.746: INFO: (13) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 4.730017ms)
Sep 16 02:50:39.746: INFO: (13) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 4.611473ms)
Sep 16 02:50:39.746: INFO: (13) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 4.665066ms)
Sep 16 02:50:39.749: INFO: (14) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.590108ms)
Sep 16 02:50:39.749: INFO: (14) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.63983ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 4.735353ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 4.881213ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 4.884335ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 4.994828ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 4.913984ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 5.070095ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 4.965098ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 5.020082ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 5.076204ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 5.148388ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 5.156492ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 5.288589ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 5.310404ms)
Sep 16 02:50:39.751: INFO: (14) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 5.323763ms)
Sep 16 02:50:39.756: INFO: (15) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 3.952266ms)
Sep 16 02:50:39.756: INFO: (15) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 4.663226ms)
Sep 16 02:50:39.756: INFO: (15) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 4.139595ms)
Sep 16 02:50:39.756: INFO: (15) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 5.039116ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 4.816979ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 4.676787ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 4.884572ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 5.016006ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 6.015082ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 6.33128ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 5.503603ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 6.01465ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 5.633ms)
Sep 16 02:50:39.757: INFO: (15) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 5.771373ms)
Sep 16 02:50:39.758: INFO: (15) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 6.034066ms)
Sep 16 02:50:39.758: INFO: (15) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 5.940002ms)
Sep 16 02:50:39.761: INFO: (16) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 3.123992ms)
Sep 16 02:50:39.761: INFO: (16) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 2.837151ms)
Sep 16 02:50:39.762: INFO: (16) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.060444ms)
Sep 16 02:50:39.762: INFO: (16) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 3.710598ms)
Sep 16 02:50:39.762: INFO: (16) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 2.922338ms)
Sep 16 02:50:39.762: INFO: (16) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 3.955488ms)
Sep 16 02:50:39.762: INFO: (16) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 3.175451ms)
Sep 16 02:50:39.762: INFO: (16) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 3.882322ms)
Sep 16 02:50:39.762: INFO: (16) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 3.364698ms)
Sep 16 02:50:39.762: INFO: (16) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.969479ms)
Sep 16 02:50:39.763: INFO: (16) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 5.186248ms)
Sep 16 02:50:39.763: INFO: (16) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 3.999346ms)
Sep 16 02:50:39.763: INFO: (16) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 4.814ms)
Sep 16 02:50:39.763: INFO: (16) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 4.215496ms)
Sep 16 02:50:39.763: INFO: (16) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 4.641941ms)
Sep 16 02:50:39.763: INFO: (16) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 5.260342ms)
Sep 16 02:50:39.766: INFO: (17) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 3.170774ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 3.580495ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 3.599276ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.698409ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 4.115845ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 4.180032ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 4.200726ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 4.250569ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 4.146904ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 4.291511ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 4.252955ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 4.150158ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 4.154127ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.228934ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.217951ms)
Sep 16 02:50:39.767: INFO: (17) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 4.255988ms)
Sep 16 02:50:39.770: INFO: (18) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 2.009411ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 3.914083ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 4.421646ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 4.485378ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 4.539959ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 4.619731ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.75611ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 4.772458ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 4.81627ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 4.768475ms)
Sep 16 02:50:39.772: INFO: (18) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 4.791419ms)
Sep 16 02:50:39.773: INFO: (18) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 5.09421ms)
Sep 16 02:50:39.773: INFO: (18) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 5.104821ms)
Sep 16 02:50:39.773: INFO: (18) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 5.057853ms)
Sep 16 02:50:39.773: INFO: (18) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 5.14718ms)
Sep 16 02:50:39.773: INFO: (18) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 5.11646ms)
Sep 16 02:50:39.775: INFO: (19) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:443/proxy/tlsrewritem... (200; 2.116166ms)
Sep 16 02:50:39.775: INFO: (19) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:462/proxy/: tls qux (200; 2.155023ms)
Sep 16 02:50:39.775: INFO: (19) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">... (200; 2.543922ms)
Sep 16 02:50:39.776: INFO: (19) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 2.813872ms)
Sep 16 02:50:39.776: INFO: (19) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 2.881769ms)
Sep 16 02:50:39.776: INFO: (19) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:162/proxy/: bar (200; 2.897441ms)
Sep 16 02:50:39.776: INFO: (19) /api/v1/namespaces/proxy-6651/pods/https:proxy-service-jt6pw-6k6lv:460/proxy/: tls baz (200; 2.916569ms)
Sep 16 02:50:39.776: INFO: (19) /api/v1/namespaces/proxy-6651/pods/http:proxy-service-jt6pw-6k6lv:160/proxy/: foo (200; 3.00131ms)
Sep 16 02:50:39.776: INFO: (19) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname2/proxy/: bar (200; 3.407715ms)
Sep 16 02:50:39.776: INFO: (19) /api/v1/namespaces/proxy-6651/services/http:proxy-service-jt6pw:portname1/proxy/: foo (200; 3.677967ms)
Sep 16 02:50:39.777: INFO: (19) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname1/proxy/: foo (200; 3.702731ms)
Sep 16 02:50:39.777: INFO: (19) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname1/proxy/: tls baz (200; 3.719195ms)
Sep 16 02:50:39.777: INFO: (19) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv/proxy/rewriteme">test</a> (200; 3.682755ms)
Sep 16 02:50:39.777: INFO: (19) /api/v1/namespaces/proxy-6651/services/proxy-service-jt6pw:portname2/proxy/: bar (200; 3.688901ms)
Sep 16 02:50:39.777: INFO: (19) /api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/: <a href="/api/v1/namespaces/proxy-6651/pods/proxy-service-jt6pw-6k6lv:1080/proxy/rewriteme">test<... (200; 3.679573ms)
Sep 16 02:50:39.777: INFO: (19) /api/v1/namespaces/proxy-6651/services/https:proxy-service-jt6pw:tlsportname2/proxy/: tls qux (200; 3.772555ms)
STEP: deleting ReplicationController proxy-service-jt6pw in namespace proxy-6651, will wait for the garbage collector to delete the pods
Sep 16 02:50:39.832: INFO: Deleting ReplicationController proxy-service-jt6pw took: 3.788016ms
Sep 16 02:50:40.232: INFO: Terminating ReplicationController proxy-service-jt6pw pods took: 400.170605ms
[AfterEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:50:43.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6651" for this suite.

• [SLOW TEST:10.647 seconds]
[sig-network] Proxy
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":277,"completed":188,"skipped":3071,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:50:43.237: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Sep 16 02:50:43.252: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:51:00.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6307" for this suite.

• [SLOW TEST:17.459 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":277,"completed":189,"skipped":3084,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:51:00.696: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 16 02:51:00.720: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9156 /api/v1/namespaces/watch-9156/configmaps/e2e-watch-test-label-changed cb8ca9b6-02af-47b2-8358-cfa1bca117f5 26483 0 2020-09-16 02:51:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-16 02:51:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:51:00.720: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9156 /api/v1/namespaces/watch-9156/configmaps/e2e-watch-test-label-changed cb8ca9b6-02af-47b2-8358-cfa1bca117f5 26484 0 2020-09-16 02:51:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-16 02:51:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:51:00.721: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9156 /api/v1/namespaces/watch-9156/configmaps/e2e-watch-test-label-changed cb8ca9b6-02af-47b2-8358-cfa1bca117f5 26485 0 2020-09-16 02:51:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-16 02:51:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 16 02:51:10.733: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9156 /api/v1/namespaces/watch-9156/configmaps/e2e-watch-test-label-changed cb8ca9b6-02af-47b2-8358-cfa1bca117f5 26518 0 2020-09-16 02:51:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-16 02:51:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:51:10.734: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9156 /api/v1/namespaces/watch-9156/configmaps/e2e-watch-test-label-changed cb8ca9b6-02af-47b2-8358-cfa1bca117f5 26519 0 2020-09-16 02:51:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-16 02:51:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 02:51:10.734: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9156 /api/v1/namespaces/watch-9156/configmaps/e2e-watch-test-label-changed cb8ca9b6-02af-47b2-8358-cfa1bca117f5 26520 0 2020-09-16 02:51:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-16 02:51:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:51:10.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9156" for this suite.

• [SLOW TEST:10.042 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":277,"completed":190,"skipped":3089,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:51:10.738: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 02:51:11.510: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 02:51:13.515: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821471, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821471, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821471, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821471, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 02:51:16.521: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:51:16.523: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5926-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:51:17.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1058" for this suite.
STEP: Destroying namespace "webhook-1058-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.962 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":277,"completed":191,"skipped":3137,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:51:17.701: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-227d0087-e51f-4b28-8f1f-67207e349bed
STEP: Creating a pod to test consume configMaps
Sep 16 02:51:17.724: INFO: Waiting up to 5m0s for pod "pod-configmaps-e323ab39-4167-4df3-b0aa-46acaadea2e8" in namespace "configmap-4375" to be "Succeeded or Failed"
Sep 16 02:51:17.726: INFO: Pod "pod-configmaps-e323ab39-4167-4df3-b0aa-46acaadea2e8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.301696ms
Sep 16 02:51:19.728: INFO: Pod "pod-configmaps-e323ab39-4167-4df3-b0aa-46acaadea2e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003615989s
Sep 16 02:51:21.730: INFO: Pod "pod-configmaps-e323ab39-4167-4df3-b0aa-46acaadea2e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006044082s
Sep 16 02:51:23.733: INFO: Pod "pod-configmaps-e323ab39-4167-4df3-b0aa-46acaadea2e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008409166s
STEP: Saw pod success
Sep 16 02:51:23.733: INFO: Pod "pod-configmaps-e323ab39-4167-4df3-b0aa-46acaadea2e8" satisfied condition "Succeeded or Failed"
Sep 16 02:51:23.734: INFO: Trying to get logs from node 192.168.4.87 pod pod-configmaps-e323ab39-4167-4df3-b0aa-46acaadea2e8 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:51:23.745: INFO: Waiting for pod pod-configmaps-e323ab39-4167-4df3-b0aa-46acaadea2e8 to disappear
Sep 16 02:51:23.746: INFO: Pod pod-configmaps-e323ab39-4167-4df3-b0aa-46acaadea2e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:51:23.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4375" for this suite.

• [SLOW TEST:6.051 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":192,"skipped":3138,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:51:23.752: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:51:39.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3902" for this suite.

• [SLOW TEST:16.083 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":277,"completed":193,"skipped":3140,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:51:39.835: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-20310aeb-ed08-4140-b374-2cb6abd92c2a
STEP: Creating a pod to test consume configMaps
Sep 16 02:51:39.855: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c1dfd5bd-97a9-4632-a245-9153dc47c4ea" in namespace "projected-8767" to be "Succeeded or Failed"
Sep 16 02:51:39.857: INFO: Pod "pod-projected-configmaps-c1dfd5bd-97a9-4632-a245-9153dc47c4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 1.293612ms
Sep 16 02:51:41.859: INFO: Pod "pod-projected-configmaps-c1dfd5bd-97a9-4632-a245-9153dc47c4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003399395s
Sep 16 02:51:43.861: INFO: Pod "pod-projected-configmaps-c1dfd5bd-97a9-4632-a245-9153dc47c4ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006093309s
STEP: Saw pod success
Sep 16 02:51:43.861: INFO: Pod "pod-projected-configmaps-c1dfd5bd-97a9-4632-a245-9153dc47c4ea" satisfied condition "Succeeded or Failed"
Sep 16 02:51:43.863: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-configmaps-c1dfd5bd-97a9-4632-a245-9153dc47c4ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 02:51:43.872: INFO: Waiting for pod pod-projected-configmaps-c1dfd5bd-97a9-4632-a245-9153dc47c4ea to disappear
Sep 16 02:51:43.874: INFO: Pod pod-projected-configmaps-c1dfd5bd-97a9-4632-a245-9153dc47c4ea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:51:43.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8767" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":194,"skipped":3146,"failed":0}
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:51:43.878: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 16 02:51:51.916: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 16 02:51:51.918: INFO: Pod pod-with-poststart-http-hook still exists
Sep 16 02:51:53.918: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 16 02:51:53.921: INFO: Pod pod-with-poststart-http-hook still exists
Sep 16 02:51:55.918: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 16 02:51:55.920: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:51:55.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-854" for this suite.

• [SLOW TEST:12.047 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":277,"completed":195,"skipped":3152,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:51:55.925: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 16 02:51:55.944: INFO: Waiting up to 5m0s for pod "pod-a04e9082-f03e-4620-b99e-3db60eca83e8" in namespace "emptydir-8037" to be "Succeeded or Failed"
Sep 16 02:51:55.945: INFO: Pod "pod-a04e9082-f03e-4620-b99e-3db60eca83e8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.176268ms
Sep 16 02:51:57.948: INFO: Pod "pod-a04e9082-f03e-4620-b99e-3db60eca83e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003570038s
Sep 16 02:51:59.950: INFO: Pod "pod-a04e9082-f03e-4620-b99e-3db60eca83e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005814188s
STEP: Saw pod success
Sep 16 02:51:59.950: INFO: Pod "pod-a04e9082-f03e-4620-b99e-3db60eca83e8" satisfied condition "Succeeded or Failed"
Sep 16 02:51:59.951: INFO: Trying to get logs from node 192.168.4.87 pod pod-a04e9082-f03e-4620-b99e-3db60eca83e8 container test-container: <nil>
STEP: delete the pod
Sep 16 02:51:59.962: INFO: Waiting for pod pod-a04e9082-f03e-4620-b99e-3db60eca83e8 to disappear
Sep 16 02:51:59.963: INFO: Pod pod-a04e9082-f03e-4620-b99e-3db60eca83e8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:51:59.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8037" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":196,"skipped":3153,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:51:59.968: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-41
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Sep 16 02:51:59.989: INFO: Found 0 stateful pods, waiting for 3
Sep 16 02:52:09.992: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:52:09.992: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:52:09.992: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
Sep 16 02:52:19.992: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:52:19.992: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:52:19.992: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 16 02:52:20.016: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 16 02:52:30.042: INFO: Updating stateful set ss2
Sep 16 02:52:30.045: INFO: Waiting for Pod statefulset-41/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Sep 16 02:52:40.060: INFO: Found 1 stateful pods, waiting for 3
Sep 16 02:52:50.063: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:52:50.063: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:52:50.063: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 16 02:52:50.081: INFO: Updating stateful set ss2
Sep 16 02:52:50.084: INFO: Waiting for Pod statefulset-41/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 16 02:53:00.088: INFO: Waiting for Pod statefulset-41/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 16 02:53:10.102: INFO: Updating stateful set ss2
Sep 16 02:53:10.105: INFO: Waiting for StatefulSet statefulset-41/ss2 to complete update
Sep 16 02:53:10.105: INFO: Waiting for Pod statefulset-41/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 16 02:53:20.110: INFO: Deleting all statefulset in ns statefulset-41
Sep 16 02:53:20.111: INFO: Scaling statefulset ss2 to 0
Sep 16 02:53:40.119: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 02:53:40.120: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:53:40.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-41" for this suite.

• [SLOW TEST:100.164 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":277,"completed":197,"skipped":3203,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:53:40.133: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1293
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1293
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1293
Sep 16 02:53:40.160: INFO: Found 0 stateful pods, waiting for 1
Sep 16 02:53:50.163: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 16 02:53:50.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-1293 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:53:50.372: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:53:50.372: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:53:50.372: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 16 02:53:50.374: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 16 02:54:00.377: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 16 02:54:00.377: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 02:54:00.385: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999345s
Sep 16 02:54:01.387: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998158229s
Sep 16 02:54:02.390: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99576143s
Sep 16 02:54:03.392: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.993256678s
Sep 16 02:54:04.395: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.99060803s
Sep 16 02:54:05.397: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.98810265s
Sep 16 02:54:06.400: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.985521433s
Sep 16 02:54:07.403: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.982584205s
Sep 16 02:54:08.406: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.979976135s
Sep 16 02:54:09.409: INFO: Verifying statefulset ss doesn't scale past 1 for another 977.008466ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1293
Sep 16 02:54:10.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-1293 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:54:10.575: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 16 02:54:10.575: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 16 02:54:10.575: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 16 02:54:10.577: INFO: Found 1 stateful pods, waiting for 3
Sep 16 02:54:20.580: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:54:20.580: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 16 02:54:20.580: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 16 02:54:20.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-1293 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:54:20.754: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:54:20.754: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:54:20.754: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 16 02:54:20.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-1293 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:54:20.966: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:54:20.966: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:54:20.966: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 16 02:54:20.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-1293 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 16 02:54:21.167: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 16 02:54:21.167: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 16 02:54:21.167: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 16 02:54:21.167: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 02:54:21.169: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 16 02:54:31.173: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 16 02:54:31.173: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 16 02:54:31.173: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 16 02:54:31.179: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999743s
Sep 16 02:54:32.181: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998177395s
Sep 16 02:54:33.184: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99544288s
Sep 16 02:54:34.187: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992474763s
Sep 16 02:54:35.190: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989406892s
Sep 16 02:54:36.193: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.986660744s
Sep 16 02:54:37.196: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.983891708s
Sep 16 02:54:38.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.981106974s
Sep 16 02:54:39.201: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.978197012s
Sep 16 02:54:40.204: INFO: Verifying statefulset ss doesn't scale past 3 for another 975.31768ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1293
Sep 16 02:54:41.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-1293 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:54:41.387: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 16 02:54:41.387: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 16 02:54:41.387: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 16 02:54:41.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-1293 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:54:41.567: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 16 02:54:41.567: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 16 02:54:41.567: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 16 02:54:41.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=statefulset-1293 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 16 02:54:41.752: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 16 02:54:41.752: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 16 02:54:41.752: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 16 02:54:41.752: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 16 02:55:01.762: INFO: Deleting all statefulset in ns statefulset-1293
Sep 16 02:55:01.763: INFO: Scaling statefulset ss to 0
Sep 16 02:55:01.768: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 02:55:01.770: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:55:01.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1293" for this suite.

• [SLOW TEST:81.647 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":277,"completed":198,"skipped":3242,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:55:01.780: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 02:55:01.798: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80e338a8-365c-4f83-8dfd-45015b28753f" in namespace "downward-api-9937" to be "Succeeded or Failed"
Sep 16 02:55:01.800: INFO: Pod "downwardapi-volume-80e338a8-365c-4f83-8dfd-45015b28753f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.322822ms
Sep 16 02:55:03.802: INFO: Pod "downwardapi-volume-80e338a8-365c-4f83-8dfd-45015b28753f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003741658s
Sep 16 02:55:05.804: INFO: Pod "downwardapi-volume-80e338a8-365c-4f83-8dfd-45015b28753f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006183994s
STEP: Saw pod success
Sep 16 02:55:05.804: INFO: Pod "downwardapi-volume-80e338a8-365c-4f83-8dfd-45015b28753f" satisfied condition "Succeeded or Failed"
Sep 16 02:55:05.806: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-80e338a8-365c-4f83-8dfd-45015b28753f container client-container: <nil>
STEP: delete the pod
Sep 16 02:55:05.821: INFO: Waiting for pod downwardapi-volume-80e338a8-365c-4f83-8dfd-45015b28753f to disappear
Sep 16 02:55:05.822: INFO: Pod downwardapi-volume-80e338a8-365c-4f83-8dfd-45015b28753f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:55:05.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9937" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":199,"skipped":3266,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:55:05.827: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 16 02:55:10.363: INFO: Successfully updated pod "annotationupdateb07f4882-bd5e-447e-80b6-26e505149793"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:55:12.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9266" for this suite.

• [SLOW TEST:6.551 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":200,"skipped":3300,"failed":0}
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:55:12.378: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Sep 16 02:55:12.393: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Sep 16 02:55:12.829: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep 16 02:55:14.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821712, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821712, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821712, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821712, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 02:55:16.850: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821712, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821712, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821712, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735821712, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 02:55:19.569: INFO: Waited 714.983306ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:55:20.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1050" for this suite.

• [SLOW TEST:7.785 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":277,"completed":201,"skipped":3300,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:55:20.164: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 16 02:55:20.185: INFO: Waiting up to 5m0s for pod "pod-374cc09f-6a6c-4b2f-9c95-36fdd0b1bfd7" in namespace "emptydir-8733" to be "Succeeded or Failed"
Sep 16 02:55:20.186: INFO: Pod "pod-374cc09f-6a6c-4b2f-9c95-36fdd0b1bfd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.233304ms
Sep 16 02:55:22.189: INFO: Pod "pod-374cc09f-6a6c-4b2f-9c95-36fdd0b1bfd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003641356s
Sep 16 02:55:24.191: INFO: Pod "pod-374cc09f-6a6c-4b2f-9c95-36fdd0b1bfd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005830971s
STEP: Saw pod success
Sep 16 02:55:24.191: INFO: Pod "pod-374cc09f-6a6c-4b2f-9c95-36fdd0b1bfd7" satisfied condition "Succeeded or Failed"
Sep 16 02:55:24.192: INFO: Trying to get logs from node 192.168.4.87 pod pod-374cc09f-6a6c-4b2f-9c95-36fdd0b1bfd7 container test-container: <nil>
STEP: delete the pod
Sep 16 02:55:24.202: INFO: Waiting for pod pod-374cc09f-6a6c-4b2f-9c95-36fdd0b1bfd7 to disappear
Sep 16 02:55:24.204: INFO: Pod pod-374cc09f-6a6c-4b2f-9c95-36fdd0b1bfd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:55:24.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8733" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":202,"skipped":3310,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:55:24.209: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-7f775c37-7f64-4490-8d1e-c4f69420a89e in namespace container-probe-7571
Sep 16 02:55:28.240: INFO: Started pod liveness-7f775c37-7f64-4490-8d1e-c4f69420a89e in namespace container-probe-7571
STEP: checking the pod's current state and verifying that restartCount is present
Sep 16 02:55:28.241: INFO: Initial restart count of pod liveness-7f775c37-7f64-4490-8d1e-c4f69420a89e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:59:28.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7571" for this suite.

• [SLOW TEST:244.309 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":277,"completed":203,"skipped":3321,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:59:28.518: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:59:28.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-9256" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":277,"completed":204,"skipped":3332,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:59:28.558: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Sep 16 02:59:28.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-2253 -- logs-generator --log-lines-total 100 --run-duration 20s'
Sep 16 02:59:28.651: INFO: stderr: ""
Sep 16 02:59:28.651: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Sep 16 02:59:28.651: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Sep 16 02:59:28.651: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2253" to be "running and ready, or succeeded"
Sep 16 02:59:28.653: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.426936ms
Sep 16 02:59:30.655: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003222626s
Sep 16 02:59:32.657: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.00563437s
Sep 16 02:59:32.657: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Sep 16 02:59:32.657: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Sep 16 02:59:32.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 logs logs-generator logs-generator --namespace=kubectl-2253'
Sep 16 02:59:32.748: INFO: stderr: ""
Sep 16 02:59:32.748: INFO: stdout: "I0916 02:59:31.166983       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/qs9 542\nI0916 02:59:31.367091       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/lclp 402\nI0916 02:59:31.567112       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/bstq 265\nI0916 02:59:31.767114       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/b42 377\nI0916 02:59:31.967103       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/54l 384\nI0916 02:59:32.167127       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/8x5 457\nI0916 02:59:32.367155       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/ln6z 312\nI0916 02:59:32.567091       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/nckj 583\n"
STEP: limiting log lines
Sep 16 02:59:32.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 logs logs-generator logs-generator --namespace=kubectl-2253 --tail=1'
Sep 16 02:59:32.829: INFO: stderr: ""
Sep 16 02:59:32.829: INFO: stdout: "I0916 02:59:32.767102       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/blt8 455\n"
Sep 16 02:59:32.829: INFO: got output "I0916 02:59:32.767102       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/blt8 455\n"
STEP: limiting log bytes
Sep 16 02:59:32.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 logs logs-generator logs-generator --namespace=kubectl-2253 --limit-bytes=1'
Sep 16 02:59:32.910: INFO: stderr: ""
Sep 16 02:59:32.910: INFO: stdout: "I"
Sep 16 02:59:32.910: INFO: got output "I"
STEP: exposing timestamps
Sep 16 02:59:32.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 logs logs-generator logs-generator --namespace=kubectl-2253 --tail=1 --timestamps'
Sep 16 02:59:32.987: INFO: stderr: ""
Sep 16 02:59:32.987: INFO: stdout: "2020-09-16T02:59:32.967225797Z I0916 02:59:32.967105       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/v62l 547\n"
Sep 16 02:59:32.987: INFO: got output "2020-09-16T02:59:32.967225797Z I0916 02:59:32.967105       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/v62l 547\n"
STEP: restricting to a time range
Sep 16 02:59:35.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 logs logs-generator logs-generator --namespace=kubectl-2253 --since=1s'
Sep 16 02:59:35.571: INFO: stderr: ""
Sep 16 02:59:35.571: INFO: stdout: "I0916 02:59:34.767112       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/v8qb 459\nI0916 02:59:34.967106       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/d6rn 327\nI0916 02:59:35.167098       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/865 216\nI0916 02:59:35.367117       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/bl2x 445\nI0916 02:59:35.567123       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/jszx 509\n"
Sep 16 02:59:35.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 logs logs-generator logs-generator --namespace=kubectl-2253 --since=24h'
Sep 16 02:59:35.652: INFO: stderr: ""
Sep 16 02:59:35.652: INFO: stdout: "I0916 02:59:31.166983       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/qs9 542\nI0916 02:59:31.367091       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/lclp 402\nI0916 02:59:31.567112       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/bstq 265\nI0916 02:59:31.767114       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/b42 377\nI0916 02:59:31.967103       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/54l 384\nI0916 02:59:32.167127       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/8x5 457\nI0916 02:59:32.367155       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/ln6z 312\nI0916 02:59:32.567091       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/nckj 583\nI0916 02:59:32.767102       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/blt8 455\nI0916 02:59:32.967105       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/v62l 547\nI0916 02:59:33.167108       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/zc9k 339\nI0916 02:59:33.367112       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/t47r 431\nI0916 02:59:33.567105       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/5z9 233\nI0916 02:59:33.767105       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/vklh 369\nI0916 02:59:33.967106       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/qk8 556\nI0916 02:59:34.167106       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/hdcm 438\nI0916 02:59:34.367101       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/jw6 352\nI0916 02:59:34.567107       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/xg8 211\nI0916 02:59:34.767112       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/v8qb 459\nI0916 02:59:34.967106       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/d6rn 327\nI0916 02:59:35.167098       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/865 216\nI0916 02:59:35.367117       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/bl2x 445\nI0916 02:59:35.567123       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/jszx 509\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Sep 16 02:59:35.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete pod logs-generator --namespace=kubectl-2253'
Sep 16 02:59:48.812: INFO: stderr: ""
Sep 16 02:59:48.812: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 02:59:48.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2253" for this suite.

• [SLOW TEST:20.258 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1284
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":277,"completed":205,"skipped":3373,"failed":0}
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 02:59:48.817: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 02:59:48.842: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 16 02:59:48.847: INFO: Number of nodes with available pods: 0
Sep 16 02:59:48.847: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 16 02:59:48.856: INFO: Number of nodes with available pods: 0
Sep 16 02:59:48.856: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:49.859: INFO: Number of nodes with available pods: 0
Sep 16 02:59:49.859: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:50.859: INFO: Number of nodes with available pods: 0
Sep 16 02:59:50.859: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:51.859: INFO: Number of nodes with available pods: 1
Sep 16 02:59:51.859: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 16 02:59:51.867: INFO: Number of nodes with available pods: 1
Sep 16 02:59:51.867: INFO: Number of running nodes: 0, number of available pods: 1
Sep 16 02:59:52.869: INFO: Number of nodes with available pods: 0
Sep 16 02:59:52.869: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 16 02:59:52.873: INFO: Number of nodes with available pods: 0
Sep 16 02:59:52.873: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:53.875: INFO: Number of nodes with available pods: 0
Sep 16 02:59:53.875: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:54.876: INFO: Number of nodes with available pods: 0
Sep 16 02:59:54.876: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:55.875: INFO: Number of nodes with available pods: 0
Sep 16 02:59:55.875: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:56.875: INFO: Number of nodes with available pods: 0
Sep 16 02:59:56.875: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:57.875: INFO: Number of nodes with available pods: 0
Sep 16 02:59:57.875: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:58.876: INFO: Number of nodes with available pods: 0
Sep 16 02:59:58.876: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 02:59:59.876: INFO: Number of nodes with available pods: 0
Sep 16 02:59:59.876: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 03:00:00.875: INFO: Number of nodes with available pods: 0
Sep 16 03:00:00.875: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 03:00:01.876: INFO: Number of nodes with available pods: 1
Sep 16 03:00:01.876: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4621, will wait for the garbage collector to delete the pods
Sep 16 03:00:01.933: INFO: Deleting DaemonSet.extensions daemon-set took: 3.624804ms
Sep 16 03:00:02.334: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.160981ms
Sep 16 03:00:08.835: INFO: Number of nodes with available pods: 0
Sep 16 03:00:08.835: INFO: Number of running nodes: 0, number of available pods: 0
Sep 16 03:00:08.836: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4621/daemonsets","resourceVersion":"29086"},"items":null}

Sep 16 03:00:08.838: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4621/pods","resourceVersion":"29086"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:00:08.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4621" for this suite.

• [SLOW TEST:20.034 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":277,"completed":206,"skipped":3375,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:00:08.850: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 16 03:00:08.870: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6785 /api/v1/namespaces/watch-6785/configmaps/e2e-watch-test-watch-closed baed4fe0-51f8-4926-b3d5-e80c64e23741 29095 0 2020-09-16 03:00:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-16 03:00:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 03:00:08.871: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6785 /api/v1/namespaces/watch-6785/configmaps/e2e-watch-test-watch-closed baed4fe0-51f8-4926-b3d5-e80c64e23741 29096 0 2020-09-16 03:00:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-16 03:00:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 16 03:00:08.876: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6785 /api/v1/namespaces/watch-6785/configmaps/e2e-watch-test-watch-closed baed4fe0-51f8-4926-b3d5-e80c64e23741 29097 0 2020-09-16 03:00:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-16 03:00:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 16 03:00:08.877: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6785 /api/v1/namespaces/watch-6785/configmaps/e2e-watch-test-watch-closed baed4fe0-51f8-4926-b3d5-e80c64e23741 29098 0 2020-09-16 03:00:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-16 03:00:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:00:08.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6785" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":277,"completed":207,"skipped":3392,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:00:08.881: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:00:08.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4680" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":277,"completed":208,"skipped":3429,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:00:08.905: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 03:00:08.923: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d1b45bf-fa5e-42d5-ae51-c71a7f86ad49" in namespace "projected-163" to be "Succeeded or Failed"
Sep 16 03:00:08.924: INFO: Pod "downwardapi-volume-6d1b45bf-fa5e-42d5-ae51-c71a7f86ad49": Phase="Pending", Reason="", readiness=false. Elapsed: 1.328777ms
Sep 16 03:00:10.926: INFO: Pod "downwardapi-volume-6d1b45bf-fa5e-42d5-ae51-c71a7f86ad49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003327729s
Sep 16 03:00:12.928: INFO: Pod "downwardapi-volume-6d1b45bf-fa5e-42d5-ae51-c71a7f86ad49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005042696s
STEP: Saw pod success
Sep 16 03:00:12.928: INFO: Pod "downwardapi-volume-6d1b45bf-fa5e-42d5-ae51-c71a7f86ad49" satisfied condition "Succeeded or Failed"
Sep 16 03:00:12.929: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-6d1b45bf-fa5e-42d5-ae51-c71a7f86ad49 container client-container: <nil>
STEP: delete the pod
Sep 16 03:00:12.938: INFO: Waiting for pod downwardapi-volume-6d1b45bf-fa5e-42d5-ae51-c71a7f86ad49 to disappear
Sep 16 03:00:12.940: INFO: Pod downwardapi-volume-6d1b45bf-fa5e-42d5-ae51-c71a7f86ad49 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:00:12.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-163" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":209,"skipped":3432,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:00:12.944: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 16 03:00:12.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9760'
Sep 16 03:00:15.028: INFO: stderr: ""
Sep 16 03:00:15.028: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Sep 16 03:00:15.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete pods e2e-test-httpd-pod --namespace=kubectl-9760'
Sep 16 03:00:27.808: INFO: stderr: ""
Sep 16 03:00:27.808: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:00:27.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9760" for this suite.

• [SLOW TEST:14.868 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":277,"completed":210,"skipped":3468,"failed":0}
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:00:27.812: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 16 03:00:33.842: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0916 03:00:33.842380      26 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:00:33.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8692" for this suite.

• [SLOW TEST:6.034 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":277,"completed":211,"skipped":3471,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:00:33.847: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 16 03:00:41.910: INFO: &Pod{ObjectMeta:{send-events-c5b46192-d780-4281-a29e-a34c197e68ad  events-4762 /api/v1/namespaces/events-4762/pods/send-events-c5b46192-d780-4281-a29e-a34c197e68ad e6dc5076-8a99-40a7-8332-7d4b842328fa 29492 0 2020-09-16 03:00:33 +0000 UTC <nil> <nil> map[name:foo time:899649107] map[] [] []  [{e2e.test Update v1 2020-09-16 03:00:33 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 03:00:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 48 52 46 53 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2s5xq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2s5xq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2s5xq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 03:00:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 03:00:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 03:00:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 03:00:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:172.151.104.53,StartTime:2020-09-16 03:00:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 03:00:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:reg.mg.hcbss/devcke/agnhost:2.12,ImageID:docker-pullable://reg.mg.hcbss/devcke/agnhost@sha256:1dfec5637a7010d6c0955c26f0a752266fa2646ed2bf8e6ad745cdcfcb611db8,ContainerID:docker://493465e3e05dd8992ed3907ec3d3b36043d2a94e8173c9ea3b1069e2ae4bdeec,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.104.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Sep 16 03:00:43.913: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 16 03:00:45.916: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:00:45.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4762" for this suite.

• [SLOW TEST:12.076 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":277,"completed":212,"skipped":3499,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:00:45.923: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 03:00:46.523: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 03:00:48.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822046, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822046, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822046, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822046, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 03:00:51.534: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:01:03.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8229" for this suite.
STEP: Destroying namespace "webhook-8229-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:17.706 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":277,"completed":213,"skipped":3502,"failed":0}
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:01:03.630: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-124e7f56-859b-448a-8968-28b1c89d1545
STEP: Creating a pod to test consume secrets
Sep 16 03:01:03.654: INFO: Waiting up to 5m0s for pod "pod-secrets-abf56a55-e150-424e-ae08-79d1a4c6f4af" in namespace "secrets-7393" to be "Succeeded or Failed"
Sep 16 03:01:03.655: INFO: Pod "pod-secrets-abf56a55-e150-424e-ae08-79d1a4c6f4af": Phase="Pending", Reason="", readiness=false. Elapsed: 1.357937ms
Sep 16 03:01:05.657: INFO: Pod "pod-secrets-abf56a55-e150-424e-ae08-79d1a4c6f4af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003805173s
Sep 16 03:01:07.660: INFO: Pod "pod-secrets-abf56a55-e150-424e-ae08-79d1a4c6f4af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00610739s
STEP: Saw pod success
Sep 16 03:01:07.660: INFO: Pod "pod-secrets-abf56a55-e150-424e-ae08-79d1a4c6f4af" satisfied condition "Succeeded or Failed"
Sep 16 03:01:07.661: INFO: Trying to get logs from node 192.168.4.87 pod pod-secrets-abf56a55-e150-424e-ae08-79d1a4c6f4af container secret-volume-test: <nil>
STEP: delete the pod
Sep 16 03:01:07.670: INFO: Waiting for pod pod-secrets-abf56a55-e150-424e-ae08-79d1a4c6f4af to disappear
Sep 16 03:01:07.671: INFO: Pod pod-secrets-abf56a55-e150-424e-ae08-79d1a4c6f4af no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:01:07.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7393" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":214,"skipped":3502,"failed":0}

------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:01:07.676: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:01:23.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1041" for this suite.

• [SLOW TEST:16.059 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":277,"completed":215,"skipped":3502,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:01:23.736: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:01:23.764: INFO: (0) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 11.168501ms)
Sep 16 03:01:23.766: INFO: (1) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.891101ms)
Sep 16 03:01:23.768: INFO: (2) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.751886ms)
Sep 16 03:01:23.770: INFO: (3) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.677684ms)
Sep 16 03:01:23.771: INFO: (4) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.677184ms)
Sep 16 03:01:23.773: INFO: (5) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.72053ms)
Sep 16 03:01:23.775: INFO: (6) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.579965ms)
Sep 16 03:01:23.776: INFO: (7) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.620656ms)
Sep 16 03:01:23.778: INFO: (8) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.63846ms)
Sep 16 03:01:23.780: INFO: (9) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.813039ms)
Sep 16 03:01:23.782: INFO: (10) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.761326ms)
Sep 16 03:01:23.783: INFO: (11) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.712426ms)
Sep 16 03:01:23.785: INFO: (12) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.652765ms)
Sep 16 03:01:23.787: INFO: (13) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.668407ms)
Sep 16 03:01:23.788: INFO: (14) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.58713ms)
Sep 16 03:01:23.790: INFO: (15) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.614343ms)
Sep 16 03:01:23.791: INFO: (16) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.504014ms)
Sep 16 03:01:23.793: INFO: (17) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.596996ms)
Sep 16 03:01:23.795: INFO: (18) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.552785ms)
Sep 16 03:01:23.796: INFO: (19) /api/v1/nodes/192.168.4.87:10250/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.617635ms)
[AfterEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:01:23.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1663" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":277,"completed":216,"skipped":3514,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:01:23.802: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 16 03:01:23.822: INFO: Waiting up to 5m0s for pod "pod-d512f53e-4f18-4b97-923c-15837924d143" in namespace "emptydir-1695" to be "Succeeded or Failed"
Sep 16 03:01:23.824: INFO: Pod "pod-d512f53e-4f18-4b97-923c-15837924d143": Phase="Pending", Reason="", readiness=false. Elapsed: 1.180194ms
Sep 16 03:01:25.826: INFO: Pod "pod-d512f53e-4f18-4b97-923c-15837924d143": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003511404s
Sep 16 03:01:27.828: INFO: Pod "pod-d512f53e-4f18-4b97-923c-15837924d143": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005685624s
STEP: Saw pod success
Sep 16 03:01:27.828: INFO: Pod "pod-d512f53e-4f18-4b97-923c-15837924d143" satisfied condition "Succeeded or Failed"
Sep 16 03:01:27.830: INFO: Trying to get logs from node 192.168.4.87 pod pod-d512f53e-4f18-4b97-923c-15837924d143 container test-container: <nil>
STEP: delete the pod
Sep 16 03:01:27.838: INFO: Waiting for pod pod-d512f53e-4f18-4b97-923c-15837924d143 to disappear
Sep 16 03:01:27.839: INFO: Pod pod-d512f53e-4f18-4b97-923c-15837924d143 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:01:27.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1695" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":217,"skipped":3542,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:01:27.844: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:01:27.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-937" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":277,"completed":218,"skipped":3617,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:01:27.871: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 03:01:29.060: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 03:01:31.066: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822089, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822089, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822089, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822089, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 03:01:34.076: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:01:34.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3883" for this suite.
STEP: Destroying namespace "webhook-3883-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.255 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":277,"completed":219,"skipped":3672,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:01:34.126: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Sep 16 03:01:34.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-2922'
Sep 16 03:01:34.460: INFO: stderr: ""
Sep 16 03:01:34.460: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 16 03:01:34.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2922'
Sep 16 03:01:34.540: INFO: stderr: ""
Sep 16 03:01:34.540: INFO: stdout: "update-demo-nautilus-6vf2r update-demo-nautilus-wsgfk "
Sep 16 03:01:34.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-6vf2r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2922'
Sep 16 03:01:34.607: INFO: stderr: ""
Sep 16 03:01:34.607: INFO: stdout: ""
Sep 16 03:01:34.607: INFO: update-demo-nautilus-6vf2r is created but not running
Sep 16 03:01:39.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2922'
Sep 16 03:01:39.684: INFO: stderr: ""
Sep 16 03:01:39.684: INFO: stdout: "update-demo-nautilus-6vf2r update-demo-nautilus-wsgfk "
Sep 16 03:01:39.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-6vf2r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2922'
Sep 16 03:01:39.750: INFO: stderr: ""
Sep 16 03:01:39.750: INFO: stdout: "true"
Sep 16 03:01:39.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-6vf2r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2922'
Sep 16 03:01:39.818: INFO: stderr: ""
Sep 16 03:01:39.818: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 16 03:01:39.818: INFO: validating pod update-demo-nautilus-6vf2r
Sep 16 03:01:39.849: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 16 03:01:39.849: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 16 03:01:39.849: INFO: update-demo-nautilus-6vf2r is verified up and running
Sep 16 03:01:39.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-wsgfk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2922'
Sep 16 03:01:39.916: INFO: stderr: ""
Sep 16 03:01:39.916: INFO: stdout: "true"
Sep 16 03:01:39.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-wsgfk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2922'
Sep 16 03:01:39.983: INFO: stderr: ""
Sep 16 03:01:39.983: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 16 03:01:39.983: INFO: validating pod update-demo-nautilus-wsgfk
Sep 16 03:01:39.990: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 16 03:01:39.990: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 16 03:01:39.990: INFO: update-demo-nautilus-wsgfk is verified up and running
STEP: using delete to clean up resources
Sep 16 03:01:39.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete --grace-period=0 --force -f - --namespace=kubectl-2922'
Sep 16 03:01:40.077: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 16 03:01:40.077: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 16 03:01:40.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2922'
Sep 16 03:01:40.166: INFO: stderr: "No resources found in kubectl-2922 namespace.\n"
Sep 16 03:01:40.166: INFO: stdout: ""
Sep 16 03:01:40.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -l name=update-demo --namespace=kubectl-2922 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 16 03:01:40.246: INFO: stderr: ""
Sep 16 03:01:40.246: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:01:40.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2922" for this suite.

• [SLOW TEST:6.126 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":277,"completed":220,"skipped":3676,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:01:40.253: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:02:09.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2942" for this suite.

• [SLOW TEST:29.134 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    when starting a container that exits
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":277,"completed":221,"skipped":3708,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:02:09.387: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 16 03:02:09.402: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 16 03:02:09.408: INFO: Waiting for terminating namespaces to be deleted...
Sep 16 03:02:09.409: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.86 before test
Sep 16 03:02:09.420: INFO: calico-kube-controllers-97dc579d-s2z7r from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 16 03:02:09.420: INFO: sonobuoy-e2e-job-a58be685376b45c9 from sonobuoy started at 2020-09-16 01:52:44 +0000 UTC (2 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container e2e ready: true, restart count 0
Sep 16 03:02:09.420: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 16 03:02:09.420: INFO: coredns-75587db8b6-vlztj from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container coredns ready: true, restart count 0
Sep 16 03:02:09.420: INFO: ckecsi-attacher-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep 16 03:02:09.420: INFO: kubernetes-dashboard-7d464dfc59-d5sxx from kubernetes-dashboard started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 16 03:02:09.420: INFO: ckecsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep 16 03:02:09.420: INFO: cke-lvmcsi-nf9cd from cke-storage started at 2020-09-16 01:25:20 +0000 UTC (2 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 03:02:09.420: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 03:02:09.420: INFO: ckecsi-runc-jq25h from cke-storage started at 2020-09-16 01:25:30 +0000 UTC (2 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 03:02:09.420: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 03:02:09.420: INFO: sonobuoy from sonobuoy started at 2020-09-16 01:52:42 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 16 03:02:09.420: INFO: metrics-server-cf7f9ccc5-ddpmv from kube-system started at 2020-09-16 02:39:33 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.420: INFO: 	Container metrics-server ready: true, restart count 0
Sep 16 03:02:09.420: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.87 before test
Sep 16 03:02:09.425: INFO: ckecsi-provisioner-1 from cke-storage started at 2020-09-16 02:39:48 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.425: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep 16 03:02:09.425: INFO: cke-lvmcsi-q44bw from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (2 container statuses recorded)
Sep 16 03:02:09.425: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 03:02:09.425: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 03:02:09.425: INFO: cke-lvmcsi-resizer-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.425: INFO: 	Container csi-lvm-resizer ready: true, restart count 0
Sep 16 03:02:09.425: INFO: ckecsi-runc-nc5cc from cke-storage started at 2020-09-16 02:39:48 +0000 UTC (2 container statuses recorded)
Sep 16 03:02:09.425: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 03:02:09.425: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 03:02:09.425: INFO: dashboard-metrics-scraper-6fb76cb999-mzs62 from kubernetes-dashboard started at 2020-09-16 02:39:33 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.425: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 16 03:02:09.425: INFO: cke-lvmcsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.425: INFO: 	Container csi-provisioner ready: true, restart count 1
Sep 16 03:02:09.425: INFO: ckecsi-attacher-1 from cke-storage started at 2020-09-16 02:39:48 +0000 UTC (1 container statuses recorded)
Sep 16 03:02:09.425: INFO: 	Container ckecsi-attacher ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fa443b6f-853a-453e-a608-e289a8701097 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fa443b6f-853a-453e-a608-e289a8701097 off the node 192.168.4.87
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fa443b6f-853a-453e-a608-e289a8701097
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:02:17.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5948" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:8.076 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":277,"completed":222,"skipped":3727,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:02:17.463: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:02:17.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 version'
Sep 16 03:02:17.577: INFO: stderr: ""
Sep 16 03:02:17.577: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.8\", GitCommit:\"9f2892aab98fe339f3bd70e3c470144299398ace\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T16:12:48Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.8\", GitCommit:\"9f2892aab98fe339f3bd70e3c470144299398ace\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T16:04:18Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:02:17.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3926" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":277,"completed":223,"skipped":3762,"failed":0}
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:02:17.582: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-bacb0ef6-8061-4bb8-b120-30687ce5f40c in namespace container-probe-5880
Sep 16 03:02:21.606: INFO: Started pod liveness-bacb0ef6-8061-4bb8-b120-30687ce5f40c in namespace container-probe-5880
STEP: checking the pod's current state and verifying that restartCount is present
Sep 16 03:02:21.608: INFO: Initial restart count of pod liveness-bacb0ef6-8061-4bb8-b120-30687ce5f40c is 0
Sep 16 03:02:45.635: INFO: Restart count of pod container-probe-5880/liveness-bacb0ef6-8061-4bb8-b120-30687ce5f40c is now 1 (24.027327935s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:02:45.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5880" for this suite.

• [SLOW TEST:28.063 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":224,"skipped":3766,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:02:45.645: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 03:02:46.752: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 03:02:48.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822166, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822166, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822166, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822166, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 03:02:51.763: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:02:51.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8420" for this suite.
STEP: Destroying namespace "webhook-8420-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.236 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":277,"completed":225,"skipped":3768,"failed":0}
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:02:51.881: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 16 03:02:51.905: INFO: Waiting up to 5m0s for pod "pod-6b22c429-9633-46bb-81a4-aa2cafb61089" in namespace "emptydir-2198" to be "Succeeded or Failed"
Sep 16 03:02:51.908: INFO: Pod "pod-6b22c429-9633-46bb-81a4-aa2cafb61089": Phase="Pending", Reason="", readiness=false. Elapsed: 2.293153ms
Sep 16 03:02:53.910: INFO: Pod "pod-6b22c429-9633-46bb-81a4-aa2cafb61089": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004691938s
Sep 16 03:02:55.912: INFO: Pod "pod-6b22c429-9633-46bb-81a4-aa2cafb61089": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006974656s
Sep 16 03:02:57.914: INFO: Pod "pod-6b22c429-9633-46bb-81a4-aa2cafb61089": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009156874s
STEP: Saw pod success
Sep 16 03:02:57.914: INFO: Pod "pod-6b22c429-9633-46bb-81a4-aa2cafb61089" satisfied condition "Succeeded or Failed"
Sep 16 03:02:57.916: INFO: Trying to get logs from node 192.168.4.87 pod pod-6b22c429-9633-46bb-81a4-aa2cafb61089 container test-container: <nil>
STEP: delete the pod
Sep 16 03:02:57.924: INFO: Waiting for pod pod-6b22c429-9633-46bb-81a4-aa2cafb61089 to disappear
Sep 16 03:02:57.926: INFO: Pod pod-6b22c429-9633-46bb-81a4-aa2cafb61089 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:02:57.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2198" for this suite.

• [SLOW TEST:6.049 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":226,"skipped":3768,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:02:57.931: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 03:02:57.949: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a46ab27-91d0-408f-82ed-76dbd40d32a8" in namespace "downward-api-8466" to be "Succeeded or Failed"
Sep 16 03:02:57.950: INFO: Pod "downwardapi-volume-6a46ab27-91d0-408f-82ed-76dbd40d32a8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.239798ms
Sep 16 03:02:59.953: INFO: Pod "downwardapi-volume-6a46ab27-91d0-408f-82ed-76dbd40d32a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003601987s
Sep 16 03:03:01.955: INFO: Pod "downwardapi-volume-6a46ab27-91d0-408f-82ed-76dbd40d32a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006000129s
STEP: Saw pod success
Sep 16 03:03:01.955: INFO: Pod "downwardapi-volume-6a46ab27-91d0-408f-82ed-76dbd40d32a8" satisfied condition "Succeeded or Failed"
Sep 16 03:03:01.957: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-6a46ab27-91d0-408f-82ed-76dbd40d32a8 container client-container: <nil>
STEP: delete the pod
Sep 16 03:03:01.966: INFO: Waiting for pod downwardapi-volume-6a46ab27-91d0-408f-82ed-76dbd40d32a8 to disappear
Sep 16 03:03:01.967: INFO: Pod downwardapi-volume-6a46ab27-91d0-408f-82ed-76dbd40d32a8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:03:01.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8466" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":227,"skipped":3859,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:03:01.971: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-b71c6758-6545-4c26-b0c3-f2c56f27f9be
STEP: Creating a pod to test consume configMaps
Sep 16 03:03:01.991: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c60a250-057c-4f89-bf12-0d949262b5c6" in namespace "configmap-6544" to be "Succeeded or Failed"
Sep 16 03:03:01.993: INFO: Pod "pod-configmaps-3c60a250-057c-4f89-bf12-0d949262b5c6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.306009ms
Sep 16 03:03:03.995: INFO: Pod "pod-configmaps-3c60a250-057c-4f89-bf12-0d949262b5c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003415152s
Sep 16 03:03:05.997: INFO: Pod "pod-configmaps-3c60a250-057c-4f89-bf12-0d949262b5c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006060019s
STEP: Saw pod success
Sep 16 03:03:05.997: INFO: Pod "pod-configmaps-3c60a250-057c-4f89-bf12-0d949262b5c6" satisfied condition "Succeeded or Failed"
Sep 16 03:03:05.999: INFO: Trying to get logs from node 192.168.4.87 pod pod-configmaps-3c60a250-057c-4f89-bf12-0d949262b5c6 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 03:03:06.008: INFO: Waiting for pod pod-configmaps-3c60a250-057c-4f89-bf12-0d949262b5c6 to disappear
Sep 16 03:03:06.010: INFO: Pod pod-configmaps-3c60a250-057c-4f89-bf12-0d949262b5c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:03:06.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6544" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":228,"skipped":3865,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:03:06.014: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:03:06.043: INFO: Create a RollingUpdate DaemonSet
Sep 16 03:03:06.046: INFO: Check that daemon pods launch on every node of the cluster
Sep 16 03:03:06.049: INFO: Number of nodes with available pods: 0
Sep 16 03:03:06.049: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:03:07.055: INFO: Number of nodes with available pods: 0
Sep 16 03:03:07.055: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:03:08.055: INFO: Number of nodes with available pods: 0
Sep 16 03:03:08.055: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:03:09.053: INFO: Number of nodes with available pods: 1
Sep 16 03:03:09.053: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 03:03:10.054: INFO: Number of nodes with available pods: 2
Sep 16 03:03:10.054: INFO: Number of running nodes: 2, number of available pods: 2
Sep 16 03:03:10.054: INFO: Update the DaemonSet to trigger a rollout
Sep 16 03:03:10.058: INFO: Updating DaemonSet daemon-set
Sep 16 03:03:13.066: INFO: Roll back the DaemonSet before rollout is complete
Sep 16 03:03:13.070: INFO: Updating DaemonSet daemon-set
Sep 16 03:03:13.070: INFO: Make sure DaemonSet rollback is complete
Sep 16 03:03:13.071: INFO: Wrong image for pod: daemon-set-8xjwn. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 16 03:03:13.071: INFO: Pod daemon-set-8xjwn is not available
Sep 16 03:03:14.076: INFO: Pod daemon-set-fnv7s is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8965, will wait for the garbage collector to delete the pods
Sep 16 03:03:14.136: INFO: Deleting DaemonSet.extensions daemon-set took: 3.042899ms
Sep 16 03:03:14.536: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.199966ms
Sep 16 03:03:28.838: INFO: Number of nodes with available pods: 0
Sep 16 03:03:28.838: INFO: Number of running nodes: 0, number of available pods: 0
Sep 16 03:03:28.839: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8965/daemonsets","resourceVersion":"30839"},"items":null}

Sep 16 03:03:28.841: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8965/pods","resourceVersion":"30839"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:03:28.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8965" for this suite.

• [SLOW TEST:22.836 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":277,"completed":229,"skipped":3883,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:03:28.850: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 03:03:29.328: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 03:03:31.334: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822209, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822209, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822209, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822209, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 03:03:34.340: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:03:34.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8743" for this suite.
STEP: Destroying namespace "webhook-8743-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.553 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":277,"completed":230,"skipped":3891,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:03:34.403: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-d20b46a7-752c-4124-ab9c-1fdabd34406b
STEP: Creating a pod to test consume secrets
Sep 16 03:03:34.427: INFO: Waiting up to 5m0s for pod "pod-secrets-bebe9561-2b98-476e-93c9-d9c91a76037a" in namespace "secrets-3394" to be "Succeeded or Failed"
Sep 16 03:03:34.429: INFO: Pod "pod-secrets-bebe9561-2b98-476e-93c9-d9c91a76037a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.267372ms
Sep 16 03:03:36.431: INFO: Pod "pod-secrets-bebe9561-2b98-476e-93c9-d9c91a76037a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003519221s
Sep 16 03:03:38.433: INFO: Pod "pod-secrets-bebe9561-2b98-476e-93c9-d9c91a76037a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00583472s
Sep 16 03:03:40.436: INFO: Pod "pod-secrets-bebe9561-2b98-476e-93c9-d9c91a76037a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008269266s
STEP: Saw pod success
Sep 16 03:03:40.436: INFO: Pod "pod-secrets-bebe9561-2b98-476e-93c9-d9c91a76037a" satisfied condition "Succeeded or Failed"
Sep 16 03:03:40.437: INFO: Trying to get logs from node 192.168.4.87 pod pod-secrets-bebe9561-2b98-476e-93c9-d9c91a76037a container secret-volume-test: <nil>
STEP: delete the pod
Sep 16 03:03:40.446: INFO: Waiting for pod pod-secrets-bebe9561-2b98-476e-93c9-d9c91a76037a to disappear
Sep 16 03:03:40.448: INFO: Pod pod-secrets-bebe9561-2b98-476e-93c9-d9c91a76037a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:03:40.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3394" for this suite.

• [SLOW TEST:6.049 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":231,"skipped":3909,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:03:40.453: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 03:03:40.470: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b70879c2-82ec-4768-bad2-23c7124cb27c" in namespace "downward-api-6598" to be "Succeeded or Failed"
Sep 16 03:03:40.472: INFO: Pod "downwardapi-volume-b70879c2-82ec-4768-bad2-23c7124cb27c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.249131ms
Sep 16 03:03:42.474: INFO: Pod "downwardapi-volume-b70879c2-82ec-4768-bad2-23c7124cb27c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00317281s
Sep 16 03:03:44.476: INFO: Pod "downwardapi-volume-b70879c2-82ec-4768-bad2-23c7124cb27c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005228692s
STEP: Saw pod success
Sep 16 03:03:44.476: INFO: Pod "downwardapi-volume-b70879c2-82ec-4768-bad2-23c7124cb27c" satisfied condition "Succeeded or Failed"
Sep 16 03:03:44.477: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-b70879c2-82ec-4768-bad2-23c7124cb27c container client-container: <nil>
STEP: delete the pod
Sep 16 03:03:44.487: INFO: Waiting for pod downwardapi-volume-b70879c2-82ec-4768-bad2-23c7124cb27c to disappear
Sep 16 03:03:44.488: INFO: Pod downwardapi-volume-b70879c2-82ec-4768-bad2-23c7124cb27c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:03:44.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6598" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":232,"skipped":3934,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:03:44.493: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Sep 16 03:03:44.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-4278'
Sep 16 03:03:44.754: INFO: stderr: ""
Sep 16 03:03:44.754: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 16 03:03:44.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4278'
Sep 16 03:03:44.828: INFO: stderr: ""
Sep 16 03:03:44.828: INFO: stdout: "update-demo-nautilus-9m78k update-demo-nautilus-qrf55 "
Sep 16 03:03:44.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-9m78k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:03:44.897: INFO: stderr: ""
Sep 16 03:03:44.897: INFO: stdout: ""
Sep 16 03:03:44.897: INFO: update-demo-nautilus-9m78k is created but not running
Sep 16 03:03:49.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4278'
Sep 16 03:03:49.969: INFO: stderr: ""
Sep 16 03:03:49.969: INFO: stdout: "update-demo-nautilus-9m78k update-demo-nautilus-qrf55 "
Sep 16 03:03:49.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-9m78k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:03:50.046: INFO: stderr: ""
Sep 16 03:03:50.046: INFO: stdout: "true"
Sep 16 03:03:50.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-9m78k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:03:50.131: INFO: stderr: ""
Sep 16 03:03:50.131: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 16 03:03:50.131: INFO: validating pod update-demo-nautilus-9m78k
Sep 16 03:03:50.135: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 16 03:03:50.135: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 16 03:03:50.135: INFO: update-demo-nautilus-9m78k is verified up and running
Sep 16 03:03:50.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-qrf55 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:03:50.208: INFO: stderr: ""
Sep 16 03:03:50.208: INFO: stdout: "true"
Sep 16 03:03:50.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-qrf55 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:03:50.282: INFO: stderr: ""
Sep 16 03:03:50.282: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 16 03:03:50.282: INFO: validating pod update-demo-nautilus-qrf55
Sep 16 03:03:50.286: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 16 03:03:50.286: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 16 03:03:50.286: INFO: update-demo-nautilus-qrf55 is verified up and running
STEP: scaling down the replication controller
Sep 16 03:03:50.288: INFO: scanned /root for discovery docs: <nil>
Sep 16 03:03:50.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4278'
Sep 16 03:03:51.371: INFO: stderr: ""
Sep 16 03:03:51.371: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 16 03:03:51.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4278'
Sep 16 03:03:51.445: INFO: stderr: ""
Sep 16 03:03:51.445: INFO: stdout: "update-demo-nautilus-9m78k update-demo-nautilus-qrf55 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 16 03:03:56.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4278'
Sep 16 03:03:56.518: INFO: stderr: ""
Sep 16 03:03:56.518: INFO: stdout: "update-demo-nautilus-9m78k update-demo-nautilus-qrf55 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 16 03:04:01.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4278'
Sep 16 03:04:01.596: INFO: stderr: ""
Sep 16 03:04:01.596: INFO: stdout: "update-demo-nautilus-9m78k "
Sep 16 03:04:01.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-9m78k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:04:01.667: INFO: stderr: ""
Sep 16 03:04:01.667: INFO: stdout: "true"
Sep 16 03:04:01.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-9m78k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:04:01.738: INFO: stderr: ""
Sep 16 03:04:01.738: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 16 03:04:01.738: INFO: validating pod update-demo-nautilus-9m78k
Sep 16 03:04:01.740: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 16 03:04:01.740: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 16 03:04:01.740: INFO: update-demo-nautilus-9m78k is verified up and running
STEP: scaling up the replication controller
Sep 16 03:04:01.742: INFO: scanned /root for discovery docs: <nil>
Sep 16 03:04:01.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4278'
Sep 16 03:04:02.825: INFO: stderr: ""
Sep 16 03:04:02.825: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 16 03:04:02.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4278'
Sep 16 03:04:02.897: INFO: stderr: ""
Sep 16 03:04:02.897: INFO: stdout: "update-demo-nautilus-9m78k update-demo-nautilus-hnndm "
Sep 16 03:04:02.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-9m78k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:04:02.965: INFO: stderr: ""
Sep 16 03:04:02.965: INFO: stdout: "true"
Sep 16 03:04:02.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-9m78k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:04:03.036: INFO: stderr: ""
Sep 16 03:04:03.036: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 16 03:04:03.036: INFO: validating pod update-demo-nautilus-9m78k
Sep 16 03:04:03.038: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 16 03:04:03.038: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 16 03:04:03.038: INFO: update-demo-nautilus-9m78k is verified up and running
Sep 16 03:04:03.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-hnndm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:04:03.110: INFO: stderr: ""
Sep 16 03:04:03.110: INFO: stdout: ""
Sep 16 03:04:03.110: INFO: update-demo-nautilus-hnndm is created but not running
Sep 16 03:04:08.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4278'
Sep 16 03:04:08.187: INFO: stderr: ""
Sep 16 03:04:08.187: INFO: stdout: "update-demo-nautilus-9m78k update-demo-nautilus-hnndm "
Sep 16 03:04:08.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-9m78k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:04:08.264: INFO: stderr: ""
Sep 16 03:04:08.264: INFO: stdout: "true"
Sep 16 03:04:08.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-9m78k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:04:08.333: INFO: stderr: ""
Sep 16 03:04:08.333: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 16 03:04:08.333: INFO: validating pod update-demo-nautilus-9m78k
Sep 16 03:04:08.335: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 16 03:04:08.336: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 16 03:04:08.336: INFO: update-demo-nautilus-9m78k is verified up and running
Sep 16 03:04:08.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-hnndm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:04:08.404: INFO: stderr: ""
Sep 16 03:04:08.404: INFO: stdout: "true"
Sep 16 03:04:08.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods update-demo-nautilus-hnndm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4278'
Sep 16 03:04:08.474: INFO: stderr: ""
Sep 16 03:04:08.474: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 16 03:04:08.474: INFO: validating pod update-demo-nautilus-hnndm
Sep 16 03:04:08.476: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 16 03:04:08.476: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 16 03:04:08.476: INFO: update-demo-nautilus-hnndm is verified up and running
STEP: using delete to clean up resources
Sep 16 03:04:08.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete --grace-period=0 --force -f - --namespace=kubectl-4278'
Sep 16 03:04:08.547: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 16 03:04:08.547: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 16 03:04:08.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4278'
Sep 16 03:04:08.619: INFO: stderr: "No resources found in kubectl-4278 namespace.\n"
Sep 16 03:04:08.619: INFO: stdout: ""
Sep 16 03:04:08.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -l name=update-demo --namespace=kubectl-4278 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 16 03:04:08.691: INFO: stderr: ""
Sep 16 03:04:08.691: INFO: stdout: "update-demo-nautilus-9m78k\nupdate-demo-nautilus-hnndm\n"
Sep 16 03:04:09.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4278'
Sep 16 03:04:09.266: INFO: stderr: "No resources found in kubectl-4278 namespace.\n"
Sep 16 03:04:09.266: INFO: stdout: ""
Sep 16 03:04:09.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 get pods -l name=update-demo --namespace=kubectl-4278 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 16 03:04:09.351: INFO: stderr: ""
Sep 16 03:04:09.351: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:04:09.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4278" for this suite.

• [SLOW TEST:24.867 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":277,"completed":233,"skipped":3944,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:04:09.360: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-de26a36f-da83-4f22-9d78-f4102c13f259
STEP: Creating a pod to test consume secrets
Sep 16 03:04:09.383: INFO: Waiting up to 5m0s for pod "pod-secrets-699d70b5-f78e-4d36-a524-020332ed888f" in namespace "secrets-4923" to be "Succeeded or Failed"
Sep 16 03:04:09.384: INFO: Pod "pod-secrets-699d70b5-f78e-4d36-a524-020332ed888f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.463393ms
Sep 16 03:04:11.386: INFO: Pod "pod-secrets-699d70b5-f78e-4d36-a524-020332ed888f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003501828s
Sep 16 03:04:13.389: INFO: Pod "pod-secrets-699d70b5-f78e-4d36-a524-020332ed888f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005955101s
STEP: Saw pod success
Sep 16 03:04:13.389: INFO: Pod "pod-secrets-699d70b5-f78e-4d36-a524-020332ed888f" satisfied condition "Succeeded or Failed"
Sep 16 03:04:13.390: INFO: Trying to get logs from node 192.168.4.87 pod pod-secrets-699d70b5-f78e-4d36-a524-020332ed888f container secret-volume-test: <nil>
STEP: delete the pod
Sep 16 03:04:13.399: INFO: Waiting for pod pod-secrets-699d70b5-f78e-4d36-a524-020332ed888f to disappear
Sep 16 03:04:13.401: INFO: Pod pod-secrets-699d70b5-f78e-4d36-a524-020332ed888f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:04:13.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4923" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":234,"skipped":3958,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:04:13.405: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-8e1c6f32-a707-4b92-8960-6df784590e03
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-8e1c6f32-a707-4b92-8960-6df784590e03
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:05:29.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9540" for this suite.

• [SLOW TEST:76.282 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":235,"skipped":3967,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:05:29.687: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Sep 16 03:05:29.706: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-120268828 proxy --unix-socket=/tmp/kubectl-proxy-unix902653807/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:05:29.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9648" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":277,"completed":236,"skipped":3998,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:05:29.769: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 03:05:30.838: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Sep 16 03:05:32.843: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822330, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822330, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822330, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822330, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 03:05:34.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822330, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822330, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822330, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822330, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 03:05:37.849: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:05:37.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4743" for this suite.
STEP: Destroying namespace "webhook-4743-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.138 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":277,"completed":237,"skipped":4003,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:05:37.908: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 03:05:37.930: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24c7b94f-df28-4b0a-b63a-c88a5f7b74fb" in namespace "projected-2450" to be "Succeeded or Failed"
Sep 16 03:05:37.932: INFO: Pod "downwardapi-volume-24c7b94f-df28-4b0a-b63a-c88a5f7b74fb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.986252ms
Sep 16 03:05:39.934: INFO: Pod "downwardapi-volume-24c7b94f-df28-4b0a-b63a-c88a5f7b74fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003957649s
Sep 16 03:05:41.936: INFO: Pod "downwardapi-volume-24c7b94f-df28-4b0a-b63a-c88a5f7b74fb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006215676s
Sep 16 03:05:43.939: INFO: Pod "downwardapi-volume-24c7b94f-df28-4b0a-b63a-c88a5f7b74fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008696369s
STEP: Saw pod success
Sep 16 03:05:43.939: INFO: Pod "downwardapi-volume-24c7b94f-df28-4b0a-b63a-c88a5f7b74fb" satisfied condition "Succeeded or Failed"
Sep 16 03:05:43.940: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-24c7b94f-df28-4b0a-b63a-c88a5f7b74fb container client-container: <nil>
STEP: delete the pod
Sep 16 03:05:43.950: INFO: Waiting for pod downwardapi-volume-24c7b94f-df28-4b0a-b63a-c88a5f7b74fb to disappear
Sep 16 03:05:43.952: INFO: Pod downwardapi-volume-24c7b94f-df28-4b0a-b63a-c88a5f7b74fb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:05:43.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2450" for this suite.

• [SLOW TEST:6.048 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":238,"skipped":4008,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:05:43.956: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8069
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-8069
I0916 03:05:43.983260      26 runners.go:190] Created replication controller with name: externalname-service, namespace: services-8069, replica count: 2
I0916 03:05:47.033602      26 runners.go:190] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0916 03:05:50.033779      26 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 16 03:05:50.033: INFO: Creating new exec pod
Sep 16 03:05:55.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-8069 execpodpslxn -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 16 03:05:55.256: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 16 03:05:55.256: INFO: stdout: ""
Sep 16 03:05:55.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-8069 execpodpslxn -- /bin/sh -x -c nc -zv -t -w 2 11.254.190.131 80'
Sep 16 03:05:55.418: INFO: stderr: "+ nc -zv -t -w 2 11.254.190.131 80\nConnection to 11.254.190.131 80 port [tcp/http] succeeded!\n"
Sep 16 03:05:55.418: INFO: stdout: ""
Sep 16 03:05:55.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-8069 execpodpslxn -- /bin/sh -x -c nc -zv -t -w 2 192.168.4.86 31632'
Sep 16 03:05:55.588: INFO: stderr: "+ nc -zv -t -w 2 192.168.4.86 31632\nConnection to 192.168.4.86 31632 port [tcp/31632] succeeded!\n"
Sep 16 03:05:55.588: INFO: stdout: ""
Sep 16 03:05:55.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-8069 execpodpslxn -- /bin/sh -x -c nc -zv -t -w 2 192.168.4.87 31632'
Sep 16 03:05:55.749: INFO: stderr: "+ nc -zv -t -w 2 192.168.4.87 31632\nConnection to 192.168.4.87 31632 port [tcp/31632] succeeded!\n"
Sep 16 03:05:55.749: INFO: stdout: ""
Sep 16 03:05:55.749: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:05:55.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8069" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:11.809 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":277,"completed":239,"skipped":4031,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:05:55.765: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 16 03:06:03.802: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 16 03:06:03.804: INFO: Pod pod-with-prestop-http-hook still exists
Sep 16 03:06:05.804: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 16 03:06:05.806: INFO: Pod pod-with-prestop-http-hook still exists
Sep 16 03:06:07.804: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 16 03:06:07.806: INFO: Pod pod-with-prestop-http-hook still exists
Sep 16 03:06:09.804: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 16 03:06:09.806: INFO: Pod pod-with-prestop-http-hook still exists
Sep 16 03:06:11.804: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 16 03:06:11.806: INFO: Pod pod-with-prestop-http-hook still exists
Sep 16 03:06:13.804: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 16 03:06:13.807: INFO: Pod pod-with-prestop-http-hook still exists
Sep 16 03:06:15.804: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 16 03:06:15.807: INFO: Pod pod-with-prestop-http-hook still exists
Sep 16 03:06:17.804: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 16 03:06:17.806: INFO: Pod pod-with-prestop-http-hook still exists
Sep 16 03:06:19.804: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 16 03:06:19.806: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:06:19.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8443" for this suite.

• [SLOW TEST:24.051 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":277,"completed":240,"skipped":4079,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:06:19.817: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 16 03:06:24.855: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:06:25.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2445" for this suite.

• [SLOW TEST:6.050 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":277,"completed":241,"skipped":4099,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:06:25.868: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 16 03:06:30.396: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7152 pod-service-account-fc395a69-b5a2-4e8d-933b-3e9ddac81b75 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 16 03:06:30.557: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7152 pod-service-account-fc395a69-b5a2-4e8d-933b-3e9ddac81b75 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 16 03:06:30.737: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7152 pod-service-account-fc395a69-b5a2-4e8d-933b-3e9ddac81b75 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:06:30.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7152" for this suite.

• [SLOW TEST:5.065 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":277,"completed":242,"skipped":4168,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:06:30.933: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8672
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8672
STEP: creating replication controller externalsvc in namespace services-8672
I0916 03:06:30.965860      26 runners.go:190] Created replication controller with name: externalsvc, namespace: services-8672, replica count: 2
I0916 03:06:34.016221      26 runners.go:190] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0916 03:06:37.016390      26 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Sep 16 03:06:37.024: INFO: Creating new exec pod
Sep 16 03:06:41.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 exec --namespace=services-8672 execpodg7fvf -- /bin/sh -x -c nslookup clusterip-service'
Sep 16 03:06:41.308: INFO: stderr: "+ nslookup clusterip-service\n"
Sep 16 03:06:41.308: INFO: stdout: "Server:\t\t11.254.0.10\nAddress:\t11.254.0.10#53\n\nclusterip-service.services-8672.svc.cluster.local\tcanonical name = externalsvc.services-8672.svc.cluster.local.\nName:\texternalsvc.services-8672.svc.cluster.local\nAddress: 11.254.22.249\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8672, will wait for the garbage collector to delete the pods
Sep 16 03:06:41.363: INFO: Deleting ReplicationController externalsvc took: 3.528689ms
Sep 16 03:06:41.463: INFO: Terminating ReplicationController externalsvc pods took: 100.150533ms
Sep 16 03:06:47.072: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:06:47.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8672" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:16.149 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":277,"completed":243,"skipped":4173,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:06:47.082: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:06:47.100: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Creating first CR 
Sep 16 03:06:47.645: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-16T03:06:47Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-16T03:06:47Z]] name:name1 resourceVersion:32184 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:282bd35b-0f5d-4f9d-a096-751358558a69] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Sep 16 03:06:57.649: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-16T03:06:57Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-16T03:06:57Z]] name:name2 resourceVersion:32237 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:995462e0-e576-40b7-b2e5-64dfd5bb388b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Sep 16 03:07:07.652: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-16T03:06:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-16T03:07:07Z]] name:name1 resourceVersion:32261 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:282bd35b-0f5d-4f9d-a096-751358558a69] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Sep 16 03:07:17.656: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-16T03:06:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-16T03:07:17Z]] name:name2 resourceVersion:32285 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:995462e0-e576-40b7-b2e5-64dfd5bb388b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Sep 16 03:07:27.661: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-16T03:06:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-16T03:07:07Z]] name:name1 resourceVersion:32309 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:282bd35b-0f5d-4f9d-a096-751358558a69] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Sep 16 03:07:37.665: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-16T03:06:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-16T03:07:17Z]] name:name2 resourceVersion:32333 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:995462e0-e576-40b7-b2e5-64dfd5bb388b] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:07:48.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-8481" for this suite.

• [SLOW TEST:61.094 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":277,"completed":244,"skipped":4214,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:07:48.177: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-c1dab51c-974f-4491-b93d-0327897c962b
STEP: Creating a pod to test consume secrets
Sep 16 03:07:48.216: INFO: Waiting up to 5m0s for pod "pod-secrets-0371ead8-43bf-4b79-bef3-43a79f7cde86" in namespace "secrets-2017" to be "Succeeded or Failed"
Sep 16 03:07:48.218: INFO: Pod "pod-secrets-0371ead8-43bf-4b79-bef3-43a79f7cde86": Phase="Pending", Reason="", readiness=false. Elapsed: 1.287493ms
Sep 16 03:07:50.220: INFO: Pod "pod-secrets-0371ead8-43bf-4b79-bef3-43a79f7cde86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00358875s
Sep 16 03:07:52.222: INFO: Pod "pod-secrets-0371ead8-43bf-4b79-bef3-43a79f7cde86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005946298s
STEP: Saw pod success
Sep 16 03:07:52.222: INFO: Pod "pod-secrets-0371ead8-43bf-4b79-bef3-43a79f7cde86" satisfied condition "Succeeded or Failed"
Sep 16 03:07:52.224: INFO: Trying to get logs from node 192.168.4.87 pod pod-secrets-0371ead8-43bf-4b79-bef3-43a79f7cde86 container secret-volume-test: <nil>
STEP: delete the pod
Sep 16 03:07:52.237: INFO: Waiting for pod pod-secrets-0371ead8-43bf-4b79-bef3-43a79f7cde86 to disappear
Sep 16 03:07:52.239: INFO: Pod pod-secrets-0371ead8-43bf-4b79-bef3-43a79f7cde86 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:07:52.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2017" for this suite.
STEP: Destroying namespace "secret-namespace-2247" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":277,"completed":245,"skipped":4232,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:07:52.245: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-4c5a4e44-e21e-4bb7-b383-38c33d3fc047
STEP: Creating a pod to test consume configMaps
Sep 16 03:07:52.266: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-96003123-1e6a-48bc-864f-3fd072f0bb45" in namespace "projected-1328" to be "Succeeded or Failed"
Sep 16 03:07:52.268: INFO: Pod "pod-projected-configmaps-96003123-1e6a-48bc-864f-3fd072f0bb45": Phase="Pending", Reason="", readiness=false. Elapsed: 1.558514ms
Sep 16 03:07:54.270: INFO: Pod "pod-projected-configmaps-96003123-1e6a-48bc-864f-3fd072f0bb45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004005977s
Sep 16 03:07:56.272: INFO: Pod "pod-projected-configmaps-96003123-1e6a-48bc-864f-3fd072f0bb45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006178875s
STEP: Saw pod success
Sep 16 03:07:56.272: INFO: Pod "pod-projected-configmaps-96003123-1e6a-48bc-864f-3fd072f0bb45" satisfied condition "Succeeded or Failed"
Sep 16 03:07:56.274: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-configmaps-96003123-1e6a-48bc-864f-3fd072f0bb45 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 03:07:56.283: INFO: Waiting for pod pod-projected-configmaps-96003123-1e6a-48bc-864f-3fd072f0bb45 to disappear
Sep 16 03:07:56.284: INFO: Pod pod-projected-configmaps-96003123-1e6a-48bc-864f-3fd072f0bb45 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:07:56.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1328" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":246,"skipped":4259,"failed":0}

------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:07:56.289: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:07:56.309: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-2d013e9d-9ee5-48c9-991e-28c054d45643" in namespace "security-context-test-5841" to be "Succeeded or Failed"
Sep 16 03:07:56.310: INFO: Pod "alpine-nnp-false-2d013e9d-9ee5-48c9-991e-28c054d45643": Phase="Pending", Reason="", readiness=false. Elapsed: 1.417444ms
Sep 16 03:07:58.312: INFO: Pod "alpine-nnp-false-2d013e9d-9ee5-48c9-991e-28c054d45643": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00345488s
Sep 16 03:08:00.315: INFO: Pod "alpine-nnp-false-2d013e9d-9ee5-48c9-991e-28c054d45643": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006003205s
Sep 16 03:08:00.315: INFO: Pod "alpine-nnp-false-2d013e9d-9ee5-48c9-991e-28c054d45643" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:08:00.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5841" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":247,"skipped":4259,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:08:00.325: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:08:04.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6583" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":277,"completed":248,"skipped":4267,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:08:04.358: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1291
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-1291
Sep 16 03:08:04.381: INFO: Found 0 stateful pods, waiting for 1
Sep 16 03:08:14.383: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 16 03:08:14.391: INFO: Deleting all statefulset in ns statefulset-1291
Sep 16 03:08:14.392: INFO: Scaling statefulset ss to 0
Sep 16 03:08:24.400: INFO: Waiting for statefulset status.replicas updated to 0
Sep 16 03:08:24.401: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:08:24.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1291" for this suite.

• [SLOW TEST:20.053 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":277,"completed":249,"skipped":4276,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:08:24.411: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:08:24.456: INFO: (0) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 25.494663ms)
Sep 16 03:08:24.458: INFO: (1) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.887766ms)
Sep 16 03:08:24.460: INFO: (2) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.855797ms)
Sep 16 03:08:24.462: INFO: (3) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.738899ms)
Sep 16 03:08:24.464: INFO: (4) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.991154ms)
Sep 16 03:08:24.466: INFO: (5) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.806562ms)
Sep 16 03:08:24.468: INFO: (6) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.870966ms)
Sep 16 03:08:24.470: INFO: (7) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 2.110341ms)
Sep 16 03:08:24.472: INFO: (8) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.780892ms)
Sep 16 03:08:24.473: INFO: (9) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.774533ms)
Sep 16 03:08:24.475: INFO: (10) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.846358ms)
Sep 16 03:08:24.477: INFO: (11) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.864022ms)
Sep 16 03:08:24.489: INFO: (12) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 11.455249ms)
Sep 16 03:08:24.491: INFO: (13) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 2.275519ms)
Sep 16 03:08:24.493: INFO: (14) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.864485ms)
Sep 16 03:08:24.495: INFO: (15) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 2.053752ms)
Sep 16 03:08:24.497: INFO: (16) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.887858ms)
Sep 16 03:08:24.499: INFO: (17) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.798071ms)
Sep 16 03:08:24.500: INFO: (18) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.651215ms)
Sep 16 03:08:24.502: INFO: (19) /api/v1/nodes/192.168.4.86/proxy/logs/: <pre>
<a href="calico/">calico/</a>
<a href="containers/">containers/</a>
<a href="pods/">pods/</... (200; 1.831572ms)
[AfterEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:08:24.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6858" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":277,"completed":250,"skipped":4284,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:08:24.507: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-6838, will wait for the garbage collector to delete the pods
Sep 16 03:08:28.585: INFO: Deleting Job.batch foo took: 3.931532ms
Sep 16 03:08:28.685: INFO: Terminating Job.batch foo pods took: 100.20468ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:08.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6838" for this suite.

• [SLOW TEST:44.384 seconds]
[sig-apps] Job
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":277,"completed":251,"skipped":4293,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:08.892: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Sep 16 03:09:09.927: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0916 03:09:09.927496      26 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:09.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1275" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":277,"completed":252,"skipped":4303,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:09.932: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 03:09:09.952: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9020a1c2-e7e5-400b-b0b9-a5e0c3a05323" in namespace "projected-6312" to be "Succeeded or Failed"
Sep 16 03:09:09.954: INFO: Pod "downwardapi-volume-9020a1c2-e7e5-400b-b0b9-a5e0c3a05323": Phase="Pending", Reason="", readiness=false. Elapsed: 1.326794ms
Sep 16 03:09:11.956: INFO: Pod "downwardapi-volume-9020a1c2-e7e5-400b-b0b9-a5e0c3a05323": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003828391s
Sep 16 03:09:13.958: INFO: Pod "downwardapi-volume-9020a1c2-e7e5-400b-b0b9-a5e0c3a05323": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005787347s
STEP: Saw pod success
Sep 16 03:09:13.958: INFO: Pod "downwardapi-volume-9020a1c2-e7e5-400b-b0b9-a5e0c3a05323" satisfied condition "Succeeded or Failed"
Sep 16 03:09:13.960: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-9020a1c2-e7e5-400b-b0b9-a5e0c3a05323 container client-container: <nil>
STEP: delete the pod
Sep 16 03:09:13.969: INFO: Waiting for pod downwardapi-volume-9020a1c2-e7e5-400b-b0b9-a5e0c3a05323 to disappear
Sep 16 03:09:13.970: INFO: Pod downwardapi-volume-9020a1c2-e7e5-400b-b0b9-a5e0c3a05323 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:13.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6312" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":253,"skipped":4320,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:13.975: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:13.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8334" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":277,"completed":254,"skipped":4415,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:13.996: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:09:14.010: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:14.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9683" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":277,"completed":255,"skipped":4416,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:14.531: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 03:09:14.973: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 03:09:16.979: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822554, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822554, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822554, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822554, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 03:09:18.981: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822554, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822554, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822554, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822554, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 03:09:21.985: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Sep 16 03:09:26.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 attach --namespace=webhook-2939 to-be-attached-pod -i -c=container1'
Sep 16 03:09:26.085: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:26.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2939" for this suite.
STEP: Destroying namespace "webhook-2939-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:11.581 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":277,"completed":256,"skipped":4417,"failed":0}
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:26.111: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Sep 16 03:09:26.133: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9892" to be "Succeeded or Failed"
Sep 16 03:09:26.135: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.709034ms
Sep 16 03:09:28.136: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003540093s
Sep 16 03:09:30.139: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005786276s
Sep 16 03:09:32.141: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008434997s
STEP: Saw pod success
Sep 16 03:09:32.141: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Sep 16 03:09:32.143: INFO: Trying to get logs from node 192.168.4.87 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 16 03:09:32.153: INFO: Waiting for pod pod-host-path-test to disappear
Sep 16 03:09:32.154: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:32.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9892" for this suite.

• [SLOW TEST:6.048 seconds]
[sig-storage] HostPath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":257,"skipped":4417,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:32.159: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Sep 16 03:09:32.179: INFO: Waiting up to 5m0s for pod "client-containers-aaf3f2b9-f124-404a-a672-1aeaf183e86d" in namespace "containers-6123" to be "Succeeded or Failed"
Sep 16 03:09:32.180: INFO: Pod "client-containers-aaf3f2b9-f124-404a-a672-1aeaf183e86d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.237739ms
Sep 16 03:09:34.182: INFO: Pod "client-containers-aaf3f2b9-f124-404a-a672-1aeaf183e86d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003622242s
Sep 16 03:09:36.185: INFO: Pod "client-containers-aaf3f2b9-f124-404a-a672-1aeaf183e86d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006469086s
STEP: Saw pod success
Sep 16 03:09:36.185: INFO: Pod "client-containers-aaf3f2b9-f124-404a-a672-1aeaf183e86d" satisfied condition "Succeeded or Failed"
Sep 16 03:09:36.187: INFO: Trying to get logs from node 192.168.4.87 pod client-containers-aaf3f2b9-f124-404a-a672-1aeaf183e86d container test-container: <nil>
STEP: delete the pod
Sep 16 03:09:36.200: INFO: Waiting for pod client-containers-aaf3f2b9-f124-404a-a672-1aeaf183e86d to disappear
Sep 16 03:09:36.202: INFO: Pod client-containers-aaf3f2b9-f124-404a-a672-1aeaf183e86d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:36.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6123" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":277,"completed":258,"skipped":4425,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:36.208: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:09:36.236: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"37b4db91-f85f-4d45-afd2-77835c0cf82a", Controller:(*bool)(0xc0039b544a), BlockOwnerDeletion:(*bool)(0xc0039b544b)}}
Sep 16 03:09:36.239: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"9663acc2-4dc9-413e-af62-f8bac07e9a66", Controller:(*bool)(0xc0030fcbf6), BlockOwnerDeletion:(*bool)(0xc0030fcbf7)}}
Sep 16 03:09:36.242: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"017ede4e-da27-498d-a45c-43b52423f12f", Controller:(*bool)(0xc0039b57a6), BlockOwnerDeletion:(*bool)(0xc0039b57a7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:41.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5865" for this suite.

• [SLOW TEST:5.042 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":277,"completed":259,"skipped":4436,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:41.250: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-dbffd39b-4a84-4d85-a568-7b402b444811
STEP: Creating a pod to test consume secrets
Sep 16 03:09:41.270: INFO: Waiting up to 5m0s for pod "pod-secrets-2d2b65a6-0959-47ad-8aa1-6fbb1de3c0a6" in namespace "secrets-5060" to be "Succeeded or Failed"
Sep 16 03:09:41.271: INFO: Pod "pod-secrets-2d2b65a6-0959-47ad-8aa1-6fbb1de3c0a6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.258965ms
Sep 16 03:09:43.273: INFO: Pod "pod-secrets-2d2b65a6-0959-47ad-8aa1-6fbb1de3c0a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003293289s
Sep 16 03:09:45.276: INFO: Pod "pod-secrets-2d2b65a6-0959-47ad-8aa1-6fbb1de3c0a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005848518s
STEP: Saw pod success
Sep 16 03:09:45.276: INFO: Pod "pod-secrets-2d2b65a6-0959-47ad-8aa1-6fbb1de3c0a6" satisfied condition "Succeeded or Failed"
Sep 16 03:09:45.278: INFO: Trying to get logs from node 192.168.4.87 pod pod-secrets-2d2b65a6-0959-47ad-8aa1-6fbb1de3c0a6 container secret-volume-test: <nil>
STEP: delete the pod
Sep 16 03:09:45.287: INFO: Waiting for pod pod-secrets-2d2b65a6-0959-47ad-8aa1-6fbb1de3c0a6 to disappear
Sep 16 03:09:45.288: INFO: Pod pod-secrets-2d2b65a6-0959-47ad-8aa1-6fbb1de3c0a6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:45.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5060" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":260,"skipped":4439,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:45.293: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-6150
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6150 to expose endpoints map[]
Sep 16 03:09:45.315: INFO: Get endpoints failed (1.397154ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep 16 03:09:46.316: INFO: successfully validated that service endpoint-test2 in namespace services-6150 exposes endpoints map[] (1.003062479s elapsed)
STEP: Creating pod pod1 in namespace services-6150
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6150 to expose endpoints map[pod1:[80]]
Sep 16 03:09:49.335: INFO: successfully validated that service endpoint-test2 in namespace services-6150 exposes endpoints map[pod1:[80]] (3.015008531s elapsed)
STEP: Creating pod pod2 in namespace services-6150
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6150 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 16 03:09:52.357: INFO: successfully validated that service endpoint-test2 in namespace services-6150 exposes endpoints map[pod1:[80] pod2:[80]] (3.018830775s elapsed)
STEP: Deleting pod pod1 in namespace services-6150
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6150 to expose endpoints map[pod2:[80]]
Sep 16 03:09:53.365: INFO: successfully validated that service endpoint-test2 in namespace services-6150 exposes endpoints map[pod2:[80]] (1.006423451s elapsed)
STEP: Deleting pod pod2 in namespace services-6150
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6150 to expose endpoints map[]
Sep 16 03:09:54.372: INFO: successfully validated that service endpoint-test2 in namespace services-6150 exposes endpoints map[] (1.004052415s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:09:54.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6150" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:9.092 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":277,"completed":261,"skipped":4451,"failed":0}
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:09:54.385: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Sep 16 03:09:54.402: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 16 03:10:54.413: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:10:54.415: INFO: Starting informer...
STEP: Starting pods...
Sep 16 03:10:54.623: INFO: Pod1 is running on 192.168.4.87. Tainting Node
Sep 16 03:10:58.833: INFO: Pod2 is running on 192.168.4.87. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Sep 16 03:11:18.806: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Sep 16 03:11:28.805: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:11:28.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-7754" for this suite.

• [SLOW TEST:94.435 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":277,"completed":262,"skipped":4451,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:11:28.820: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-pzbb
STEP: Creating a pod to test atomic-volume-subpath
Sep 16 03:11:28.851: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pzbb" in namespace "subpath-4956" to be "Succeeded or Failed"
Sep 16 03:11:28.852: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.358454ms
Sep 16 03:11:30.855: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003623027s
Sep 16 03:11:32.856: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005496913s
Sep 16 03:11:34.859: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Running", Reason="", readiness=true. Elapsed: 6.007922277s
Sep 16 03:11:36.861: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Running", Reason="", readiness=true. Elapsed: 8.010328666s
Sep 16 03:11:38.864: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Running", Reason="", readiness=true. Elapsed: 10.012612476s
Sep 16 03:11:40.866: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Running", Reason="", readiness=true. Elapsed: 12.015339089s
Sep 16 03:11:42.868: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Running", Reason="", readiness=true. Elapsed: 14.017107933s
Sep 16 03:11:44.870: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Running", Reason="", readiness=true. Elapsed: 16.019501444s
Sep 16 03:11:46.873: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Running", Reason="", readiness=true. Elapsed: 18.021848488s
Sep 16 03:11:48.875: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Running", Reason="", readiness=true. Elapsed: 20.024198265s
Sep 16 03:11:50.877: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Running", Reason="", readiness=true. Elapsed: 22.026110693s
Sep 16 03:11:52.879: INFO: Pod "pod-subpath-test-projected-pzbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.027949464s
STEP: Saw pod success
Sep 16 03:11:52.879: INFO: Pod "pod-subpath-test-projected-pzbb" satisfied condition "Succeeded or Failed"
Sep 16 03:11:52.880: INFO: Trying to get logs from node 192.168.4.87 pod pod-subpath-test-projected-pzbb container test-container-subpath-projected-pzbb: <nil>
STEP: delete the pod
Sep 16 03:11:52.898: INFO: Waiting for pod pod-subpath-test-projected-pzbb to disappear
Sep 16 03:11:52.899: INFO: Pod pod-subpath-test-projected-pzbb no longer exists
STEP: Deleting pod pod-subpath-test-projected-pzbb
Sep 16 03:11:52.899: INFO: Deleting pod "pod-subpath-test-projected-pzbb" in namespace "subpath-4956"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:11:52.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4956" for this suite.

• [SLOW TEST:24.085 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":277,"completed":263,"skipped":4485,"failed":0}
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:11:52.905: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:12:23.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5833" for this suite.
STEP: Destroying namespace "nsdeletetest-8308" for this suite.
Sep 16 03:12:23.965: INFO: Namespace nsdeletetest-8308 was already deleted
STEP: Destroying namespace "nsdeletetest-6286" for this suite.

• [SLOW TEST:31.062 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":277,"completed":264,"skipped":4485,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:12:23.967: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 16 03:12:23.985: INFO: Waiting up to 5m0s for pod "downwardapi-volume-594c9a71-bbfc-4674-9d39-2b92ed0f7764" in namespace "downward-api-9426" to be "Succeeded or Failed"
Sep 16 03:12:23.986: INFO: Pod "downwardapi-volume-594c9a71-bbfc-4674-9d39-2b92ed0f7764": Phase="Pending", Reason="", readiness=false. Elapsed: 1.328803ms
Sep 16 03:12:25.989: INFO: Pod "downwardapi-volume-594c9a71-bbfc-4674-9d39-2b92ed0f7764": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003834946s
Sep 16 03:12:27.991: INFO: Pod "downwardapi-volume-594c9a71-bbfc-4674-9d39-2b92ed0f7764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006423999s
STEP: Saw pod success
Sep 16 03:12:27.991: INFO: Pod "downwardapi-volume-594c9a71-bbfc-4674-9d39-2b92ed0f7764" satisfied condition "Succeeded or Failed"
Sep 16 03:12:27.993: INFO: Trying to get logs from node 192.168.4.87 pod downwardapi-volume-594c9a71-bbfc-4674-9d39-2b92ed0f7764 container client-container: <nil>
STEP: delete the pod
Sep 16 03:12:28.002: INFO: Waiting for pod downwardapi-volume-594c9a71-bbfc-4674-9d39-2b92ed0f7764 to disappear
Sep 16 03:12:28.003: INFO: Pod downwardapi-volume-594c9a71-bbfc-4674-9d39-2b92ed0f7764 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:12:28.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9426" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":265,"skipped":4498,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:12:28.008: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 16 03:12:28.024: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 16 03:12:28.030: INFO: Waiting for terminating namespaces to be deleted...
Sep 16 03:12:28.031: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.86 before test
Sep 16 03:12:28.043: INFO: cke-lvmcsi-nf9cd from cke-storage started at 2020-09-16 01:25:20 +0000 UTC (2 container statuses recorded)
Sep 16 03:12:28.043: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 03:12:28.043: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 03:12:28.043: INFO: ckecsi-runc-jq25h from cke-storage started at 2020-09-16 01:25:30 +0000 UTC (2 container statuses recorded)
Sep 16 03:12:28.043: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 03:12:28.043: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 03:12:28.043: INFO: sonobuoy from sonobuoy started at 2020-09-16 01:52:42 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.043: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 16 03:12:28.043: INFO: metrics-server-cf7f9ccc5-ddpmv from kube-system started at 2020-09-16 02:39:33 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.043: INFO: 	Container metrics-server ready: true, restart count 0
Sep 16 03:12:28.043: INFO: ckecsi-provisioner-1 from cke-storage started at 2020-09-16 03:11:02 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.043: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep 16 03:12:28.043: INFO: calico-kube-controllers-97dc579d-s2z7r from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.043: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 16 03:12:28.043: INFO: sonobuoy-e2e-job-a58be685376b45c9 from sonobuoy started at 2020-09-16 01:52:44 +0000 UTC (2 container statuses recorded)
Sep 16 03:12:28.043: INFO: 	Container e2e ready: true, restart count 0
Sep 16 03:12:28.043: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 16 03:12:28.043: INFO: dashboard-metrics-scraper-6fb76cb999-6nsjt from kubernetes-dashboard started at 2020-09-16 03:10:58 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.044: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Sep 16 03:12:28.044: INFO: coredns-75587db8b6-vlztj from kube-system started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.044: INFO: 	Container coredns ready: true, restart count 0
Sep 16 03:12:28.044: INFO: ckecsi-attacher-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.044: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep 16 03:12:28.044: INFO: kubernetes-dashboard-7d464dfc59-d5sxx from kubernetes-dashboard started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.044: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 16 03:12:28.044: INFO: ckecsi-attacher-1 from cke-storage started at 2020-09-16 03:11:02 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.044: INFO: 	Container ckecsi-attacher ready: true, restart count 0
Sep 16 03:12:28.044: INFO: ckecsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:38 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.044: INFO: 	Container ckecsi-provisioner ready: true, restart count 0
Sep 16 03:12:28.044: INFO: 
Logging pods the kubelet thinks is on node 192.168.4.87 before test
Sep 16 03:12:28.047: INFO: cke-lvmcsi-provisioner-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.047: INFO: 	Container csi-provisioner ready: true, restart count 1
Sep 16 03:12:28.047: INFO: cke-lvmcsi-q44bw from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (2 container statuses recorded)
Sep 16 03:12:28.047: INFO: 	Container csi-lvmplugin ready: true, restart count 0
Sep 16 03:12:28.047: INFO: 	Container driver-registrar ready: true, restart count 0
Sep 16 03:12:28.047: INFO: cke-lvmcsi-resizer-0 from cke-storage started at 2020-09-16 01:25:19 +0000 UTC (1 container statuses recorded)
Sep 16 03:12:28.047: INFO: 	Container csi-lvm-resizer ready: true, restart count 0
Sep 16 03:12:28.047: INFO: ckecsi-runc-kgwwv from cke-storage started at 2020-09-16 03:11:28 +0000 UTC (2 container statuses recorded)
Sep 16 03:12:28.047: INFO: 	Container ckecsi ready: true, restart count 0
Sep 16 03:12:28.047: INFO: 	Container driver-registrar ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node 192.168.4.86
STEP: verifying the node has the label node 192.168.4.87
Sep 16 03:12:28.074: INFO: Pod cke-lvmcsi-nf9cd requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod cke-lvmcsi-provisioner-0 requesting resource cpu=0m on Node 192.168.4.87
Sep 16 03:12:28.074: INFO: Pod cke-lvmcsi-q44bw requesting resource cpu=0m on Node 192.168.4.87
Sep 16 03:12:28.074: INFO: Pod cke-lvmcsi-resizer-0 requesting resource cpu=0m on Node 192.168.4.87
Sep 16 03:12:28.074: INFO: Pod ckecsi-attacher-0 requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod ckecsi-attacher-1 requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod ckecsi-provisioner-0 requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod ckecsi-provisioner-1 requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod ckecsi-runc-jq25h requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod ckecsi-runc-kgwwv requesting resource cpu=0m on Node 192.168.4.87
Sep 16 03:12:28.074: INFO: Pod calico-kube-controllers-97dc579d-s2z7r requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod coredns-75587db8b6-vlztj requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod metrics-server-cf7f9ccc5-ddpmv requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod dashboard-metrics-scraper-6fb76cb999-6nsjt requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod kubernetes-dashboard-7d464dfc59-d5sxx requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.4.86
Sep 16 03:12:28.074: INFO: Pod sonobuoy-e2e-job-a58be685376b45c9 requesting resource cpu=0m on Node 192.168.4.86
STEP: Starting Pods to consume most of the cluster CPU.
Sep 16 03:12:28.074: INFO: Creating a pod which consumes cpu=16800m on Node 192.168.4.86
Sep 16 03:12:28.078: INFO: Creating a pod which consumes cpu=16800m on Node 192.168.4.87
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c58009c8-3fe1-4d10-acac-50c4129759ce.163525057bb89aa2], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9652/filler-pod-c58009c8-3fe1-4d10-acac-50c4129759ce to 192.168.4.86]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c58009c8-3fe1-4d10-acac-50c4129759ce.16352505e394f0e3], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c58009c8-3fe1-4d10-acac-50c4129759ce.163525060aaaa53b], Reason = [Created], Message = [Created container filler-pod-c58009c8-3fe1-4d10-acac-50c4129759ce]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c58009c8-3fe1-4d10-acac-50c4129759ce.163525061ae4f26e], Reason = [Started], Message = [Started container filler-pod-c58009c8-3fe1-4d10-acac-50c4129759ce]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c7eea007-3ce7-4fe4-8af3-95df5742621b.163525057bd98978], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9652/filler-pod-c7eea007-3ce7-4fe4-8af3-95df5742621b to 192.168.4.87]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c7eea007-3ce7-4fe4-8af3-95df5742621b.16352505e1cc790b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c7eea007-3ce7-4fe4-8af3-95df5742621b.163525060aab17e0], Reason = [Created], Message = [Created container filler-pod-c7eea007-3ce7-4fe4-8af3-95df5742621b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c7eea007-3ce7-4fe4-8af3-95df5742621b.163525061bdc00ef], Reason = [Started], Message = [Started container filler-pod-c7eea007-3ce7-4fe4-8af3-95df5742621b]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.163525066aee74d5], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 192.168.4.86
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 192.168.4.87
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:12:33.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9652" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:5.105 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":277,"completed":266,"skipped":4511,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:12:33.114: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Sep 16 03:12:33.639: INFO: created pod pod-service-account-defaultsa
Sep 16 03:12:33.639: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 16 03:12:33.641: INFO: created pod pod-service-account-mountsa
Sep 16 03:12:33.641: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 16 03:12:33.644: INFO: created pod pod-service-account-nomountsa
Sep 16 03:12:33.644: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 16 03:12:33.646: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 16 03:12:33.646: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 16 03:12:33.649: INFO: created pod pod-service-account-mountsa-mountspec
Sep 16 03:12:33.649: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 16 03:12:33.651: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 16 03:12:33.651: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 16 03:12:33.653: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 16 03:12:33.653: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 16 03:12:33.655: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 16 03:12:33.655: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 16 03:12:33.657: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 16 03:12:33.657: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:12:33.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6855" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":277,"completed":267,"skipped":4539,"failed":0}
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:12:33.662: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 16 03:12:33.691: INFO: Number of nodes with available pods: 0
Sep 16 03:12:33.691: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:34.695: INFO: Number of nodes with available pods: 0
Sep 16 03:12:34.695: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:35.695: INFO: Number of nodes with available pods: 0
Sep 16 03:12:35.695: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:36.697: INFO: Number of nodes with available pods: 0
Sep 16 03:12:36.697: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:37.696: INFO: Number of nodes with available pods: 0
Sep 16 03:12:37.696: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:38.696: INFO: Number of nodes with available pods: 0
Sep 16 03:12:38.696: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:39.696: INFO: Number of nodes with available pods: 0
Sep 16 03:12:39.696: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:40.696: INFO: Number of nodes with available pods: 0
Sep 16 03:12:40.696: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:41.696: INFO: Number of nodes with available pods: 1
Sep 16 03:12:41.696: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:42.696: INFO: Number of nodes with available pods: 1
Sep 16 03:12:42.696: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:43.695: INFO: Number of nodes with available pods: 1
Sep 16 03:12:43.695: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:44.696: INFO: Number of nodes with available pods: 1
Sep 16 03:12:44.696: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:45.695: INFO: Number of nodes with available pods: 1
Sep 16 03:12:45.695: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:46.695: INFO: Number of nodes with available pods: 1
Sep 16 03:12:46.695: INFO: Node 192.168.4.86 is running more than one daemon pod
Sep 16 03:12:47.695: INFO: Number of nodes with available pods: 2
Sep 16 03:12:47.695: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 16 03:12:47.705: INFO: Number of nodes with available pods: 1
Sep 16 03:12:47.705: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 03:12:48.710: INFO: Number of nodes with available pods: 1
Sep 16 03:12:48.710: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 03:12:49.709: INFO: Number of nodes with available pods: 1
Sep 16 03:12:49.709: INFO: Node 192.168.4.87 is running more than one daemon pod
Sep 16 03:12:50.710: INFO: Number of nodes with available pods: 2
Sep 16 03:12:50.710: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5264, will wait for the garbage collector to delete the pods
Sep 16 03:12:50.767: INFO: Deleting DaemonSet.extensions daemon-set took: 3.736742ms
Sep 16 03:12:51.168: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.16304ms
Sep 16 03:12:58.869: INFO: Number of nodes with available pods: 0
Sep 16 03:12:58.869: INFO: Number of running nodes: 0, number of available pods: 0
Sep 16 03:12:58.871: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5264/daemonsets","resourceVersion":"34503"},"items":null}

Sep 16 03:12:58.872: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5264/pods","resourceVersion":"34503"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:12:58.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5264" for this suite.

• [SLOW TEST:25.219 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":277,"completed":268,"skipped":4543,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:12:58.881: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Sep 16 03:12:58.903: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Sep 16 03:12:58.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-2786'
Sep 16 03:13:01.334: INFO: stderr: ""
Sep 16 03:13:01.334: INFO: stdout: "service/agnhost-slave created\n"
Sep 16 03:13:01.334: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Sep 16 03:13:01.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-2786'
Sep 16 03:13:01.564: INFO: stderr: ""
Sep 16 03:13:01.564: INFO: stdout: "service/agnhost-master created\n"
Sep 16 03:13:01.564: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 16 03:13:01.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-2786'
Sep 16 03:13:01.825: INFO: stderr: ""
Sep 16 03:13:01.825: INFO: stdout: "service/frontend created\n"
Sep 16 03:13:01.825: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Sep 16 03:13:01.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-2786'
Sep 16 03:13:02.048: INFO: stderr: ""
Sep 16 03:13:02.048: INFO: stdout: "deployment.apps/frontend created\n"
Sep 16 03:13:02.048: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 16 03:13:02.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-2786'
Sep 16 03:13:02.330: INFO: stderr: ""
Sep 16 03:13:02.330: INFO: stdout: "deployment.apps/agnhost-master created\n"
Sep 16 03:13:02.330: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 16 03:13:02.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 create -f - --namespace=kubectl-2786'
Sep 16 03:13:02.975: INFO: stderr: ""
Sep 16 03:13:02.975: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Sep 16 03:13:02.975: INFO: Waiting for all frontend pods to be Running.
Sep 16 03:13:13.025: INFO: Waiting for frontend to serve content.
Sep 16 03:13:13.032: INFO: Trying to add a new entry to the guestbook.
Sep 16 03:13:13.037: INFO: Verifying that added entry can be retrieved.
Sep 16 03:13:13.042: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources
Sep 16 03:13:18.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete --grace-period=0 --force -f - --namespace=kubectl-2786'
Sep 16 03:13:18.126: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 16 03:13:18.126: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 16 03:13:18.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete --grace-period=0 --force -f - --namespace=kubectl-2786'
Sep 16 03:13:18.207: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 16 03:13:18.207: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 16 03:13:18.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete --grace-period=0 --force -f - --namespace=kubectl-2786'
Sep 16 03:13:18.302: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 16 03:13:18.302: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 16 03:13:18.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete --grace-period=0 --force -f - --namespace=kubectl-2786'
Sep 16 03:13:18.384: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 16 03:13:18.384: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 16 03:13:18.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete --grace-period=0 --force -f - --namespace=kubectl-2786'
Sep 16 03:13:18.459: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 16 03:13:18.459: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 16 03:13:18.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-120268828 delete --grace-period=0 --force -f - --namespace=kubectl-2786'
Sep 16 03:13:18.535: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 16 03:13:18.536: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:13:18.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2786" for this suite.

• [SLOW TEST:19.659 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:310
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":277,"completed":269,"skipped":4557,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:13:18.541: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep 16 03:13:24.574: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8961 PodName:pod-sharedvolume-0a0286f1-9e17-42a9-80f3-dd9026ea5b52 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 16 03:13:24.574: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
Sep 16 03:13:24.673: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:13:24.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8961" for this suite.

• [SLOW TEST:6.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":277,"completed":270,"skipped":4572,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:13:24.681: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 16 03:13:25.312: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 16 03:13:27.317: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822805, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822805, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822805, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822805, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 16 03:13:30.323: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:13:30.325: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9685-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:13:31.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9637" for this suite.
STEP: Destroying namespace "webhook-9637-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.730 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":277,"completed":271,"skipped":4614,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:13:31.412: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-a6032c53-7e0b-471e-8001-d2aafda1f8b8
STEP: Creating a pod to test consume secrets
Sep 16 03:13:31.442: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-977dcf54-7483-47e6-b260-302c06f9e5a6" in namespace "projected-6974" to be "Succeeded or Failed"
Sep 16 03:13:31.443: INFO: Pod "pod-projected-secrets-977dcf54-7483-47e6-b260-302c06f9e5a6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.402222ms
Sep 16 03:13:33.445: INFO: Pod "pod-projected-secrets-977dcf54-7483-47e6-b260-302c06f9e5a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003772618s
Sep 16 03:13:35.447: INFO: Pod "pod-projected-secrets-977dcf54-7483-47e6-b260-302c06f9e5a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00567333s
STEP: Saw pod success
Sep 16 03:13:35.447: INFO: Pod "pod-projected-secrets-977dcf54-7483-47e6-b260-302c06f9e5a6" satisfied condition "Succeeded or Failed"
Sep 16 03:13:35.449: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-secrets-977dcf54-7483-47e6-b260-302c06f9e5a6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 16 03:13:35.458: INFO: Waiting for pod pod-projected-secrets-977dcf54-7483-47e6-b260-302c06f9e5a6 to disappear
Sep 16 03:13:35.459: INFO: Pod pod-projected-secrets-977dcf54-7483-47e6-b260-302c06f9e5a6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:13:35.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6974" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":272,"skipped":4667,"failed":0}
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:13:35.463: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 16 03:13:38.491: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:13:38.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1684" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":273,"skipped":4669,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:13:38.500: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:13:45.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7295" for this suite.

• [SLOW TEST:7.028 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":277,"completed":274,"skipped":4682,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:13:45.528: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-1435/configmap-test-2d1558b8-372a-4fb5-b467-83c879715e7f
STEP: Creating a pod to test consume configMaps
Sep 16 03:13:45.551: INFO: Waiting up to 5m0s for pod "pod-configmaps-323af51a-ec8d-4de4-b82c-4d837867606f" in namespace "configmap-1435" to be "Succeeded or Failed"
Sep 16 03:13:45.552: INFO: Pod "pod-configmaps-323af51a-ec8d-4de4-b82c-4d837867606f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.373501ms
Sep 16 03:13:47.554: INFO: Pod "pod-configmaps-323af51a-ec8d-4de4-b82c-4d837867606f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003759642s
Sep 16 03:13:49.557: INFO: Pod "pod-configmaps-323af51a-ec8d-4de4-b82c-4d837867606f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006212786s
STEP: Saw pod success
Sep 16 03:13:49.557: INFO: Pod "pod-configmaps-323af51a-ec8d-4de4-b82c-4d837867606f" satisfied condition "Succeeded or Failed"
Sep 16 03:13:49.558: INFO: Trying to get logs from node 192.168.4.87 pod pod-configmaps-323af51a-ec8d-4de4-b82c-4d837867606f container env-test: <nil>
STEP: delete the pod
Sep 16 03:13:49.567: INFO: Waiting for pod pod-configmaps-323af51a-ec8d-4de4-b82c-4d837867606f to disappear
Sep 16 03:13:49.569: INFO: Pod pod-configmaps-323af51a-ec8d-4de4-b82c-4d837867606f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:13:49.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1435" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":275,"skipped":4693,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:13:49.573: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-f39f9177-0668-4865-a999-aa21afcbabbf
STEP: Creating a pod to test consume configMaps
Sep 16 03:13:49.592: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-28c88087-0781-4d33-a4e2-e55de9f83c7c" in namespace "projected-1042" to be "Succeeded or Failed"
Sep 16 03:13:49.594: INFO: Pod "pod-projected-configmaps-28c88087-0781-4d33-a4e2-e55de9f83c7c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.246083ms
Sep 16 03:13:51.596: INFO: Pod "pod-projected-configmaps-28c88087-0781-4d33-a4e2-e55de9f83c7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003342664s
Sep 16 03:13:53.598: INFO: Pod "pod-projected-configmaps-28c88087-0781-4d33-a4e2-e55de9f83c7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005775016s
STEP: Saw pod success
Sep 16 03:13:53.598: INFO: Pod "pod-projected-configmaps-28c88087-0781-4d33-a4e2-e55de9f83c7c" satisfied condition "Succeeded or Failed"
Sep 16 03:13:53.600: INFO: Trying to get logs from node 192.168.4.87 pod pod-projected-configmaps-28c88087-0781-4d33-a4e2-e55de9f83c7c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 16 03:13:53.609: INFO: Waiting for pod pod-projected-configmaps-28c88087-0781-4d33-a4e2-e55de9f83c7c to disappear
Sep 16 03:13:53.610: INFO: Pod pod-projected-configmaps-28c88087-0781-4d33-a4e2-e55de9f83c7c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:13:53.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1042" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":276,"skipped":4711,"failed":0}
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 16 03:13:53.614: INFO: >>> kubeConfig: /tmp/kubeconfig-120268828
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 16 03:13:53.634: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 16 03:13:58.636: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 16 03:13:58.636: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 16 03:14:00.638: INFO: Creating deployment "test-rollover-deployment"
Sep 16 03:14:00.642: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 16 03:14:02.646: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 16 03:14:02.649: INFO: Ensure that both replica sets have 1 created replica
Sep 16 03:14:02.653: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 16 03:14:02.657: INFO: Updating deployment test-rollover-deployment
Sep 16 03:14:02.657: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 16 03:14:04.661: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 16 03:14:04.664: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 16 03:14:04.667: INFO: all replica sets need to contain the pod-template-hash label
Sep 16 03:14:04.667: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822842, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 03:14:06.671: INFO: all replica sets need to contain the pod-template-hash label
Sep 16 03:14:06.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822845, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 03:14:08.671: INFO: all replica sets need to contain the pod-template-hash label
Sep 16 03:14:08.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822845, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 03:14:10.671: INFO: all replica sets need to contain the pod-template-hash label
Sep 16 03:14:10.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822845, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 03:14:12.671: INFO: all replica sets need to contain the pod-template-hash label
Sep 16 03:14:12.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822845, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 03:14:14.672: INFO: all replica sets need to contain the pod-template-hash label
Sep 16 03:14:14.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822845, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735822840, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 16 03:14:16.671: INFO: 
Sep 16 03:14:16.671: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 16 03:14:16.675: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9900 /apis/apps/v1/namespaces/deployment-9900/deployments/test-rollover-deployment e76d2837-5a5e-42dd-9e5c-7ce22c2c352b 35349 2 2020-09-16 03:14:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-09-16 03:14:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-16 03:14:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00398aa28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-09-16 03:14:00 +0000 UTC,LastTransitionTime:2020-09-16 03:14:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-09-16 03:14:15 +0000 UTC,LastTransitionTime:2020-09-16 03:14:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 16 03:14:16.677: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-9900 /apis/apps/v1/namespaces/deployment-9900/replicasets/test-rollover-deployment-84f7f6f64b dbb39e16-2a94-4c02-b212-b02024e0dd28 35339 2 2020-09-16 03:14:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment e76d2837-5a5e-42dd-9e5c-7ce22c2c352b 0xc003c8ec77 0xc003c8ec78}] []  [{kube-controller-manager Update apps/v1 2020-09-16 03:14:15 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 55 54 100 50 56 51 55 45 53 97 53 101 45 52 50 100 100 45 57 101 53 99 45 55 99 101 50 50 99 50 99 51 53 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003c8ed08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 16 03:14:16.677: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 16 03:14:16.678: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9900 /apis/apps/v1/namespaces/deployment-9900/replicasets/test-rollover-controller b1b14649-9f1b-4e44-9492-1c50873eeee4 35348 2 2020-09-16 03:13:53 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment e76d2837-5a5e-42dd-9e5c-7ce22c2c352b 0xc003c8ea67 0xc003c8ea68}] []  [{e2e.test Update apps/v1 2020-09-16 03:13:53 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-16 03:14:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 55 54 100 50 56 51 55 45 53 97 53 101 45 52 50 100 100 45 57 101 53 99 45 55 99 101 50 50 99 50 99 51 53 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003c8eb08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 16 03:14:16.678: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-9900 /apis/apps/v1/namespaces/deployment-9900/replicasets/test-rollover-deployment-5686c4cfd5 7ed85935-f3df-45e5-b047-1acd2f1c20ec 35291 2 2020-09-16 03:14:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment e76d2837-5a5e-42dd-9e5c-7ce22c2c352b 0xc003c8eb77 0xc003c8eb78}] []  [{kube-controller-manager Update apps/v1 2020-09-16 03:14:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 55 54 100 50 56 51 55 45 53 97 53 101 45 52 50 100 100 45 57 101 53 99 45 55 99 101 50 50 99 50 99 51 53 50 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003c8ec08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 16 03:14:16.680: INFO: Pod "test-rollover-deployment-84f7f6f64b-lshjl" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-lshjl test-rollover-deployment-84f7f6f64b- deployment-9900 /api/v1/namespaces/deployment-9900/pods/test-rollover-deployment-84f7f6f64b-lshjl 81f1fe87-6031-419b-b07e-e2e4a83f2f53 35313 0 2020-09-16 03:14:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b dbb39e16-2a94-4c02-b212-b02024e0dd28 0xc003c8f2d7 0xc003c8f2d8}] []  [{kube-controller-manager Update v1 2020-09-16 03:14:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 98 98 51 57 101 49 54 45 50 97 57 52 45 52 99 48 50 45 98 50 49 50 45 98 48 50 48 50 52 101 48 100 100 50 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-16 03:14:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 49 53 49 46 49 48 52 46 53 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9rcmx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9rcmx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9rcmx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.4.87,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 03:14:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 03:14:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 03:14:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-16 03:14:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.4.87,PodIP:172.151.104.57,StartTime:2020-09-16 03:14:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-16 03:14:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:reg.mg.hcbss/devcke/agnhost:2.12,ImageID:docker-pullable://reg.mg.hcbss/devcke/agnhost@sha256:1dfec5637a7010d6c0955c26f0a752266fa2646ed2bf8e6ad745cdcfcb611db8,ContainerID:docker://e81465614fdb7b73d628776d1681bd86c6c6185f340f0607759ec5a71ec01d72,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.151.104.57,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 16 03:14:16.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9900" for this suite.

• [SLOW TEST:23.069 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":277,"completed":277,"skipped":4713,"failed":0}
SSSep 16 03:14:16.684: INFO: Running AfterSuite actions on all nodes
Sep 16 03:14:16.684: INFO: Running AfterSuite actions on node 1
Sep 16 03:14:16.684: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":277,"completed":277,"skipped":4715,"failed":0}

Ran 277 of 4992 Specs in 4888.033 seconds
SUCCESS! -- 277 Passed | 0 Failed | 0 Pending | 4715 Skipped
PASS

Ginkgo ran 1 suite in 1h21m29.644527262s
Test Suite Passed
