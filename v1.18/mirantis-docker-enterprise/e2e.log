I1111 20:59:38.878931      21 test_context.go:410] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-504766910
I1111 20:59:38.879136      21 test_context.go:423] Tolerating taints "com.docker.ucp.manager" when considering if nodes are ready
I1111 20:59:38.879343      21 e2e.go:124] Starting e2e run "75f4a91d-80a0-46c6-9f6e-c2b5305785c8" on Ginkgo node 1
{"msg":"Test Suite starting","total":277,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1605128376 - Will randomize all specs
Will run 277 of 4993 specs

Nov 11 20:59:38.921: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 20:59:38.925: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov 11 20:59:38.948: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 11 20:59:38.979: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 11 20:59:38.980: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Nov 11 20:59:38.980: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 11 20:59:38.993: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov 11 20:59:38.993: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'ucp-metrics' (0 seconds elapsed)
Nov 11 20:59:38.993: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'ucp-nvidia-device-plugin' (0 seconds elapsed)
Nov 11 20:59:38.993: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ucp-tigera-pinhnsnet' (0 seconds elapsed)
Nov 11 20:59:38.993: INFO: e2e test version: v1.18.10
Nov 11 20:59:38.994: INFO: kube-apiserver version: v1.18.10-mirantis-1
Nov 11 20:59:38.994: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 20:59:38.999: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 20:59:39.000: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
Nov 11 20:59:39.444: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov 11 20:59:39.467: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1997
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 20:59:55.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1997" for this suite.

• [SLOW TEST:16.718 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":277,"completed":1,"skipped":42,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 20:59:55.720: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-42f7be26-38bc-4f93-83ff-0859bf2eebdc
STEP: Creating a pod to test consume configMaps
Nov 11 20:59:56.319: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-10471250-1950-4c8c-b0a7-8315bef143e1" in namespace "projected-3742" to be "Succeeded or Failed"
Nov 11 20:59:56.321: INFO: Pod "pod-projected-configmaps-10471250-1950-4c8c-b0a7-8315bef143e1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.925766ms
Nov 11 20:59:58.324: INFO: Pod "pod-projected-configmaps-10471250-1950-4c8c-b0a7-8315bef143e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004337226s
Nov 11 21:00:00.326: INFO: Pod "pod-projected-configmaps-10471250-1950-4c8c-b0a7-8315bef143e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006706674s
STEP: Saw pod success
Nov 11 21:00:00.326: INFO: Pod "pod-projected-configmaps-10471250-1950-4c8c-b0a7-8315bef143e1" satisfied condition "Succeeded or Failed"
Nov 11 21:00:00.328: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-configmaps-10471250-1950-4c8c-b0a7-8315bef143e1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:00:00.348: INFO: Waiting for pod pod-projected-configmaps-10471250-1950-4c8c-b0a7-8315bef143e1 to disappear
Nov 11 21:00:00.350: INFO: Pod pod-projected-configmaps-10471250-1950-4c8c-b0a7-8315bef143e1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:00:00.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3742" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":2,"skipped":72,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:00:00.356: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2729
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 11 21:00:00.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-2729'
Nov 11 21:00:01.250: INFO: stderr: ""
Nov 11 21:00:01.250: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Nov 11 21:00:11.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pod e2e-test-httpd-pod --namespace=kubectl-2729 -o json'
Nov 11 21:00:11.372: INFO: stderr: ""
Nov 11 21:00:11.372: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-11-11T21:00:01Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-11-11T21:00:01Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"192.168.211.69\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"hyperkube\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-11-11T21:00:08Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2729\",\n        \"resourceVersion\": \"4517\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-2729/pods/e2e-test-httpd-pod\",\n        \"uid\": \"5e6770e7-bf12-4c8f-890e-26066e99fd35\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-nc77g\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-0-62.us-west-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-nc77g\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-nc77g\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-11T21:00:01Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-11T21:00:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-11T21:00:08Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-11T21:00:01Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://712a17e0a319e73a58383055d7d1db35a93af036a7bb2ac0ef34c3e0bd4c14a2\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-11-11T21:00:07Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.0.62\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.211.69\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.211.69\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-11-11T21:00:01Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov 11 21:00:11.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 replace -f - --namespace=kubectl-2729'
Nov 11 21:00:11.684: INFO: stderr: ""
Nov 11 21:00:11.684: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Nov 11 21:00:11.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete pods e2e-test-httpd-pod --namespace=kubectl-2729'
Nov 11 21:00:15.572: INFO: stderr: ""
Nov 11 21:00:15.572: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:00:15.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2729" for this suite.

• [SLOW TEST:15.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1450
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":277,"completed":3,"skipped":78,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:00:15.582: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9854
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:00:16.869: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:00:18.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:00:20.878: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:00:22.879: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:00:24.878: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725217, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:00:27.886: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:00:28.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9854" for this suite.
STEP: Destroying namespace "webhook-9854-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:12.510 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":277,"completed":4,"skipped":85,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:00:28.093: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2445
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:00:28.602: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov 11 21:00:32.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-2445 create -f -'
Nov 11 21:00:32.637: INFO: stderr: ""
Nov 11 21:00:32.637: INFO: stdout: "e2e-test-crd-publish-openapi-9675-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 11 21:00:32.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-2445 delete e2e-test-crd-publish-openapi-9675-crds test-cr'
Nov 11 21:00:32.711: INFO: stderr: ""
Nov 11 21:00:32.711: INFO: stdout: "e2e-test-crd-publish-openapi-9675-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov 11 21:00:32.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-2445 apply -f -'
Nov 11 21:00:32.881: INFO: stderr: ""
Nov 11 21:00:32.881: INFO: stdout: "e2e-test-crd-publish-openapi-9675-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 11 21:00:32.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-2445 delete e2e-test-crd-publish-openapi-9675-crds test-cr'
Nov 11 21:00:32.954: INFO: stderr: ""
Nov 11 21:00:32.954: INFO: stdout: "e2e-test-crd-publish-openapi-9675-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Nov 11 21:00:32.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 explain e2e-test-crd-publish-openapi-9675-crds'
Nov 11 21:00:33.116: INFO: stderr: ""
Nov 11 21:00:33.116: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9675-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:00:36.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2445" for this suite.

• [SLOW TEST:8.574 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":277,"completed":5,"skipped":90,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:00:36.668: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Nov 11 21:00:39.752: INFO: Successfully updated pod "labelsupdate16beb557-9cb1-4e4e-8513-d70b6d2f1870"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:00:43.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9852" for this suite.

• [SLOW TEST:7.111 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":6,"skipped":93,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:00:43.781: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6753
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-c971d6e4-8966-4012-8382-3ee9763e2501
STEP: Creating a pod to test consume configMaps
Nov 11 21:00:44.348: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5e524b4a-3623-470d-a8a5-cf9876e9b625" in namespace "projected-6753" to be "Succeeded or Failed"
Nov 11 21:00:44.351: INFO: Pod "pod-projected-configmaps-5e524b4a-3623-470d-a8a5-cf9876e9b625": Phase="Pending", Reason="", readiness=false. Elapsed: 2.001281ms
Nov 11 21:00:46.353: INFO: Pod "pod-projected-configmaps-5e524b4a-3623-470d-a8a5-cf9876e9b625": Phase="Running", Reason="", readiness=true. Elapsed: 2.004224653s
Nov 11 21:00:48.355: INFO: Pod "pod-projected-configmaps-5e524b4a-3623-470d-a8a5-cf9876e9b625": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006592731s
STEP: Saw pod success
Nov 11 21:00:48.355: INFO: Pod "pod-projected-configmaps-5e524b4a-3623-470d-a8a5-cf9876e9b625" satisfied condition "Succeeded or Failed"
Nov 11 21:00:48.357: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-configmaps-5e524b4a-3623-470d-a8a5-cf9876e9b625 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:00:48.373: INFO: Waiting for pod pod-projected-configmaps-5e524b4a-3623-470d-a8a5-cf9876e9b625 to disappear
Nov 11 21:00:48.376: INFO: Pod pod-projected-configmaps-5e524b4a-3623-470d-a8a5-cf9876e9b625 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:00:48.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6753" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":7,"skipped":122,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:00:48.385: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6066
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Nov 11 21:00:48.947: INFO: Waiting up to 5m0s for pod "client-containers-efa6a7bf-5cb3-4456-8dde-5e47e17726c4" in namespace "containers-6066" to be "Succeeded or Failed"
Nov 11 21:00:48.949: INFO: Pod "client-containers-efa6a7bf-5cb3-4456-8dde-5e47e17726c4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.671054ms
Nov 11 21:00:50.951: INFO: Pod "client-containers-efa6a7bf-5cb3-4456-8dde-5e47e17726c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00404079s
Nov 11 21:00:52.953: INFO: Pod "client-containers-efa6a7bf-5cb3-4456-8dde-5e47e17726c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006369085s
STEP: Saw pod success
Nov 11 21:00:52.953: INFO: Pod "client-containers-efa6a7bf-5cb3-4456-8dde-5e47e17726c4" satisfied condition "Succeeded or Failed"
Nov 11 21:00:52.955: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod client-containers-efa6a7bf-5cb3-4456-8dde-5e47e17726c4 container test-container: <nil>
STEP: delete the pod
Nov 11 21:00:52.968: INFO: Waiting for pod client-containers-efa6a7bf-5cb3-4456-8dde-5e47e17726c4 to disappear
Nov 11 21:00:52.970: INFO: Pod client-containers-efa6a7bf-5cb3-4456-8dde-5e47e17726c4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:00:52.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6066" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":277,"completed":8,"skipped":139,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:00:52.978: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6701
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:01:06.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6701" for this suite.

• [SLOW TEST:13.687 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":277,"completed":9,"skipped":156,"failed":0}
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:01:06.665: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Nov 11 21:01:07.194: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 11 21:01:07.202: INFO: Waiting for terminating namespaces to be deleted...
Nov 11 21:01:07.204: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-166.us-west-2.compute.internal before test
Nov 11 21:01:07.215: INFO: calico-node-vdd82 from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:01:07.215: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:01:07.215: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:01:07.215: INFO: ucp-nvidia-device-plugin-749cm from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:01:07.215: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:01:07.215: INFO: sonobuoy-e2e-job-9a557cfe0d894233 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:01:07.215: INFO: 	Container e2e ready: true, restart count 0
Nov 11 21:01:07.215: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:01:07.215: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-g728j from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:01:07.215: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:01:07.215: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:01:07.215: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-62.us-west-2.compute.internal before test
Nov 11 21:01:07.220: INFO: calico-node-7npjl from kube-system started at 2020-11-11 20:42:41 +0000 UTC (2 container statuses recorded)
Nov 11 21:01:07.220: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:01:07.220: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:01:07.220: INFO: ucp-nvidia-device-plugin-rwkzr from kube-system started at 2020-11-11 20:42:41 +0000 UTC (1 container statuses recorded)
Nov 11 21:01:07.220: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:01:07.220: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-wkssd from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:01:07.220: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:01:07.220: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:01:07.220: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-177.us-west-2.compute.internal before test
Nov 11 21:01:07.233: INFO: ucp-nvidia-device-plugin-nsr8m from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:01:07.233: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:01:07.233: INFO: calico-node-ppmtk from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:01:07.233: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:01:07.233: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:01:07.233: INFO: sonobuoy from sonobuoy started at 2020-11-11 20:59:16 +0000 UTC (1 container statuses recorded)
Nov 11 21:01:07.233: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 11 21:01:07.233: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-9pcd4 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:01:07.233: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:01:07.233: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16468fd63aca2430], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16468fd6489722e1], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:01:08.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1420" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":277,"completed":10,"skipped":157,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:01:08.284: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1998
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov 11 21:01:08.870: INFO: Waiting up to 5m0s for pod "pod-ea5ba41d-ed19-4240-8eb8-afdbcc95981d" in namespace "emptydir-1998" to be "Succeeded or Failed"
Nov 11 21:01:08.872: INFO: Pod "pod-ea5ba41d-ed19-4240-8eb8-afdbcc95981d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.946224ms
Nov 11 21:01:10.875: INFO: Pod "pod-ea5ba41d-ed19-4240-8eb8-afdbcc95981d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004513938s
Nov 11 21:01:12.877: INFO: Pod "pod-ea5ba41d-ed19-4240-8eb8-afdbcc95981d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006981387s
STEP: Saw pod success
Nov 11 21:01:12.877: INFO: Pod "pod-ea5ba41d-ed19-4240-8eb8-afdbcc95981d" satisfied condition "Succeeded or Failed"
Nov 11 21:01:12.879: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-ea5ba41d-ed19-4240-8eb8-afdbcc95981d container test-container: <nil>
STEP: delete the pod
Nov 11 21:01:12.917: INFO: Waiting for pod pod-ea5ba41d-ed19-4240-8eb8-afdbcc95981d to disappear
Nov 11 21:01:12.920: INFO: Pod pod-ea5ba41d-ed19-4240-8eb8-afdbcc95981d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:01:12.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1998" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":11,"skipped":166,"failed":0}
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:01:12.929: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1058
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1058.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1058.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 11 21:01:33.599: INFO: DNS probes using dns-1058/dns-test-f9356871-e7fc-4ffd-b80b-29bb6d0c6923 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:01:33.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1058" for this suite.

• [SLOW TEST:20.691 seconds]
[sig-network] DNS
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":277,"completed":12,"skipped":172,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:01:33.620: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4212
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-a7476492-f94a-4cdc-bb86-284493e58152
STEP: Creating a pod to test consume secrets
Nov 11 21:01:34.243: INFO: Waiting up to 5m0s for pod "pod-secrets-e06afd00-abc7-4048-9e71-0ede1a3a8e8d" in namespace "secrets-4212" to be "Succeeded or Failed"
Nov 11 21:01:34.247: INFO: Pod "pod-secrets-e06afd00-abc7-4048-9e71-0ede1a3a8e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.879992ms
Nov 11 21:01:36.250: INFO: Pod "pod-secrets-e06afd00-abc7-4048-9e71-0ede1a3a8e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007128242s
Nov 11 21:01:38.252: INFO: Pod "pod-secrets-e06afd00-abc7-4048-9e71-0ede1a3a8e8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009597376s
STEP: Saw pod success
Nov 11 21:01:38.252: INFO: Pod "pod-secrets-e06afd00-abc7-4048-9e71-0ede1a3a8e8d" satisfied condition "Succeeded or Failed"
Nov 11 21:01:38.254: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-secrets-e06afd00-abc7-4048-9e71-0ede1a3a8e8d container secret-env-test: <nil>
STEP: delete the pod
Nov 11 21:01:38.265: INFO: Waiting for pod pod-secrets-e06afd00-abc7-4048-9e71-0ede1a3a8e8d to disappear
Nov 11 21:01:38.268: INFO: Pod pod-secrets-e06afd00-abc7-4048-9e71-0ede1a3a8e8d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:01:38.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4212" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":277,"completed":13,"skipped":194,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:01:38.282: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2046
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:01:41.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2046" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":277,"completed":14,"skipped":246,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:01:41.970: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9353
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Nov 11 21:01:42.500: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Nov 11 21:01:42.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-9353'
Nov 11 21:01:42.727: INFO: stderr: ""
Nov 11 21:01:42.727: INFO: stdout: "service/agnhost-slave created\n"
Nov 11 21:01:42.727: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Nov 11 21:01:42.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-9353'
Nov 11 21:01:42.894: INFO: stderr: ""
Nov 11 21:01:42.894: INFO: stdout: "service/agnhost-master created\n"
Nov 11 21:01:42.894: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 11 21:01:42.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-9353'
Nov 11 21:01:43.088: INFO: stderr: ""
Nov 11 21:01:43.088: INFO: stdout: "service/frontend created\n"
Nov 11 21:01:43.089: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Nov 11 21:01:43.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-9353'
Nov 11 21:01:43.330: INFO: stderr: ""
Nov 11 21:01:43.330: INFO: stdout: "deployment.apps/frontend created\n"
Nov 11 21:01:43.330: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 11 21:01:43.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-9353'
Nov 11 21:01:43.719: INFO: stderr: ""
Nov 11 21:01:43.719: INFO: stdout: "deployment.apps/agnhost-master created\n"
Nov 11 21:01:43.720: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 11 21:01:43.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-9353'
Nov 11 21:01:44.012: INFO: stderr: ""
Nov 11 21:01:44.012: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Nov 11 21:01:44.012: INFO: Waiting for all frontend pods to be Running.
Nov 11 21:01:54.063: INFO: Waiting for frontend to serve content.
Nov 11 21:01:54.070: INFO: Trying to add a new entry to the guestbook.
Nov 11 21:01:54.078: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov 11 21:01:54.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete --grace-period=0 --force -f - --namespace=kubectl-9353'
Nov 11 21:01:54.180: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 21:01:54.180: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov 11 21:01:54.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete --grace-period=0 --force -f - --namespace=kubectl-9353'
Nov 11 21:01:54.257: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 21:01:54.257: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 11 21:01:54.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete --grace-period=0 --force -f - --namespace=kubectl-9353'
Nov 11 21:01:54.347: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 21:01:54.347: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 11 21:01:54.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete --grace-period=0 --force -f - --namespace=kubectl-9353'
Nov 11 21:01:54.449: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 21:01:54.449: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 11 21:01:54.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete --grace-period=0 --force -f - --namespace=kubectl-9353'
Nov 11 21:01:54.520: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 21:01:54.520: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 11 21:01:54.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete --grace-period=0 --force -f - --namespace=kubectl-9353'
Nov 11 21:01:54.588: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 21:01:54.588: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:01:54.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9353" for this suite.

• [SLOW TEST:12.624 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:310
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":277,"completed":15,"skipped":266,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:01:54.595: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-7736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:01:55.267: INFO: Waiting up to 5m0s for pod "busybox-user-65534-b6c7821a-f5bc-48ee-bd26-d98acbd8b29a" in namespace "security-context-test-7736" to be "Succeeded or Failed"
Nov 11 21:01:55.269: INFO: Pod "busybox-user-65534-b6c7821a-f5bc-48ee-bd26-d98acbd8b29a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.678825ms
Nov 11 21:01:57.271: INFO: Pod "busybox-user-65534-b6c7821a-f5bc-48ee-bd26-d98acbd8b29a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003900162s
Nov 11 21:01:59.277: INFO: Pod "busybox-user-65534-b6c7821a-f5bc-48ee-bd26-d98acbd8b29a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01018665s
Nov 11 21:01:59.277: INFO: Pod "busybox-user-65534-b6c7821a-f5bc-48ee-bd26-d98acbd8b29a" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:01:59.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7736" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":16,"skipped":327,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:01:59.293: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9881
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:01:59.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97aa95cd-456b-42db-a7a7-c3ed0323fb1a" in namespace "projected-9881" to be "Succeeded or Failed"
Nov 11 21:01:59.961: INFO: Pod "downwardapi-volume-97aa95cd-456b-42db-a7a7-c3ed0323fb1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.944518ms
Nov 11 21:02:01.965: INFO: Pod "downwardapi-volume-97aa95cd-456b-42db-a7a7-c3ed0323fb1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007023901s
STEP: Saw pod success
Nov 11 21:02:01.965: INFO: Pod "downwardapi-volume-97aa95cd-456b-42db-a7a7-c3ed0323fb1a" satisfied condition "Succeeded or Failed"
Nov 11 21:02:01.967: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-97aa95cd-456b-42db-a7a7-c3ed0323fb1a container client-container: <nil>
STEP: delete the pod
Nov 11 21:02:01.980: INFO: Waiting for pod downwardapi-volume-97aa95cd-456b-42db-a7a7-c3ed0323fb1a to disappear
Nov 11 21:02:01.984: INFO: Pod downwardapi-volume-97aa95cd-456b-42db-a7a7-c3ed0323fb1a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:02:01.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9881" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":17,"skipped":340,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:02:01.990: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:02:02.600: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68d53194-3568-41e9-85ca-65bfdb7e2a13" in namespace "downward-api-8069" to be "Succeeded or Failed"
Nov 11 21:02:02.602: INFO: Pod "downwardapi-volume-68d53194-3568-41e9-85ca-65bfdb7e2a13": Phase="Pending", Reason="", readiness=false. Elapsed: 1.914729ms
Nov 11 21:02:04.605: INFO: Pod "downwardapi-volume-68d53194-3568-41e9-85ca-65bfdb7e2a13": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005028315s
Nov 11 21:02:06.607: INFO: Pod "downwardapi-volume-68d53194-3568-41e9-85ca-65bfdb7e2a13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00757248s
STEP: Saw pod success
Nov 11 21:02:06.607: INFO: Pod "downwardapi-volume-68d53194-3568-41e9-85ca-65bfdb7e2a13" satisfied condition "Succeeded or Failed"
Nov 11 21:02:06.609: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-68d53194-3568-41e9-85ca-65bfdb7e2a13 container client-container: <nil>
STEP: delete the pod
Nov 11 21:02:06.622: INFO: Waiting for pod downwardapi-volume-68d53194-3568-41e9-85ca-65bfdb7e2a13 to disappear
Nov 11 21:02:06.625: INFO: Pod downwardapi-volume-68d53194-3568-41e9-85ca-65bfdb7e2a13 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:02:06.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8069" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":18,"skipped":341,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:02:06.632: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2815
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Nov 11 21:02:07.160: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:02:27.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2815" for this suite.

• [SLOW TEST:20.392 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":277,"completed":19,"skipped":351,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:02:27.024: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9854
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:02:27.917: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:02:29.923: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725348, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725348, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725348, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725348, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:02:32.933: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:02:32.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9854" for this suite.
STEP: Destroying namespace "webhook-9854-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.982 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":277,"completed":20,"skipped":359,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:02:33.006: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4470
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-4470
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4470
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4470
Nov 11 21:02:33.531: INFO: Found 0 stateful pods, waiting for 1
Nov 11 21:02:43.533: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov 11 21:02:43.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-4470 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 21:02:43.740: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 21:02:43.741: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 21:02:43.741: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 21:02:43.743: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 11 21:02:53.745: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 21:02:53.746: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 21:02:53.779: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999974s
Nov 11 21:02:54.781: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998051685s
Nov 11 21:02:55.784: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.995675819s
Nov 11 21:02:56.786: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.99322393s
Nov 11 21:02:57.789: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.990888122s
Nov 11 21:02:58.791: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.988580038s
Nov 11 21:02:59.794: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.986122207s
Nov 11 21:03:00.796: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.983503575s
Nov 11 21:03:01.798: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.981111495s
Nov 11 21:03:02.801: INFO: Verifying statefulset ss doesn't scale past 1 for another 978.75917ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4470
Nov 11 21:03:03.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-4470 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 21:03:04.062: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 21:03:04.062: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 21:03:04.062: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 21:03:04.065: INFO: Found 1 stateful pods, waiting for 3
Nov 11 21:03:14.067: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 21:03:14.067: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 21:03:14.067: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 11 21:03:24.068: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 21:03:24.068: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 21:03:24.068: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov 11 21:03:24.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-4470 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 21:03:24.284: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 21:03:24.284: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 21:03:24.284: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 21:03:24.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-4470 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 21:03:24.489: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 21:03:24.489: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 21:03:24.489: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 21:03:24.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-4470 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 21:03:24.697: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 21:03:24.697: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 21:03:24.697: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 21:03:24.697: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 21:03:24.700: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov 11 21:03:34.704: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 21:03:34.704: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 21:03:34.704: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 21:03:34.741: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999585s
Nov 11 21:03:35.744: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997077194s
Nov 11 21:03:36.753: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994289265s
Nov 11 21:03:37.756: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984475913s
Nov 11 21:03:38.758: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982067241s
Nov 11 21:03:39.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979556165s
Nov 11 21:03:40.764: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977061107s
Nov 11 21:03:41.766: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974285764s
Nov 11 21:03:42.769: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971864352s
Nov 11 21:03:43.773: INFO: Verifying statefulset ss doesn't scale past 3 for another 968.695206ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4470
Nov 11 21:03:44.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-4470 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 21:03:44.956: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 21:03:44.956: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 21:03:44.956: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 21:03:44.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-4470 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 21:03:45.174: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 21:03:45.174: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 21:03:45.174: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 21:03:45.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-4470 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 21:03:45.368: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 21:03:45.368: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 21:03:45.368: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 21:03:45.368: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Nov 11 21:04:15.452: INFO: Deleting all statefulset in ns statefulset-4470
Nov 11 21:04:15.454: INFO: Scaling statefulset ss to 0
Nov 11 21:04:15.500: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 21:04:15.502: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:04:15.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4470" for this suite.

• [SLOW TEST:102.509 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":277,"completed":21,"skipped":380,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:04:15.516: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5286
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 11 21:04:19.156: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:04:19.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5286" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":22,"skipped":408,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:04:19.177: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4575
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-4575
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 11 21:04:19.706: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 11 21:04:19.866: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 21:04:21.871: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:04:23.869: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:04:25.869: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:04:27.869: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:04:29.869: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:04:31.869: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:04:33.869: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:04:35.869: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:04:37.869: INFO: The status of Pod netserver-0 is Running (Ready = true)
Nov 11 21:04:37.873: INFO: The status of Pod netserver-1 is Running (Ready = true)
Nov 11 21:04:37.876: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Nov 11 21:04:39.943: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.211.87:8080/dial?request=hostname&protocol=http&host=192.168.64.198&port=8080&tries=1'] Namespace:pod-network-test-4575 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:04:39.943: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:04:40.065: INFO: Waiting for responses: map[]
Nov 11 21:04:40.067: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.211.87:8080/dial?request=hostname&protocol=http&host=192.168.211.86&port=8080&tries=1'] Namespace:pod-network-test-4575 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:04:40.067: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:04:40.192: INFO: Waiting for responses: map[]
Nov 11 21:04:40.193: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.211.87:8080/dial?request=hostname&protocol=http&host=192.168.10.70&port=8080&tries=1'] Namespace:pod-network-test-4575 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:04:40.193: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:04:40.316: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:04:40.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4575" for this suite.

• [SLOW TEST:21.145 seconds]
[sig-network] Networking
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":277,"completed":23,"skipped":435,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:04:40.323: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2639
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 11 21:04:40.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2639'
Nov 11 21:04:40.984: INFO: stderr: ""
Nov 11 21:04:40.984: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Nov 11 21:04:40.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete pods e2e-test-httpd-pod --namespace=kubectl-2639'
Nov 11 21:04:41.068: INFO: stderr: ""
Nov 11 21:04:41.068: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:04:41.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2639" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":277,"completed":24,"skipped":455,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:04:41.078: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3003
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Nov 11 21:04:41.638: INFO: Waiting up to 5m0s for pod "var-expansion-02ce48d4-0186-4197-94c6-28e3a27356f8" in namespace "var-expansion-3003" to be "Succeeded or Failed"
Nov 11 21:04:41.639: INFO: Pod "var-expansion-02ce48d4-0186-4197-94c6-28e3a27356f8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.726073ms
Nov 11 21:04:43.642: INFO: Pod "var-expansion-02ce48d4-0186-4197-94c6-28e3a27356f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004196882s
Nov 11 21:04:45.644: INFO: Pod "var-expansion-02ce48d4-0186-4197-94c6-28e3a27356f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006933723s
STEP: Saw pod success
Nov 11 21:04:45.644: INFO: Pod "var-expansion-02ce48d4-0186-4197-94c6-28e3a27356f8" satisfied condition "Succeeded or Failed"
Nov 11 21:04:45.648: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod var-expansion-02ce48d4-0186-4197-94c6-28e3a27356f8 container dapi-container: <nil>
STEP: delete the pod
Nov 11 21:04:45.672: INFO: Waiting for pod var-expansion-02ce48d4-0186-4197-94c6-28e3a27356f8 to disappear
Nov 11 21:04:45.675: INFO: Pod var-expansion-02ce48d4-0186-4197-94c6-28e3a27356f8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:04:45.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3003" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":277,"completed":25,"skipped":494,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:04:45.689: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5115
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-f48ad664-8e46-4e0c-806b-5bc3b017696e
STEP: Creating a pod to test consume configMaps
Nov 11 21:04:46.246: INFO: Waiting up to 5m0s for pod "pod-configmaps-99783400-4fe9-4811-9a9c-a9ed351deb01" in namespace "configmap-5115" to be "Succeeded or Failed"
Nov 11 21:04:46.248: INFO: Pod "pod-configmaps-99783400-4fe9-4811-9a9c-a9ed351deb01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.438914ms
Nov 11 21:04:48.251: INFO: Pod "pod-configmaps-99783400-4fe9-4811-9a9c-a9ed351deb01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005372111s
STEP: Saw pod success
Nov 11 21:04:48.251: INFO: Pod "pod-configmaps-99783400-4fe9-4811-9a9c-a9ed351deb01" satisfied condition "Succeeded or Failed"
Nov 11 21:04:48.253: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-configmaps-99783400-4fe9-4811-9a9c-a9ed351deb01 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:04:48.269: INFO: Waiting for pod pod-configmaps-99783400-4fe9-4811-9a9c-a9ed351deb01 to disappear
Nov 11 21:04:48.274: INFO: Pod pod-configmaps-99783400-4fe9-4811-9a9c-a9ed351deb01 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:04:48.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5115" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":26,"skipped":554,"failed":0}
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:04:48.287: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4698
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Nov 11 21:04:48.848: INFO: Waiting up to 5m0s for pod "downward-api-1183475b-a2ae-49b9-b65d-a187090a293a" in namespace "downward-api-4698" to be "Succeeded or Failed"
Nov 11 21:04:48.850: INFO: Pod "downward-api-1183475b-a2ae-49b9-b65d-a187090a293a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.599376ms
Nov 11 21:04:50.852: INFO: Pod "downward-api-1183475b-a2ae-49b9-b65d-a187090a293a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003641069s
Nov 11 21:04:52.854: INFO: Pod "downward-api-1183475b-a2ae-49b9-b65d-a187090a293a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005762085s
STEP: Saw pod success
Nov 11 21:04:52.854: INFO: Pod "downward-api-1183475b-a2ae-49b9-b65d-a187090a293a" satisfied condition "Succeeded or Failed"
Nov 11 21:04:52.855: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downward-api-1183475b-a2ae-49b9-b65d-a187090a293a container dapi-container: <nil>
STEP: delete the pod
Nov 11 21:04:52.869: INFO: Waiting for pod downward-api-1183475b-a2ae-49b9-b65d-a187090a293a to disappear
Nov 11 21:04:52.871: INFO: Pod downward-api-1183475b-a2ae-49b9-b65d-a187090a293a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:04:52.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4698" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":277,"completed":27,"skipped":559,"failed":0}

------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:04:52.877: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-8167
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov 11 21:04:59.568: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:04:59.568: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:04:59.680: INFO: Exec stderr: ""
Nov 11 21:04:59.680: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:04:59.680: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:04:59.822: INFO: Exec stderr: ""
Nov 11 21:04:59.822: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:04:59.822: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:04:59.940: INFO: Exec stderr: ""
Nov 11 21:04:59.940: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:04:59.940: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:05:00.051: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov 11 21:05:00.051: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:05:00.051: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:05:00.163: INFO: Exec stderr: ""
Nov 11 21:05:00.163: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:05:00.163: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:05:00.293: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov 11 21:05:00.293: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:05:00.293: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:05:00.419: INFO: Exec stderr: ""
Nov 11 21:05:00.419: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:05:00.419: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:05:00.529: INFO: Exec stderr: ""
Nov 11 21:05:00.529: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:05:00.529: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:05:00.655: INFO: Exec stderr: ""
Nov 11 21:05:00.655: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8167 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:05:00.655: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:05:00.753: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:00.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8167" for this suite.

• [SLOW TEST:7.884 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":28,"skipped":559,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:00.761: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8143
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 11 21:05:01.333: INFO: Waiting up to 5m0s for pod "pod-6f54f487-f7de-4693-9b50-6806ce03244b" in namespace "emptydir-8143" to be "Succeeded or Failed"
Nov 11 21:05:01.335: INFO: Pod "pod-6f54f487-f7de-4693-9b50-6806ce03244b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.951864ms
Nov 11 21:05:03.338: INFO: Pod "pod-6f54f487-f7de-4693-9b50-6806ce03244b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00449507s
STEP: Saw pod success
Nov 11 21:05:03.338: INFO: Pod "pod-6f54f487-f7de-4693-9b50-6806ce03244b" satisfied condition "Succeeded or Failed"
Nov 11 21:05:03.340: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-6f54f487-f7de-4693-9b50-6806ce03244b container test-container: <nil>
STEP: delete the pod
Nov 11 21:05:03.365: INFO: Waiting for pod pod-6f54f487-f7de-4693-9b50-6806ce03244b to disappear
Nov 11 21:05:03.369: INFO: Pod pod-6f54f487-f7de-4693-9b50-6806ce03244b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:03.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8143" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":29,"skipped":603,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:03.379: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Nov 11 21:05:03.909: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 11 21:05:03.918: INFO: Waiting for terminating namespaces to be deleted...
Nov 11 21:05:03.920: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-166.us-west-2.compute.internal before test
Nov 11 21:05:03.926: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-g728j from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:05:03.926: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:05:03.926: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:05:03.926: INFO: calico-node-vdd82 from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:05:03.926: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:05:03.926: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:05:03.926: INFO: ucp-nvidia-device-plugin-749cm from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:05:03.926: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:05:03.926: INFO: sonobuoy-e2e-job-9a557cfe0d894233 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:05:03.926: INFO: 	Container e2e ready: true, restart count 0
Nov 11 21:05:03.926: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:05:03.926: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-62.us-west-2.compute.internal before test
Nov 11 21:05:03.930: INFO: calico-node-7npjl from kube-system started at 2020-11-11 20:42:41 +0000 UTC (2 container statuses recorded)
Nov 11 21:05:03.930: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:05:03.930: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:05:03.930: INFO: ucp-nvidia-device-plugin-rwkzr from kube-system started at 2020-11-11 20:42:41 +0000 UTC (1 container statuses recorded)
Nov 11 21:05:03.930: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:05:03.930: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-wkssd from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:05:03.930: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:05:03.930: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:05:03.930: INFO: test-host-network-pod from e2e-kubelet-etc-hosts-8167 started at 2020-11-11 21:04:57 +0000 UTC (2 container statuses recorded)
Nov 11 21:05:03.930: INFO: 	Container busybox-1 ready: true, restart count 0
Nov 11 21:05:03.930: INFO: 	Container busybox-2 ready: true, restart count 0
Nov 11 21:05:03.930: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-177.us-west-2.compute.internal before test
Nov 11 21:05:03.938: INFO: test-pod from e2e-kubelet-etc-hosts-8167 started at 2020-11-11 21:04:53 +0000 UTC (3 container statuses recorded)
Nov 11 21:05:03.938: INFO: 	Container busybox-1 ready: true, restart count 0
Nov 11 21:05:03.938: INFO: 	Container busybox-2 ready: true, restart count 0
Nov 11 21:05:03.938: INFO: 	Container busybox-3 ready: true, restart count 0
Nov 11 21:05:03.938: INFO: ucp-nvidia-device-plugin-nsr8m from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:05:03.938: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:05:03.938: INFO: calico-node-ppmtk from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:05:03.938: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:05:03.938: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:05:03.938: INFO: sonobuoy from sonobuoy started at 2020-11-11 20:59:16 +0000 UTC (1 container statuses recorded)
Nov 11 21:05:03.938: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 11 21:05:03.938: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-9pcd4 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:05:03.938: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:05:03.938: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node ip-172-31-0-166.us-west-2.compute.internal
STEP: verifying the node has the label node ip-172-31-0-62.us-west-2.compute.internal
STEP: verifying the node has the label node ip-172-31-1-177.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod test-host-network-pod requesting resource cpu=0m on Node ip-172-31-0-62.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod test-pod requesting resource cpu=0m on Node ip-172-31-1-177.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod calico-node-7npjl requesting resource cpu=250m on Node ip-172-31-0-62.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod calico-node-ppmtk requesting resource cpu=250m on Node ip-172-31-1-177.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod calico-node-vdd82 requesting resource cpu=250m on Node ip-172-31-0-166.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod ucp-nvidia-device-plugin-749cm requesting resource cpu=50m on Node ip-172-31-0-166.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod ucp-nvidia-device-plugin-nsr8m requesting resource cpu=50m on Node ip-172-31-1-177.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod ucp-nvidia-device-plugin-rwkzr requesting resource cpu=50m on Node ip-172-31-0-62.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-1-177.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod sonobuoy-e2e-job-9a557cfe0d894233 requesting resource cpu=0m on Node ip-172-31-0-166.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-9pcd4 requesting resource cpu=0m on Node ip-172-31-1-177.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-g728j requesting resource cpu=0m on Node ip-172-31-0-166.us-west-2.compute.internal
Nov 11 21:05:04.006: INFO: Pod sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-wkssd requesting resource cpu=0m on Node ip-172-31-0-62.us-west-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
Nov 11 21:05:04.006: INFO: Creating a pod which consumes cpu=1155m on Node ip-172-31-0-166.us-west-2.compute.internal
Nov 11 21:05:04.046: INFO: Creating a pod which consumes cpu=1155m on Node ip-172-31-0-62.us-west-2.compute.internal
Nov 11 21:05:04.079: INFO: Creating a pod which consumes cpu=1155m on Node ip-172-31-1-177.us-west-2.compute.internal
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-037df5a9-98ca-4f59-9552-ef02a5e06d05.1646900d5589c799], Reason = [Scheduled], Message = [Successfully assigned sched-pred-277/filler-pod-037df5a9-98ca-4f59-9552-ef02a5e06d05 to ip-172-31-0-62.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-037df5a9-98ca-4f59-9552-ef02a5e06d05.1646900d971c0d7a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-037df5a9-98ca-4f59-9552-ef02a5e06d05.1646900d9aaf92d6], Reason = [Created], Message = [Created container filler-pod-037df5a9-98ca-4f59-9552-ef02a5e06d05]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-037df5a9-98ca-4f59-9552-ef02a5e06d05.1646900da2bb1aee], Reason = [Started], Message = [Started container filler-pod-037df5a9-98ca-4f59-9552-ef02a5e06d05]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1fde2109-d762-41a7-81c1-eee9b03e76ed.1646900d5bc95278], Reason = [Scheduled], Message = [Successfully assigned sched-pred-277/filler-pod-1fde2109-d762-41a7-81c1-eee9b03e76ed to ip-172-31-1-177.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1fde2109-d762-41a7-81c1-eee9b03e76ed.1646900d9bc8221f], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1fde2109-d762-41a7-81c1-eee9b03e76ed.1646900dc5d9ac57], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1fde2109-d762-41a7-81c1-eee9b03e76ed.1646900dc8ca97ad], Reason = [Created], Message = [Created container filler-pod-1fde2109-d762-41a7-81c1-eee9b03e76ed]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1fde2109-d762-41a7-81c1-eee9b03e76ed.1646900dd2adc6ff], Reason = [Started], Message = [Started container filler-pod-1fde2109-d762-41a7-81c1-eee9b03e76ed]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa560c89-7ace-43af-8df3-96661d9157b6.1646900d555842c3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-277/filler-pod-aa560c89-7ace-43af-8df3-96661d9157b6 to ip-172-31-0-166.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa560c89-7ace-43af-8df3-96661d9157b6.1646900d9314c8f9], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa560c89-7ace-43af-8df3-96661d9157b6.1646900dbdc38d2b], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.2"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa560c89-7ace-43af-8df3-96661d9157b6.1646900dc010b6a2], Reason = [Created], Message = [Created container filler-pod-aa560c89-7ace-43af-8df3-96661d9157b6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-aa560c89-7ace-43af-8df3-96661d9157b6.1646900dc992c6b0], Reason = [Started], Message = [Started container filler-pod-aa560c89-7ace-43af-8df3-96661d9157b6]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1646900e53080d85], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taint {com.docker.ucp.manager: }, that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1646900e632ca69e], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taint {com.docker.ucp.manager: }, that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node ip-172-31-1-177.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-0-166.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-0-62.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:09.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-277" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:5.877 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":277,"completed":30,"skipped":610,"failed":0}
SSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:09.256: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4101
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov 11 21:05:09.864: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 11 21:05:14.871: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:15.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4101" for this suite.

• [SLOW TEST:6.653 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":277,"completed":31,"skipped":613,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:15.910: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2771
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov 11 21:05:19.682: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:20.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2771" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":277,"completed":32,"skipped":639,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:20.711: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-9f3eaa9e-aac1-40fb-9566-d555e3f9b1dd
STEP: Creating a pod to test consume secrets
Nov 11 21:05:21.428: INFO: Waiting up to 5m0s for pod "pod-secrets-74066bc7-97bf-49e8-9826-3bab41644762" in namespace "secrets-3435" to be "Succeeded or Failed"
Nov 11 21:05:21.433: INFO: Pod "pod-secrets-74066bc7-97bf-49e8-9826-3bab41644762": Phase="Pending", Reason="", readiness=false. Elapsed: 5.059377ms
Nov 11 21:05:23.436: INFO: Pod "pod-secrets-74066bc7-97bf-49e8-9826-3bab41644762": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007328299s
Nov 11 21:05:25.438: INFO: Pod "pod-secrets-74066bc7-97bf-49e8-9826-3bab41644762": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009934762s
STEP: Saw pod success
Nov 11 21:05:25.438: INFO: Pod "pod-secrets-74066bc7-97bf-49e8-9826-3bab41644762" satisfied condition "Succeeded or Failed"
Nov 11 21:05:25.440: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod pod-secrets-74066bc7-97bf-49e8-9826-3bab41644762 container secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:05:25.452: INFO: Waiting for pod pod-secrets-74066bc7-97bf-49e8-9826-3bab41644762 to disappear
Nov 11 21:05:25.455: INFO: Pod pod-secrets-74066bc7-97bf-49e8-9826-3bab41644762 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:25.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3435" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":33,"skipped":651,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:25.462: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-992
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:05:26.498: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:05:28.510: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725526, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725526, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725527, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725526, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:05:31.520: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:31.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-992" for this suite.
STEP: Destroying namespace "webhook-992-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.153 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":277,"completed":34,"skipped":671,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:31.616: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-6089
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:05:32.644: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Nov 11 21:05:34.650: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725533, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725533, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725533, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725532, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:05:37.660: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:05:37.664: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:38.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6089" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:7.254 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":277,"completed":35,"skipped":686,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:38.870: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1473
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:05:39.406: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9425af3d-5fbb-43bd-8adb-46ed19648b04" in namespace "projected-1473" to be "Succeeded or Failed"
Nov 11 21:05:39.408: INFO: Pod "downwardapi-volume-9425af3d-5fbb-43bd-8adb-46ed19648b04": Phase="Pending", Reason="", readiness=false. Elapsed: 1.672732ms
Nov 11 21:05:41.410: INFO: Pod "downwardapi-volume-9425af3d-5fbb-43bd-8adb-46ed19648b04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003986883s
STEP: Saw pod success
Nov 11 21:05:41.410: INFO: Pod "downwardapi-volume-9425af3d-5fbb-43bd-8adb-46ed19648b04" satisfied condition "Succeeded or Failed"
Nov 11 21:05:41.412: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod downwardapi-volume-9425af3d-5fbb-43bd-8adb-46ed19648b04 container client-container: <nil>
STEP: delete the pod
Nov 11 21:05:41.425: INFO: Waiting for pod downwardapi-volume-9425af3d-5fbb-43bd-8adb-46ed19648b04 to disappear
Nov 11 21:05:41.427: INFO: Pod downwardapi-volume-9425af3d-5fbb-43bd-8adb-46ed19648b04 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:41.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1473" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":36,"skipped":700,"failed":0}
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:41.434: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5283
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 11 21:05:44.111: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:44.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5283" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":37,"skipped":706,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:44.169: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-39054188-bc2b-4cd0-9f44-346da19c8d19
STEP: Creating a pod to test consume secrets
Nov 11 21:05:44.851: INFO: Waiting up to 5m0s for pod "pod-secrets-3d593359-76a2-4cc0-8567-6293fa1daf9c" in namespace "secrets-4782" to be "Succeeded or Failed"
Nov 11 21:05:44.855: INFO: Pod "pod-secrets-3d593359-76a2-4cc0-8567-6293fa1daf9c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.420984ms
Nov 11 21:05:46.859: INFO: Pod "pod-secrets-3d593359-76a2-4cc0-8567-6293fa1daf9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007289796s
Nov 11 21:05:48.861: INFO: Pod "pod-secrets-3d593359-76a2-4cc0-8567-6293fa1daf9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009372518s
STEP: Saw pod success
Nov 11 21:05:48.861: INFO: Pod "pod-secrets-3d593359-76a2-4cc0-8567-6293fa1daf9c" satisfied condition "Succeeded or Failed"
Nov 11 21:05:48.862: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-secrets-3d593359-76a2-4cc0-8567-6293fa1daf9c container secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:05:48.875: INFO: Waiting for pod pod-secrets-3d593359-76a2-4cc0-8567-6293fa1daf9c to disappear
Nov 11 21:05:48.877: INFO: Pod pod-secrets-3d593359-76a2-4cc0-8567-6293fa1daf9c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:05:48.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4782" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":38,"skipped":708,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:05:48.884: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-192
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-192
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-192
Nov 11 21:05:49.558: INFO: Found 0 stateful pods, waiting for 1
Nov 11 21:05:59.560: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Nov 11 21:05:59.573: INFO: Deleting all statefulset in ns statefulset-192
Nov 11 21:05:59.575: INFO: Scaling statefulset ss to 0
Nov 11 21:06:19.613: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 21:06:19.614: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:19.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-192" for this suite.

• [SLOW TEST:30.744 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":277,"completed":39,"skipped":740,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:19.629: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6698
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:31.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6698" for this suite.

• [SLOW TEST:11.681 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":277,"completed":40,"skipped":784,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:31.310: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6552
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-cfe71e3f-e9a6-4e15-91ae-a11638298129
STEP: Creating a pod to test consume secrets
Nov 11 21:06:31.879: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-75ea9c7a-672b-419e-bff5-b28f7ea32246" in namespace "projected-6552" to be "Succeeded or Failed"
Nov 11 21:06:31.881: INFO: Pod "pod-projected-secrets-75ea9c7a-672b-419e-bff5-b28f7ea32246": Phase="Pending", Reason="", readiness=false. Elapsed: 1.673244ms
Nov 11 21:06:33.883: INFO: Pod "pod-projected-secrets-75ea9c7a-672b-419e-bff5-b28f7ea32246": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004071494s
Nov 11 21:06:35.886: INFO: Pod "pod-projected-secrets-75ea9c7a-672b-419e-bff5-b28f7ea32246": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006235359s
STEP: Saw pod success
Nov 11 21:06:35.886: INFO: Pod "pod-projected-secrets-75ea9c7a-672b-419e-bff5-b28f7ea32246" satisfied condition "Succeeded or Failed"
Nov 11 21:06:35.887: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-secrets-75ea9c7a-672b-419e-bff5-b28f7ea32246 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:06:35.902: INFO: Waiting for pod pod-projected-secrets-75ea9c7a-672b-419e-bff5-b28f7ea32246 to disappear
Nov 11 21:06:35.904: INFO: Pod pod-projected-secrets-75ea9c7a-672b-419e-bff5-b28f7ea32246 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:35.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6552" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":41,"skipped":792,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:35.911: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2565
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Nov 11 21:06:36.615: INFO: Created pod &Pod{ObjectMeta:{dns-2565  dns-2565 /api/v1/namespaces/dns-2565/pods/dns-2565 650546b2-403e-4667-9892-fb50636ebd4e 7880 0 2020-11-11 21:06:36 +0000 UTC <nil> <nil> map[] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2020-11-11 21:06:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qk4s4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qk4s4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qk4s4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 21:06:36.618: INFO: The status of Pod dns-2565 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 21:06:38.620: INFO: The status of Pod dns-2565 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Nov 11 21:06:38.620: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-2565 PodName:dns-2565 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:06:38.620: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Verifying customized DNS server is configured on pod...
Nov 11 21:06:38.738: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-2565 PodName:dns-2565 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:06:38.738: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:06:38.882: INFO: Deleting pod dns-2565...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:38.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2565" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":277,"completed":42,"skipped":796,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:38.898: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6812
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Nov 11 21:06:39.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 cluster-info'
Nov 11 21:06:39.505: INFO: stderr: ""
Nov 11 21:06:39.505: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:39.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6812" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":277,"completed":43,"skipped":838,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:39.525: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3191
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-5be3047b-fe36-43b1-a483-6fe0c315d462
STEP: Creating a pod to test consume secrets
Nov 11 21:06:40.115: INFO: Waiting up to 5m0s for pod "pod-secrets-d985e1bf-e74b-4827-bbc9-47e05042147b" in namespace "secrets-3191" to be "Succeeded or Failed"
Nov 11 21:06:40.121: INFO: Pod "pod-secrets-d985e1bf-e74b-4827-bbc9-47e05042147b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.303645ms
Nov 11 21:06:42.124: INFO: Pod "pod-secrets-d985e1bf-e74b-4827-bbc9-47e05042147b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008885815s
Nov 11 21:06:44.153: INFO: Pod "pod-secrets-d985e1bf-e74b-4827-bbc9-47e05042147b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03826213s
STEP: Saw pod success
Nov 11 21:06:44.153: INFO: Pod "pod-secrets-d985e1bf-e74b-4827-bbc9-47e05042147b" satisfied condition "Succeeded or Failed"
Nov 11 21:06:44.155: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-secrets-d985e1bf-e74b-4827-bbc9-47e05042147b container secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:06:44.182: INFO: Waiting for pod pod-secrets-d985e1bf-e74b-4827-bbc9-47e05042147b to disappear
Nov 11 21:06:44.203: INFO: Pod pod-secrets-d985e1bf-e74b-4827-bbc9-47e05042147b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:44.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3191" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":44,"skipped":858,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:44.228: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6152
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:06:44.792: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:45.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6152" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":277,"completed":45,"skipped":859,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:45.445: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4411
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 11 21:06:46.055: INFO: Waiting up to 5m0s for pod "pod-b9b5f663-c09f-4525-bf1b-0ec0bc8ff7e2" in namespace "emptydir-4411" to be "Succeeded or Failed"
Nov 11 21:06:46.058: INFO: Pod "pod-b9b5f663-c09f-4525-bf1b-0ec0bc8ff7e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.182538ms
Nov 11 21:06:48.060: INFO: Pod "pod-b9b5f663-c09f-4525-bf1b-0ec0bc8ff7e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00433463s
Nov 11 21:06:50.062: INFO: Pod "pod-b9b5f663-c09f-4525-bf1b-0ec0bc8ff7e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006769161s
STEP: Saw pod success
Nov 11 21:06:50.062: INFO: Pod "pod-b9b5f663-c09f-4525-bf1b-0ec0bc8ff7e2" satisfied condition "Succeeded or Failed"
Nov 11 21:06:50.064: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-b9b5f663-c09f-4525-bf1b-0ec0bc8ff7e2 container test-container: <nil>
STEP: delete the pod
Nov 11 21:06:50.078: INFO: Waiting for pod pod-b9b5f663-c09f-4525-bf1b-0ec0bc8ff7e2 to disappear
Nov 11 21:06:50.081: INFO: Pod pod-b9b5f663-c09f-4525-bf1b-0ec0bc8ff7e2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:50.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4411" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":46,"skipped":864,"failed":0}

------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:50.092: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:06:50.769: INFO: Waiting up to 5m0s for pod "downwardapi-volume-234dd1b9-5086-49e2-a519-afac8b0e043c" in namespace "downward-api-1420" to be "Succeeded or Failed"
Nov 11 21:06:50.771: INFO: Pod "downwardapi-volume-234dd1b9-5086-49e2-a519-afac8b0e043c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.504841ms
Nov 11 21:06:52.774: INFO: Pod "downwardapi-volume-234dd1b9-5086-49e2-a519-afac8b0e043c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005177335s
STEP: Saw pod success
Nov 11 21:06:52.774: INFO: Pod "downwardapi-volume-234dd1b9-5086-49e2-a519-afac8b0e043c" satisfied condition "Succeeded or Failed"
Nov 11 21:06:52.776: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-234dd1b9-5086-49e2-a519-afac8b0e043c container client-container: <nil>
STEP: delete the pod
Nov 11 21:06:52.789: INFO: Waiting for pod downwardapi-volume-234dd1b9-5086-49e2-a519-afac8b0e043c to disappear
Nov 11 21:06:52.793: INFO: Pod downwardapi-volume-234dd1b9-5086-49e2-a519-afac8b0e043c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:52.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1420" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":47,"skipped":864,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:52.801: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3104
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:06:53.367: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dcb2aeb9-3438-4e1a-b0da-44c5a93fc3fd" in namespace "downward-api-3104" to be "Succeeded or Failed"
Nov 11 21:06:53.368: INFO: Pod "downwardapi-volume-dcb2aeb9-3438-4e1a-b0da-44c5a93fc3fd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.695592ms
Nov 11 21:06:55.405: INFO: Pod "downwardapi-volume-dcb2aeb9-3438-4e1a-b0da-44c5a93fc3fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038658774s
Nov 11 21:06:57.408: INFO: Pod "downwardapi-volume-dcb2aeb9-3438-4e1a-b0da-44c5a93fc3fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040975867s
STEP: Saw pod success
Nov 11 21:06:57.408: INFO: Pod "downwardapi-volume-dcb2aeb9-3438-4e1a-b0da-44c5a93fc3fd" satisfied condition "Succeeded or Failed"
Nov 11 21:06:57.409: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-dcb2aeb9-3438-4e1a-b0da-44c5a93fc3fd container client-container: <nil>
STEP: delete the pod
Nov 11 21:06:57.420: INFO: Waiting for pod downwardapi-volume-dcb2aeb9-3438-4e1a-b0da-44c5a93fc3fd to disappear
Nov 11 21:06:57.425: INFO: Pod downwardapi-volume-dcb2aeb9-3438-4e1a-b0da-44c5a93fc3fd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:06:57.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3104" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":277,"completed":48,"skipped":866,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:06:57.432: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2686
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Nov 11 21:06:57.962: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:07:02.002: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:07:15.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2686" for this suite.

• [SLOW TEST:18.481 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":277,"completed":49,"skipped":876,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:07:15.913: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5225
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-ch9h
STEP: Creating a pod to test atomic-volume-subpath
Nov 11 21:07:16.510: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ch9h" in namespace "subpath-5225" to be "Succeeded or Failed"
Nov 11 21:07:16.513: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.364411ms
Nov 11 21:07:18.515: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004476773s
Nov 11 21:07:20.518: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 4.007470252s
Nov 11 21:07:22.522: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 6.012020415s
Nov 11 21:07:24.525: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 8.014605837s
Nov 11 21:07:26.527: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 10.017008375s
Nov 11 21:07:28.532: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 12.021642246s
Nov 11 21:07:30.534: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 14.024042903s
Nov 11 21:07:32.536: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 16.02621529s
Nov 11 21:07:34.539: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 18.028546276s
Nov 11 21:07:36.541: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 20.030877543s
Nov 11 21:07:38.543: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Running", Reason="", readiness=true. Elapsed: 22.033224465s
Nov 11 21:07:40.546: INFO: Pod "pod-subpath-test-configmap-ch9h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.035816212s
STEP: Saw pod success
Nov 11 21:07:40.546: INFO: Pod "pod-subpath-test-configmap-ch9h" satisfied condition "Succeeded or Failed"
Nov 11 21:07:40.548: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-subpath-test-configmap-ch9h container test-container-subpath-configmap-ch9h: <nil>
STEP: delete the pod
Nov 11 21:07:40.562: INFO: Waiting for pod pod-subpath-test-configmap-ch9h to disappear
Nov 11 21:07:40.564: INFO: Pod pod-subpath-test-configmap-ch9h no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ch9h
Nov 11 21:07:40.564: INFO: Deleting pod "pod-subpath-test-configmap-ch9h" in namespace "subpath-5225"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:07:40.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5225" for this suite.

• [SLOW TEST:24.660 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":277,"completed":50,"skipped":887,"failed":0}
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:07:40.573: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1344
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Nov 11 21:07:41.149: INFO: Waiting up to 5m0s for pod "var-expansion-b36da90e-0498-43aa-b7d0-1c420826ebaa" in namespace "var-expansion-1344" to be "Succeeded or Failed"
Nov 11 21:07:41.150: INFO: Pod "var-expansion-b36da90e-0498-43aa-b7d0-1c420826ebaa": Phase="Pending", Reason="", readiness=false. Elapsed: 1.715189ms
Nov 11 21:07:43.153: INFO: Pod "var-expansion-b36da90e-0498-43aa-b7d0-1c420826ebaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004193914s
STEP: Saw pod success
Nov 11 21:07:43.153: INFO: Pod "var-expansion-b36da90e-0498-43aa-b7d0-1c420826ebaa" satisfied condition "Succeeded or Failed"
Nov 11 21:07:43.155: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod var-expansion-b36da90e-0498-43aa-b7d0-1c420826ebaa container dapi-container: <nil>
STEP: delete the pod
Nov 11 21:07:43.168: INFO: Waiting for pod var-expansion-b36da90e-0498-43aa-b7d0-1c420826ebaa to disappear
Nov 11 21:07:43.172: INFO: Pod var-expansion-b36da90e-0498-43aa-b7d0-1c420826ebaa no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:07:43.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1344" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":277,"completed":51,"skipped":893,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:07:43.179: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8616
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-8616
I1111 21:07:43.805844      21 runners.go:190] Created replication controller with name: externalname-service, namespace: services-8616, replica count: 2
I1111 21:07:46.856168      21 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 21:07:46.856: INFO: Creating new exec pod
Nov 11 21:07:52.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-8616 execpodsbz6m -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov 11 21:07:52.217: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 11 21:07:52.218: INFO: stdout: ""
Nov 11 21:07:52.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-8616 execpodsbz6m -- /bin/sh -x -c nc -zv -t -w 2 10.96.60.123 80'
Nov 11 21:07:52.418: INFO: stderr: "+ nc -zv -t -w 2 10.96.60.123 80\nConnection to 10.96.60.123 80 port [tcp/http] succeeded!\n"
Nov 11 21:07:52.418: INFO: stdout: ""
Nov 11 21:07:52.418: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:07:52.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8616" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:9.256 seconds]
[sig-network] Services
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":277,"completed":52,"skipped":912,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:07:52.436: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7695
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-7695
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 11 21:07:53.113: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 11 21:07:53.254: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 21:07:55.256: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:07:57.256: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:07:59.256: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:08:01.258: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:08:03.256: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:08:05.256: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:08:07.256: INFO: The status of Pod netserver-0 is Running (Ready = true)
Nov 11 21:08:07.259: INFO: The status of Pod netserver-1 is Running (Ready = true)
Nov 11 21:08:07.263: INFO: The status of Pod netserver-2 is Running (Ready = false)
Nov 11 21:08:09.265: INFO: The status of Pod netserver-2 is Running (Ready = false)
Nov 11 21:08:11.265: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Nov 11 21:08:15.370: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.64.202:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7695 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:08:15.370: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:08:15.480: INFO: Found all expected endpoints: [netserver-0]
Nov 11 21:08:15.483: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.211.110:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7695 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:08:15.483: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:08:15.608: INFO: Found all expected endpoints: [netserver-1]
Nov 11 21:08:15.610: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.10.76:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7695 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:08:15.610: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:08:15.774: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:08:15.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7695" for this suite.

• [SLOW TEST:23.346 seconds]
[sig-network] Networking
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":53,"skipped":934,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:08:15.782: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4197
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:08:16.355: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e029589e-fcb5-4f46-8ba5-f3cfee1924e2" in namespace "projected-4197" to be "Succeeded or Failed"
Nov 11 21:08:16.357: INFO: Pod "downwardapi-volume-e029589e-fcb5-4f46-8ba5-f3cfee1924e2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.808479ms
Nov 11 21:08:18.359: INFO: Pod "downwardapi-volume-e029589e-fcb5-4f46-8ba5-f3cfee1924e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004075414s
Nov 11 21:08:20.362: INFO: Pod "downwardapi-volume-e029589e-fcb5-4f46-8ba5-f3cfee1924e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006989838s
STEP: Saw pod success
Nov 11 21:08:20.362: INFO: Pod "downwardapi-volume-e029589e-fcb5-4f46-8ba5-f3cfee1924e2" satisfied condition "Succeeded or Failed"
Nov 11 21:08:20.364: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod downwardapi-volume-e029589e-fcb5-4f46-8ba5-f3cfee1924e2 container client-container: <nil>
STEP: delete the pod
Nov 11 21:08:20.385: INFO: Waiting for pod downwardapi-volume-e029589e-fcb5-4f46-8ba5-f3cfee1924e2 to disappear
Nov 11 21:08:20.387: INFO: Pod downwardapi-volume-e029589e-fcb5-4f46-8ba5-f3cfee1924e2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:08:20.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4197" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":54,"skipped":959,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:08:20.396: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8231
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Nov 11 21:08:20.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-8231'
Nov 11 21:08:21.342: INFO: stderr: ""
Nov 11 21:08:21.342: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 11 21:08:21.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8231'
Nov 11 21:08:21.421: INFO: stderr: ""
Nov 11 21:08:21.421: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Nov 11 21:08:26.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8231'
Nov 11 21:08:26.493: INFO: stderr: ""
Nov 11 21:08:26.493: INFO: stdout: "update-demo-nautilus-628xz update-demo-nautilus-pkrhx "
Nov 11 21:08:26.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-628xz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:26.563: INFO: stderr: ""
Nov 11 21:08:26.563: INFO: stdout: "true"
Nov 11 21:08:26.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-628xz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:26.634: INFO: stderr: ""
Nov 11 21:08:26.634: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 11 21:08:26.634: INFO: validating pod update-demo-nautilus-628xz
Nov 11 21:08:26.638: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 21:08:26.638: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 21:08:26.638: INFO: update-demo-nautilus-628xz is verified up and running
Nov 11 21:08:26.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-pkrhx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:26.707: INFO: stderr: ""
Nov 11 21:08:26.707: INFO: stdout: "true"
Nov 11 21:08:26.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-pkrhx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:26.775: INFO: stderr: ""
Nov 11 21:08:26.775: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 11 21:08:26.775: INFO: validating pod update-demo-nautilus-pkrhx
Nov 11 21:08:26.778: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 21:08:26.778: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 21:08:26.778: INFO: update-demo-nautilus-pkrhx is verified up and running
STEP: scaling down the replication controller
Nov 11 21:08:26.780: INFO: scanned /root for discovery docs: <nil>
Nov 11 21:08:26.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-8231'
Nov 11 21:08:27.870: INFO: stderr: ""
Nov 11 21:08:27.870: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 11 21:08:27.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8231'
Nov 11 21:08:27.941: INFO: stderr: ""
Nov 11 21:08:27.941: INFO: stdout: "update-demo-nautilus-628xz update-demo-nautilus-pkrhx "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 11 21:08:32.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8231'
Nov 11 21:08:33.013: INFO: stderr: ""
Nov 11 21:08:33.013: INFO: stdout: "update-demo-nautilus-628xz "
Nov 11 21:08:33.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-628xz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:33.083: INFO: stderr: ""
Nov 11 21:08:33.083: INFO: stdout: "true"
Nov 11 21:08:33.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-628xz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:33.152: INFO: stderr: ""
Nov 11 21:08:33.152: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 11 21:08:33.152: INFO: validating pod update-demo-nautilus-628xz
Nov 11 21:08:33.155: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 21:08:33.155: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 21:08:33.155: INFO: update-demo-nautilus-628xz is verified up and running
STEP: scaling up the replication controller
Nov 11 21:08:33.156: INFO: scanned /root for discovery docs: <nil>
Nov 11 21:08:33.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-8231'
Nov 11 21:08:34.246: INFO: stderr: ""
Nov 11 21:08:34.246: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 11 21:08:34.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8231'
Nov 11 21:08:34.320: INFO: stderr: ""
Nov 11 21:08:34.320: INFO: stdout: "update-demo-nautilus-628xz update-demo-nautilus-kn88w "
Nov 11 21:08:34.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-628xz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:34.394: INFO: stderr: ""
Nov 11 21:08:34.394: INFO: stdout: "true"
Nov 11 21:08:34.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-628xz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:34.464: INFO: stderr: ""
Nov 11 21:08:34.464: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 11 21:08:34.464: INFO: validating pod update-demo-nautilus-628xz
Nov 11 21:08:34.467: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 21:08:34.467: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 21:08:34.467: INFO: update-demo-nautilus-628xz is verified up and running
Nov 11 21:08:34.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-kn88w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:34.536: INFO: stderr: ""
Nov 11 21:08:34.536: INFO: stdout: ""
Nov 11 21:08:34.536: INFO: update-demo-nautilus-kn88w is created but not running
Nov 11 21:08:39.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8231'
Nov 11 21:08:39.611: INFO: stderr: ""
Nov 11 21:08:39.611: INFO: stdout: "update-demo-nautilus-628xz update-demo-nautilus-kn88w "
Nov 11 21:08:39.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-628xz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:39.680: INFO: stderr: ""
Nov 11 21:08:39.680: INFO: stdout: "true"
Nov 11 21:08:39.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-628xz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:39.749: INFO: stderr: ""
Nov 11 21:08:39.749: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 11 21:08:39.749: INFO: validating pod update-demo-nautilus-628xz
Nov 11 21:08:39.752: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 21:08:39.752: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 21:08:39.752: INFO: update-demo-nautilus-628xz is verified up and running
Nov 11 21:08:39.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-kn88w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:39.821: INFO: stderr: ""
Nov 11 21:08:39.821: INFO: stdout: "true"
Nov 11 21:08:39.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-kn88w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8231'
Nov 11 21:08:39.888: INFO: stderr: ""
Nov 11 21:08:39.888: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 11 21:08:39.888: INFO: validating pod update-demo-nautilus-kn88w
Nov 11 21:08:39.891: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 21:08:39.891: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 21:08:39.891: INFO: update-demo-nautilus-kn88w is verified up and running
STEP: using delete to clean up resources
Nov 11 21:08:39.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete --grace-period=0 --force -f - --namespace=kubectl-8231'
Nov 11 21:08:39.962: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 21:08:39.962: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 11 21:08:39.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8231'
Nov 11 21:08:40.038: INFO: stderr: "No resources found in kubectl-8231 namespace.\n"
Nov 11 21:08:40.038: INFO: stdout: ""
Nov 11 21:08:40.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -l name=update-demo --namespace=kubectl-8231 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 11 21:08:40.118: INFO: stderr: ""
Nov 11 21:08:40.118: INFO: stdout: "update-demo-nautilus-628xz\nupdate-demo-nautilus-kn88w\n"
Nov 11 21:08:40.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8231'
Nov 11 21:08:40.692: INFO: stderr: "No resources found in kubectl-8231 namespace.\n"
Nov 11 21:08:40.692: INFO: stdout: ""
Nov 11 21:08:40.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -l name=update-demo --namespace=kubectl-8231 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 11 21:08:40.764: INFO: stderr: ""
Nov 11 21:08:40.764: INFO: stdout: "update-demo-nautilus-628xz\nupdate-demo-nautilus-kn88w\n"
Nov 11 21:08:41.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8231'
Nov 11 21:08:41.196: INFO: stderr: "No resources found in kubectl-8231 namespace.\n"
Nov 11 21:08:41.196: INFO: stdout: ""
Nov 11 21:08:41.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -l name=update-demo --namespace=kubectl-8231 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 11 21:08:41.270: INFO: stderr: ""
Nov 11 21:08:41.270: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:08:41.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8231" for this suite.

• [SLOW TEST:20.881 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":277,"completed":55,"skipped":967,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:08:41.278: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4143
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Nov 11 21:08:41.825: INFO: namespace kubectl-4143
Nov 11 21:08:41.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-4143'
Nov 11 21:08:42.122: INFO: stderr: ""
Nov 11 21:08:42.122: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Nov 11 21:08:43.125: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 21:08:43.125: INFO: Found 0 / 1
Nov 11 21:08:44.124: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 21:08:44.124: INFO: Found 0 / 1
Nov 11 21:08:45.125: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 21:08:45.125: INFO: Found 1 / 1
Nov 11 21:08:45.125: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 11 21:08:45.127: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 21:08:45.127: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 11 21:08:45.127: INFO: wait on agnhost-master startup in kubectl-4143 
Nov 11 21:08:45.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 logs agnhost-master-f6jq6 agnhost-master --namespace=kubectl-4143'
Nov 11 21:08:45.205: INFO: stderr: ""
Nov 11 21:08:45.205: INFO: stdout: "Paused\n"
STEP: exposing RC
Nov 11 21:08:45.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4143'
Nov 11 21:08:45.294: INFO: stderr: ""
Nov 11 21:08:45.294: INFO: stdout: "service/rm2 exposed\n"
Nov 11 21:08:45.295: INFO: Service rm2 in namespace kubectl-4143 found.
STEP: exposing service
Nov 11 21:08:47.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4143'
Nov 11 21:08:47.395: INFO: stderr: ""
Nov 11 21:08:47.395: INFO: stdout: "service/rm3 exposed\n"
Nov 11 21:08:47.399: INFO: Service rm3 in namespace kubectl-4143 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:08:49.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4143" for this suite.

• [SLOW TEST:8.131 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1119
    should create services for rc  [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":277,"completed":56,"skipped":1006,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:08:49.409: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9744
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:08:56.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9744" for this suite.

• [SLOW TEST:7.589 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":277,"completed":57,"skipped":1007,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:08:56.999: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6528
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Nov 11 21:09:37.581: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1111 21:09:37.581790      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:09:37.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6528" for this suite.

• [SLOW TEST:40.593 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":277,"completed":58,"skipped":1008,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:09:37.592: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8934
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-3deb287b-a743-459e-9abd-787af505e1ec
STEP: Creating a pod to test consume secrets
Nov 11 21:09:38.165: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-09e357f3-7d50-459b-ab80-cc07c637fe75" in namespace "projected-8934" to be "Succeeded or Failed"
Nov 11 21:09:38.167: INFO: Pod "pod-projected-secrets-09e357f3-7d50-459b-ab80-cc07c637fe75": Phase="Pending", Reason="", readiness=false. Elapsed: 1.901939ms
Nov 11 21:09:40.169: INFO: Pod "pod-projected-secrets-09e357f3-7d50-459b-ab80-cc07c637fe75": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004052035s
Nov 11 21:09:42.171: INFO: Pod "pod-projected-secrets-09e357f3-7d50-459b-ab80-cc07c637fe75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006323066s
STEP: Saw pod success
Nov 11 21:09:42.171: INFO: Pod "pod-projected-secrets-09e357f3-7d50-459b-ab80-cc07c637fe75" satisfied condition "Succeeded or Failed"
Nov 11 21:09:42.173: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-secrets-09e357f3-7d50-459b-ab80-cc07c637fe75 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:09:42.188: INFO: Waiting for pod pod-projected-secrets-09e357f3-7d50-459b-ab80-cc07c637fe75 to disappear
Nov 11 21:09:42.190: INFO: Pod pod-projected-secrets-09e357f3-7d50-459b-ab80-cc07c637fe75 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:09:42.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8934" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":59,"skipped":1051,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:09:42.198: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4432
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Nov 11 21:09:48.874: INFO: 0 pods remaining
Nov 11 21:09:48.874: INFO: 0 pods has nil DeletionTimestamp
Nov 11 21:09:48.874: INFO: 
STEP: Gathering metrics
W1111 21:09:49.823450      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 11 21:09:49.823: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:09:49.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4432" for this suite.

• [SLOW TEST:7.634 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":277,"completed":60,"skipped":1069,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:09:49.832: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3597
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:09:50.886: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:09:52.892: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725791, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725791, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725791, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725791, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:09:55.901: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:10:08.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3597" for this suite.
STEP: Destroying namespace "webhook-3597-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:18.244 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":277,"completed":61,"skipped":1069,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:10:08.076: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2801
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:10:08.851: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:10:10.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725809, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725809, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725809, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725809, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:10:13.868: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:10:14.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2801" for this suite.
STEP: Destroying namespace "webhook-2801-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.192 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":277,"completed":62,"skipped":1073,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:10:14.268: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:10:15.254: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:10:17.261: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725815, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725815, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725816, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725815, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:10:20.269: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Nov 11 21:10:24.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 attach --namespace=webhook-1386 to-be-attached-pod -i -c=container1'
Nov 11 21:10:24.427: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:10:24.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1386" for this suite.
STEP: Destroying namespace "webhook-1386-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:10.244 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":277,"completed":63,"skipped":1077,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:10:24.514: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4986
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:10:36.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4986" for this suite.

• [SLOW TEST:11.719 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":277,"completed":64,"skipped":1165,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:10:36.233: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:10:36.864: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7cc15514-3f4c-4246-bc21-ed335f3b502f" in namespace "projected-3582" to be "Succeeded or Failed"
Nov 11 21:10:36.867: INFO: Pod "downwardapi-volume-7cc15514-3f4c-4246-bc21-ed335f3b502f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.336548ms
Nov 11 21:10:38.871: INFO: Pod "downwardapi-volume-7cc15514-3f4c-4246-bc21-ed335f3b502f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006862092s
STEP: Saw pod success
Nov 11 21:10:38.871: INFO: Pod "downwardapi-volume-7cc15514-3f4c-4246-bc21-ed335f3b502f" satisfied condition "Succeeded or Failed"
Nov 11 21:10:38.878: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-7cc15514-3f4c-4246-bc21-ed335f3b502f container client-container: <nil>
STEP: delete the pod
Nov 11 21:10:38.903: INFO: Waiting for pod downwardapi-volume-7cc15514-3f4c-4246-bc21-ed335f3b502f to disappear
Nov 11 21:10:38.906: INFO: Pod downwardapi-volume-7cc15514-3f4c-4246-bc21-ed335f3b502f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:10:38.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3582" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":65,"skipped":1176,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:10:38.913: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:10:39.462: INFO: (0) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 8.989811ms)
Nov 11 21:10:39.464: INFO: (1) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.362447ms)
Nov 11 21:10:39.467: INFO: (2) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.520478ms)
Nov 11 21:10:39.469: INFO: (3) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.469331ms)
Nov 11 21:10:39.472: INFO: (4) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.305652ms)
Nov 11 21:10:39.474: INFO: (5) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.455083ms)
Nov 11 21:10:39.476: INFO: (6) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.197692ms)
Nov 11 21:10:39.479: INFO: (7) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.297499ms)
Nov 11 21:10:39.481: INFO: (8) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.173346ms)
Nov 11 21:10:39.483: INFO: (9) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.282461ms)
Nov 11 21:10:39.486: INFO: (10) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.182802ms)
Nov 11 21:10:39.488: INFO: (11) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.380978ms)
Nov 11 21:10:39.494: INFO: (12) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 6.189646ms)
Nov 11 21:10:39.498: INFO: (13) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.466141ms)
Nov 11 21:10:39.500: INFO: (14) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.347126ms)
Nov 11 21:10:39.502: INFO: (15) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.372823ms)
Nov 11 21:10:39.505: INFO: (16) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.482625ms)
Nov 11 21:10:39.508: INFO: (17) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.631886ms)
Nov 11 21:10:39.510: INFO: (18) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.415644ms)
Nov 11 21:10:39.513: INFO: (19) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.462703ms)
[AfterEach] version v1
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:10:39.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8298" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":277,"completed":66,"skipped":1191,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:10:39.520: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1161
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:10:40.052: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov 11 21:10:43.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-1161 create -f -'
Nov 11 21:10:44.072: INFO: stderr: ""
Nov 11 21:10:44.072: INFO: stdout: "e2e-test-crd-publish-openapi-6804-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 11 21:10:44.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-1161 delete e2e-test-crd-publish-openapi-6804-crds test-cr'
Nov 11 21:10:44.190: INFO: stderr: ""
Nov 11 21:10:44.190: INFO: stdout: "e2e-test-crd-publish-openapi-6804-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov 11 21:10:44.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-1161 apply -f -'
Nov 11 21:10:44.426: INFO: stderr: ""
Nov 11 21:10:44.426: INFO: stdout: "e2e-test-crd-publish-openapi-6804-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 11 21:10:44.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-1161 delete e2e-test-crd-publish-openapi-6804-crds test-cr'
Nov 11 21:10:44.513: INFO: stderr: ""
Nov 11 21:10:44.513: INFO: stdout: "e2e-test-crd-publish-openapi-6804-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov 11 21:10:44.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 explain e2e-test-crd-publish-openapi-6804-crds'
Nov 11 21:10:44.803: INFO: stderr: ""
Nov 11 21:10:44.803: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6804-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:10:48.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1161" for this suite.

• [SLOW TEST:8.871 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":277,"completed":67,"skipped":1201,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:10:48.394: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8760
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Nov 11 21:10:48.956: INFO: Waiting up to 5m0s for pod "pod-16768795-ef54-459e-bbc1-38c399e06dff" in namespace "emptydir-8760" to be "Succeeded or Failed"
Nov 11 21:10:48.957: INFO: Pod "pod-16768795-ef54-459e-bbc1-38c399e06dff": Phase="Pending", Reason="", readiness=false. Elapsed: 1.594877ms
Nov 11 21:10:50.960: INFO: Pod "pod-16768795-ef54-459e-bbc1-38c399e06dff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003852221s
STEP: Saw pod success
Nov 11 21:10:50.960: INFO: Pod "pod-16768795-ef54-459e-bbc1-38c399e06dff" satisfied condition "Succeeded or Failed"
Nov 11 21:10:50.961: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-16768795-ef54-459e-bbc1-38c399e06dff container test-container: <nil>
STEP: delete the pod
Nov 11 21:10:50.975: INFO: Waiting for pod pod-16768795-ef54-459e-bbc1-38c399e06dff to disappear
Nov 11 21:10:50.985: INFO: Pod pod-16768795-ef54-459e-bbc1-38c399e06dff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:10:50.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8760" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":68,"skipped":1225,"failed":0}
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:10:50.998: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9001
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:11:51.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9001" for this suite.

• [SLOW TEST:60.574 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":277,"completed":69,"skipped":1230,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:11:51.573: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1347
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:11:52.515: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:11:54.527: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725912, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725912, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725913, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740725912, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:11:57.537: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:11:57.540: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9470-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:11:58.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1347" for this suite.
STEP: Destroying namespace "webhook-1347-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.110 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":277,"completed":70,"skipped":1248,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:11:58.683: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1585
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-e5fbf73c-242e-40c6-ace1-e27e63ca63eb
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:12:03.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1585" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":71,"skipped":1255,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:12:03.302: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-47593020-8869-4122-b36a-24c23caa3ece
STEP: Creating a pod to test consume configMaps
Nov 11 21:12:04.102: INFO: Waiting up to 5m0s for pod "pod-configmaps-e82d90f5-e785-476c-9a94-a7d119f5cf6d" in namespace "configmap-1573" to be "Succeeded or Failed"
Nov 11 21:12:04.119: INFO: Pod "pod-configmaps-e82d90f5-e785-476c-9a94-a7d119f5cf6d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.545994ms
Nov 11 21:12:06.121: INFO: Pod "pod-configmaps-e82d90f5-e785-476c-9a94-a7d119f5cf6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019008125s
Nov 11 21:12:08.123: INFO: Pod "pod-configmaps-e82d90f5-e785-476c-9a94-a7d119f5cf6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021395947s
STEP: Saw pod success
Nov 11 21:12:08.123: INFO: Pod "pod-configmaps-e82d90f5-e785-476c-9a94-a7d119f5cf6d" satisfied condition "Succeeded or Failed"
Nov 11 21:12:08.125: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod pod-configmaps-e82d90f5-e785-476c-9a94-a7d119f5cf6d container configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:12:08.139: INFO: Waiting for pod pod-configmaps-e82d90f5-e785-476c-9a94-a7d119f5cf6d to disappear
Nov 11 21:12:08.143: INFO: Pod pod-configmaps-e82d90f5-e785-476c-9a94-a7d119f5cf6d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:12:08.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1573" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":72,"skipped":1271,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:12:08.150: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-969
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-e2a9e5e9-50e2-457e-b472-0a28b054aaa3
STEP: Creating secret with name s-test-opt-upd-7aa52cbf-6fb3-4911-a4ed-337e880c9174
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e2a9e5e9-50e2-457e-b472-0a28b054aaa3
STEP: Updating secret s-test-opt-upd-7aa52cbf-6fb3-4911-a4ed-337e880c9174
STEP: Creating secret with name s-test-opt-create-45cda5f6-f3cb-4981-b152-08a90ff327d7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:13:17.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-969" for this suite.

• [SLOW TEST:69.237 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":73,"skipped":1295,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:13:17.387: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-2844
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-2844
STEP: Creating statefulset with conflicting port in namespace statefulset-2844
STEP: Waiting until pod test-pod will start running in namespace statefulset-2844
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2844
Nov 11 21:13:21.998: INFO: Observed stateful pod in namespace: statefulset-2844, name: ss-0, uid: 6a2a2739-4c22-4520-94fb-8cc92f7518df, status phase: Pending. Waiting for statefulset controller to delete.
Nov 11 21:13:22.001: INFO: Observed stateful pod in namespace: statefulset-2844, name: ss-0, uid: 6a2a2739-4c22-4520-94fb-8cc92f7518df, status phase: Pending. Waiting for statefulset controller to delete.
Nov 11 21:13:22.374: INFO: Observed stateful pod in namespace: statefulset-2844, name: ss-0, uid: 6a2a2739-4c22-4520-94fb-8cc92f7518df, status phase: Failed. Waiting for statefulset controller to delete.
Nov 11 21:13:22.570: INFO: Observed stateful pod in namespace: statefulset-2844, name: ss-0, uid: 6a2a2739-4c22-4520-94fb-8cc92f7518df, status phase: Failed. Waiting for statefulset controller to delete.
Nov 11 21:13:22.578: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2844
STEP: Removing pod with conflicting port in namespace statefulset-2844
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2844 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Nov 11 21:13:26.608: INFO: Deleting all statefulset in ns statefulset-2844
Nov 11 21:13:26.610: INFO: Scaling statefulset ss to 0
Nov 11 21:13:36.628: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 21:13:36.631: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:13:36.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2844" for this suite.

• [SLOW TEST:19.261 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":277,"completed":74,"skipped":1307,"failed":0}
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:13:36.649: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 11 21:13:39.273: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:13:39.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1482" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":75,"skipped":1308,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:13:39.296: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7794
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-7794
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7794 to expose endpoints map[]
Nov 11 21:13:39.861: INFO: Get endpoints failed (3.936181ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Nov 11 21:13:40.862: INFO: successfully validated that service endpoint-test2 in namespace services-7794 exposes endpoints map[] (1.005800456s elapsed)
STEP: Creating pod pod1 in namespace services-7794
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7794 to expose endpoints map[pod1:[80]]
Nov 11 21:13:43.918: INFO: successfully validated that service endpoint-test2 in namespace services-7794 exposes endpoints map[pod1:[80]] (3.021803417s elapsed)
STEP: Creating pod pod2 in namespace services-7794
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7794 to expose endpoints map[pod1:[80] pod2:[80]]
Nov 11 21:13:46.979: INFO: successfully validated that service endpoint-test2 in namespace services-7794 exposes endpoints map[pod1:[80] pod2:[80]] (3.024340216s elapsed)
STEP: Deleting pod pod1 in namespace services-7794
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7794 to expose endpoints map[pod2:[80]]
Nov 11 21:13:47.989: INFO: successfully validated that service endpoint-test2 in namespace services-7794 exposes endpoints map[pod2:[80]] (1.007239003s elapsed)
STEP: Deleting pod pod2 in namespace services-7794
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7794 to expose endpoints map[]
Nov 11 21:13:49.020: INFO: successfully validated that service endpoint-test2 in namespace services-7794 exposes endpoints map[] (1.027448969s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:13:49.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7794" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:9.751 seconds]
[sig-network] Services
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":277,"completed":76,"skipped":1316,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:13:49.047: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9666, will wait for the garbage collector to delete the pods
Nov 11 21:13:53.728: INFO: Deleting Job.batch foo took: 3.915354ms
Nov 11 21:13:54.029: INFO: Terminating Job.batch foo pods took: 300.224209ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:14:30.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9666" for this suite.

• [SLOW TEST:41.891 seconds]
[sig-apps] Job
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":277,"completed":77,"skipped":1325,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:14:30.938: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Nov 11 21:14:31.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-7643'
Nov 11 21:14:31.787: INFO: stderr: ""
Nov 11 21:14:31.787: INFO: stdout: "pod/pause created\n"
Nov 11 21:14:31.787: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 11 21:14:31.787: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7643" to be "running and ready"
Nov 11 21:14:31.789: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.666834ms
Nov 11 21:14:33.792: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00561002s
Nov 11 21:14:35.795: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.007998124s
Nov 11 21:14:35.795: INFO: Pod "pause" satisfied condition "running and ready"
Nov 11 21:14:35.795: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Nov 11 21:14:35.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 label pods pause testing-label=testing-label-value --namespace=kubectl-7643'
Nov 11 21:14:35.880: INFO: stderr: ""
Nov 11 21:14:35.880: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov 11 21:14:35.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pod pause -L testing-label --namespace=kubectl-7643'
Nov 11 21:14:35.952: INFO: stderr: ""
Nov 11 21:14:35.952: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov 11 21:14:35.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 label pods pause testing-label- --namespace=kubectl-7643'
Nov 11 21:14:36.036: INFO: stderr: ""
Nov 11 21:14:36.036: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov 11 21:14:36.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pod pause -L testing-label --namespace=kubectl-7643'
Nov 11 21:14:36.128: INFO: stderr: ""
Nov 11 21:14:36.128: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Nov 11 21:14:36.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete --grace-period=0 --force -f - --namespace=kubectl-7643'
Nov 11 21:14:36.235: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 21:14:36.235: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 11 21:14:36.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get rc,svc -l name=pause --no-headers --namespace=kubectl-7643'
Nov 11 21:14:36.311: INFO: stderr: "No resources found in kubectl-7643 namespace.\n"
Nov 11 21:14:36.311: INFO: stdout: ""
Nov 11 21:14:36.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -l name=pause --namespace=kubectl-7643 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 11 21:14:36.391: INFO: stderr: ""
Nov 11 21:14:36.391: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:14:36.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7643" for this suite.

• [SLOW TEST:5.477 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1203
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":277,"completed":78,"skipped":1326,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:14:36.415: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9384
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-9384/configmap-test-ba6c9ca5-ce6e-408a-8f3c-0be95222a194
STEP: Creating a pod to test consume configMaps
Nov 11 21:14:36.838: INFO: Waiting up to 5m0s for pod "pod-configmaps-f02bf694-74ed-408b-87e5-9e8164b79ae2" in namespace "configmap-9384" to be "Succeeded or Failed"
Nov 11 21:14:36.841: INFO: Pod "pod-configmaps-f02bf694-74ed-408b-87e5-9e8164b79ae2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.937117ms
Nov 11 21:14:38.843: INFO: Pod "pod-configmaps-f02bf694-74ed-408b-87e5-9e8164b79ae2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005201378s
Nov 11 21:14:40.846: INFO: Pod "pod-configmaps-f02bf694-74ed-408b-87e5-9e8164b79ae2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007607318s
STEP: Saw pod success
Nov 11 21:14:40.846: INFO: Pod "pod-configmaps-f02bf694-74ed-408b-87e5-9e8164b79ae2" satisfied condition "Succeeded or Failed"
Nov 11 21:14:40.847: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-configmaps-f02bf694-74ed-408b-87e5-9e8164b79ae2 container env-test: <nil>
STEP: delete the pod
Nov 11 21:14:40.871: INFO: Waiting for pod pod-configmaps-f02bf694-74ed-408b-87e5-9e8164b79ae2 to disappear
Nov 11 21:14:40.874: INFO: Pod pod-configmaps-f02bf694-74ed-408b-87e5-9e8164b79ae2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:14:40.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9384" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":277,"completed":79,"skipped":1354,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:14:40.882: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5019
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-e274afc0-99dd-4770-925f-3e32e68d2ba9
STEP: Creating a pod to test consume secrets
Nov 11 21:14:41.468: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-932eafaf-33a3-4e9d-824c-efa8de7c8a80" in namespace "projected-5019" to be "Succeeded or Failed"
Nov 11 21:14:41.469: INFO: Pod "pod-projected-secrets-932eafaf-33a3-4e9d-824c-efa8de7c8a80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.926618ms
Nov 11 21:14:43.472: INFO: Pod "pod-projected-secrets-932eafaf-33a3-4e9d-824c-efa8de7c8a80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004434266s
Nov 11 21:14:45.474: INFO: Pod "pod-projected-secrets-932eafaf-33a3-4e9d-824c-efa8de7c8a80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006773927s
STEP: Saw pod success
Nov 11 21:14:45.474: INFO: Pod "pod-projected-secrets-932eafaf-33a3-4e9d-824c-efa8de7c8a80" satisfied condition "Succeeded or Failed"
Nov 11 21:14:45.476: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-secrets-932eafaf-33a3-4e9d-824c-efa8de7c8a80 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:14:45.487: INFO: Waiting for pod pod-projected-secrets-932eafaf-33a3-4e9d-824c-efa8de7c8a80 to disappear
Nov 11 21:14:45.490: INFO: Pod pod-projected-secrets-932eafaf-33a3-4e9d-824c-efa8de7c8a80 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:14:45.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5019" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":80,"skipped":1359,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:14:45.497: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-4288
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Nov 11 21:14:52.591: INFO: Successfully updated pod "adopt-release-lpw9r"
STEP: Checking that the Job readopts the Pod
Nov 11 21:14:52.591: INFO: Waiting up to 15m0s for pod "adopt-release-lpw9r" in namespace "job-4288" to be "adopted"
Nov 11 21:14:52.595: INFO: Pod "adopt-release-lpw9r": Phase="Running", Reason="", readiness=true. Elapsed: 3.663811ms
Nov 11 21:14:54.597: INFO: Pod "adopt-release-lpw9r": Phase="Running", Reason="", readiness=true. Elapsed: 2.006123739s
Nov 11 21:14:54.597: INFO: Pod "adopt-release-lpw9r" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Nov 11 21:14:55.110: INFO: Successfully updated pod "adopt-release-lpw9r"
STEP: Checking that the Job releases the Pod
Nov 11 21:14:55.110: INFO: Waiting up to 15m0s for pod "adopt-release-lpw9r" in namespace "job-4288" to be "released"
Nov 11 21:14:55.113: INFO: Pod "adopt-release-lpw9r": Phase="Running", Reason="", readiness=true. Elapsed: 3.650809ms
Nov 11 21:14:57.115: INFO: Pod "adopt-release-lpw9r": Phase="Running", Reason="", readiness=true. Elapsed: 2.005637705s
Nov 11 21:14:57.116: INFO: Pod "adopt-release-lpw9r" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:14:57.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4288" for this suite.

• [SLOW TEST:11.625 seconds]
[sig-apps] Job
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":277,"completed":81,"skipped":1375,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:14:57.122: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-31
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-9aedece0-6374-41ad-84d6-e84147e64a93
STEP: Creating a pod to test consume configMaps
Nov 11 21:14:57.715: INFO: Waiting up to 5m0s for pod "pod-configmaps-c71d9794-4314-4a8f-b4d9-393622df0e07" in namespace "configmap-31" to be "Succeeded or Failed"
Nov 11 21:14:57.717: INFO: Pod "pod-configmaps-c71d9794-4314-4a8f-b4d9-393622df0e07": Phase="Pending", Reason="", readiness=false. Elapsed: 1.660123ms
Nov 11 21:14:59.720: INFO: Pod "pod-configmaps-c71d9794-4314-4a8f-b4d9-393622df0e07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004415432s
Nov 11 21:15:01.723: INFO: Pod "pod-configmaps-c71d9794-4314-4a8f-b4d9-393622df0e07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007380771s
STEP: Saw pod success
Nov 11 21:15:01.723: INFO: Pod "pod-configmaps-c71d9794-4314-4a8f-b4d9-393622df0e07" satisfied condition "Succeeded or Failed"
Nov 11 21:15:01.725: INFO: Trying to get logs from node ip-172-31-0-166.us-west-2.compute.internal pod pod-configmaps-c71d9794-4314-4a8f-b4d9-393622df0e07 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:15:01.753: INFO: Waiting for pod pod-configmaps-c71d9794-4314-4a8f-b4d9-393622df0e07 to disappear
Nov 11 21:15:01.757: INFO: Pod pod-configmaps-c71d9794-4314-4a8f-b4d9-393622df0e07 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:15:01.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-31" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":82,"skipped":1381,"failed":0}
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:15:01.767: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-9635
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-9635
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9635
STEP: Deleting pre-stop pod
Nov 11 21:15:13.496: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:15:13.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9635" for this suite.

• [SLOW TEST:11.740 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":277,"completed":83,"skipped":1382,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:15:13.507: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:15:14.533: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:15:16.539: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726114, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726114, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726115, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726114, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:15:19.548: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:15:19.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6325" for this suite.
STEP: Destroying namespace "webhook-6325-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.078 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":277,"completed":84,"skipped":1384,"failed":0}
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:15:19.586: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:15:28.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7903" for this suite.

• [SLOW TEST:8.602 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:79
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":277,"completed":85,"skipped":1385,"failed":0}
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:15:28.188: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-7347
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:15:28.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-7347" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":277,"completed":86,"skipped":1385,"failed":0}
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:15:28.778: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7904
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8841
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9282
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:15:36.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7904" for this suite.
STEP: Destroying namespace "nsdeletetest-8841" for this suite.
Nov 11 21:15:36.415: INFO: Namespace nsdeletetest-8841 was already deleted
STEP: Destroying namespace "nsdeletetest-9282" for this suite.

• [SLOW TEST:7.641 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":277,"completed":87,"skipped":1388,"failed":0}
S
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:15:36.419: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4487
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4487.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4487.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4487.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4487.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 11 21:15:49.035: INFO: DNS probes using dns-test-e782428d-5fcd-4fa3-af0a-20cdd93b9f90 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4487.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4487.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4487.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4487.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 11 21:15:53.133: INFO: DNS probes using dns-test-75fad034-2cd2-44b9-abbf-b325151e0f30 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4487.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4487.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4487.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4487.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 11 21:15:57.209: INFO: DNS probes using dns-test-2394a674-c21d-48d0-913f-ceec510f0c2f succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:15:57.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4487" for this suite.

• [SLOW TEST:20.836 seconds]
[sig-network] DNS
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":277,"completed":88,"skipped":1389,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:15:57.256: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9584
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 11 21:15:57.948: INFO: Waiting up to 5m0s for pod "pod-ae646089-4fb0-4107-8337-51df99965b30" in namespace "emptydir-9584" to be "Succeeded or Failed"
Nov 11 21:15:57.954: INFO: Pod "pod-ae646089-4fb0-4107-8337-51df99965b30": Phase="Pending", Reason="", readiness=false. Elapsed: 6.693344ms
Nov 11 21:15:59.957: INFO: Pod "pod-ae646089-4fb0-4107-8337-51df99965b30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009328021s
Nov 11 21:16:01.959: INFO: Pod "pod-ae646089-4fb0-4107-8337-51df99965b30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011648015s
STEP: Saw pod success
Nov 11 21:16:01.959: INFO: Pod "pod-ae646089-4fb0-4107-8337-51df99965b30" satisfied condition "Succeeded or Failed"
Nov 11 21:16:01.961: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-ae646089-4fb0-4107-8337-51df99965b30 container test-container: <nil>
STEP: delete the pod
Nov 11 21:16:01.977: INFO: Waiting for pod pod-ae646089-4fb0-4107-8337-51df99965b30 to disappear
Nov 11 21:16:01.981: INFO: Pod pod-ae646089-4fb0-4107-8337-51df99965b30 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:16:01.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9584" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":89,"skipped":1490,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:16:01.989: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Nov 11 21:16:02.543: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-504766910 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:16:02.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9480" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":277,"completed":90,"skipped":1518,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:16:02.622: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2784
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-e1363e43-fa71-4174-8f26-e3d589a62819 in namespace container-probe-2784
Nov 11 21:16:05.206: INFO: Started pod liveness-e1363e43-fa71-4174-8f26-e3d589a62819 in namespace container-probe-2784
STEP: checking the pod's current state and verifying that restartCount is present
Nov 11 21:16:05.208: INFO: Initial restart count of pod liveness-e1363e43-fa71-4174-8f26-e3d589a62819 is 0
Nov 11 21:16:21.230: INFO: Restart count of pod container-probe-2784/liveness-e1363e43-fa71-4174-8f26-e3d589a62819 is now 1 (16.021718765s elapsed)
Nov 11 21:16:39.264: INFO: Restart count of pod container-probe-2784/liveness-e1363e43-fa71-4174-8f26-e3d589a62819 is now 2 (34.05626289s elapsed)
Nov 11 21:16:59.305: INFO: Restart count of pod container-probe-2784/liveness-e1363e43-fa71-4174-8f26-e3d589a62819 is now 3 (54.097191929s elapsed)
Nov 11 21:17:19.329: INFO: Restart count of pod container-probe-2784/liveness-e1363e43-fa71-4174-8f26-e3d589a62819 is now 4 (1m14.121572786s elapsed)
Nov 11 21:18:31.414: INFO: Restart count of pod container-probe-2784/liveness-e1363e43-fa71-4174-8f26-e3d589a62819 is now 5 (2m26.206385293s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:18:31.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2784" for this suite.

• [SLOW TEST:148.807 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":277,"completed":91,"skipped":1533,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:18:31.430: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-9453
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9453 to expose endpoints map[]
Nov 11 21:18:31.987: INFO: Get endpoints failed (1.412173ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov 11 21:18:32.989: INFO: successfully validated that service multi-endpoint-test in namespace services-9453 exposes endpoints map[] (1.003609443s elapsed)
STEP: Creating pod pod1 in namespace services-9453
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9453 to expose endpoints map[pod1:[100]]
Nov 11 21:18:35.040: INFO: successfully validated that service multi-endpoint-test in namespace services-9453 exposes endpoints map[pod1:[100]] (2.011380601s elapsed)
STEP: Creating pod pod2 in namespace services-9453
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9453 to expose endpoints map[pod1:[100] pod2:[101]]
Nov 11 21:18:38.133: INFO: successfully validated that service multi-endpoint-test in namespace services-9453 exposes endpoints map[pod1:[100] pod2:[101]] (3.024026185s elapsed)
STEP: Deleting pod pod1 in namespace services-9453
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9453 to expose endpoints map[pod2:[101]]
Nov 11 21:18:39.149: INFO: successfully validated that service multi-endpoint-test in namespace services-9453 exposes endpoints map[pod2:[101]] (1.010419979s elapsed)
STEP: Deleting pod pod2 in namespace services-9453
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9453 to expose endpoints map[]
Nov 11 21:18:40.157: INFO: successfully validated that service multi-endpoint-test in namespace services-9453 exposes endpoints map[] (1.00416677s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:18:40.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9453" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:8.744 seconds]
[sig-network] Services
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":277,"completed":92,"skipped":1566,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:18:40.175: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-7a0d5a61-189b-49d7-81ee-d7cdbaf22729
STEP: Creating secret with name secret-projected-all-test-volume-8b71eb70-16ae-4660-90a4-44108e145eed
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov 11 21:18:40.849: INFO: Waiting up to 5m0s for pod "projected-volume-6537cf62-9c7b-460e-a03b-c726416cf35c" in namespace "projected-6957" to be "Succeeded or Failed"
Nov 11 21:18:40.852: INFO: Pod "projected-volume-6537cf62-9c7b-460e-a03b-c726416cf35c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.96311ms
Nov 11 21:18:42.854: INFO: Pod "projected-volume-6537cf62-9c7b-460e-a03b-c726416cf35c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005011194s
Nov 11 21:18:44.856: INFO: Pod "projected-volume-6537cf62-9c7b-460e-a03b-c726416cf35c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007269848s
STEP: Saw pod success
Nov 11 21:18:44.856: INFO: Pod "projected-volume-6537cf62-9c7b-460e-a03b-c726416cf35c" satisfied condition "Succeeded or Failed"
Nov 11 21:18:44.858: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod projected-volume-6537cf62-9c7b-460e-a03b-c726416cf35c container projected-all-volume-test: <nil>
STEP: delete the pod
Nov 11 21:18:44.870: INFO: Waiting for pod projected-volume-6537cf62-9c7b-460e-a03b-c726416cf35c to disappear
Nov 11 21:18:44.874: INFO: Pod projected-volume-6537cf62-9c7b-460e-a03b-c726416cf35c no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:18:44.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6957" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":277,"completed":93,"skipped":1577,"failed":0}

------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:18:44.881: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1462
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:18:45.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1462" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":277,"completed":94,"skipped":1577,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:18:45.536: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7013
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-4d89a92f-a95b-4ee7-bdc9-59c887f766b0
STEP: Creating a pod to test consume secrets
Nov 11 21:18:46.180: INFO: Waiting up to 5m0s for pod "pod-secrets-f0b1c959-21d8-4a3a-a55a-a5b9aa0199fc" in namespace "secrets-7013" to be "Succeeded or Failed"
Nov 11 21:18:46.188: INFO: Pod "pod-secrets-f0b1c959-21d8-4a3a-a55a-a5b9aa0199fc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.798984ms
Nov 11 21:18:48.190: INFO: Pod "pod-secrets-f0b1c959-21d8-4a3a-a55a-a5b9aa0199fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01029034s
STEP: Saw pod success
Nov 11 21:18:48.190: INFO: Pod "pod-secrets-f0b1c959-21d8-4a3a-a55a-a5b9aa0199fc" satisfied condition "Succeeded or Failed"
Nov 11 21:18:48.192: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-secrets-f0b1c959-21d8-4a3a-a55a-a5b9aa0199fc container secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:18:48.207: INFO: Waiting for pod pod-secrets-f0b1c959-21d8-4a3a-a55a-a5b9aa0199fc to disappear
Nov 11 21:18:48.209: INFO: Pod pod-secrets-f0b1c959-21d8-4a3a-a55a-a5b9aa0199fc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:18:48.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7013" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":95,"skipped":1578,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:18:48.217: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-161
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov 11 21:18:52.793: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-161 PodName:pod-sharedvolume-85af5c22-436c-4ada-9478-4d352b84e0b9 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:18:52.793: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:18:52.915: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:18:52.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-161" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":277,"completed":96,"skipped":1590,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:18:52.923: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1647
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 11 21:18:53.580: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:18:53.583: INFO: Number of nodes with available pods: 0
Nov 11 21:18:53.583: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:18:54.587: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:18:54.589: INFO: Number of nodes with available pods: 0
Nov 11 21:18:54.590: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:18:55.587: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:18:55.589: INFO: Number of nodes with available pods: 0
Nov 11 21:18:55.589: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:18:56.590: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:18:56.595: INFO: Number of nodes with available pods: 3
Nov 11 21:18:56.595: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov 11 21:18:56.611: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:18:56.616: INFO: Number of nodes with available pods: 3
Nov 11 21:18:56.616: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1647, will wait for the garbage collector to delete the pods
Nov 11 21:18:57.678: INFO: Deleting DaemonSet.extensions daemon-set took: 3.771976ms
Nov 11 21:18:57.979: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.179033ms
Nov 11 21:20:25.581: INFO: Number of nodes with available pods: 0
Nov 11 21:20:25.581: INFO: Number of running nodes: 0, number of available pods: 0
Nov 11 21:20:25.584: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1647/daemonsets","resourceVersion":"13780"},"items":null}

Nov 11 21:20:25.586: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1647/pods","resourceVersion":"13780"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:20:25.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1647" for this suite.

• [SLOW TEST:92.677 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":277,"completed":97,"skipped":1599,"failed":0}
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:20:25.600: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6345
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-5vb4
STEP: Creating a pod to test atomic-volume-subpath
Nov 11 21:20:26.239: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-5vb4" in namespace "subpath-6345" to be "Succeeded or Failed"
Nov 11 21:20:26.241: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114995ms
Nov 11 21:20:28.244: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004330588s
Nov 11 21:20:30.246: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 4.006973491s
Nov 11 21:20:32.249: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 6.009415766s
Nov 11 21:20:34.251: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 8.011800488s
Nov 11 21:20:36.253: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 10.014096453s
Nov 11 21:20:38.256: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 12.016278752s
Nov 11 21:20:40.258: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 14.018847665s
Nov 11 21:20:42.262: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 16.02287511s
Nov 11 21:20:44.264: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 18.025043308s
Nov 11 21:20:46.267: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 20.027382999s
Nov 11 21:20:48.269: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Running", Reason="", readiness=true. Elapsed: 22.029690553s
Nov 11 21:20:50.273: INFO: Pod "pod-subpath-test-secret-5vb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.033801904s
STEP: Saw pod success
Nov 11 21:20:50.274: INFO: Pod "pod-subpath-test-secret-5vb4" satisfied condition "Succeeded or Failed"
Nov 11 21:20:50.276: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-subpath-test-secret-5vb4 container test-container-subpath-secret-5vb4: <nil>
STEP: delete the pod
Nov 11 21:20:50.292: INFO: Waiting for pod pod-subpath-test-secret-5vb4 to disappear
Nov 11 21:20:50.294: INFO: Pod pod-subpath-test-secret-5vb4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-5vb4
Nov 11 21:20:50.294: INFO: Deleting pod "pod-subpath-test-secret-5vb4" in namespace "subpath-6345"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:20:50.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6345" for this suite.

• [SLOW TEST:24.702 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":277,"completed":98,"skipped":1601,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:20:50.302: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9547
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Nov 11 21:20:50.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 api-versions'
Nov 11 21:20:50.900: INFO: stderr: ""
Nov 11 21:20:50.900: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.istio.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncompose.docker.com/v1alpha3\ncompose.docker.com/v1beta1\ncompose.docker.com/v1beta2\nconfig.istio.io/v1alpha2\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.istio.io/v1alpha3\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nrbac.istio.io/v1alpha1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:20:50.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9547" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":277,"completed":99,"skipped":1635,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:20:50.910: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8474
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-fc25290e-9043-4e22-afcb-7625f884ef08
STEP: Creating a pod to test consume configMaps
Nov 11 21:20:51.486: INFO: Waiting up to 5m0s for pod "pod-configmaps-c8fb7822-d53e-45f6-9c2d-85dc5c691afb" in namespace "configmap-8474" to be "Succeeded or Failed"
Nov 11 21:20:51.489: INFO: Pod "pod-configmaps-c8fb7822-d53e-45f6-9c2d-85dc5c691afb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.777055ms
Nov 11 21:20:53.493: INFO: Pod "pod-configmaps-c8fb7822-d53e-45f6-9c2d-85dc5c691afb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006701725s
Nov 11 21:20:55.495: INFO: Pod "pod-configmaps-c8fb7822-d53e-45f6-9c2d-85dc5c691afb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008768744s
STEP: Saw pod success
Nov 11 21:20:55.495: INFO: Pod "pod-configmaps-c8fb7822-d53e-45f6-9c2d-85dc5c691afb" satisfied condition "Succeeded or Failed"
Nov 11 21:20:55.497: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-configmaps-c8fb7822-d53e-45f6-9c2d-85dc5c691afb container configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:20:55.511: INFO: Waiting for pod pod-configmaps-c8fb7822-d53e-45f6-9c2d-85dc5c691afb to disappear
Nov 11 21:20:55.515: INFO: Pod pod-configmaps-c8fb7822-d53e-45f6-9c2d-85dc5c691afb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:20:55.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8474" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":100,"skipped":1667,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:20:55.527: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1502
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 11 21:20:56.193: INFO: Waiting up to 5m0s for pod "pod-28f184ae-b3e6-400d-9bc3-d4544a4f0a76" in namespace "emptydir-1502" to be "Succeeded or Failed"
Nov 11 21:20:56.197: INFO: Pod "pod-28f184ae-b3e6-400d-9bc3-d4544a4f0a76": Phase="Pending", Reason="", readiness=false. Elapsed: 3.691673ms
Nov 11 21:20:58.199: INFO: Pod "pod-28f184ae-b3e6-400d-9bc3-d4544a4f0a76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005937413s
STEP: Saw pod success
Nov 11 21:20:58.199: INFO: Pod "pod-28f184ae-b3e6-400d-9bc3-d4544a4f0a76" satisfied condition "Succeeded or Failed"
Nov 11 21:20:58.201: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-28f184ae-b3e6-400d-9bc3-d4544a4f0a76 container test-container: <nil>
STEP: delete the pod
Nov 11 21:20:58.213: INFO: Waiting for pod pod-28f184ae-b3e6-400d-9bc3-d4544a4f0a76 to disappear
Nov 11 21:20:58.216: INFO: Pod pod-28f184ae-b3e6-400d-9bc3-d4544a4f0a76 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:20:58.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1502" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":101,"skipped":1673,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:20:58.223: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2364
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:20:58.855: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"9354be0b-a8aa-49d6-a0eb-c57450b25195", Controller:(*bool)(0xc0021841fa), BlockOwnerDeletion:(*bool)(0xc0021841fb)}}
Nov 11 21:20:58.867: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"02a03e86-a9bd-4cc7-b50c-606f77caff5e", Controller:(*bool)(0xc0021843c6), BlockOwnerDeletion:(*bool)(0xc0021843c7)}}
Nov 11 21:20:58.892: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"bf6fb420-3da8-4432-9484-72558fa6d244", Controller:(*bool)(0xc00218459a), BlockOwnerDeletion:(*bool)(0xc00218459b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:03.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2364" for this suite.

• [SLOW TEST:5.687 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":277,"completed":102,"skipped":1678,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:03.911: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5901
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:21:04.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 version'
Nov 11 21:21:04.420: INFO: stderr: ""
Nov 11 21:21:04.420: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.10\", GitCommit:\"62876fc6d93e891aa7fbe19771e6a6c03773b0f7\", GitTreeState:\"clean\", BuildDate:\"2020-10-15T01:52:24Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18+\", GitVersion:\"v1.18.10-mirantis-1\", GitCommit:\"7265139154a920591d0f09a3a1188ccab0b7cc2e\", GitTreeState:\"clean\", BuildDate:\"2020-10-16T03:13:32Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:04.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5901" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":277,"completed":103,"skipped":1740,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:04.431: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:21:04.997: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-a97f03f7-6dd9-4ab2-831e-765e4d27b279" in namespace "security-context-test-9717" to be "Succeeded or Failed"
Nov 11 21:21:05.000: INFO: Pod "busybox-privileged-false-a97f03f7-6dd9-4ab2-831e-765e4d27b279": Phase="Pending", Reason="", readiness=false. Elapsed: 3.0631ms
Nov 11 21:21:07.003: INFO: Pod "busybox-privileged-false-a97f03f7-6dd9-4ab2-831e-765e4d27b279": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006781491s
Nov 11 21:21:07.003: INFO: Pod "busybox-privileged-false-a97f03f7-6dd9-4ab2-831e-765e4d27b279" satisfied condition "Succeeded or Failed"
Nov 11 21:21:07.016: INFO: Got logs for pod "busybox-privileged-false-a97f03f7-6dd9-4ab2-831e-765e4d27b279": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:07.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9717" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":104,"skipped":1753,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:07.028: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4440
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:21:07.643: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1775295b-0d2e-43aa-98d4-d34322ce09e0" in namespace "projected-4440" to be "Succeeded or Failed"
Nov 11 21:21:07.652: INFO: Pod "downwardapi-volume-1775295b-0d2e-43aa-98d4-d34322ce09e0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.358038ms
Nov 11 21:21:09.678: INFO: Pod "downwardapi-volume-1775295b-0d2e-43aa-98d4-d34322ce09e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03520476s
Nov 11 21:21:11.680: INFO: Pod "downwardapi-volume-1775295b-0d2e-43aa-98d4-d34322ce09e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037231045s
STEP: Saw pod success
Nov 11 21:21:11.681: INFO: Pod "downwardapi-volume-1775295b-0d2e-43aa-98d4-d34322ce09e0" satisfied condition "Succeeded or Failed"
Nov 11 21:21:11.682: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-1775295b-0d2e-43aa-98d4-d34322ce09e0 container client-container: <nil>
STEP: delete the pod
Nov 11 21:21:11.694: INFO: Waiting for pod downwardapi-volume-1775295b-0d2e-43aa-98d4-d34322ce09e0 to disappear
Nov 11 21:21:11.697: INFO: Pod downwardapi-volume-1775295b-0d2e-43aa-98d4-d34322ce09e0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:11.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4440" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":105,"skipped":1764,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:11.704: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-954
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-381511df-a5ef-4b46-ae8a-ec6839ff2297
STEP: Creating a pod to test consume secrets
Nov 11 21:21:12.392: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2ab5d587-b723-44ef-a35b-a40b4752b70c" in namespace "projected-954" to be "Succeeded or Failed"
Nov 11 21:21:12.396: INFO: Pod "pod-projected-secrets-2ab5d587-b723-44ef-a35b-a40b4752b70c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.903412ms
Nov 11 21:21:14.398: INFO: Pod "pod-projected-secrets-2ab5d587-b723-44ef-a35b-a40b4752b70c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00619709s
STEP: Saw pod success
Nov 11 21:21:14.398: INFO: Pod "pod-projected-secrets-2ab5d587-b723-44ef-a35b-a40b4752b70c" satisfied condition "Succeeded or Failed"
Nov 11 21:21:14.400: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-secrets-2ab5d587-b723-44ef-a35b-a40b4752b70c container secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:21:14.414: INFO: Waiting for pod pod-projected-secrets-2ab5d587-b723-44ef-a35b-a40b4752b70c to disappear
Nov 11 21:21:14.416: INFO: Pod pod-projected-secrets-2ab5d587-b723-44ef-a35b-a40b4752b70c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:14.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-954" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":106,"skipped":1784,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:14.423: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-7155
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:14.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7155" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":277,"completed":107,"skipped":1800,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:14.981: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:21:15.944: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:21:17.950: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726476, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726476, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726476, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726476, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:21:20.972: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:21:20.974: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4182-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:22.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7229" for this suite.
STEP: Destroying namespace "webhook-7229-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.252 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":277,"completed":108,"skipped":1801,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:22.235: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6916
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Nov 11 21:21:22.821: INFO: Waiting up to 5m0s for pod "downward-api-d9a54c3a-ce96-4754-8e08-f5954fc9a7f4" in namespace "downward-api-6916" to be "Succeeded or Failed"
Nov 11 21:21:22.823: INFO: Pod "downward-api-d9a54c3a-ce96-4754-8e08-f5954fc9a7f4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.992135ms
Nov 11 21:21:24.830: INFO: Pod "downward-api-d9a54c3a-ce96-4754-8e08-f5954fc9a7f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009061117s
Nov 11 21:21:26.832: INFO: Pod "downward-api-d9a54c3a-ce96-4754-8e08-f5954fc9a7f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011341314s
STEP: Saw pod success
Nov 11 21:21:26.833: INFO: Pod "downward-api-d9a54c3a-ce96-4754-8e08-f5954fc9a7f4" satisfied condition "Succeeded or Failed"
Nov 11 21:21:26.834: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod downward-api-d9a54c3a-ce96-4754-8e08-f5954fc9a7f4 container dapi-container: <nil>
STEP: delete the pod
Nov 11 21:21:26.873: INFO: Waiting for pod downward-api-d9a54c3a-ce96-4754-8e08-f5954fc9a7f4 to disappear
Nov 11 21:21:26.876: INFO: Pod downward-api-d9a54c3a-ce96-4754-8e08-f5954fc9a7f4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:26.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6916" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":277,"completed":109,"skipped":1818,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:26.885: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6702
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov 11 21:21:32.069: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6702 pod-service-account-57361d6f-ae03-4f3f-8357-24b6889383b0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov 11 21:21:32.492: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6702 pod-service-account-57361d6f-ae03-4f3f-8357-24b6889383b0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov 11 21:21:32.694: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6702 pod-service-account-57361d6f-ae03-4f3f-8357-24b6889383b0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:32.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6702" for this suite.

• [SLOW TEST:6.012 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":277,"completed":110,"skipped":1836,"failed":0}
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:32.898: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-497
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:21:33.433: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov 11 21:21:37.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-497 create -f -'
Nov 11 21:21:37.718: INFO: stderr: ""
Nov 11 21:21:37.718: INFO: stdout: "e2e-test-crd-publish-openapi-7622-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 11 21:21:37.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-497 delete e2e-test-crd-publish-openapi-7622-crds test-cr'
Nov 11 21:21:37.792: INFO: stderr: ""
Nov 11 21:21:37.792: INFO: stdout: "e2e-test-crd-publish-openapi-7622-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov 11 21:21:37.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-497 apply -f -'
Nov 11 21:21:37.984: INFO: stderr: ""
Nov 11 21:21:37.984: INFO: stdout: "e2e-test-crd-publish-openapi-7622-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 11 21:21:37.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-497 delete e2e-test-crd-publish-openapi-7622-crds test-cr'
Nov 11 21:21:38.057: INFO: stderr: ""
Nov 11 21:21:38.057: INFO: stdout: "e2e-test-crd-publish-openapi-7622-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov 11 21:21:38.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 explain e2e-test-crd-publish-openapi-7622-crds'
Nov 11 21:21:38.266: INFO: stderr: ""
Nov 11 21:21:38.266: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7622-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:41.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-497" for this suite.

• [SLOW TEST:8.930 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":277,"completed":111,"skipped":1836,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:41.828: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-df6608d1-1cbd-4984-85a1-4cb948becd37
STEP: Creating a pod to test consume configMaps
Nov 11 21:21:42.405: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bca3ccc0-29fc-43a3-adb7-7609ff0a1dac" in namespace "projected-9855" to be "Succeeded or Failed"
Nov 11 21:21:42.407: INFO: Pod "pod-projected-configmaps-bca3ccc0-29fc-43a3-adb7-7609ff0a1dac": Phase="Pending", Reason="", readiness=false. Elapsed: 1.598349ms
Nov 11 21:21:44.409: INFO: Pod "pod-projected-configmaps-bca3ccc0-29fc-43a3-adb7-7609ff0a1dac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003916567s
Nov 11 21:21:46.412: INFO: Pod "pod-projected-configmaps-bca3ccc0-29fc-43a3-adb7-7609ff0a1dac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006218444s
STEP: Saw pod success
Nov 11 21:21:46.412: INFO: Pod "pod-projected-configmaps-bca3ccc0-29fc-43a3-adb7-7609ff0a1dac" satisfied condition "Succeeded or Failed"
Nov 11 21:21:46.413: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-configmaps-bca3ccc0-29fc-43a3-adb7-7609ff0a1dac container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:21:46.428: INFO: Waiting for pod pod-projected-configmaps-bca3ccc0-29fc-43a3-adb7-7609ff0a1dac to disappear
Nov 11 21:21:46.430: INFO: Pod pod-projected-configmaps-bca3ccc0-29fc-43a3-adb7-7609ff0a1dac no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:46.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9855" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":112,"skipped":1855,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:46.436: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3764
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:21:46.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-3764'
Nov 11 21:21:47.393: INFO: stderr: ""
Nov 11 21:21:47.393: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Nov 11 21:21:47.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-3764'
Nov 11 21:21:47.554: INFO: stderr: ""
Nov 11 21:21:47.554: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Nov 11 21:21:48.557: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 21:21:48.557: INFO: Found 0 / 1
Nov 11 21:21:49.557: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 21:21:49.557: INFO: Found 0 / 1
Nov 11 21:21:50.557: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 21:21:50.557: INFO: Found 1 / 1
Nov 11 21:21:50.557: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 11 21:21:50.561: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 21:21:50.561: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 11 21:21:50.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 describe pod agnhost-master-l52rf --namespace=kubectl-3764'
Nov 11 21:21:50.641: INFO: stderr: ""
Nov 11 21:21:50.641: INFO: stdout: "Name:         agnhost-master-l52rf\nNamespace:    kubectl-3764\nPriority:     0\nNode:         ip-172-31-0-62.us-west-2.compute.internal/172.31.0.62\nStart Time:   Wed, 11 Nov 2020 21:21:48 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           192.168.211.99\nIPs:\n  IP:           192.168.211.99\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://f2c14f63e8862d83ce6837b88f16b049941f487edac24d86339f4c74511218e4\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 11 Nov 2020 21:21:49 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fs5rx (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-fs5rx:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-fs5rx\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-3764/agnhost-master-l52rf to ip-172-31-0-62.us-west-2.compute.internal\n  Normal  Pulled     2s    kubelet            Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-master\n  Normal  Started    1s    kubelet            Started container agnhost-master\n"
Nov 11 21:21:50.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 describe rc agnhost-master --namespace=kubectl-3764'
Nov 11 21:21:50.736: INFO: stderr: ""
Nov 11 21:21:50.736: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-3764\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-master-l52rf\n"
Nov 11 21:21:50.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 describe service agnhost-master --namespace=kubectl-3764'
Nov 11 21:21:50.810: INFO: stderr: ""
Nov 11 21:21:50.810: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-3764\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.96.44.195\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.211.99:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 11 21:21:50.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 describe node ip-172-31-0-166.us-west-2.compute.internal'
Nov 11 21:21:50.907: INFO: stderr: ""
Nov 11 21:21:50.907: INFO: stdout: "Name:               ip-172-31-0-166.us-west-2.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    com.docker.ucp.collection=shared\n                    com.docker.ucp.collection.root=true\n                    com.docker.ucp.collection.shared=true\n                    com.docker.ucp.collection.swarm=true\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-0-166.us-west-2.compute.internal\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 11 Nov 2020 20:42:38 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-0-166.us-west-2.compute.internal\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 11 Nov 2020 21:21:49 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 11 Nov 2020 20:42:40 +0000   Wed, 11 Nov 2020 20:42:40 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Wed, 11 Nov 2020 21:20:41 +0000   Wed, 11 Nov 2020 20:42:38 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 11 Nov 2020 21:20:41 +0000   Wed, 11 Nov 2020 20:42:38 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 11 Nov 2020 21:20:41 +0000   Wed, 11 Nov 2020 20:42:38 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 11 Nov 2020 21:20:41 +0000   Wed, 11 Nov 2020 20:42:48 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.0.166\n  Hostname:    ip-172-31-0-166.us-west-2.compute.internal\nCapacity:\n  cpu:                2\n  ephemeral-storage:  101583780Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7936536Ki\n  pods:               110\nAllocatable:\n  cpu:                1950m\n  ephemeral-storage:  101071780Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7629336Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec2f8de2525aa8ff0d5901fd1dab59a9\n  System UUID:                ec2f8de2-525a-a8ff-0d59-01fd1dab59a9\n  Boot ID:                    2d7ef7d9-e37e-4a27-82a2-eaddff10049d\n  Kernel Version:             5.4.0-1029-aws\n  OS Image:                   Ubuntu 18.04.5 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://19.3.12\n  Kubelet Version:            v1.18.10-mirantis-1\n  Kube-Proxy Version:         v1.18.10-mirantis-1\nNon-terminated Pods:          (4 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-vdd82                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         39m\n  kube-system                 ucp-nvidia-device-plugin-749cm                             50m (2%)      200m (10%)  10Mi (0%)        100Mi (1%)     39m\n  sonobuoy                    sonobuoy-e2e-job-9a557cfe0d894233                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         22m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-g728j    0 (0%)        0 (0%)      0 (0%)           0 (0%)         22m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                300m (15%)  200m (10%)\n  memory             10Mi (0%)   100Mi (1%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From        Message\n  ----    ------                   ----               ----        -------\n  Normal  Starting                 39m                kubelet     Starting kubelet.\n  Normal  NodeHasSufficientMemory  39m (x2 over 39m)  kubelet     Node ip-172-31-0-166.us-west-2.compute.internal status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    39m (x2 over 39m)  kubelet     Node ip-172-31-0-166.us-west-2.compute.internal status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     39m (x2 over 39m)  kubelet     Node ip-172-31-0-166.us-west-2.compute.internal status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  39m                kubelet     Updated Node Allocatable limit across pods\n  Normal  Starting                 39m                kube-proxy  Starting kube-proxy.\n  Normal  NodeReady                39m                kubelet     Node ip-172-31-0-166.us-west-2.compute.internal status is now: NodeReady\n"
Nov 11 21:21:50.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 describe namespace kubectl-3764'
Nov 11 21:21:50.983: INFO: stderr: ""
Nov 11 21:21:50.983: INFO: stdout: "Name:         kubectl-3764\nLabels:       e2e-framework=kubectl\n              e2e-run=75f4a91d-80a0-46c6-9f6e-c2b5305785c8\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:21:50.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3764" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":277,"completed":113,"skipped":1862,"failed":0}
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:21:50.989: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5475
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-225d72a1-f08c-4dc3-84fc-cbc32d0cf9b4
STEP: Creating configMap with name cm-test-opt-upd-2b01fdf2-39d0-430c-af75-719760dc6ace
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-225d72a1-f08c-4dc3-84fc-cbc32d0cf9b4
STEP: Updating configmap cm-test-opt-upd-2b01fdf2-39d0-430c-af75-719760dc6ace
STEP: Creating configMap with name cm-test-opt-create-e38ce433-2ea2-490c-954b-5589270f3f73
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:23:13.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5475" for this suite.

• [SLOW TEST:82.926 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":114,"skipped":1865,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:23:13.916: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1587
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1587
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1587
STEP: creating replication controller externalsvc in namespace services-1587
I1111 21:23:14.492939      21 runners.go:190] Created replication controller with name: externalsvc, namespace: services-1587, replica count: 2
I1111 21:23:17.543202      21 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Nov 11 21:23:17.555: INFO: Creating new exec pod
Nov 11 21:23:19.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-1587 execpodhzmfw -- /bin/sh -x -c nslookup clusterip-service'
Nov 11 21:23:19.790: INFO: stderr: "+ nslookup clusterip-service\n"
Nov 11 21:23:19.790: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-1587.svc.cluster.local\tcanonical name = externalsvc.services-1587.svc.cluster.local.\nName:\texternalsvc.services-1587.svc.cluster.local\nAddress: 10.96.117.96\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1587, will wait for the garbage collector to delete the pods
Nov 11 21:23:19.846: INFO: Deleting ReplicationController externalsvc took: 3.806453ms
Nov 11 21:23:20.746: INFO: Terminating ReplicationController externalsvc pods took: 900.157848ms
Nov 11 21:23:28.157: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:23:28.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1587" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:14.254 seconds]
[sig-network] Services
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":277,"completed":115,"skipped":1878,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:23:28.171: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5994
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 11 21:23:31.293: INFO: Successfully updated pod "pod-update-activedeadlineseconds-3d764121-a2a6-4bec-9368-79ab8ef303ad"
Nov 11 21:23:31.293: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-3d764121-a2a6-4bec-9368-79ab8ef303ad" in namespace "pods-5994" to be "terminated due to deadline exceeded"
Nov 11 21:23:31.294: INFO: Pod "pod-update-activedeadlineseconds-3d764121-a2a6-4bec-9368-79ab8ef303ad": Phase="Running", Reason="", readiness=true. Elapsed: 1.57161ms
Nov 11 21:23:33.300: INFO: Pod "pod-update-activedeadlineseconds-3d764121-a2a6-4bec-9368-79ab8ef303ad": Phase="Running", Reason="", readiness=true. Elapsed: 2.00692512s
Nov 11 21:23:35.302: INFO: Pod "pod-update-activedeadlineseconds-3d764121-a2a6-4bec-9368-79ab8ef303ad": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009570432s
Nov 11 21:23:35.302: INFO: Pod "pod-update-activedeadlineseconds-3d764121-a2a6-4bec-9368-79ab8ef303ad" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:23:35.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5994" for this suite.

• [SLOW TEST:7.140 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":277,"completed":116,"skipped":1916,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:23:35.312: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1936
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-633d7ff5-f2b2-4eff-9b10-54aa430bc379
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-633d7ff5-f2b2-4eff-9b10-54aa430bc379
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:23:39.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1936" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":117,"skipped":1942,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:23:39.935: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5566
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:23:40.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc3cad8e-c4c2-4af3-bac7-801dd5f1ffc6" in namespace "projected-5566" to be "Succeeded or Failed"
Nov 11 21:23:40.505: INFO: Pod "downwardapi-volume-bc3cad8e-c4c2-4af3-bac7-801dd5f1ffc6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.763041ms
Nov 11 21:23:42.507: INFO: Pod "downwardapi-volume-bc3cad8e-c4c2-4af3-bac7-801dd5f1ffc6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004143457s
Nov 11 21:23:44.510: INFO: Pod "downwardapi-volume-bc3cad8e-c4c2-4af3-bac7-801dd5f1ffc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006271052s
STEP: Saw pod success
Nov 11 21:23:44.510: INFO: Pod "downwardapi-volume-bc3cad8e-c4c2-4af3-bac7-801dd5f1ffc6" satisfied condition "Succeeded or Failed"
Nov 11 21:23:44.511: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod downwardapi-volume-bc3cad8e-c4c2-4af3-bac7-801dd5f1ffc6 container client-container: <nil>
STEP: delete the pod
Nov 11 21:23:44.523: INFO: Waiting for pod downwardapi-volume-bc3cad8e-c4c2-4af3-bac7-801dd5f1ffc6 to disappear
Nov 11 21:23:44.526: INFO: Pod downwardapi-volume-bc3cad8e-c4c2-4af3-bac7-801dd5f1ffc6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:23:44.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5566" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":118,"skipped":1955,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:23:44.534: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:23:45.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6949" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":277,"completed":119,"skipped":1983,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:23:45.184: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4620
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Nov 11 21:23:45.727: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Nov 11 21:23:45.975: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Nov 11 21:23:48.001: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:23:50.003: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:23:52.003: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:23:54.003: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:23:56.003: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:23:58.005: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:24:00.004: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726626, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:24:02.924: INFO: Waited 915.280537ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:24:03.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4620" for this suite.

• [SLOW TEST:18.653 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":277,"completed":120,"skipped":1993,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:24:03.836: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2940
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:24:04.397: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:24:05.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2940" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":277,"completed":121,"skipped":2006,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:24:05.524: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2464
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1111 21:24:08.293020      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 11 21:24:08.293: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:24:08.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2464" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":277,"completed":122,"skipped":2016,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:24:08.314: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6799
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Nov 11 21:24:08.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-6799 -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov 11 21:24:08.965: INFO: stderr: ""
Nov 11 21:24:08.965: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Nov 11 21:24:08.965: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov 11 21:24:08.965: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6799" to be "running and ready, or succeeded"
Nov 11 21:24:08.967: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002457ms
Nov 11 21:24:10.970: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00494008s
Nov 11 21:24:12.975: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.009652941s
Nov 11 21:24:12.975: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov 11 21:24:12.975: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Nov 11 21:24:12.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 logs logs-generator logs-generator --namespace=kubectl-6799'
Nov 11 21:24:13.056: INFO: stderr: ""
Nov 11 21:24:13.056: INFO: stdout: "I1111 21:24:10.363569       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/z855 533\nI1111 21:24:10.563710       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/vmm 259\nI1111 21:24:10.763731       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/h77v 254\nI1111 21:24:10.963696       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/8zgr 261\nI1111 21:24:11.163701       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/99p7 398\nI1111 21:24:11.363688       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/bvxh 264\nI1111 21:24:11.563703       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/ng5x 271\nI1111 21:24:11.763722       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/rrx 313\nI1111 21:24:11.963743       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/n2n 480\nI1111 21:24:12.163738       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/46mp 317\nI1111 21:24:12.363741       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/rmvv 276\nI1111 21:24:12.563703       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/vfd 366\nI1111 21:24:12.763723       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/5rs 544\nI1111 21:24:12.963746       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/7dn 274\n"
STEP: limiting log lines
Nov 11 21:24:13.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 logs logs-generator logs-generator --namespace=kubectl-6799 --tail=1'
Nov 11 21:24:13.133: INFO: stderr: ""
Nov 11 21:24:13.133: INFO: stdout: "I1111 21:24:12.963746       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/7dn 274\n"
Nov 11 21:24:13.133: INFO: got output "I1111 21:24:12.963746       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/7dn 274\n"
STEP: limiting log bytes
Nov 11 21:24:13.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 logs logs-generator logs-generator --namespace=kubectl-6799 --limit-bytes=1'
Nov 11 21:24:13.212: INFO: stderr: ""
Nov 11 21:24:13.212: INFO: stdout: "I"
Nov 11 21:24:13.212: INFO: got output "I"
STEP: exposing timestamps
Nov 11 21:24:13.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 logs logs-generator logs-generator --namespace=kubectl-6799 --tail=1 --timestamps'
Nov 11 21:24:13.290: INFO: stderr: ""
Nov 11 21:24:13.290: INFO: stdout: "2020-11-11T21:24:13.163793839Z I1111 21:24:13.163664       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/mgf 200\n"
Nov 11 21:24:13.290: INFO: got output "2020-11-11T21:24:13.163793839Z I1111 21:24:13.163664       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/mgf 200\n"
STEP: restricting to a time range
Nov 11 21:24:15.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 logs logs-generator logs-generator --namespace=kubectl-6799 --since=1s'
Nov 11 21:24:15.870: INFO: stderr: ""
Nov 11 21:24:15.870: INFO: stdout: "I1111 21:24:14.963723       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/vhnh 475\nI1111 21:24:15.163723       1 logs_generator.go:76] 24 GET /api/v1/namespaces/default/pods/5nk 433\nI1111 21:24:15.363692       1 logs_generator.go:76] 25 POST /api/v1/namespaces/default/pods/j7q 504\nI1111 21:24:15.563703       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/fv9 298\nI1111 21:24:15.763733       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/rvxl 284\n"
Nov 11 21:24:15.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 logs logs-generator logs-generator --namespace=kubectl-6799 --since=24h'
Nov 11 21:24:15.946: INFO: stderr: ""
Nov 11 21:24:15.947: INFO: stdout: "I1111 21:24:10.363569       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/z855 533\nI1111 21:24:10.563710       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/vmm 259\nI1111 21:24:10.763731       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/h77v 254\nI1111 21:24:10.963696       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/8zgr 261\nI1111 21:24:11.163701       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/99p7 398\nI1111 21:24:11.363688       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/bvxh 264\nI1111 21:24:11.563703       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/ng5x 271\nI1111 21:24:11.763722       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/rrx 313\nI1111 21:24:11.963743       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/n2n 480\nI1111 21:24:12.163738       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/46mp 317\nI1111 21:24:12.363741       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/rmvv 276\nI1111 21:24:12.563703       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/vfd 366\nI1111 21:24:12.763723       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/5rs 544\nI1111 21:24:12.963746       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/7dn 274\nI1111 21:24:13.163664       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/mgf 200\nI1111 21:24:13.363732       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/mzmz 248\nI1111 21:24:13.563695       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/tcc9 251\nI1111 21:24:13.763692       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/l8f 203\nI1111 21:24:13.963693       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/w9n 499\nI1111 21:24:14.163694       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/p2j 209\nI1111 21:24:14.363683       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/7xs 208\nI1111 21:24:14.563723       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/fkc 513\nI1111 21:24:14.763702       1 logs_generator.go:76] 22 POST /api/v1/namespaces/kube-system/pods/p5wk 217\nI1111 21:24:14.963723       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/vhnh 475\nI1111 21:24:15.163723       1 logs_generator.go:76] 24 GET /api/v1/namespaces/default/pods/5nk 433\nI1111 21:24:15.363692       1 logs_generator.go:76] 25 POST /api/v1/namespaces/default/pods/j7q 504\nI1111 21:24:15.563703       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/fv9 298\nI1111 21:24:15.763733       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/rvxl 284\nI1111 21:24:15.963697       1 logs_generator.go:76] 28 GET /api/v1/namespaces/default/pods/tsj 352\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Nov 11 21:24:15.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete pod logs-generator --namespace=kubectl-6799'
Nov 11 21:24:20.854: INFO: stderr: ""
Nov 11 21:24:20.854: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:24:20.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6799" for this suite.

• [SLOW TEST:12.547 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1284
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":277,"completed":123,"skipped":2021,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:24:20.862: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2133
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-pc4f
STEP: Creating a pod to test atomic-volume-subpath
Nov 11 21:24:21.431: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pc4f" in namespace "subpath-2133" to be "Succeeded or Failed"
Nov 11 21:24:21.433: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.988922ms
Nov 11 21:24:23.436: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 2.00444213s
Nov 11 21:24:25.443: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 4.012152917s
Nov 11 21:24:27.446: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 6.014446268s
Nov 11 21:24:29.448: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 8.017030502s
Nov 11 21:24:31.451: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 10.019305793s
Nov 11 21:24:33.453: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 12.021613054s
Nov 11 21:24:35.455: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 14.024034639s
Nov 11 21:24:37.460: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 16.029072755s
Nov 11 21:24:39.463: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 18.031437977s
Nov 11 21:24:41.465: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Running", Reason="", readiness=true. Elapsed: 20.034002691s
Nov 11 21:24:43.468: INFO: Pod "pod-subpath-test-projected-pc4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.03642859s
STEP: Saw pod success
Nov 11 21:24:43.468: INFO: Pod "pod-subpath-test-projected-pc4f" satisfied condition "Succeeded or Failed"
Nov 11 21:24:43.470: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-subpath-test-projected-pc4f container test-container-subpath-projected-pc4f: <nil>
STEP: delete the pod
Nov 11 21:24:43.488: INFO: Waiting for pod pod-subpath-test-projected-pc4f to disappear
Nov 11 21:24:43.490: INFO: Pod pod-subpath-test-projected-pc4f no longer exists
STEP: Deleting pod pod-subpath-test-projected-pc4f
Nov 11 21:24:43.490: INFO: Deleting pod "pod-subpath-test-projected-pc4f" in namespace "subpath-2133"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:24:43.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2133" for this suite.

• [SLOW TEST:22.636 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":277,"completed":124,"skipped":2029,"failed":0}
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:24:43.499: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4134
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-3b49bbc0-b4b8-4180-b245-76e4978ebbcb in namespace container-probe-4134
Nov 11 21:24:48.068: INFO: Started pod liveness-3b49bbc0-b4b8-4180-b245-76e4978ebbcb in namespace container-probe-4134
STEP: checking the pod's current state and verifying that restartCount is present
Nov 11 21:24:48.070: INFO: Initial restart count of pod liveness-3b49bbc0-b4b8-4180-b245-76e4978ebbcb is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:28:48.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4134" for this suite.

• [SLOW TEST:244.890 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":277,"completed":125,"skipped":2035,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:28:48.389: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5342
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-46d7b5ad-e413-4375-8e1b-d52d87a900a3
STEP: Creating a pod to test consume secrets
Nov 11 21:28:48.967: INFO: Waiting up to 5m0s for pod "pod-secrets-76024878-586c-4bff-9bde-c9685188769a" in namespace "secrets-5342" to be "Succeeded or Failed"
Nov 11 21:28:48.969: INFO: Pod "pod-secrets-76024878-586c-4bff-9bde-c9685188769a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.746834ms
Nov 11 21:28:50.971: INFO: Pod "pod-secrets-76024878-586c-4bff-9bde-c9685188769a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003982697s
Nov 11 21:28:52.975: INFO: Pod "pod-secrets-76024878-586c-4bff-9bde-c9685188769a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008011879s
STEP: Saw pod success
Nov 11 21:28:52.975: INFO: Pod "pod-secrets-76024878-586c-4bff-9bde-c9685188769a" satisfied condition "Succeeded or Failed"
Nov 11 21:28:52.978: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-secrets-76024878-586c-4bff-9bde-c9685188769a container secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:28:53.008: INFO: Waiting for pod pod-secrets-76024878-586c-4bff-9bde-c9685188769a to disappear
Nov 11 21:28:53.013: INFO: Pod pod-secrets-76024878-586c-4bff-9bde-c9685188769a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:28:53.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5342" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":126,"skipped":2040,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:28:53.020: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8319
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:28:53.974: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:28:55.987: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726934, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726934, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726934, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740726934, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:28:58.997: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:28:58.999: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1640-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:29:00.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8319" for this suite.
STEP: Destroying namespace "webhook-8319-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.258 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":277,"completed":127,"skipped":2040,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:29:00.278: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 11 21:29:08.862: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 11 21:29:08.864: INFO: Pod pod-with-poststart-http-hook still exists
Nov 11 21:29:10.864: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 11 21:29:10.866: INFO: Pod pod-with-poststart-http-hook still exists
Nov 11 21:29:12.864: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 11 21:29:12.866: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:29:12.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4688" for this suite.

• [SLOW TEST:12.595 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":277,"completed":128,"skipped":2055,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:29:12.875: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9543
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:29:13.438: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1089b782-00b0-4739-a3d1-7feafff55708" in namespace "downward-api-9543" to be "Succeeded or Failed"
Nov 11 21:29:13.441: INFO: Pod "downwardapi-volume-1089b782-00b0-4739-a3d1-7feafff55708": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038396ms
Nov 11 21:29:15.443: INFO: Pod "downwardapi-volume-1089b782-00b0-4739-a3d1-7feafff55708": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004452482s
Nov 11 21:29:17.445: INFO: Pod "downwardapi-volume-1089b782-00b0-4739-a3d1-7feafff55708": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006766302s
STEP: Saw pod success
Nov 11 21:29:17.445: INFO: Pod "downwardapi-volume-1089b782-00b0-4739-a3d1-7feafff55708" satisfied condition "Succeeded or Failed"
Nov 11 21:29:17.447: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-1089b782-00b0-4739-a3d1-7feafff55708 container client-container: <nil>
STEP: delete the pod
Nov 11 21:29:17.458: INFO: Waiting for pod downwardapi-volume-1089b782-00b0-4739-a3d1-7feafff55708 to disappear
Nov 11 21:29:17.461: INFO: Pod downwardapi-volume-1089b782-00b0-4739-a3d1-7feafff55708 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:29:17.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9543" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":129,"skipped":2091,"failed":0}
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:29:17.468: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5313
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Nov 11 21:29:18.623: INFO: created pod pod-service-account-defaultsa
Nov 11 21:29:18.623: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 11 21:29:18.740: INFO: created pod pod-service-account-mountsa
Nov 11 21:29:18.740: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 11 21:29:18.811: INFO: created pod pod-service-account-nomountsa
Nov 11 21:29:18.811: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 11 21:29:18.860: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 11 21:29:18.860: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 11 21:29:18.998: INFO: created pod pod-service-account-mountsa-mountspec
Nov 11 21:29:18.998: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 11 21:29:19.045: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 11 21:29:19.045: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 11 21:29:19.075: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 11 21:29:19.075: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 11 21:29:19.116: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 11 21:29:19.116: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 11 21:29:19.177: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 11 21:29:19.177: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:29:19.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5313" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":277,"completed":130,"skipped":2100,"failed":0}
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:29:19.190: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:29:19.768: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 11 21:29:24.787: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 11 21:29:24.787: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Nov 11 21:29:24.905: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-8369 /apis/apps/v1/namespaces/deployment-8369/deployments/test-cleanup-deployment 02c7fc7b-5bed-4467-b662-2223752db019 16964 1 2020-11-11 21:29:24 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2020-11-11 21:29:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0045c8d18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Nov 11 21:29:24.909: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:29:24.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8369" for this suite.

• [SLOW TEST:5.737 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":277,"completed":131,"skipped":2106,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:29:24.928: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8349
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:29:25.629: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:29:26.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8349" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":277,"completed":132,"skipped":2121,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:29:26.662: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4009
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4009.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4009.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4009.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4009.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4009.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4009.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 11 21:29:31.349: INFO: DNS probes using dns-4009/dns-test-04d95449-06fa-4edd-bf9b-0d52e052af13 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:29:31.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4009" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":277,"completed":133,"skipped":2133,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:29:31.456: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8101
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 11 21:29:32.270: INFO: Waiting up to 5m0s for pod "pod-5a17c047-41a3-4895-aa06-023decb1be06" in namespace "emptydir-8101" to be "Succeeded or Failed"
Nov 11 21:29:32.276: INFO: Pod "pod-5a17c047-41a3-4895-aa06-023decb1be06": Phase="Pending", Reason="", readiness=false. Elapsed: 6.369916ms
Nov 11 21:29:34.278: INFO: Pod "pod-5a17c047-41a3-4895-aa06-023decb1be06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008580414s
STEP: Saw pod success
Nov 11 21:29:34.278: INFO: Pod "pod-5a17c047-41a3-4895-aa06-023decb1be06" satisfied condition "Succeeded or Failed"
Nov 11 21:29:34.280: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-5a17c047-41a3-4895-aa06-023decb1be06 container test-container: <nil>
STEP: delete the pod
Nov 11 21:29:34.306: INFO: Waiting for pod pod-5a17c047-41a3-4895-aa06-023decb1be06 to disappear
Nov 11 21:29:34.309: INFO: Pod pod-5a17c047-41a3-4895-aa06-023decb1be06 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:29:34.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8101" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":134,"skipped":2162,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:29:34.329: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6065
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Nov 11 21:29:34.906: INFO: Waiting up to 5m0s for pod "client-containers-678b4071-d46c-4ffc-874b-367617fbccb2" in namespace "containers-6065" to be "Succeeded or Failed"
Nov 11 21:29:34.908: INFO: Pod "client-containers-678b4071-d46c-4ffc-874b-367617fbccb2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.441308ms
Nov 11 21:29:36.911: INFO: Pod "client-containers-678b4071-d46c-4ffc-874b-367617fbccb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004998807s
Nov 11 21:29:38.914: INFO: Pod "client-containers-678b4071-d46c-4ffc-874b-367617fbccb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007886937s
STEP: Saw pod success
Nov 11 21:29:38.914: INFO: Pod "client-containers-678b4071-d46c-4ffc-874b-367617fbccb2" satisfied condition "Succeeded or Failed"
Nov 11 21:29:38.916: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod client-containers-678b4071-d46c-4ffc-874b-367617fbccb2 container test-container: <nil>
STEP: delete the pod
Nov 11 21:29:38.936: INFO: Waiting for pod client-containers-678b4071-d46c-4ffc-874b-367617fbccb2 to disappear
Nov 11 21:29:38.938: INFO: Pod client-containers-678b4071-d46c-4ffc-874b-367617fbccb2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:29:38.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6065" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":277,"completed":135,"skipped":2174,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:29:38.961: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3889
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-6a9fe1b5-b5ed-4c31-ac4b-96d2ac0cd85b
STEP: Creating secret with name s-test-opt-upd-91c94227-559f-4a06-9dcc-ef4c57e4020e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6a9fe1b5-b5ed-4c31-ac4b-96d2ac0cd85b
STEP: Updating secret s-test-opt-upd-91c94227-559f-4a06-9dcc-ef4c57e4020e
STEP: Creating secret with name s-test-opt-create-69ac5c5b-d73c-42d2-929d-08b93580bf43
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:31:11.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3889" for this suite.

• [SLOW TEST:93.032 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":136,"skipped":2179,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:31:11.993: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-6185
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 11 21:31:12.524: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 11 21:31:12.827: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 21:31:14.829: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:16.830: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:18.832: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:20.830: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:22.830: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:24.830: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:26.829: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:28.829: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:30.830: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:32.830: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 21:31:34.829: INFO: The status of Pod netserver-0 is Running (Ready = true)
Nov 11 21:31:34.833: INFO: The status of Pod netserver-1 is Running (Ready = true)
Nov 11 21:31:34.836: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Nov 11 21:31:38.876: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.211.121:8080/dial?request=hostname&protocol=udp&host=192.168.64.218&port=8081&tries=1'] Namespace:pod-network-test-6185 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:31:38.876: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:31:39.029: INFO: Waiting for responses: map[]
Nov 11 21:31:39.037: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.211.121:8080/dial?request=hostname&protocol=udp&host=192.168.211.122&port=8081&tries=1'] Namespace:pod-network-test-6185 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:31:39.037: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:31:39.155: INFO: Waiting for responses: map[]
Nov 11 21:31:39.159: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.211.121:8080/dial?request=hostname&protocol=udp&host=192.168.10.104&port=8081&tries=1'] Namespace:pod-network-test-6185 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 21:31:39.159: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:31:39.281: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:31:39.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6185" for this suite.

• [SLOW TEST:27.294 seconds]
[sig-network] Networking
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":277,"completed":137,"skipped":2201,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:31:39.288: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4267
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Nov 11 21:31:39.818: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:31:43.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4267" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":277,"completed":138,"skipped":2215,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:31:43.087: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8590
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-681f5c7b-638b-4c62-a740-b340d84cd048
STEP: Creating a pod to test consume configMaps
Nov 11 21:31:43.668: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe593eb8-047b-4ec3-ac1c-1c49914dbaf0" in namespace "configmap-8590" to be "Succeeded or Failed"
Nov 11 21:31:43.680: INFO: Pod "pod-configmaps-fe593eb8-047b-4ec3-ac1c-1c49914dbaf0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.487516ms
Nov 11 21:31:45.683: INFO: Pod "pod-configmaps-fe593eb8-047b-4ec3-ac1c-1c49914dbaf0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015326252s
Nov 11 21:31:47.685: INFO: Pod "pod-configmaps-fe593eb8-047b-4ec3-ac1c-1c49914dbaf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017504167s
STEP: Saw pod success
Nov 11 21:31:47.685: INFO: Pod "pod-configmaps-fe593eb8-047b-4ec3-ac1c-1c49914dbaf0" satisfied condition "Succeeded or Failed"
Nov 11 21:31:47.687: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-configmaps-fe593eb8-047b-4ec3-ac1c-1c49914dbaf0 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:31:47.701: INFO: Waiting for pod pod-configmaps-fe593eb8-047b-4ec3-ac1c-1c49914dbaf0 to disappear
Nov 11 21:31:47.703: INFO: Pod pod-configmaps-fe593eb8-047b-4ec3-ac1c-1c49914dbaf0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:31:47.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8590" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":139,"skipped":2239,"failed":0}
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:31:47.712: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2991
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-0e92083f-6815-412c-b9cb-819923f5c90e in namespace container-probe-2991
Nov 11 21:31:52.277: INFO: Started pod test-webserver-0e92083f-6815-412c-b9cb-819923f5c90e in namespace container-probe-2991
STEP: checking the pod's current state and verifying that restartCount is present
Nov 11 21:31:52.279: INFO: Initial restart count of pod test-webserver-0e92083f-6815-412c-b9cb-819923f5c90e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:35:52.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2991" for this suite.

• [SLOW TEST:244.891 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":140,"skipped":2241,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:35:52.604: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1315
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-30c881e5-c976-4f9c-9972-3b5c0b48737b
STEP: Creating a pod to test consume secrets
Nov 11 21:35:53.178: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-336b4ae4-c124-4e6c-bb7d-fac2667e8fd3" in namespace "projected-1315" to be "Succeeded or Failed"
Nov 11 21:35:53.180: INFO: Pod "pod-projected-secrets-336b4ae4-c124-4e6c-bb7d-fac2667e8fd3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.828342ms
Nov 11 21:35:55.183: INFO: Pod "pod-projected-secrets-336b4ae4-c124-4e6c-bb7d-fac2667e8fd3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004735202s
Nov 11 21:35:57.185: INFO: Pod "pod-projected-secrets-336b4ae4-c124-4e6c-bb7d-fac2667e8fd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007444021s
STEP: Saw pod success
Nov 11 21:35:57.185: INFO: Pod "pod-projected-secrets-336b4ae4-c124-4e6c-bb7d-fac2667e8fd3" satisfied condition "Succeeded or Failed"
Nov 11 21:35:57.188: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-secrets-336b4ae4-c124-4e6c-bb7d-fac2667e8fd3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:35:57.211: INFO: Waiting for pod pod-projected-secrets-336b4ae4-c124-4e6c-bb7d-fac2667e8fd3 to disappear
Nov 11 21:35:57.214: INFO: Pod pod-projected-secrets-336b4ae4-c124-4e6c-bb7d-fac2667e8fd3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:35:57.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1315" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":141,"skipped":2259,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:35:57.221: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1836
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-ab6e3541-57c2-482a-957c-b11a7d7dca92
STEP: Creating a pod to test consume secrets
Nov 11 21:35:57.789: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-910076d1-8fc8-45ff-83b7-5ac176fb47b9" in namespace "projected-1836" to be "Succeeded or Failed"
Nov 11 21:35:57.790: INFO: Pod "pod-projected-secrets-910076d1-8fc8-45ff-83b7-5ac176fb47b9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.816723ms
Nov 11 21:35:59.793: INFO: Pod "pod-projected-secrets-910076d1-8fc8-45ff-83b7-5ac176fb47b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004189023s
STEP: Saw pod success
Nov 11 21:35:59.793: INFO: Pod "pod-projected-secrets-910076d1-8fc8-45ff-83b7-5ac176fb47b9" satisfied condition "Succeeded or Failed"
Nov 11 21:35:59.795: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-secrets-910076d1-8fc8-45ff-83b7-5ac176fb47b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:35:59.821: INFO: Waiting for pod pod-projected-secrets-910076d1-8fc8-45ff-83b7-5ac176fb47b9 to disappear
Nov 11 21:35:59.824: INFO: Pod pod-projected-secrets-910076d1-8fc8-45ff-83b7-5ac176fb47b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:35:59.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1836" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":142,"skipped":2293,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:35:59.831: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-144
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-15840b51-20fa-408c-83d0-fa3db58e81b3 in namespace container-probe-144
Nov 11 21:36:04.400: INFO: Started pod liveness-15840b51-20fa-408c-83d0-fa3db58e81b3 in namespace container-probe-144
STEP: checking the pod's current state and verifying that restartCount is present
Nov 11 21:36:04.402: INFO: Initial restart count of pod liveness-15840b51-20fa-408c-83d0-fa3db58e81b3 is 0
Nov 11 21:36:24.428: INFO: Restart count of pod container-probe-144/liveness-15840b51-20fa-408c-83d0-fa3db58e81b3 is now 1 (20.025651544s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:36:24.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-144" for this suite.

• [SLOW TEST:24.612 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":143,"skipped":2305,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:36:24.444: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Nov 11 21:36:24.972: INFO: PodSpec: initContainers in spec.initContainers
Nov 11 21:37:07.426: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-0073f1a4-9ac4-4925-950a-249ffb53b1d4", GenerateName:"", Namespace:"init-container-7644", SelfLink:"/api/v1/namespaces/init-container-7644/pods/pod-init-0073f1a4-9ac4-4925-950a-249ffb53b1d4", UID:"abe4bc06-3093-45ad-b9ae-27a85611cfd3", ResourceVersion:"18980", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63740727384, loc:(*time.Location)(0x7b665e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"972781725"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003b68640), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003b68660)}, v1.ManagedFieldsEntry{Manager:"hyperkube", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003b68680), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003b686a0)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-27q7z", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0068c4480), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-27q7z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-27q7z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-27q7z", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0030b7808), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-0-62.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002048930), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0030b7880)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0030b78a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0030b78a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0030b78ac), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740727385, loc:(*time.Location)(0x7b665e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740727385, loc:(*time.Location)(0x7b665e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740727385, loc:(*time.Location)(0x7b665e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740727385, loc:(*time.Location)(0x7b665e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.0.62", PodIP:"192.168.211.127", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.211.127"}}, StartTime:(*v1.Time)(0xc003b686c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002048a10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002048a80)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://f170f163c06ec053afb1770358dffa08e043ca8f1a729ae9de28b6cd08aafc00", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003b68700), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003b686e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc0030b792f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:37:07.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7644" for this suite.

• [SLOW TEST:42.997 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":277,"completed":144,"skipped":2339,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:37:07.441: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 11 21:37:08.026: INFO: Waiting up to 5m0s for pod "pod-26f83ffa-b822-47d5-a2bc-d3b4e9362cb2" in namespace "emptydir-2956" to be "Succeeded or Failed"
Nov 11 21:37:08.030: INFO: Pod "pod-26f83ffa-b822-47d5-a2bc-d3b4e9362cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.241035ms
Nov 11 21:37:10.033: INFO: Pod "pod-26f83ffa-b822-47d5-a2bc-d3b4e9362cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006725293s
Nov 11 21:37:12.035: INFO: Pod "pod-26f83ffa-b822-47d5-a2bc-d3b4e9362cb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008999295s
STEP: Saw pod success
Nov 11 21:37:12.035: INFO: Pod "pod-26f83ffa-b822-47d5-a2bc-d3b4e9362cb2" satisfied condition "Succeeded or Failed"
Nov 11 21:37:12.037: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod pod-26f83ffa-b822-47d5-a2bc-d3b4e9362cb2 container test-container: <nil>
STEP: delete the pod
Nov 11 21:37:12.057: INFO: Waiting for pod pod-26f83ffa-b822-47d5-a2bc-d3b4e9362cb2 to disappear
Nov 11 21:37:12.061: INFO: Pod pod-26f83ffa-b822-47d5-a2bc-d3b4e9362cb2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:37:12.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2956" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":145,"skipped":2343,"failed":0}
S
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:37:12.067: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:37:12.599: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov 11 21:37:14.744: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:37:15.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-521" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":277,"completed":146,"skipped":2344,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:37:15.759: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-2909
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:37:16.289: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2909
I1111 21:37:16.322955      21 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2909, replica count: 1
I1111 21:37:17.373376      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1111 21:37:18.373549      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1111 21:37:19.373718      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 21:37:19.482: INFO: Created: latency-svc-qpnwk
Nov 11 21:37:19.696: INFO: Got endpoints: latency-svc-qpnwk [222.195401ms]
Nov 11 21:37:19.721: INFO: Created: latency-svc-9xcb9
Nov 11 21:37:19.746: INFO: Created: latency-svc-z8vks
Nov 11 21:37:19.752: INFO: Created: latency-svc-n7mmx
Nov 11 21:37:19.755: INFO: Created: latency-svc-l5kxp
Nov 11 21:37:19.758: INFO: Created: latency-svc-gmcl5
Nov 11 21:37:19.765: INFO: Created: latency-svc-cmnnw
Nov 11 21:37:19.774: INFO: Created: latency-svc-l44jk
Nov 11 21:37:19.810: INFO: Created: latency-svc-gckvk
Nov 11 21:37:19.834: INFO: Got endpoints: latency-svc-gmcl5 [137.471387ms]
Nov 11 21:37:19.834: INFO: Got endpoints: latency-svc-z8vks [137.947058ms]
Nov 11 21:37:19.834: INFO: Got endpoints: latency-svc-9xcb9 [137.976726ms]
Nov 11 21:37:19.846: INFO: Got endpoints: latency-svc-l5kxp [150.252944ms]
Nov 11 21:37:19.846: INFO: Got endpoints: latency-svc-n7mmx [150.097011ms]
Nov 11 21:37:19.848: INFO: Created: latency-svc-njh5q
Nov 11 21:37:19.863: INFO: Created: latency-svc-rxnr8
Nov 11 21:37:19.869: INFO: Got endpoints: latency-svc-cmnnw [172.454421ms]
Nov 11 21:37:19.879: INFO: Created: latency-svc-fs8kp
Nov 11 21:37:19.879: INFO: Created: latency-svc-6ttfp
Nov 11 21:37:19.908: INFO: Created: latency-svc-dz9cp
Nov 11 21:37:19.952: INFO: Created: latency-svc-bb82r
Nov 11 21:37:19.988: INFO: Created: latency-svc-7jlqh
Nov 11 21:37:20.006: INFO: Got endpoints: latency-svc-l44jk [308.797752ms]
Nov 11 21:37:20.006: INFO: Got endpoints: latency-svc-rxnr8 [308.970092ms]
Nov 11 21:37:20.006: INFO: Got endpoints: latency-svc-njh5q [308.707891ms]
Nov 11 21:37:20.006: INFO: Got endpoints: latency-svc-gckvk [309.637896ms]
Nov 11 21:37:20.039: INFO: Got endpoints: latency-svc-fs8kp [341.330787ms]
Nov 11 21:37:20.069: INFO: Got endpoints: latency-svc-bb82r [372.298937ms]
Nov 11 21:37:20.073: INFO: Created: latency-svc-2csdl
Nov 11 21:37:20.079: INFO: Got endpoints: latency-svc-dz9cp [381.129807ms]
Nov 11 21:37:20.117: INFO: Created: latency-svc-wzz4l
Nov 11 21:37:20.134: INFO: Got endpoints: latency-svc-6ttfp [437.151797ms]
Nov 11 21:37:20.151: INFO: Created: latency-svc-7v8zd
Nov 11 21:37:20.170: INFO: Created: latency-svc-x6fdw
Nov 11 21:37:20.178: INFO: Created: latency-svc-qjtpm
Nov 11 21:37:20.209: INFO: Created: latency-svc-gnhqd
Nov 11 21:37:20.226: INFO: Created: latency-svc-cjrr6
Nov 11 21:37:20.239: INFO: Created: latency-svc-t7859
Nov 11 21:37:20.249: INFO: Created: latency-svc-rr8kv
Nov 11 21:37:20.262: INFO: Created: latency-svc-xkxlc
Nov 11 21:37:20.284: INFO: Created: latency-svc-9hk8b
Nov 11 21:37:20.297: INFO: Created: latency-svc-2xjpl
Nov 11 21:37:20.307: INFO: Created: latency-svc-798lw
Nov 11 21:37:20.313: INFO: Created: latency-svc-qlkbv
Nov 11 21:37:20.327: INFO: Got endpoints: latency-svc-7jlqh [629.835785ms]
Nov 11 21:37:20.378: INFO: Got endpoints: latency-svc-2csdl [543.702525ms]
Nov 11 21:37:20.393: INFO: Got endpoints: latency-svc-x6fdw [546.749807ms]
Nov 11 21:37:20.407: INFO: Created: latency-svc-pkpgw
Nov 11 21:37:20.438: INFO: Got endpoints: latency-svc-wzz4l [603.923572ms]
Nov 11 21:37:20.453: INFO: Got endpoints: latency-svc-7v8zd [618.620731ms]
Nov 11 21:37:20.484: INFO: Created: latency-svc-7r6gc
Nov 11 21:37:20.495: INFO: Created: latency-svc-vgkvb
Nov 11 21:37:20.539: INFO: Got endpoints: latency-svc-gnhqd [669.665306ms]
Nov 11 21:37:20.566: INFO: Created: latency-svc-2k5sv
Nov 11 21:37:20.591: INFO: Got endpoints: latency-svc-rr8kv [584.959343ms]
Nov 11 21:37:20.591: INFO: Got endpoints: latency-svc-t7859 [584.445611ms]
Nov 11 21:37:20.591: INFO: Got endpoints: latency-svc-cjrr6 [584.794039ms]
Nov 11 21:37:20.598: INFO: Got endpoints: latency-svc-qjtpm [752.004301ms]
Nov 11 21:37:20.628: INFO: Created: latency-svc-kmgm2
Nov 11 21:37:20.636: INFO: Got endpoints: latency-svc-xkxlc [629.577836ms]
Nov 11 21:37:20.665: INFO: Got endpoints: latency-svc-798lw [585.735183ms]
Nov 11 21:37:20.677: INFO: Created: latency-svc-2znv4
Nov 11 21:37:20.701: INFO: Created: latency-svc-dzf5k
Nov 11 21:37:20.711: INFO: Got endpoints: latency-svc-qlkbv [576.492063ms]
Nov 11 21:37:20.731: INFO: Got endpoints: latency-svc-9hk8b [692.248961ms]
Nov 11 21:37:20.733: INFO: Got endpoints: latency-svc-pkpgw [406.19604ms]
Nov 11 21:37:20.733: INFO: Got endpoints: latency-svc-2xjpl [664.02581ms]
Nov 11 21:37:20.749: INFO: Created: latency-svc-72g78
Nov 11 21:37:20.759: INFO: Got endpoints: latency-svc-7r6gc [380.98172ms]
Nov 11 21:37:20.759: INFO: Got endpoints: latency-svc-vgkvb [365.977723ms]
Nov 11 21:37:20.769: INFO: Created: latency-svc-mt7zb
Nov 11 21:37:20.797: INFO: Created: latency-svc-xfmhp
Nov 11 21:37:20.821: INFO: Created: latency-svc-bldj8
Nov 11 21:37:20.822: INFO: Got endpoints: latency-svc-kmgm2 [383.834286ms]
Nov 11 21:37:20.844: INFO: Got endpoints: latency-svc-2k5sv [391.001776ms]
Nov 11 21:37:20.857: INFO: Got endpoints: latency-svc-2znv4 [317.765008ms]
Nov 11 21:37:20.857: INFO: Got endpoints: latency-svc-72g78 [266.011603ms]
Nov 11 21:37:20.882: INFO: Created: latency-svc-47t5g
Nov 11 21:37:20.882: INFO: Got endpoints: latency-svc-dzf5k [283.714519ms]
Nov 11 21:37:20.895: INFO: Created: latency-svc-bgvkx
Nov 11 21:37:20.929: INFO: Created: latency-svc-6lwtg
Nov 11 21:37:20.955: INFO: Created: latency-svc-597kd
Nov 11 21:37:21.002: INFO: Got endpoints: latency-svc-mt7zb [411.001389ms]
Nov 11 21:37:21.002: INFO: Got endpoints: latency-svc-xfmhp [271.17941ms]
Nov 11 21:37:21.070: INFO: Got endpoints: latency-svc-47t5g [478.872141ms]
Nov 11 21:37:21.070: INFO: Got endpoints: latency-svc-bgvkx [405.774417ms]
Nov 11 21:37:21.176: INFO: Got endpoints: latency-svc-597kd [442.295862ms]
Nov 11 21:37:21.176: INFO: Got endpoints: latency-svc-6lwtg [465.094056ms]
Nov 11 21:37:21.176: INFO: Got endpoints: latency-svc-bldj8 [442.293323ms]
Nov 11 21:37:21.179: INFO: Created: latency-svc-ljz9j
Nov 11 21:37:21.203: INFO: Created: latency-svc-8lsxj
Nov 11 21:37:21.238: INFO: Created: latency-svc-c4wmf
Nov 11 21:37:21.283: INFO: Created: latency-svc-s89r9
Nov 11 21:37:21.295: INFO: Created: latency-svc-b5knz
Nov 11 21:37:21.310: INFO: Created: latency-svc-5fb62
Nov 11 21:37:21.348: INFO: Got endpoints: latency-svc-8lsxj [588.638613ms]
Nov 11 21:37:21.349: INFO: Created: latency-svc-z7pxj
Nov 11 21:37:21.407: INFO: Got endpoints: latency-svc-b5knz [550.660337ms]
Nov 11 21:37:21.420: INFO: Created: latency-svc-fxzz2
Nov 11 21:37:21.425: INFO: Got endpoints: latency-svc-ljz9j [788.637804ms]
Nov 11 21:37:21.425: INFO: Got endpoints: latency-svc-c4wmf [666.027401ms]
Nov 11 21:37:21.443: INFO: Got endpoints: latency-svc-s89r9 [585.6867ms]
Nov 11 21:37:21.449: INFO: Created: latency-svc-k5mgg
Nov 11 21:37:21.460: INFO: Created: latency-svc-pd6qb
Nov 11 21:37:21.475: INFO: Created: latency-svc-ck6hs
Nov 11 21:37:21.494: INFO: Created: latency-svc-glsbm
Nov 11 21:37:21.517: INFO: Created: latency-svc-vrvrv
Nov 11 21:37:21.527: INFO: Created: latency-svc-5qfnz
Nov 11 21:37:21.535: INFO: Got endpoints: latency-svc-5fb62 [712.718108ms]
Nov 11 21:37:21.540: INFO: Created: latency-svc-2mmvk
Nov 11 21:37:21.555: INFO: Got endpoints: latency-svc-fxzz2 [672.399904ms]
Nov 11 21:37:21.561: INFO: Got endpoints: latency-svc-z7pxj [717.531607ms]
Nov 11 21:37:21.571: INFO: Created: latency-svc-qc27l
Nov 11 21:37:21.590: INFO: Got endpoints: latency-svc-pd6qb [182.166254ms]
Nov 11 21:37:21.590: INFO: Got endpoints: latency-svc-k5mgg [587.433927ms]
Nov 11 21:37:21.592: INFO: Created: latency-svc-zjwrs
Nov 11 21:37:21.606: INFO: Created: latency-svc-zfs79
Nov 11 21:37:21.619: INFO: Got endpoints: latency-svc-glsbm [548.621556ms]
Nov 11 21:37:21.623: INFO: Got endpoints: latency-svc-ck6hs [620.455812ms]
Nov 11 21:37:21.639: INFO: Created: latency-svc-7lcrq
Nov 11 21:37:21.668: INFO: Created: latency-svc-mxh7g
Nov 11 21:37:21.695: INFO: Created: latency-svc-7dlpj
Nov 11 21:37:21.727: INFO: Created: latency-svc-6zhp8
Nov 11 21:37:21.736: INFO: Got endpoints: latency-svc-zjwrs [388.203975ms]
Nov 11 21:37:21.736: INFO: Got endpoints: latency-svc-5qfnz [560.212398ms]
Nov 11 21:37:21.736: INFO: Got endpoints: latency-svc-vrvrv [665.867966ms]
Nov 11 21:37:21.748: INFO: Got endpoints: latency-svc-qc27l [571.728181ms]
Nov 11 21:37:21.748: INFO: Got endpoints: latency-svc-2mmvk [572.232818ms]
Nov 11 21:37:21.781: INFO: Got endpoints: latency-svc-zfs79 [355.953622ms]
Nov 11 21:37:21.781: INFO: Got endpoints: latency-svc-7lcrq [355.770574ms]
Nov 11 21:37:21.793: INFO: Got endpoints: latency-svc-mxh7g [350.43659ms]
Nov 11 21:37:21.819: INFO: Created: latency-svc-rhd2r
Nov 11 21:37:21.837: INFO: Got endpoints: latency-svc-7dlpj [301.583776ms]
Nov 11 21:37:21.875: INFO: Created: latency-svc-f7dtt
Nov 11 21:37:21.887: INFO: Created: latency-svc-vntzc
Nov 11 21:37:21.897: INFO: Created: latency-svc-mvtrq
Nov 11 21:37:21.905: INFO: Created: latency-svc-jz9vz
Nov 11 21:37:21.925: INFO: Created: latency-svc-fqvzn
Nov 11 21:37:21.944: INFO: Created: latency-svc-znwrs
Nov 11 21:37:21.965: INFO: Created: latency-svc-vkp5q
Nov 11 21:37:21.976: INFO: Got endpoints: latency-svc-rhd2r [414.150765ms]
Nov 11 21:37:21.976: INFO: Got endpoints: latency-svc-6zhp8 [420.756608ms]
Nov 11 21:37:21.997: INFO: Got endpoints: latency-svc-vntzc [407.578103ms]
Nov 11 21:37:21.998: INFO: Got endpoints: latency-svc-f7dtt [407.834586ms]
Nov 11 21:37:22.012: INFO: Got endpoints: latency-svc-jz9vz [389.252509ms]
Nov 11 21:37:22.012: INFO: Got endpoints: latency-svc-mvtrq [393.131854ms]
Nov 11 21:37:22.033: INFO: Got endpoints: latency-svc-fqvzn [296.388296ms]
Nov 11 21:37:22.039: INFO: Created: latency-svc-w7g5j
Nov 11 21:37:22.044: INFO: Created: latency-svc-kpd9w
Nov 11 21:37:22.050: INFO: Created: latency-svc-5f5nv
Nov 11 21:37:22.057: INFO: Created: latency-svc-bx26x
Nov 11 21:37:22.099: INFO: Created: latency-svc-nhvjs
Nov 11 21:37:22.100: INFO: Created: latency-svc-tdzg7
Nov 11 21:37:22.105: INFO: Got endpoints: latency-svc-vkp5q [368.524409ms]
Nov 11 21:37:22.105: INFO: Got endpoints: latency-svc-w7g5j [357.284733ms]
Nov 11 21:37:22.125: INFO: Created: latency-svc-j8vff
Nov 11 21:37:22.152: INFO: Got endpoints: latency-svc-znwrs [415.528141ms]
Nov 11 21:37:22.152: INFO: Created: latency-svc-l2bjm
Nov 11 21:37:22.159: INFO: Got endpoints: latency-svc-kpd9w [411.208459ms]
Nov 11 21:37:22.165: INFO: Got endpoints: latency-svc-5f5nv [384.228821ms]
Nov 11 21:37:22.177: INFO: Created: latency-svc-5q7qx
Nov 11 21:37:22.185: INFO: Created: latency-svc-whqvs
Nov 11 21:37:22.202: INFO: Got endpoints: latency-svc-bx26x [408.865119ms]
Nov 11 21:37:22.205: INFO: Created: latency-svc-j4dzf
Nov 11 21:37:22.205: INFO: Created: latency-svc-mz6q7
Nov 11 21:37:22.239: INFO: Created: latency-svc-hc2kp
Nov 11 21:37:22.240: INFO: Got endpoints: latency-svc-tdzg7 [459.25252ms]
Nov 11 21:37:22.250: INFO: Created: latency-svc-5mbvb
Nov 11 21:37:22.267: INFO: Created: latency-svc-v8957
Nov 11 21:37:22.267: INFO: Created: latency-svc-bpln2
Nov 11 21:37:22.274: INFO: Created: latency-svc-xmkq6
Nov 11 21:37:22.295: INFO: Created: latency-svc-2rqvr
Nov 11 21:37:22.295: INFO: Got endpoints: latency-svc-nhvjs [458.770434ms]
Nov 11 21:37:22.302: INFO: Created: latency-svc-wpd2r
Nov 11 21:37:22.380: INFO: Created: latency-svc-dd9l8
Nov 11 21:37:22.435: INFO: Created: latency-svc-49s9z
Nov 11 21:37:22.457: INFO: Got endpoints: latency-svc-j8vff [480.967108ms]
Nov 11 21:37:22.479: INFO: Got endpoints: latency-svc-l2bjm [502.993026ms]
Nov 11 21:37:22.492: INFO: Got endpoints: latency-svc-5q7qx [494.425182ms]
Nov 11 21:37:22.525: INFO: Got endpoints: latency-svc-whqvs [527.084655ms]
Nov 11 21:37:22.539: INFO: Created: latency-svc-22k2v
Nov 11 21:37:22.553: INFO: Got endpoints: latency-svc-j4dzf [540.306624ms]
Nov 11 21:37:22.563: INFO: Created: latency-svc-t5zbl
Nov 11 21:37:22.585: INFO: Created: latency-svc-h6v75
Nov 11 21:37:22.602: INFO: Created: latency-svc-zzm6j
Nov 11 21:37:22.620: INFO: Created: latency-svc-htz8h
Nov 11 21:37:22.621: INFO: Got endpoints: latency-svc-mz6q7 [587.941405ms]
Nov 11 21:37:22.637: INFO: Got endpoints: latency-svc-hc2kp [624.415062ms]
Nov 11 21:37:22.670: INFO: Created: latency-svc-jd9sg
Nov 11 21:37:22.703: INFO: Created: latency-svc-4cqvk
Nov 11 21:37:22.717: INFO: Got endpoints: latency-svc-5mbvb [611.881154ms]
Nov 11 21:37:22.796: INFO: Got endpoints: latency-svc-v8957 [690.882833ms]
Nov 11 21:37:22.830: INFO: Got endpoints: latency-svc-bpln2 [677.915919ms]
Nov 11 21:37:22.902: INFO: Created: latency-svc-lncmx
Nov 11 21:37:22.907: INFO: Got endpoints: latency-svc-xmkq6 [747.55255ms]
Nov 11 21:37:22.941: INFO: Created: latency-svc-r5x2h
Nov 11 21:37:22.977: INFO: Created: latency-svc-jswfh
Nov 11 21:37:23.041: INFO: Got endpoints: latency-svc-wpd2r [839.044151ms]
Nov 11 21:37:23.041: INFO: Got endpoints: latency-svc-dd9l8 [801.27642ms]
Nov 11 21:37:23.041: INFO: Got endpoints: latency-svc-2rqvr [876.132908ms]
Nov 11 21:37:23.052: INFO: Created: latency-svc-dqqgp
Nov 11 21:37:23.067: INFO: Got endpoints: latency-svc-49s9z [771.528276ms]
Nov 11 21:37:23.117: INFO: Got endpoints: latency-svc-22k2v [637.860662ms]
Nov 11 21:37:23.178: INFO: Got endpoints: latency-svc-t5zbl [720.979828ms]
Nov 11 21:37:23.180: INFO: Created: latency-svc-f7ld2
Nov 11 21:37:23.200: INFO: Created: latency-svc-tjxsw
Nov 11 21:37:23.209: INFO: Created: latency-svc-rngph
Nov 11 21:37:23.256: INFO: Created: latency-svc-kvnhn
Nov 11 21:37:23.269: INFO: Got endpoints: latency-svc-zzm6j [744.233139ms]
Nov 11 21:37:23.269: INFO: Got endpoints: latency-svc-h6v75 [777.491241ms]
Nov 11 21:37:23.291: INFO: Created: latency-svc-wzb8t
Nov 11 21:37:23.308: INFO: Created: latency-svc-p4thw
Nov 11 21:37:23.329: INFO: Got endpoints: latency-svc-htz8h [776.003159ms]
Nov 11 21:37:23.332: INFO: Created: latency-svc-hnl4t
Nov 11 21:37:23.342: INFO: Created: latency-svc-wkr45
Nov 11 21:37:23.402: INFO: Got endpoints: latency-svc-jd9sg [781.158705ms]
Nov 11 21:37:23.447: INFO: Got endpoints: latency-svc-4cqvk [810.694852ms]
Nov 11 21:37:23.450: INFO: Created: latency-svc-9h5zn
Nov 11 21:37:23.481: INFO: Got endpoints: latency-svc-lncmx [763.391289ms]
Nov 11 21:37:23.487: INFO: Created: latency-svc-whhw6
Nov 11 21:37:23.513: INFO: Got endpoints: latency-svc-r5x2h [716.184608ms]
Nov 11 21:37:23.541: INFO: Created: latency-svc-5fgxd
Nov 11 21:37:23.567: INFO: Created: latency-svc-pbqnr
Nov 11 21:37:23.574: INFO: Got endpoints: latency-svc-jswfh [744.225823ms]
Nov 11 21:37:23.585: INFO: Created: latency-svc-8zcvb
Nov 11 21:37:23.616: INFO: Got endpoints: latency-svc-dqqgp [709.067641ms]
Nov 11 21:37:23.639: INFO: Created: latency-svc-k7ftp
Nov 11 21:37:23.645: INFO: Got endpoints: latency-svc-f7ld2 [603.550988ms]
Nov 11 21:37:23.672: INFO: Created: latency-svc-kqg4z
Nov 11 21:37:23.698: INFO: Created: latency-svc-czzj5
Nov 11 21:37:23.702: INFO: Got endpoints: latency-svc-tjxsw [660.324666ms]
Nov 11 21:37:23.755: INFO: Created: latency-svc-cw4sk
Nov 11 21:37:23.849: INFO: Got endpoints: latency-svc-kvnhn [807.590714ms]
Nov 11 21:37:23.862: INFO: Got endpoints: latency-svc-rngph [795.234548ms]
Nov 11 21:37:23.900: INFO: Got endpoints: latency-svc-wzb8t [721.864924ms]
Nov 11 21:37:23.931: INFO: Created: latency-svc-tvmt9
Nov 11 21:37:23.932: INFO: Got endpoints: latency-svc-p4thw [814.815474ms]
Nov 11 21:37:23.987: INFO: Created: latency-svc-wntv5
Nov 11 21:37:23.987: INFO: Got endpoints: latency-svc-hnl4t [718.185569ms]
Nov 11 21:37:23.987: INFO: Created: latency-svc-xxq7d
Nov 11 21:37:24.013: INFO: Created: latency-svc-stgh6
Nov 11 21:37:24.017: INFO: Got endpoints: latency-svc-wkr45 [747.169587ms]
Nov 11 21:37:24.028: INFO: Created: latency-svc-vw9fb
Nov 11 21:37:24.054: INFO: Got endpoints: latency-svc-9h5zn [725.779879ms]
Nov 11 21:37:24.062: INFO: Created: latency-svc-fxc89
Nov 11 21:37:24.072: INFO: Created: latency-svc-zm7sf
Nov 11 21:37:24.094: INFO: Got endpoints: latency-svc-whhw6 [691.71711ms]
Nov 11 21:37:24.117: INFO: Created: latency-svc-rp9b2
Nov 11 21:37:24.143: INFO: Got endpoints: latency-svc-5fgxd [695.471929ms]
Nov 11 21:37:24.163: INFO: Created: latency-svc-79wkc
Nov 11 21:37:24.191: INFO: Got endpoints: latency-svc-pbqnr [709.914313ms]
Nov 11 21:37:24.220: INFO: Created: latency-svc-8n8qx
Nov 11 21:37:24.233: INFO: Got endpoints: latency-svc-8zcvb [720.622586ms]
Nov 11 21:37:24.263: INFO: Created: latency-svc-7vdjk
Nov 11 21:37:24.288: INFO: Got endpoints: latency-svc-k7ftp [713.510879ms]
Nov 11 21:37:24.320: INFO: Created: latency-svc-8cw58
Nov 11 21:37:24.338: INFO: Got endpoints: latency-svc-kqg4z [721.924271ms]
Nov 11 21:37:24.359: INFO: Created: latency-svc-l2rqf
Nov 11 21:37:24.392: INFO: Got endpoints: latency-svc-czzj5 [746.914244ms]
Nov 11 21:37:24.473: INFO: Got endpoints: latency-svc-cw4sk [771.162058ms]
Nov 11 21:37:24.506: INFO: Created: latency-svc-2khtk
Nov 11 21:37:24.509: INFO: Got endpoints: latency-svc-tvmt9 [660.02985ms]
Nov 11 21:37:24.518: INFO: Created: latency-svc-48fj6
Nov 11 21:37:24.523: INFO: Created: latency-svc-l68dq
Nov 11 21:37:24.532: INFO: Got endpoints: latency-svc-xxq7d [632.225374ms]
Nov 11 21:37:24.545: INFO: Created: latency-svc-d6lsh
Nov 11 21:37:24.597: INFO: Got endpoints: latency-svc-wntv5 [734.249855ms]
Nov 11 21:37:24.611: INFO: Created: latency-svc-fpqr8
Nov 11 21:37:24.636: INFO: Got endpoints: latency-svc-stgh6 [704.571074ms]
Nov 11 21:37:24.648: INFO: Created: latency-svc-8kwwp
Nov 11 21:37:24.685: INFO: Got endpoints: latency-svc-vw9fb [697.718091ms]
Nov 11 21:37:24.697: INFO: Created: latency-svc-trzs5
Nov 11 21:37:24.735: INFO: Got endpoints: latency-svc-fxc89 [718.384735ms]
Nov 11 21:37:24.748: INFO: Created: latency-svc-pphp8
Nov 11 21:37:24.783: INFO: Got endpoints: latency-svc-zm7sf [728.105756ms]
Nov 11 21:37:24.793: INFO: Created: latency-svc-9rxjk
Nov 11 21:37:24.831: INFO: Got endpoints: latency-svc-rp9b2 [736.591654ms]
Nov 11 21:37:24.843: INFO: Created: latency-svc-kx4jd
Nov 11 21:37:24.885: INFO: Got endpoints: latency-svc-79wkc [741.442253ms]
Nov 11 21:37:24.895: INFO: Created: latency-svc-rfxgq
Nov 11 21:37:24.932: INFO: Got endpoints: latency-svc-8n8qx [741.26213ms]
Nov 11 21:37:24.945: INFO: Created: latency-svc-tkvsc
Nov 11 21:37:24.982: INFO: Got endpoints: latency-svc-7vdjk [748.472235ms]
Nov 11 21:37:25.000: INFO: Created: latency-svc-ds2r2
Nov 11 21:37:25.038: INFO: Got endpoints: latency-svc-8cw58 [750.457072ms]
Nov 11 21:37:25.049: INFO: Created: latency-svc-w2zz7
Nov 11 21:37:25.097: INFO: Got endpoints: latency-svc-l2rqf [759.140397ms]
Nov 11 21:37:25.112: INFO: Created: latency-svc-qjftx
Nov 11 21:37:25.133: INFO: Got endpoints: latency-svc-2khtk [741.139261ms]
Nov 11 21:37:25.155: INFO: Created: latency-svc-zlx6p
Nov 11 21:37:25.188: INFO: Got endpoints: latency-svc-48fj6 [714.593536ms]
Nov 11 21:37:25.210: INFO: Created: latency-svc-dnf7l
Nov 11 21:37:25.233: INFO: Got endpoints: latency-svc-l68dq [724.228314ms]
Nov 11 21:37:25.262: INFO: Created: latency-svc-v5wg8
Nov 11 21:37:25.294: INFO: Got endpoints: latency-svc-d6lsh [761.752403ms]
Nov 11 21:37:25.387: INFO: Created: latency-svc-b696z
Nov 11 21:37:25.406: INFO: Got endpoints: latency-svc-fpqr8 [809.626419ms]
Nov 11 21:37:25.420: INFO: Got endpoints: latency-svc-8kwwp [783.768583ms]
Nov 11 21:37:25.446: INFO: Got endpoints: latency-svc-trzs5 [760.224445ms]
Nov 11 21:37:25.452: INFO: Created: latency-svc-slvls
Nov 11 21:37:25.456: INFO: Created: latency-svc-dq87v
Nov 11 21:37:25.460: INFO: Created: latency-svc-q5jlh
Nov 11 21:37:25.494: INFO: Got endpoints: latency-svc-pphp8 [758.546616ms]
Nov 11 21:37:25.512: INFO: Created: latency-svc-75kbh
Nov 11 21:37:25.538: INFO: Got endpoints: latency-svc-9rxjk [754.943209ms]
Nov 11 21:37:25.554: INFO: Created: latency-svc-t6ghb
Nov 11 21:37:25.582: INFO: Got endpoints: latency-svc-kx4jd [751.533845ms]
Nov 11 21:37:25.598: INFO: Created: latency-svc-pfdfm
Nov 11 21:37:25.631: INFO: Got endpoints: latency-svc-rfxgq [746.46589ms]
Nov 11 21:37:25.649: INFO: Created: latency-svc-bzzb7
Nov 11 21:37:25.684: INFO: Got endpoints: latency-svc-tkvsc [751.369345ms]
Nov 11 21:37:25.698: INFO: Created: latency-svc-4vpvn
Nov 11 21:37:25.730: INFO: Got endpoints: latency-svc-ds2r2 [747.657265ms]
Nov 11 21:37:25.745: INFO: Created: latency-svc-cxdwk
Nov 11 21:37:25.779: INFO: Got endpoints: latency-svc-w2zz7 [740.767454ms]
Nov 11 21:37:25.789: INFO: Created: latency-svc-dxf7h
Nov 11 21:37:25.830: INFO: Got endpoints: latency-svc-qjftx [732.983927ms]
Nov 11 21:37:25.907: INFO: Created: latency-svc-x84w6
Nov 11 21:37:25.919: INFO: Got endpoints: latency-svc-zlx6p [786.564122ms]
Nov 11 21:37:25.936: INFO: Got endpoints: latency-svc-dnf7l [748.675217ms]
Nov 11 21:37:25.941: INFO: Created: latency-svc-7rpr6
Nov 11 21:37:25.951: INFO: Created: latency-svc-nj9hq
Nov 11 21:37:25.985: INFO: Got endpoints: latency-svc-v5wg8 [751.428271ms]
Nov 11 21:37:25.999: INFO: Created: latency-svc-5h59c
Nov 11 21:37:26.041: INFO: Got endpoints: latency-svc-b696z [745.627484ms]
Nov 11 21:37:26.060: INFO: Created: latency-svc-56cd6
Nov 11 21:37:26.089: INFO: Got endpoints: latency-svc-dq87v [682.914744ms]
Nov 11 21:37:26.098: INFO: Created: latency-svc-7k8sr
Nov 11 21:37:26.134: INFO: Got endpoints: latency-svc-slvls [713.461847ms]
Nov 11 21:37:26.155: INFO: Created: latency-svc-npnr9
Nov 11 21:37:26.185: INFO: Got endpoints: latency-svc-q5jlh [739.542032ms]
Nov 11 21:37:26.195: INFO: Created: latency-svc-g4vgv
Nov 11 21:37:26.232: INFO: Got endpoints: latency-svc-75kbh [738.049176ms]
Nov 11 21:37:26.261: INFO: Created: latency-svc-bptt2
Nov 11 21:37:26.285: INFO: Got endpoints: latency-svc-t6ghb [747.712907ms]
Nov 11 21:37:26.293: INFO: Created: latency-svc-8lzd6
Nov 11 21:37:26.330: INFO: Got endpoints: latency-svc-pfdfm [747.669174ms]
Nov 11 21:37:26.369: INFO: Created: latency-svc-cl695
Nov 11 21:37:26.380: INFO: Got endpoints: latency-svc-bzzb7 [749.155821ms]
Nov 11 21:37:26.397: INFO: Created: latency-svc-zhwd2
Nov 11 21:37:26.433: INFO: Got endpoints: latency-svc-4vpvn [749.698918ms]
Nov 11 21:37:26.444: INFO: Created: latency-svc-m9bmb
Nov 11 21:37:26.483: INFO: Got endpoints: latency-svc-cxdwk [753.54962ms]
Nov 11 21:37:26.497: INFO: Created: latency-svc-hvmcz
Nov 11 21:37:26.531: INFO: Got endpoints: latency-svc-dxf7h [751.56805ms]
Nov 11 21:37:26.540: INFO: Created: latency-svc-xt6wb
Nov 11 21:37:26.586: INFO: Got endpoints: latency-svc-x84w6 [755.503436ms]
Nov 11 21:37:26.602: INFO: Created: latency-svc-c4nsn
Nov 11 21:37:26.638: INFO: Got endpoints: latency-svc-7rpr6 [718.805941ms]
Nov 11 21:37:26.656: INFO: Created: latency-svc-f6xzx
Nov 11 21:37:26.696: INFO: Got endpoints: latency-svc-nj9hq [759.208105ms]
Nov 11 21:37:26.717: INFO: Created: latency-svc-tnvns
Nov 11 21:37:26.733: INFO: Got endpoints: latency-svc-5h59c [747.884397ms]
Nov 11 21:37:26.745: INFO: Created: latency-svc-bjn5d
Nov 11 21:37:26.782: INFO: Got endpoints: latency-svc-56cd6 [741.142551ms]
Nov 11 21:37:26.795: INFO: Created: latency-svc-r7g5n
Nov 11 21:37:26.851: INFO: Got endpoints: latency-svc-7k8sr [762.255046ms]
Nov 11 21:37:26.874: INFO: Created: latency-svc-jwngp
Nov 11 21:37:26.905: INFO: Got endpoints: latency-svc-npnr9 [771.59798ms]
Nov 11 21:37:26.924: INFO: Created: latency-svc-j57lx
Nov 11 21:37:26.948: INFO: Got endpoints: latency-svc-g4vgv [762.595613ms]
Nov 11 21:37:26.968: INFO: Created: latency-svc-4l95k
Nov 11 21:37:26.986: INFO: Got endpoints: latency-svc-bptt2 [754.092546ms]
Nov 11 21:37:27.003: INFO: Created: latency-svc-b4tn9
Nov 11 21:37:27.033: INFO: Got endpoints: latency-svc-8lzd6 [746.998495ms]
Nov 11 21:37:27.051: INFO: Created: latency-svc-2jcmz
Nov 11 21:37:27.084: INFO: Got endpoints: latency-svc-cl695 [754.325998ms]
Nov 11 21:37:27.111: INFO: Created: latency-svc-wcqp8
Nov 11 21:37:27.142: INFO: Got endpoints: latency-svc-zhwd2 [761.337312ms]
Nov 11 21:37:27.160: INFO: Created: latency-svc-clr7r
Nov 11 21:37:27.189: INFO: Got endpoints: latency-svc-m9bmb [755.075052ms]
Nov 11 21:37:27.211: INFO: Created: latency-svc-2fssx
Nov 11 21:37:27.229: INFO: Got endpoints: latency-svc-hvmcz [745.614586ms]
Nov 11 21:37:27.261: INFO: Created: latency-svc-hhbgv
Nov 11 21:37:27.281: INFO: Got endpoints: latency-svc-xt6wb [750.129729ms]
Nov 11 21:37:27.324: INFO: Created: latency-svc-c87q2
Nov 11 21:37:27.353: INFO: Got endpoints: latency-svc-c4nsn [766.856088ms]
Nov 11 21:37:27.382: INFO: Created: latency-svc-t22v8
Nov 11 21:37:27.389: INFO: Got endpoints: latency-svc-f6xzx [750.110887ms]
Nov 11 21:37:27.399: INFO: Created: latency-svc-rs2dk
Nov 11 21:37:27.461: INFO: Got endpoints: latency-svc-tnvns [765.315397ms]
Nov 11 21:37:27.478: INFO: Created: latency-svc-kzkdd
Nov 11 21:37:27.499: INFO: Got endpoints: latency-svc-bjn5d [766.674372ms]
Nov 11 21:37:27.529: INFO: Created: latency-svc-2x2mj
Nov 11 21:37:27.545: INFO: Got endpoints: latency-svc-r7g5n [762.84909ms]
Nov 11 21:37:27.569: INFO: Created: latency-svc-pcrql
Nov 11 21:37:27.587: INFO: Got endpoints: latency-svc-jwngp [735.548517ms]
Nov 11 21:37:27.654: INFO: Got endpoints: latency-svc-j57lx [748.798537ms]
Nov 11 21:37:27.684: INFO: Got endpoints: latency-svc-4l95k [735.854128ms]
Nov 11 21:37:27.737: INFO: Got endpoints: latency-svc-b4tn9 [750.991144ms]
Nov 11 21:37:27.786: INFO: Got endpoints: latency-svc-2jcmz [753.884587ms]
Nov 11 21:37:27.842: INFO: Got endpoints: latency-svc-wcqp8 [757.624651ms]
Nov 11 21:37:27.885: INFO: Got endpoints: latency-svc-clr7r [742.991136ms]
Nov 11 21:37:27.934: INFO: Got endpoints: latency-svc-2fssx [745.763937ms]
Nov 11 21:37:27.984: INFO: Got endpoints: latency-svc-hhbgv [754.852364ms]
Nov 11 21:37:28.031: INFO: Got endpoints: latency-svc-c87q2 [749.674453ms]
Nov 11 21:37:28.079: INFO: Got endpoints: latency-svc-t22v8 [726.066155ms]
Nov 11 21:37:28.131: INFO: Got endpoints: latency-svc-rs2dk [742.277959ms]
Nov 11 21:37:28.182: INFO: Got endpoints: latency-svc-kzkdd [720.915174ms]
Nov 11 21:37:28.231: INFO: Got endpoints: latency-svc-2x2mj [731.143239ms]
Nov 11 21:37:28.285: INFO: Got endpoints: latency-svc-pcrql [739.965513ms]
Nov 11 21:37:28.285: INFO: Latencies: [137.471387ms 137.947058ms 137.976726ms 150.097011ms 150.252944ms 172.454421ms 182.166254ms 266.011603ms 271.17941ms 283.714519ms 296.388296ms 301.583776ms 308.707891ms 308.797752ms 308.970092ms 309.637896ms 317.765008ms 341.330787ms 350.43659ms 355.770574ms 355.953622ms 357.284733ms 365.977723ms 368.524409ms 372.298937ms 380.98172ms 381.129807ms 383.834286ms 384.228821ms 388.203975ms 389.252509ms 391.001776ms 393.131854ms 405.774417ms 406.19604ms 407.578103ms 407.834586ms 408.865119ms 411.001389ms 411.208459ms 414.150765ms 415.528141ms 420.756608ms 437.151797ms 442.293323ms 442.295862ms 458.770434ms 459.25252ms 465.094056ms 478.872141ms 480.967108ms 494.425182ms 502.993026ms 527.084655ms 540.306624ms 543.702525ms 546.749807ms 548.621556ms 550.660337ms 560.212398ms 571.728181ms 572.232818ms 576.492063ms 584.445611ms 584.794039ms 584.959343ms 585.6867ms 585.735183ms 587.433927ms 587.941405ms 588.638613ms 603.550988ms 603.923572ms 611.881154ms 618.620731ms 620.455812ms 624.415062ms 629.577836ms 629.835785ms 632.225374ms 637.860662ms 660.02985ms 660.324666ms 664.02581ms 665.867966ms 666.027401ms 669.665306ms 672.399904ms 677.915919ms 682.914744ms 690.882833ms 691.71711ms 692.248961ms 695.471929ms 697.718091ms 704.571074ms 709.067641ms 709.914313ms 712.718108ms 713.461847ms 713.510879ms 714.593536ms 716.184608ms 717.531607ms 718.185569ms 718.384735ms 718.805941ms 720.622586ms 720.915174ms 720.979828ms 721.864924ms 721.924271ms 724.228314ms 725.779879ms 726.066155ms 728.105756ms 731.143239ms 732.983927ms 734.249855ms 735.548517ms 735.854128ms 736.591654ms 738.049176ms 739.542032ms 739.965513ms 740.767454ms 741.139261ms 741.142551ms 741.26213ms 741.442253ms 742.277959ms 742.991136ms 744.225823ms 744.233139ms 745.614586ms 745.627484ms 745.763937ms 746.46589ms 746.914244ms 746.998495ms 747.169587ms 747.55255ms 747.657265ms 747.669174ms 747.712907ms 747.884397ms 748.472235ms 748.675217ms 748.798537ms 749.155821ms 749.674453ms 749.698918ms 750.110887ms 750.129729ms 750.457072ms 750.991144ms 751.369345ms 751.428271ms 751.533845ms 751.56805ms 752.004301ms 753.54962ms 753.884587ms 754.092546ms 754.325998ms 754.852364ms 754.943209ms 755.075052ms 755.503436ms 757.624651ms 758.546616ms 759.140397ms 759.208105ms 760.224445ms 761.337312ms 761.752403ms 762.255046ms 762.595613ms 762.84909ms 763.391289ms 765.315397ms 766.674372ms 766.856088ms 771.162058ms 771.528276ms 771.59798ms 776.003159ms 777.491241ms 781.158705ms 783.768583ms 786.564122ms 788.637804ms 795.234548ms 801.27642ms 807.590714ms 809.626419ms 810.694852ms 814.815474ms 839.044151ms 876.132908ms]
Nov 11 21:37:28.285: INFO: 50 %ile: 713.510879ms
Nov 11 21:37:28.285: INFO: 90 %ile: 765.315397ms
Nov 11 21:37:28.286: INFO: 99 %ile: 839.044151ms
Nov 11 21:37:28.286: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:37:28.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2909" for this suite.

• [SLOW TEST:12.542 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":277,"completed":147,"skipped":2359,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:37:28.302: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3412
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3412 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3412;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3412 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3412;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3412.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3412.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3412.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3412.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3412.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3412.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3412.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3412.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3412.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3412.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3412.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3412.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3412.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 166.106.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.106.166_udp@PTR;check="$$(dig +tcp +noall +answer +search 166.106.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.106.166_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3412 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3412;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3412 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3412;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3412.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3412.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3412.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3412.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3412.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3412.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3412.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3412.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3412.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3412.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3412.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3412.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3412.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 166.106.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.106.166_udp@PTR;check="$$(dig +tcp +noall +answer +search 166.106.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.106.166_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 11 21:37:30.889: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.892: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.894: INFO: Unable to read wheezy_udp@dns-test-service.dns-3412 from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.897: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3412 from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.899: INFO: Unable to read wheezy_udp@dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.902: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.904: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.906: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.909: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.911: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.913: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.916: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.923: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.925: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.928: INFO: Unable to read jessie_udp@dns-test-service.dns-3412 from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.930: INFO: Unable to read jessie_tcp@dns-test-service.dns-3412 from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.932: INFO: Unable to read jessie_udp@dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.935: INFO: Unable to read jessie_tcp@dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.938: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.960: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:30.988: INFO: Lookups using dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3412 wheezy_tcp@dns-test-service.dns-3412 wheezy_udp@dns-test-service.dns-3412.svc wheezy_tcp@dns-test-service.dns-3412.svc wheezy_udp@_http._tcp.dns-test-service.dns-3412.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3412.svc wheezy_udp@_http._tcp.test-service-2.dns-3412.svc wheezy_tcp@_http._tcp.test-service-2.dns-3412.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3412 jessie_tcp@dns-test-service.dns-3412 jessie_udp@dns-test-service.dns-3412.svc jessie_tcp@dns-test-service.dns-3412.svc jessie_udp@_http._tcp.dns-test-service.dns-3412.svc jessie_tcp@_http._tcp.dns-test-service.dns-3412.svc]

Nov 11 21:37:36.098: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:36.107: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:36.130: INFO: Unable to read jessie_tcp@dns-test-service.dns-3412 from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:36.149: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:36.155: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3412.svc from pod dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235: the server could not find the requested resource (get pods dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235)
Nov 11 21:37:36.192: INFO: Lookups using dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_tcp@dns-test-service.dns-3412 jessie_udp@_http._tcp.dns-test-service.dns-3412.svc jessie_tcp@_http._tcp.dns-test-service.dns-3412.svc]

Nov 11 21:37:41.197: INFO: DNS probes using dns-3412/dns-test-eb3026aa-ca32-4c5a-8d3a-f855fc0ad235 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:37:41.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3412" for this suite.

• [SLOW TEST:13.079 seconds]
[sig-network] DNS
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":277,"completed":148,"skipped":2409,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:37:41.383: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3634
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Nov 11 21:37:42.089: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:38:02.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3634" for this suite.

• [SLOW TEST:20.713 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":277,"completed":149,"skipped":2421,"failed":0}
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:38:02.096: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2039
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:38:02.660: INFO: Waiting up to 5m0s for pod "downwardapi-volume-589ea5c7-ac26-47c5-a0fe-4866a67ef851" in namespace "downward-api-2039" to be "Succeeded or Failed"
Nov 11 21:38:02.661: INFO: Pod "downwardapi-volume-589ea5c7-ac26-47c5-a0fe-4866a67ef851": Phase="Pending", Reason="", readiness=false. Elapsed: 1.847996ms
Nov 11 21:38:04.665: INFO: Pod "downwardapi-volume-589ea5c7-ac26-47c5-a0fe-4866a67ef851": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005541705s
Nov 11 21:38:06.668: INFO: Pod "downwardapi-volume-589ea5c7-ac26-47c5-a0fe-4866a67ef851": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00801469s
STEP: Saw pod success
Nov 11 21:38:06.668: INFO: Pod "downwardapi-volume-589ea5c7-ac26-47c5-a0fe-4866a67ef851" satisfied condition "Succeeded or Failed"
Nov 11 21:38:06.670: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-589ea5c7-ac26-47c5-a0fe-4866a67ef851 container client-container: <nil>
STEP: delete the pod
Nov 11 21:38:06.684: INFO: Waiting for pod downwardapi-volume-589ea5c7-ac26-47c5-a0fe-4866a67ef851 to disappear
Nov 11 21:38:06.687: INFO: Pod downwardapi-volume-589ea5c7-ac26-47c5-a0fe-4866a67ef851 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:38:06.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2039" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":150,"skipped":2421,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:38:06.694: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3630
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 11 21:38:11.320: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 11 21:38:11.322: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 11 21:38:13.322: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 11 21:38:13.329: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 11 21:38:15.322: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 11 21:38:15.326: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:38:15.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3630" for this suite.

• [SLOW TEST:8.645 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":277,"completed":151,"skipped":2444,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:38:15.340: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Nov 11 21:38:15.877: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 11 21:38:15.892: INFO: Waiting for terminating namespaces to be deleted...
Nov 11 21:38:15.894: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-166.us-west-2.compute.internal before test
Nov 11 21:38:15.910: INFO: calico-node-vdd82 from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:38:15.910: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:38:15.910: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:38:15.910: INFO: ucp-nvidia-device-plugin-749cm from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:38:15.910: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:38:15.910: INFO: sonobuoy-e2e-job-9a557cfe0d894233 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:38:15.910: INFO: 	Container e2e ready: true, restart count 0
Nov 11 21:38:15.910: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:38:15.910: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-g728j from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:38:15.910: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:38:15.910: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:38:15.910: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-62.us-west-2.compute.internal before test
Nov 11 21:38:15.915: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-wkssd from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:38:15.915: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:38:15.915: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:38:15.915: INFO: calico-node-7npjl from kube-system started at 2020-11-11 20:42:41 +0000 UTC (2 container statuses recorded)
Nov 11 21:38:15.915: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:38:15.915: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:38:15.915: INFO: ucp-nvidia-device-plugin-rwkzr from kube-system started at 2020-11-11 20:42:41 +0000 UTC (1 container statuses recorded)
Nov 11 21:38:15.915: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:38:15.915: INFO: pod-handle-http-request from container-lifecycle-hook-3630 started at 2020-11-11 21:38:07 +0000 UTC (1 container statuses recorded)
Nov 11 21:38:15.915: INFO: 	Container pod-handle-http-request ready: true, restart count 0
Nov 11 21:38:15.915: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-177.us-west-2.compute.internal before test
Nov 11 21:38:15.924: INFO: ucp-nvidia-device-plugin-nsr8m from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:38:15.924: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:38:15.924: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-9pcd4 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:38:15.924: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:38:15.924: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:38:15.924: INFO: calico-node-ppmtk from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:38:15.924: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:38:15.924: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:38:15.924: INFO: sonobuoy from sonobuoy started at 2020-11-11 20:59:16 +0000 UTC (1 container statuses recorded)
Nov 11 21:38:15.924: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-bde0061a-cd7b-46b7-b0c9-0cb035722545 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-bde0061a-cd7b-46b7-b0c9-0cb035722545 off the node ip-172-31-1-177.us-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-bde0061a-cd7b-46b7-b0c9-0cb035722545
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:38:32.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-463" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:16.839 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":277,"completed":152,"skipped":2485,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:38:32.179: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-757
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 11 21:38:32.750: INFO: Waiting up to 5m0s for pod "pod-853dcf23-8305-49ac-8356-fceabea70438" in namespace "emptydir-757" to be "Succeeded or Failed"
Nov 11 21:38:32.753: INFO: Pod "pod-853dcf23-8305-49ac-8356-fceabea70438": Phase="Pending", Reason="", readiness=false. Elapsed: 2.818958ms
Nov 11 21:38:34.755: INFO: Pod "pod-853dcf23-8305-49ac-8356-fceabea70438": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005002895s
Nov 11 21:38:36.757: INFO: Pod "pod-853dcf23-8305-49ac-8356-fceabea70438": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006808192s
STEP: Saw pod success
Nov 11 21:38:36.757: INFO: Pod "pod-853dcf23-8305-49ac-8356-fceabea70438" satisfied condition "Succeeded or Failed"
Nov 11 21:38:36.758: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-853dcf23-8305-49ac-8356-fceabea70438 container test-container: <nil>
STEP: delete the pod
Nov 11 21:38:36.769: INFO: Waiting for pod pod-853dcf23-8305-49ac-8356-fceabea70438 to disappear
Nov 11 21:38:36.772: INFO: Pod pod-853dcf23-8305-49ac-8356-fceabea70438 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:38:36.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-757" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":153,"skipped":2488,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:38:36.780: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6708
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-d6a492f7-c36d-4d86-a5c5-ba056f720ac4
STEP: Creating a pod to test consume configMaps
Nov 11 21:38:37.350: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9dc6db9-2a90-4f31-b557-ed3793ffce94" in namespace "projected-6708" to be "Succeeded or Failed"
Nov 11 21:38:37.352: INFO: Pod "pod-projected-configmaps-c9dc6db9-2a90-4f31-b557-ed3793ffce94": Phase="Pending", Reason="", readiness=false. Elapsed: 1.943429ms
Nov 11 21:38:39.354: INFO: Pod "pod-projected-configmaps-c9dc6db9-2a90-4f31-b557-ed3793ffce94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004038985s
STEP: Saw pod success
Nov 11 21:38:39.354: INFO: Pod "pod-projected-configmaps-c9dc6db9-2a90-4f31-b557-ed3793ffce94" satisfied condition "Succeeded or Failed"
Nov 11 21:38:39.355: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-configmaps-c9dc6db9-2a90-4f31-b557-ed3793ffce94 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:38:39.367: INFO: Waiting for pod pod-projected-configmaps-c9dc6db9-2a90-4f31-b557-ed3793ffce94 to disappear
Nov 11 21:38:39.370: INFO: Pod pod-projected-configmaps-c9dc6db9-2a90-4f31-b557-ed3793ffce94 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:38:39.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6708" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":154,"skipped":2522,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:38:39.383: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9304
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov 11 21:38:40.342: INFO: Pod name wrapped-volume-race-20f4a7ad-6658-4f59-b8c0-9c0037d0be97: Found 0 pods out of 5
Nov 11 21:38:45.352: INFO: Pod name wrapped-volume-race-20f4a7ad-6658-4f59-b8c0-9c0037d0be97: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-20f4a7ad-6658-4f59-b8c0-9c0037d0be97 in namespace emptydir-wrapper-9304, will wait for the garbage collector to delete the pods
Nov 11 21:38:57.445: INFO: Deleting ReplicationController wrapped-volume-race-20f4a7ad-6658-4f59-b8c0-9c0037d0be97 took: 23.506363ms
Nov 11 21:38:58.145: INFO: Terminating ReplicationController wrapped-volume-race-20f4a7ad-6658-4f59-b8c0-9c0037d0be97 pods took: 700.157728ms
STEP: Creating RC which spawns configmap-volume pods
Nov 11 21:39:10.993: INFO: Pod name wrapped-volume-race-7a3a195a-9f04-4ee3-b325-01e424eaad5d: Found 0 pods out of 5
Nov 11 21:39:15.998: INFO: Pod name wrapped-volume-race-7a3a195a-9f04-4ee3-b325-01e424eaad5d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7a3a195a-9f04-4ee3-b325-01e424eaad5d in namespace emptydir-wrapper-9304, will wait for the garbage collector to delete the pods
Nov 11 21:39:28.074: INFO: Deleting ReplicationController wrapped-volume-race-7a3a195a-9f04-4ee3-b325-01e424eaad5d took: 4.516334ms
Nov 11 21:39:28.874: INFO: Terminating ReplicationController wrapped-volume-race-7a3a195a-9f04-4ee3-b325-01e424eaad5d pods took: 800.159241ms
STEP: Creating RC which spawns configmap-volume pods
Nov 11 21:39:40.931: INFO: Pod name wrapped-volume-race-10b7dd21-90cc-4e77-afed-75cfbfe1ad12: Found 0 pods out of 5
Nov 11 21:39:45.936: INFO: Pod name wrapped-volume-race-10b7dd21-90cc-4e77-afed-75cfbfe1ad12: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-10b7dd21-90cc-4e77-afed-75cfbfe1ad12 in namespace emptydir-wrapper-9304, will wait for the garbage collector to delete the pods
Nov 11 21:39:58.026: INFO: Deleting ReplicationController wrapped-volume-race-10b7dd21-90cc-4e77-afed-75cfbfe1ad12 took: 6.689452ms
Nov 11 21:39:58.727: INFO: Terminating ReplicationController wrapped-volume-race-10b7dd21-90cc-4e77-afed-75cfbfe1ad12 pods took: 700.660119ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:40:08.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9304" for this suite.

• [SLOW TEST:89.142 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":277,"completed":155,"skipped":2535,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:40:08.525: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8046
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-8046
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Nov 11 21:40:09.110: INFO: Found 0 stateful pods, waiting for 3
Nov 11 21:40:19.113: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 21:40:19.113: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 21:40:19.113: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 21:40:19.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-8046 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 21:40:19.498: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 21:40:19.498: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 21:40:19.498: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov 11 21:40:29.549: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov 11 21:40:39.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-8046 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 21:40:39.767: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 21:40:39.767: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 21:40:39.767: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 21:40:49.778: INFO: Waiting for StatefulSet statefulset-8046/ss2 to complete update
Nov 11 21:40:49.778: INFO: Waiting for Pod statefulset-8046/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 11 21:40:49.778: INFO: Waiting for Pod statefulset-8046/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 11 21:40:59.783: INFO: Waiting for StatefulSet statefulset-8046/ss2 to complete update
Nov 11 21:40:59.783: INFO: Waiting for Pod statefulset-8046/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 11 21:41:09.783: INFO: Waiting for StatefulSet statefulset-8046/ss2 to complete update
STEP: Rolling back to a previous revision
Nov 11 21:41:19.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-8046 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 21:41:19.990: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 21:41:19.990: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 21:41:19.990: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 21:41:30.047: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov 11 21:41:40.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-8046 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 21:41:40.262: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 21:41:40.262: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 21:41:40.262: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 21:41:50.274: INFO: Waiting for StatefulSet statefulset-8046/ss2 to complete update
Nov 11 21:41:50.274: INFO: Waiting for Pod statefulset-8046/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov 11 21:41:50.274: INFO: Waiting for Pod statefulset-8046/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov 11 21:42:00.279: INFO: Waiting for StatefulSet statefulset-8046/ss2 to complete update
Nov 11 21:42:00.279: INFO: Waiting for Pod statefulset-8046/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Nov 11 21:42:10.279: INFO: Deleting all statefulset in ns statefulset-8046
Nov 11 21:42:10.281: INFO: Scaling statefulset ss2 to 0
Nov 11 21:42:20.317: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 21:42:20.319: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:42:20.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8046" for this suite.

• [SLOW TEST:131.812 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":277,"completed":156,"skipped":2546,"failed":0}
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:42:20.338: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:42:20.957: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf24275f-8c89-4410-864b-61a4934f83e8" in namespace "downward-api-5432" to be "Succeeded or Failed"
Nov 11 21:42:20.959: INFO: Pod "downwardapi-volume-bf24275f-8c89-4410-864b-61a4934f83e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074717ms
Nov 11 21:42:22.962: INFO: Pod "downwardapi-volume-bf24275f-8c89-4410-864b-61a4934f83e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004419342s
Nov 11 21:42:24.964: INFO: Pod "downwardapi-volume-bf24275f-8c89-4410-864b-61a4934f83e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007008261s
STEP: Saw pod success
Nov 11 21:42:24.964: INFO: Pod "downwardapi-volume-bf24275f-8c89-4410-864b-61a4934f83e8" satisfied condition "Succeeded or Failed"
Nov 11 21:42:24.966: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-bf24275f-8c89-4410-864b-61a4934f83e8 container client-container: <nil>
STEP: delete the pod
Nov 11 21:42:24.985: INFO: Waiting for pod downwardapi-volume-bf24275f-8c89-4410-864b-61a4934f83e8 to disappear
Nov 11 21:42:24.987: INFO: Pod downwardapi-volume-bf24275f-8c89-4410-864b-61a4934f83e8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:42:24.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5432" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":157,"skipped":2546,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:42:24.995: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:42:25.688: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov 11 21:42:25.796: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:25.798: INFO: Number of nodes with available pods: 0
Nov 11 21:42:25.798: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:42:26.805: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:26.809: INFO: Number of nodes with available pods: 0
Nov 11 21:42:26.809: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:42:27.802: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:27.804: INFO: Number of nodes with available pods: 2
Nov 11 21:42:27.804: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:42:28.803: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:28.807: INFO: Number of nodes with available pods: 3
Nov 11 21:42:28.807: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov 11 21:42:28.888: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:28.888: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:28.888: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:28.891: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:29.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:29.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:29.894: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:29.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:30.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:30.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:30.894: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:30.894: INFO: Pod daemon-set-qszd6 is not available
Nov 11 21:42:30.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:31.895: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:31.895: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:31.895: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:31.895: INFO: Pod daemon-set-qszd6 is not available
Nov 11 21:42:31.899: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:32.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:32.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:32.894: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:32.894: INFO: Pod daemon-set-qszd6 is not available
Nov 11 21:42:32.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:33.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:33.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:33.894: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:33.894: INFO: Pod daemon-set-qszd6 is not available
Nov 11 21:42:33.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:34.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:34.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:34.894: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:34.894: INFO: Pod daemon-set-qszd6 is not available
Nov 11 21:42:34.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:35.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:35.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:35.894: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:35.894: INFO: Pod daemon-set-qszd6 is not available
Nov 11 21:42:35.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:36.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:36.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:36.894: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:36.894: INFO: Pod daemon-set-qszd6 is not available
Nov 11 21:42:36.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:37.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:37.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:37.894: INFO: Wrong image for pod: daemon-set-qszd6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:37.894: INFO: Pod daemon-set-qszd6 is not available
Nov 11 21:42:37.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:38.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:38.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:38.894: INFO: Pod daemon-set-vf54m is not available
Nov 11 21:42:38.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:39.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:39.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:39.894: INFO: Pod daemon-set-vf54m is not available
Nov 11 21:42:39.898: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:40.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:40.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:40.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:41.894: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:41.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:41.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:42.893: INFO: Wrong image for pod: daemon-set-m92nm. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:42.893: INFO: Pod daemon-set-m92nm is not available
Nov 11 21:42:42.893: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:42.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:43.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:43.894: INFO: Pod daemon-set-qx5lk is not available
Nov 11 21:42:43.901: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:44.893: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:44.893: INFO: Pod daemon-set-qx5lk is not available
Nov 11 21:42:44.898: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:45.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:45.898: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:46.896: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:46.899: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:47.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:47.894: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:47.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:48.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:48.894: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:48.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:49.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:49.894: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:49.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:50.895: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:50.895: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:50.898: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:51.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:51.894: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:51.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:52.893: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:52.893: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:52.896: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:53.897: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:53.897: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:53.901: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:54.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:54.894: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:54.898: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:55.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:55.894: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:55.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:56.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:56.894: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:56.898: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:57.894: INFO: Wrong image for pod: daemon-set-nxm2v. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Nov 11 21:42:57.894: INFO: Pod daemon-set-nxm2v is not available
Nov 11 21:42:57.898: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:58.893: INFO: Pod daemon-set-jfc6j is not available
Nov 11 21:42:58.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:59.894: INFO: Pod daemon-set-jfc6j is not available
Nov 11 21:42:59.897: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Nov 11 21:42:59.900: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:42:59.902: INFO: Number of nodes with available pods: 2
Nov 11 21:42:59.902: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:43:00.906: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:00.908: INFO: Number of nodes with available pods: 2
Nov 11 21:43:00.908: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:43:01.906: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:01.908: INFO: Number of nodes with available pods: 3
Nov 11 21:43:01.908: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5785, will wait for the garbage collector to delete the pods
Nov 11 21:43:01.974: INFO: Deleting DaemonSet.extensions daemon-set took: 5.421017ms
Nov 11 21:43:02.875: INFO: Terminating DaemonSet.extensions daemon-set pods took: 900.162011ms
Nov 11 21:43:05.277: INFO: Number of nodes with available pods: 0
Nov 11 21:43:05.277: INFO: Number of running nodes: 0, number of available pods: 0
Nov 11 21:43:05.278: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5785/daemonsets","resourceVersion":"23829"},"items":null}

Nov 11 21:43:05.280: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5785/pods","resourceVersion":"23829"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:43:05.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5785" for this suite.

• [SLOW TEST:40.300 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":277,"completed":158,"skipped":2579,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:43:05.296: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4237
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-1936c0d7-e8c9-4ab2-9316-80e1676eba92
STEP: Creating a pod to test consume secrets
Nov 11 21:43:05.875: INFO: Waiting up to 5m0s for pod "pod-secrets-810e0803-2225-4a28-a80f-7939935a6427" in namespace "secrets-4237" to be "Succeeded or Failed"
Nov 11 21:43:05.877: INFO: Pod "pod-secrets-810e0803-2225-4a28-a80f-7939935a6427": Phase="Pending", Reason="", readiness=false. Elapsed: 1.865134ms
Nov 11 21:43:07.879: INFO: Pod "pod-secrets-810e0803-2225-4a28-a80f-7939935a6427": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004074901s
Nov 11 21:43:09.881: INFO: Pod "pod-secrets-810e0803-2225-4a28-a80f-7939935a6427": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006227969s
STEP: Saw pod success
Nov 11 21:43:09.881: INFO: Pod "pod-secrets-810e0803-2225-4a28-a80f-7939935a6427" satisfied condition "Succeeded or Failed"
Nov 11 21:43:09.883: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-secrets-810e0803-2225-4a28-a80f-7939935a6427 container secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:43:09.899: INFO: Waiting for pod pod-secrets-810e0803-2225-4a28-a80f-7939935a6427 to disappear
Nov 11 21:43:09.902: INFO: Pod pod-secrets-810e0803-2225-4a28-a80f-7939935a6427 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:43:09.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4237" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":159,"skipped":2596,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:43:09.909: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:43:10.448: INFO: Creating ReplicaSet my-hostname-basic-5b77da79-27d7-4c92-9a07-75a9d66b7795
Nov 11 21:43:10.481: INFO: Pod name my-hostname-basic-5b77da79-27d7-4c92-9a07-75a9d66b7795: Found 0 pods out of 1
Nov 11 21:43:15.486: INFO: Pod name my-hostname-basic-5b77da79-27d7-4c92-9a07-75a9d66b7795: Found 1 pods out of 1
Nov 11 21:43:15.486: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-5b77da79-27d7-4c92-9a07-75a9d66b7795" is running
Nov 11 21:43:15.489: INFO: Pod "my-hostname-basic-5b77da79-27d7-4c92-9a07-75a9d66b7795-lpzxg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-11 21:43:11 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-11 21:43:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-11 21:43:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-11 21:43:10 +0000 UTC Reason: Message:}])
Nov 11 21:43:15.489: INFO: Trying to dial the pod
Nov 11 21:43:20.495: INFO: Controller my-hostname-basic-5b77da79-27d7-4c92-9a07-75a9d66b7795: Got expected result from replica 1 [my-hostname-basic-5b77da79-27d7-4c92-9a07-75a9d66b7795-lpzxg]: "my-hostname-basic-5b77da79-27d7-4c92-9a07-75a9d66b7795-lpzxg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:43:20.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5297" for this suite.

• [SLOW TEST:10.592 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":160,"skipped":2615,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:43:20.502: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-9b3ef2ee-f2de-4229-9c11-315c29b2d96b
STEP: Creating a pod to test consume configMaps
Nov 11 21:43:21.074: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2c5a85d2-a00a-49fb-8063-284ed548d4a8" in namespace "projected-8447" to be "Succeeded or Failed"
Nov 11 21:43:21.077: INFO: Pod "pod-projected-configmaps-2c5a85d2-a00a-49fb-8063-284ed548d4a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.314073ms
Nov 11 21:43:23.079: INFO: Pod "pod-projected-configmaps-2c5a85d2-a00a-49fb-8063-284ed548d4a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005104719s
Nov 11 21:43:25.082: INFO: Pod "pod-projected-configmaps-2c5a85d2-a00a-49fb-8063-284ed548d4a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007494762s
STEP: Saw pod success
Nov 11 21:43:25.082: INFO: Pod "pod-projected-configmaps-2c5a85d2-a00a-49fb-8063-284ed548d4a8" satisfied condition "Succeeded or Failed"
Nov 11 21:43:25.084: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod pod-projected-configmaps-2c5a85d2-a00a-49fb-8063-284ed548d4a8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:43:25.105: INFO: Waiting for pod pod-projected-configmaps-2c5a85d2-a00a-49fb-8063-284ed548d4a8 to disappear
Nov 11 21:43:25.108: INFO: Pod pod-projected-configmaps-2c5a85d2-a00a-49fb-8063-284ed548d4a8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:43:25.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8447" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":161,"skipped":2623,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:43:25.115: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7244
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:43:25.663: INFO: Create a RollingUpdate DaemonSet
Nov 11 21:43:25.693: INFO: Check that daemon pods launch on every node of the cluster
Nov 11 21:43:25.696: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:25.697: INFO: Number of nodes with available pods: 0
Nov 11 21:43:25.697: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:43:26.702: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:26.704: INFO: Number of nodes with available pods: 0
Nov 11 21:43:26.704: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:43:27.701: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:27.705: INFO: Number of nodes with available pods: 1
Nov 11 21:43:27.705: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:43:28.701: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:28.703: INFO: Number of nodes with available pods: 3
Nov 11 21:43:28.703: INFO: Number of running nodes: 3, number of available pods: 3
Nov 11 21:43:28.703: INFO: Update the DaemonSet to trigger a rollout
Nov 11 21:43:28.736: INFO: Updating DaemonSet daemon-set
Nov 11 21:43:31.748: INFO: Roll back the DaemonSet before rollout is complete
Nov 11 21:43:31.899: INFO: Updating DaemonSet daemon-set
Nov 11 21:43:31.899: INFO: Make sure DaemonSet rollback is complete
Nov 11 21:43:31.902: INFO: Wrong image for pod: daemon-set-2cnzm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 11 21:43:31.902: INFO: Pod daemon-set-2cnzm is not available
Nov 11 21:43:31.905: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:32.907: INFO: Wrong image for pod: daemon-set-2cnzm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 11 21:43:32.907: INFO: Pod daemon-set-2cnzm is not available
Nov 11 21:43:32.910: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:33.908: INFO: Wrong image for pod: daemon-set-2cnzm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 11 21:43:33.908: INFO: Pod daemon-set-2cnzm is not available
Nov 11 21:43:33.911: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:34.907: INFO: Wrong image for pod: daemon-set-2cnzm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 11 21:43:34.907: INFO: Pod daemon-set-2cnzm is not available
Nov 11 21:43:34.910: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:35.908: INFO: Wrong image for pod: daemon-set-2cnzm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 11 21:43:35.908: INFO: Pod daemon-set-2cnzm is not available
Nov 11 21:43:35.912: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:36.908: INFO: Wrong image for pod: daemon-set-2cnzm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 11 21:43:36.908: INFO: Pod daemon-set-2cnzm is not available
Nov 11 21:43:36.916: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:37.907: INFO: Wrong image for pod: daemon-set-2cnzm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 11 21:43:37.907: INFO: Pod daemon-set-2cnzm is not available
Nov 11 21:43:37.910: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:38.907: INFO: Pod daemon-set-rsqlg is not available
Nov 11 21:43:38.910: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 21:43:39.907: INFO: Pod daemon-set-rsqlg is not available
Nov 11 21:43:39.911: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7244, will wait for the garbage collector to delete the pods
Nov 11 21:43:39.971: INFO: Deleting DaemonSet.extensions daemon-set took: 4.728877ms
Nov 11 21:43:40.872: INFO: Terminating DaemonSet.extensions daemon-set pods took: 900.370472ms
Nov 11 21:43:48.674: INFO: Number of nodes with available pods: 0
Nov 11 21:43:48.674: INFO: Number of running nodes: 0, number of available pods: 0
Nov 11 21:43:48.675: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7244/daemonsets","resourceVersion":"24237"},"items":null}

Nov 11 21:43:48.677: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7244/pods","resourceVersion":"24237"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:43:48.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7244" for this suite.

• [SLOW TEST:23.576 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":277,"completed":162,"skipped":2634,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:43:48.692: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3114
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-3157
STEP: Creating secret with name secret-test-b5d3585b-08d1-44b1-ab43-452975a6064d
STEP: Creating a pod to test consume secrets
Nov 11 21:43:49.797: INFO: Waiting up to 5m0s for pod "pod-secrets-30d94c2d-6f53-4a9f-8471-c12129e8f421" in namespace "secrets-3114" to be "Succeeded or Failed"
Nov 11 21:43:49.799: INFO: Pod "pod-secrets-30d94c2d-6f53-4a9f-8471-c12129e8f421": Phase="Pending", Reason="", readiness=false. Elapsed: 1.973265ms
Nov 11 21:43:51.801: INFO: Pod "pod-secrets-30d94c2d-6f53-4a9f-8471-c12129e8f421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003852635s
Nov 11 21:43:53.803: INFO: Pod "pod-secrets-30d94c2d-6f53-4a9f-8471-c12129e8f421": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006110167s
STEP: Saw pod success
Nov 11 21:43:53.803: INFO: Pod "pod-secrets-30d94c2d-6f53-4a9f-8471-c12129e8f421" satisfied condition "Succeeded or Failed"
Nov 11 21:43:53.805: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-secrets-30d94c2d-6f53-4a9f-8471-c12129e8f421 container secret-volume-test: <nil>
STEP: delete the pod
Nov 11 21:43:53.816: INFO: Waiting for pod pod-secrets-30d94c2d-6f53-4a9f-8471-c12129e8f421 to disappear
Nov 11 21:43:53.819: INFO: Pod pod-secrets-30d94c2d-6f53-4a9f-8471-c12129e8f421 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:43:53.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3114" for this suite.
STEP: Destroying namespace "secret-namespace-3157" for this suite.

• [SLOW TEST:5.138 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":277,"completed":163,"skipped":2652,"failed":0}
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:43:53.831: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5148
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 11 21:43:58.565: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 21:43:58.568: INFO: Pod pod-with-prestop-http-hook still exists
Nov 11 21:44:00.568: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 21:44:00.571: INFO: Pod pod-with-prestop-http-hook still exists
Nov 11 21:44:02.568: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 21:44:02.573: INFO: Pod pod-with-prestop-http-hook still exists
Nov 11 21:44:04.568: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 21:44:04.571: INFO: Pod pod-with-prestop-http-hook still exists
Nov 11 21:44:06.568: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 21:44:06.571: INFO: Pod pod-with-prestop-http-hook still exists
Nov 11 21:44:08.568: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 21:44:08.571: INFO: Pod pod-with-prestop-http-hook still exists
Nov 11 21:44:10.568: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 21:44:10.571: INFO: Pod pod-with-prestop-http-hook still exists
Nov 11 21:44:12.568: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 21:44:12.571: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:44:12.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5148" for this suite.

• [SLOW TEST:18.769 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":277,"completed":164,"skipped":2655,"failed":0}
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:44:12.600: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-5101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Nov 11 21:44:13.233: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-5101" to be "Succeeded or Failed"
Nov 11 21:44:13.235: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.33134ms
Nov 11 21:44:15.238: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004636322s
Nov 11 21:44:17.240: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00710843s
STEP: Saw pod success
Nov 11 21:44:17.240: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Nov 11 21:44:17.242: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov 11 21:44:17.253: INFO: Waiting for pod pod-host-path-test to disappear
Nov 11 21:44:17.256: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:44:17.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-5101" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":165,"skipped":2658,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:44:17.265: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1306
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov 11 21:44:19.916: INFO: &Pod{ObjectMeta:{send-events-c5f6577c-ac8b-4d5a-be05-9ebfccbbb2fd  events-1306 /api/v1/namespaces/events-1306/pods/send-events-c5f6577c-ac8b-4d5a-be05-9ebfccbbb2fd 204c682e-5520-43db-a15f-1adec129d359 24515 0 2020-11-11 21:44:17 +0000 UTC <nil> <nil> map[name:foo time:794149768] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2020-11-11 21:44:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 21:44:19 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 50 49 49 46 57 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xg5s7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xg5s7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xg5s7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 21:44:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 21:44:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 21:44:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 21:44:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:192.168.211.95,StartTime:2020-11-11 21:44:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 21:44:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://e3d6a625f7531331840df84f879954534bcb7e7e92d04b5177fbc1c6bbe2f40c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.211.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Nov 11 21:44:21.925: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov 11 21:44:23.928: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:44:23.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1306" for this suite.

• [SLOW TEST:6.681 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":277,"completed":166,"skipped":2668,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:44:23.947: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6309
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Nov 11 21:44:29.044: INFO: Successfully updated pod "annotationupdate41d478f7-8a7b-45ac-831e-dfd273df2b73"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:44:31.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6309" for this suite.

• [SLOW TEST:7.116 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":167,"skipped":2698,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:44:31.064: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6354
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-l72m
STEP: Creating a pod to test atomic-volume-subpath
Nov 11 21:44:31.633: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-l72m" in namespace "subpath-6354" to be "Succeeded or Failed"
Nov 11 21:44:31.635: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.000071ms
Nov 11 21:44:33.637: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004143729s
Nov 11 21:44:35.642: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 4.008441285s
Nov 11 21:44:37.644: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 6.011005701s
Nov 11 21:44:39.647: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 8.013328191s
Nov 11 21:44:41.649: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 10.015656024s
Nov 11 21:44:43.652: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 12.018471331s
Nov 11 21:44:45.654: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 14.020811052s
Nov 11 21:44:47.656: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 16.023140161s
Nov 11 21:44:49.659: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 18.025565546s
Nov 11 21:44:51.662: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 20.02842947s
Nov 11 21:44:53.664: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Running", Reason="", readiness=true. Elapsed: 22.03070339s
Nov 11 21:44:55.666: INFO: Pod "pod-subpath-test-configmap-l72m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.032873646s
STEP: Saw pod success
Nov 11 21:44:55.666: INFO: Pod "pod-subpath-test-configmap-l72m" satisfied condition "Succeeded or Failed"
Nov 11 21:44:55.675: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-subpath-test-configmap-l72m container test-container-subpath-configmap-l72m: <nil>
STEP: delete the pod
Nov 11 21:44:55.690: INFO: Waiting for pod pod-subpath-test-configmap-l72m to disappear
Nov 11 21:44:55.693: INFO: Pod pod-subpath-test-configmap-l72m no longer exists
STEP: Deleting pod pod-subpath-test-configmap-l72m
Nov 11 21:44:55.693: INFO: Deleting pod "pod-subpath-test-configmap-l72m" in namespace "subpath-6354"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:44:55.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6354" for this suite.

• [SLOW TEST:24.638 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":277,"completed":168,"skipped":2722,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:44:55.702: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1638
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 11 21:44:56.272: INFO: Waiting up to 5m0s for pod "pod-de2f5bf5-bf3e-4ce8-84fc-ee78f5e09d79" in namespace "emptydir-1638" to be "Succeeded or Failed"
Nov 11 21:44:56.274: INFO: Pod "pod-de2f5bf5-bf3e-4ce8-84fc-ee78f5e09d79": Phase="Pending", Reason="", readiness=false. Elapsed: 1.836033ms
Nov 11 21:44:58.277: INFO: Pod "pod-de2f5bf5-bf3e-4ce8-84fc-ee78f5e09d79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004486473s
STEP: Saw pod success
Nov 11 21:44:58.277: INFO: Pod "pod-de2f5bf5-bf3e-4ce8-84fc-ee78f5e09d79" satisfied condition "Succeeded or Failed"
Nov 11 21:44:58.279: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-de2f5bf5-bf3e-4ce8-84fc-ee78f5e09d79 container test-container: <nil>
STEP: delete the pod
Nov 11 21:44:58.292: INFO: Waiting for pod pod-de2f5bf5-bf3e-4ce8-84fc-ee78f5e09d79 to disappear
Nov 11 21:44:58.294: INFO: Pod pod-de2f5bf5-bf3e-4ce8-84fc-ee78f5e09d79 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:44:58.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1638" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":169,"skipped":2728,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:44:58.301: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1612
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:44:58.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1612" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":277,"completed":170,"skipped":2736,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:44:58.864: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9146
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-47a2e261-20e5-4ae5-bdf7-26a7f13c6389
Nov 11 21:44:59.432: INFO: Pod name my-hostname-basic-47a2e261-20e5-4ae5-bdf7-26a7f13c6389: Found 0 pods out of 1
Nov 11 21:45:04.435: INFO: Pod name my-hostname-basic-47a2e261-20e5-4ae5-bdf7-26a7f13c6389: Found 1 pods out of 1
Nov 11 21:45:04.435: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-47a2e261-20e5-4ae5-bdf7-26a7f13c6389" are running
Nov 11 21:45:04.438: INFO: Pod "my-hostname-basic-47a2e261-20e5-4ae5-bdf7-26a7f13c6389-zfgbr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-11 21:45:00 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-11 21:45:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-11 21:45:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-11 21:44:59 +0000 UTC Reason: Message:}])
Nov 11 21:45:04.438: INFO: Trying to dial the pod
Nov 11 21:45:09.447: INFO: Controller my-hostname-basic-47a2e261-20e5-4ae5-bdf7-26a7f13c6389: Got expected result from replica 1 [my-hostname-basic-47a2e261-20e5-4ae5-bdf7-26a7f13c6389-zfgbr]: "my-hostname-basic-47a2e261-20e5-4ae5-bdf7-26a7f13c6389-zfgbr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:45:09.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9146" for this suite.

• [SLOW TEST:10.590 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":171,"skipped":2768,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:45:09.455: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-fea29134-17d2-4a95-a0b1-538c854955e1
STEP: Creating a pod to test consume configMaps
Nov 11 21:45:10.034: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2da8d03e-4583-4bd0-9796-a99c56050a59" in namespace "projected-1128" to be "Succeeded or Failed"
Nov 11 21:45:10.036: INFO: Pod "pod-projected-configmaps-2da8d03e-4583-4bd0-9796-a99c56050a59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.228394ms
Nov 11 21:45:12.039: INFO: Pod "pod-projected-configmaps-2da8d03e-4583-4bd0-9796-a99c56050a59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004690738s
Nov 11 21:45:14.041: INFO: Pod "pod-projected-configmaps-2da8d03e-4583-4bd0-9796-a99c56050a59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007132796s
STEP: Saw pod success
Nov 11 21:45:14.041: INFO: Pod "pod-projected-configmaps-2da8d03e-4583-4bd0-9796-a99c56050a59" satisfied condition "Succeeded or Failed"
Nov 11 21:45:14.043: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-configmaps-2da8d03e-4583-4bd0-9796-a99c56050a59 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:45:14.053: INFO: Waiting for pod pod-projected-configmaps-2da8d03e-4583-4bd0-9796-a99c56050a59 to disappear
Nov 11 21:45:14.056: INFO: Pod pod-projected-configmaps-2da8d03e-4583-4bd0-9796-a99c56050a59 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:45:14.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1128" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":172,"skipped":2783,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:45:14.063: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2094
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Nov 11 21:45:14.650: INFO: Waiting up to 5m0s for pod "downward-api-be281f0f-8389-4987-81cc-d7f55672d599" in namespace "downward-api-2094" to be "Succeeded or Failed"
Nov 11 21:45:14.652: INFO: Pod "downward-api-be281f0f-8389-4987-81cc-d7f55672d599": Phase="Pending", Reason="", readiness=false. Elapsed: 2.703589ms
Nov 11 21:45:16.656: INFO: Pod "downward-api-be281f0f-8389-4987-81cc-d7f55672d599": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005909834s
Nov 11 21:45:18.658: INFO: Pod "downward-api-be281f0f-8389-4987-81cc-d7f55672d599": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008276933s
STEP: Saw pod success
Nov 11 21:45:18.658: INFO: Pod "downward-api-be281f0f-8389-4987-81cc-d7f55672d599" satisfied condition "Succeeded or Failed"
Nov 11 21:45:18.660: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downward-api-be281f0f-8389-4987-81cc-d7f55672d599 container dapi-container: <nil>
STEP: delete the pod
Nov 11 21:45:18.672: INFO: Waiting for pod downward-api-be281f0f-8389-4987-81cc-d7f55672d599 to disappear
Nov 11 21:45:18.675: INFO: Pod downward-api-be281f0f-8389-4987-81cc-d7f55672d599 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:45:18.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2094" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":277,"completed":173,"skipped":2791,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:45:18.685: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2442
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:45:19.245: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Pending, waiting for it to be Running (with Ready = true)
Nov 11 21:45:21.247: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Pending, waiting for it to be Running (with Ready = true)
Nov 11 21:45:23.251: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:25.247: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:27.247: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:29.249: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:31.247: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:33.248: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:35.247: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:37.248: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:39.247: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:41.248: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = false)
Nov 11 21:45:43.248: INFO: The status of Pod test-webserver-7f50b56d-13fc-48c3-be11-4aad2bad139b is Running (Ready = true)
Nov 11 21:45:43.249: INFO: Container started at 2020-11-11 21:45:20 +0000 UTC, pod became ready at 2020-11-11 21:45:41 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:45:43.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2442" for this suite.

• [SLOW TEST:24.572 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":277,"completed":174,"skipped":2879,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:45:43.257: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4736
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:45:59.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4736" for this suite.

• [SLOW TEST:16.579 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":277,"completed":175,"skipped":2918,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:45:59.836: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1020
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:46:00.365: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:46:04.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1020" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":277,"completed":176,"skipped":2942,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:46:04.552: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:46:09.280: INFO: Waiting up to 5m0s for pod "client-envvars-b1b24694-e96f-4226-adc6-f469395735b1" in namespace "pods-2898" to be "Succeeded or Failed"
Nov 11 21:46:09.282: INFO: Pod "client-envvars-b1b24694-e96f-4226-adc6-f469395735b1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.708594ms
Nov 11 21:46:11.285: INFO: Pod "client-envvars-b1b24694-e96f-4226-adc6-f469395735b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00422518s
STEP: Saw pod success
Nov 11 21:46:11.285: INFO: Pod "client-envvars-b1b24694-e96f-4226-adc6-f469395735b1" satisfied condition "Succeeded or Failed"
Nov 11 21:46:11.287: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod client-envvars-b1b24694-e96f-4226-adc6-f469395735b1 container env3cont: <nil>
STEP: delete the pod
Nov 11 21:46:11.302: INFO: Waiting for pod client-envvars-b1b24694-e96f-4226-adc6-f469395735b1 to disappear
Nov 11 21:46:11.305: INFO: Pod client-envvars-b1b24694-e96f-4226-adc6-f469395735b1 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:46:11.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2898" for this suite.

• [SLOW TEST:6.762 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":277,"completed":177,"skipped":2944,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:46:11.315: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6017
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1111 21:46:13.402853      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 11 21:46:13.402: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:46:13.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6017" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":277,"completed":178,"skipped":2952,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:46:13.439: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3825
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:46:14.363: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:46:16.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740727974, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740727974, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740727975, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740727974, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:46:19.380: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:46:19.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3825" for this suite.
STEP: Destroying namespace "webhook-3825-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.013 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":277,"completed":179,"skipped":2966,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:46:19.453: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8707
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-13f4082d-e63c-4329-abd3-dcb590339f20
STEP: Creating configMap with name cm-test-opt-upd-064d143a-bf8f-49d8-b37b-ed2d514f9a27
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-13f4082d-e63c-4329-abd3-dcb590339f20
STEP: Updating configmap cm-test-opt-upd-064d143a-bf8f-49d8-b37b-ed2d514f9a27
STEP: Creating configMap with name cm-test-opt-create-21d6039d-c232-4756-bd0e-78b162584f5a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:47:54.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8707" for this suite.

• [SLOW TEST:94.971 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":180,"skipped":3008,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:47:54.424: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9550
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1111 21:48:05.172657      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 11 21:48:05.172: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:48:05.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9550" for this suite.

• [SLOW TEST:10.756 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":277,"completed":181,"skipped":3016,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:48:05.181: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3640
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:48:09.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3640" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":182,"skipped":3036,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:48:09.825: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4290
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:48:11.143: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:48:13.149: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728091, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728091, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728091, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728091, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:48:16.201: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:48:16.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4290" for this suite.
STEP: Destroying namespace "webhook-4290-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.518 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":277,"completed":183,"skipped":3052,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:48:16.343: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-322
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:48:16.848: INFO: (0) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 8.535713ms)
Nov 11 21:48:16.850: INFO: (1) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.26925ms)
Nov 11 21:48:16.853: INFO: (2) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.313221ms)
Nov 11 21:48:16.855: INFO: (3) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.194336ms)
Nov 11 21:48:16.857: INFO: (4) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.414683ms)
Nov 11 21:48:16.860: INFO: (5) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.167035ms)
Nov 11 21:48:16.862: INFO: (6) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.458264ms)
Nov 11 21:48:16.864: INFO: (7) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.419893ms)
Nov 11 21:48:16.867: INFO: (8) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.208089ms)
Nov 11 21:48:16.869: INFO: (9) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.333976ms)
Nov 11 21:48:16.871: INFO: (10) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.410235ms)
Nov 11 21:48:16.874: INFO: (11) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.607803ms)
Nov 11 21:48:16.877: INFO: (12) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.725856ms)
Nov 11 21:48:16.879: INFO: (13) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.510008ms)
Nov 11 21:48:16.882: INFO: (14) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.145176ms)
Nov 11 21:48:16.884: INFO: (15) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.250841ms)
Nov 11 21:48:16.886: INFO: (16) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.303454ms)
Nov 11 21:48:16.889: INFO: (17) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.293722ms)
Nov 11 21:48:16.891: INFO: (18) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.136164ms)
Nov 11 21:48:16.893: INFO: (19) /api/v1/nodes/ip-172-31-0-166.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.132353ms)
[AfterEach] version v1
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:48:16.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-322" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":277,"completed":184,"skipped":3096,"failed":0}
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:48:16.899: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-c2sd
STEP: Creating a pod to test atomic-volume-subpath
Nov 11 21:48:17.474: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-c2sd" in namespace "subpath-6186" to be "Succeeded or Failed"
Nov 11 21:48:17.477: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.185612ms
Nov 11 21:48:19.480: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 2.005573951s
Nov 11 21:48:21.482: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 4.007846374s
Nov 11 21:48:23.484: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 6.010225134s
Nov 11 21:48:25.487: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 8.012608655s
Nov 11 21:48:27.489: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 10.014781913s
Nov 11 21:48:29.491: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 12.017134932s
Nov 11 21:48:31.494: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 14.019378997s
Nov 11 21:48:33.496: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 16.02203491s
Nov 11 21:48:35.498: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 18.024256719s
Nov 11 21:48:37.501: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Running", Reason="", readiness=true. Elapsed: 20.027222799s
Nov 11 21:48:39.504: INFO: Pod "pod-subpath-test-downwardapi-c2sd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.029357369s
STEP: Saw pod success
Nov 11 21:48:39.504: INFO: Pod "pod-subpath-test-downwardapi-c2sd" satisfied condition "Succeeded or Failed"
Nov 11 21:48:39.505: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-subpath-test-downwardapi-c2sd container test-container-subpath-downwardapi-c2sd: <nil>
STEP: delete the pod
Nov 11 21:48:39.526: INFO: Waiting for pod pod-subpath-test-downwardapi-c2sd to disappear
Nov 11 21:48:39.529: INFO: Pod pod-subpath-test-downwardapi-c2sd no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-c2sd
Nov 11 21:48:39.529: INFO: Deleting pod "pod-subpath-test-downwardapi-c2sd" in namespace "subpath-6186"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:48:39.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6186" for this suite.

• [SLOW TEST:22.639 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":277,"completed":185,"skipped":3102,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:48:39.539: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-2328
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:48:40.066: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Creating first CR 
Nov 11 21:48:40.614: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-11T21:48:40Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-11-11T21:48:40Z]] name:name1 resourceVersion:26369 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:a8afe74c-0065-41f6-9627-6a52a7e361ac] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Nov 11 21:48:50.621: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-11T21:48:50Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-11-11T21:48:50Z]] name:name2 resourceVersion:26414 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b2dcb868-1421-47dd-8e42-b010ef99540b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Nov 11 21:49:00.626: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-11T21:48:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-11-11T21:49:00Z]] name:name1 resourceVersion:26449 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:a8afe74c-0065-41f6-9627-6a52a7e361ac] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Nov 11 21:49:10.635: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-11T21:48:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-11-11T21:49:10Z]] name:name2 resourceVersion:26480 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b2dcb868-1421-47dd-8e42-b010ef99540b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Nov 11 21:49:20.644: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-11T21:48:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-11-11T21:49:00Z]] name:name1 resourceVersion:26513 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:a8afe74c-0065-41f6-9627-6a52a7e361ac] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Nov 11 21:49:30.649: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-11T21:48:50Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-11-11T21:49:10Z]] name:name2 resourceVersion:26544 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b2dcb868-1421-47dd-8e42-b010ef99540b] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:49:41.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2328" for this suite.

• [SLOW TEST:61.674 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":277,"completed":186,"skipped":3107,"failed":0}
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:49:41.213: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3808
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Nov 11 21:49:41.864: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 21:49:45.378: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:49:59.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3808" for this suite.

• [SLOW TEST:17.813 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":277,"completed":187,"skipped":3107,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:49:59.027: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6872
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:49:59.602: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 11 21:50:04.607: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 11 21:50:04.608: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 11 21:50:06.610: INFO: Creating deployment "test-rollover-deployment"
Nov 11 21:50:06.642: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 11 21:50:08.646: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 11 21:50:08.650: INFO: Ensure that both replica sets have 1 created replica
Nov 11 21:50:08.653: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 11 21:50:08.686: INFO: Updating deployment test-rollover-deployment
Nov 11 21:50:08.686: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 11 21:50:10.690: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 11 21:50:10.694: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 11 21:50:10.697: INFO: all replica sets need to contain the pod-template-hash label
Nov 11 21:50:10.697: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728209, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728206, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:50:12.703: INFO: all replica sets need to contain the pod-template-hash label
Nov 11 21:50:12.703: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728211, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728206, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:50:14.702: INFO: all replica sets need to contain the pod-template-hash label
Nov 11 21:50:14.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728211, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728206, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:50:16.702: INFO: all replica sets need to contain the pod-template-hash label
Nov 11 21:50:16.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728211, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728206, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:50:18.702: INFO: all replica sets need to contain the pod-template-hash label
Nov 11 21:50:18.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728211, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728206, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:50:20.702: INFO: all replica sets need to contain the pod-template-hash label
Nov 11 21:50:20.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728207, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728211, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728206, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 21:50:22.702: INFO: 
Nov 11 21:50:22.702: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Nov 11 21:50:22.706: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-6872 /apis/apps/v1/namespaces/deployment-6872/deployments/test-rollover-deployment 1b09db50-387c-4d3f-b1e9-ee05caf461e3 26830 2 2020-11-11 21:50:06 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-11-11 21:50:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-11-11 21:50:22 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006dd1498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-11-11 21:50:07 +0000 UTC,LastTransitionTime:2020-11-11 21:50:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-11-11 21:50:22 +0000 UTC,LastTransitionTime:2020-11-11 21:50:06 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 11 21:50:22.708: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-6872 /apis/apps/v1/namespaces/deployment-6872/replicasets/test-rollover-deployment-84f7f6f64b 9e048d50-df11-420c-ad9c-9acf90bd5de5 26813 2 2020-11-11 21:50:08 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 1b09db50-387c-4d3f-b1e9-ee05caf461e3 0xc004296257 0xc004296258}] []  [{kube-controller-manager Update apps/v1 2020-11-11 21:50:21 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 48 57 100 98 53 48 45 51 56 55 99 45 52 100 51 102 45 98 49 101 57 45 101 101 48 53 99 97 102 52 54 49 101 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004296478 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 11 21:50:22.709: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 11 21:50:22.709: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-6872 /apis/apps/v1/namespaces/deployment-6872/replicasets/test-rollover-controller dc955ea5-fd20-420c-8283-bc8ce89b3aa1 26826 2 2020-11-11 21:49:59 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 1b09db50-387c-4d3f-b1e9-ee05caf461e3 0xc006dd1c57 0xc006dd1c58}] []  [{e2e.test Update apps/v1 2020-11-11 21:49:59 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-11-11 21:50:22 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 48 57 100 98 53 48 45 51 56 55 99 45 52 100 51 102 45 98 49 101 57 45 101 101 48 53 99 97 102 52 54 49 101 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc006dd1d68 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 11 21:50:22.709: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-6872 /apis/apps/v1/namespaces/deployment-6872/replicasets/test-rollover-deployment-5686c4cfd5 b24c8ce2-8e4c-4c2d-8874-71aafc3b8e29 26751 2 2020-11-11 21:50:06 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 1b09db50-387c-4d3f-b1e9-ee05caf461e3 0xc006dd1e37 0xc006dd1e38}] []  [{kube-controller-manager Update apps/v1 2020-11-11 21:50:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 48 57 100 98 53 48 45 51 56 55 99 45 52 100 51 102 45 98 49 101 57 45 101 101 48 53 99 97 102 52 54 49 101 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006dd1f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 11 21:50:22.711: INFO: Pod "test-rollover-deployment-84f7f6f64b-l9bb4" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-l9bb4 test-rollover-deployment-84f7f6f64b- deployment-6872 /api/v1/namespaces/deployment-6872/pods/test-rollover-deployment-84f7f6f64b-l9bb4 26c7c9b0-5013-4f54-9faf-f48df0bfc3d0 26779 0 2020-11-11 21:50:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b 9e048d50-df11-420c-ad9c-9acf90bd5de5 0xc004669567 0xc004669568}] []  [{kube-controller-manager Update v1 2020-11-11 21:50:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 101 48 52 56 100 53 48 45 100 102 49 49 45 52 50 48 99 45 97 100 57 99 45 57 97 99 102 57 48 98 100 53 100 101 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 21:50:11 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 49 48 46 55 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-msxdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-msxdn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-msxdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 21:50:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 21:50:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 21:50:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 21:50:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:192.168.10.70,StartTime:2020-11-11 21:50:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 21:50:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://98ba24514437e2217be943eae9adf455728c3b0b2ab2f24a03e49a425ac7c5d8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.10.70,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:50:22.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6872" for this suite.

• [SLOW TEST:23.690 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":277,"completed":188,"skipped":3115,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:50:22.717: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4907
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-116f8aa3-1125-4670-b8b0-3c219b2f2427 in namespace container-probe-4907
Nov 11 21:50:27.282: INFO: Started pod busybox-116f8aa3-1125-4670-b8b0-3c219b2f2427 in namespace container-probe-4907
STEP: checking the pod's current state and verifying that restartCount is present
Nov 11 21:50:27.284: INFO: Initial restart count of pod busybox-116f8aa3-1125-4670-b8b0-3c219b2f2427 is 0
Nov 11 21:51:17.366: INFO: Restart count of pod container-probe-4907/busybox-116f8aa3-1125-4670-b8b0-3c219b2f2427 is now 1 (50.082418235s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:51:17.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4907" for this suite.

• [SLOW TEST:54.663 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":189,"skipped":3139,"failed":0}
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:51:17.381: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3849
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3849.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3849.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3849.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3849.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3849.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3849.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 11 21:51:21.968: INFO: DNS probes using dns-3849/dns-test-deda0b01-f078-4db1-aada-fefaf4a3967d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:51:21.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3849" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":277,"completed":190,"skipped":3147,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:51:21.985: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8196
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:51:22.511: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:51:29.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8196" for this suite.

• [SLOW TEST:7.161 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":277,"completed":191,"skipped":3148,"failed":0}
SSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:51:29.146: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:51:30.441: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-220fbffa-2c46-44f7-8d46-3285f1876d7e" in namespace "security-context-test-2616" to be "Succeeded or Failed"
Nov 11 21:51:30.470: INFO: Pod "alpine-nnp-false-220fbffa-2c46-44f7-8d46-3285f1876d7e": Phase="Pending", Reason="", readiness=false. Elapsed: 28.644789ms
Nov 11 21:51:32.472: INFO: Pod "alpine-nnp-false-220fbffa-2c46-44f7-8d46-3285f1876d7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031008669s
Nov 11 21:51:34.476: INFO: Pod "alpine-nnp-false-220fbffa-2c46-44f7-8d46-3285f1876d7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034381846s
Nov 11 21:51:34.476: INFO: Pod "alpine-nnp-false-220fbffa-2c46-44f7-8d46-3285f1876d7e" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:51:34.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2616" for this suite.

• [SLOW TEST:5.354 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:291
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":192,"skipped":3153,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:51:34.501: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9901
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:51:46.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9901" for this suite.

• [SLOW TEST:11.601 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":277,"completed":193,"skipped":3190,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:51:46.102: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7141
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:52:02.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7141" for this suite.

• [SLOW TEST:16.696 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":277,"completed":194,"skipped":3208,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:52:02.799: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2472
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 11 21:52:07.905: INFO: Successfully updated pod "pod-update-94b8a12e-ffdd-431d-aa29-7a13194456b7"
STEP: verifying the updated pod is in kubernetes
Nov 11 21:52:07.912: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:52:07.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2472" for this suite.

• [SLOW TEST:5.121 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":277,"completed":195,"skipped":3218,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:52:07.920: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-70
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 11 21:52:08.578: INFO: Waiting up to 5m0s for pod "pod-2dccaa58-30b8-4135-8b14-9a49cab6527a" in namespace "emptydir-70" to be "Succeeded or Failed"
Nov 11 21:52:08.581: INFO: Pod "pod-2dccaa58-30b8-4135-8b14-9a49cab6527a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.644245ms
Nov 11 21:52:10.583: INFO: Pod "pod-2dccaa58-30b8-4135-8b14-9a49cab6527a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005565199s
Nov 11 21:52:12.588: INFO: Pod "pod-2dccaa58-30b8-4135-8b14-9a49cab6527a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010229661s
STEP: Saw pod success
Nov 11 21:52:12.588: INFO: Pod "pod-2dccaa58-30b8-4135-8b14-9a49cab6527a" satisfied condition "Succeeded or Failed"
Nov 11 21:52:12.591: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod pod-2dccaa58-30b8-4135-8b14-9a49cab6527a container test-container: <nil>
STEP: delete the pod
Nov 11 21:52:12.625: INFO: Waiting for pod pod-2dccaa58-30b8-4135-8b14-9a49cab6527a to disappear
Nov 11 21:52:12.627: INFO: Pod pod-2dccaa58-30b8-4135-8b14-9a49cab6527a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:52:12.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-70" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":196,"skipped":3226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:52:12.654: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4015
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:52:13.287: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e4a6f819-5114-4477-91b5-dda11b281241" in namespace "downward-api-4015" to be "Succeeded or Failed"
Nov 11 21:52:13.291: INFO: Pod "downwardapi-volume-e4a6f819-5114-4477-91b5-dda11b281241": Phase="Pending", Reason="", readiness=false. Elapsed: 3.493745ms
Nov 11 21:52:15.293: INFO: Pod "downwardapi-volume-e4a6f819-5114-4477-91b5-dda11b281241": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005758374s
Nov 11 21:52:17.295: INFO: Pod "downwardapi-volume-e4a6f819-5114-4477-91b5-dda11b281241": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008023037s
STEP: Saw pod success
Nov 11 21:52:17.295: INFO: Pod "downwardapi-volume-e4a6f819-5114-4477-91b5-dda11b281241" satisfied condition "Succeeded or Failed"
Nov 11 21:52:17.297: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-e4a6f819-5114-4477-91b5-dda11b281241 container client-container: <nil>
STEP: delete the pod
Nov 11 21:52:17.314: INFO: Waiting for pod downwardapi-volume-e4a6f819-5114-4477-91b5-dda11b281241 to disappear
Nov 11 21:52:17.321: INFO: Pod downwardapi-volume-e4a6f819-5114-4477-91b5-dda11b281241 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:52:17.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4015" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":197,"skipped":3260,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:52:17.329: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5491
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-8463a584-d59a-4a03-bc09-289416825ff7
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-8463a584-d59a-4a03-bc09-289416825ff7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:52:22.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5491" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":198,"skipped":3271,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:52:22.092: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-742
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Nov 11 21:52:25.218: INFO: Successfully updated pod "annotationupdate33dd1c16-abe0-4900-8ba4-e26a414f8b47"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:52:29.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-742" for this suite.

• [SLOW TEST:7.151 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":199,"skipped":3280,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:52:29.244: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3600
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-3600
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3600
STEP: creating replication controller externalsvc in namespace services-3600
I1111 21:52:29.843916      21 runners.go:190] Created replication controller with name: externalsvc, namespace: services-3600, replica count: 2
I1111 21:52:32.894352      21 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Nov 11 21:52:32.908: INFO: Creating new exec pod
Nov 11 21:52:34.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-3600 execpodtxvkh -- /bin/sh -x -c nslookup nodeport-service'
Nov 11 21:52:35.331: INFO: stderr: "+ nslookup nodeport-service\n"
Nov 11 21:52:35.331: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-3600.svc.cluster.local\tcanonical name = externalsvc.services-3600.svc.cluster.local.\nName:\texternalsvc.services-3600.svc.cluster.local\nAddress: 10.96.9.53\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3600, will wait for the garbage collector to delete the pods
Nov 11 21:52:35.389: INFO: Deleting ReplicationController externalsvc took: 4.498629ms
Nov 11 21:52:36.289: INFO: Terminating ReplicationController externalsvc pods took: 900.166008ms
Nov 11 21:52:50.923: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:52:50.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3600" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:21.694 seconds]
[sig-network] Services
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":277,"completed":200,"skipped":3287,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:52:50.938: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:52:51.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9510" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":277,"completed":201,"skipped":3318,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:52:51.477: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6043
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov 11 21:52:52.012: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-a cb9758b0-a11c-4bd3-a22c-21f320f63899 27897 0 2020-11-11 21:52:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-11-11 21:52:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:52:52.012: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-a cb9758b0-a11c-4bd3-a22c-21f320f63899 27897 0 2020-11-11 21:52:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-11-11 21:52:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov 11 21:53:02.020: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-a cb9758b0-a11c-4bd3-a22c-21f320f63899 27961 0 2020-11-11 21:52:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:53:02.020: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-a cb9758b0-a11c-4bd3-a22c-21f320f63899 27961 0 2020-11-11 21:52:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov 11 21:53:12.027: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-a cb9758b0-a11c-4bd3-a22c-21f320f63899 27993 0 2020-11-11 21:52:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:53:12.027: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-a cb9758b0-a11c-4bd3-a22c-21f320f63899 27993 0 2020-11-11 21:52:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov 11 21:53:22.032: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-a cb9758b0-a11c-4bd3-a22c-21f320f63899 28025 0 2020-11-11 21:52:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:53:22.032: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-a cb9758b0-a11c-4bd3-a22c-21f320f63899 28025 0 2020-11-11 21:52:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov 11 21:53:32.038: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-b e84420cc-5300-4eb9-8a7b-b36bab885baf 28054 0 2020-11-11 21:53:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:53:32.038: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-b e84420cc-5300-4eb9-8a7b-b36bab885baf 28054 0 2020-11-11 21:53:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov 11 21:53:42.043: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-b e84420cc-5300-4eb9-8a7b-b36bab885baf 28085 0 2020-11-11 21:53:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:53:42.043: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6043 /api/v1/namespaces/watch-6043/configmaps/e2e-watch-test-configmap-b e84420cc-5300-4eb9-8a7b-b36bab885baf 28085 0 2020-11-11 21:53:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-11-11 21:53:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:53:52.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6043" for this suite.

• [SLOW TEST:60.576 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":277,"completed":202,"skipped":3332,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:53:52.053: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 11 21:53:52.630: INFO: Waiting up to 5m0s for pod "pod-86a663e8-2757-4626-9c9a-41dc66101044" in namespace "emptydir-521" to be "Succeeded or Failed"
Nov 11 21:53:52.632: INFO: Pod "pod-86a663e8-2757-4626-9c9a-41dc66101044": Phase="Pending", Reason="", readiness=false. Elapsed: 1.608787ms
Nov 11 21:53:54.634: INFO: Pod "pod-86a663e8-2757-4626-9c9a-41dc66101044": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003757679s
STEP: Saw pod success
Nov 11 21:53:54.634: INFO: Pod "pod-86a663e8-2757-4626-9c9a-41dc66101044" satisfied condition "Succeeded or Failed"
Nov 11 21:53:54.635: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-86a663e8-2757-4626-9c9a-41dc66101044 container test-container: <nil>
STEP: delete the pod
Nov 11 21:53:54.667: INFO: Waiting for pod pod-86a663e8-2757-4626-9c9a-41dc66101044 to disappear
Nov 11 21:53:54.669: INFO: Pod pod-86a663e8-2757-4626-9c9a-41dc66101044 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:53:54.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-521" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":203,"skipped":3345,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:53:54.681: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:53:59.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1051" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":204,"skipped":3376,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:53:59.271: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7762
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-swt7d in namespace proxy-7762
I1111 21:53:59.836413      21 runners.go:190] Created replication controller with name: proxy-service-swt7d, namespace: proxy-7762, replica count: 1
I1111 21:54:00.886921      21 runners.go:190] proxy-service-swt7d Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1111 21:54:01.887098      21 runners.go:190] proxy-service-swt7d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1111 21:54:02.887266      21 runners.go:190] proxy-service-swt7d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1111 21:54:03.887491      21 runners.go:190] proxy-service-swt7d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1111 21:54:04.887674      21 runners.go:190] proxy-service-swt7d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1111 21:54:05.887827      21 runners.go:190] proxy-service-swt7d Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 21:54:05.890: INFO: setup took 6.089961907s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov 11 21:54:05.896: INFO: (0) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 6.048997ms)
Nov 11 21:54:05.899: INFO: (0) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 9.559469ms)
Nov 11 21:54:05.901: INFO: (0) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 11.087036ms)
Nov 11 21:54:05.903: INFO: (0) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 13.493606ms)
Nov 11 21:54:05.905: INFO: (0) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 15.093541ms)
Nov 11 21:54:05.905: INFO: (0) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 15.412674ms)
Nov 11 21:54:05.905: INFO: (0) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 15.379731ms)
Nov 11 21:54:05.906: INFO: (0) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 15.616219ms)
Nov 11 21:54:05.906: INFO: (0) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 15.503307ms)
Nov 11 21:54:05.906: INFO: (0) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 15.930289ms)
Nov 11 21:54:05.906: INFO: (0) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 16.173253ms)
Nov 11 21:54:05.906: INFO: (0) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 16.155012ms)
Nov 11 21:54:05.906: INFO: (0) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 16.286497ms)
Nov 11 21:54:05.907: INFO: (0) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 16.346508ms)
Nov 11 21:54:05.910: INFO: (0) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 19.609831ms)
Nov 11 21:54:05.910: INFO: (0) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 19.501568ms)
Nov 11 21:54:05.917: INFO: (1) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 6.990635ms)
Nov 11 21:54:05.920: INFO: (1) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 10.334439ms)
Nov 11 21:54:05.925: INFO: (1) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 15.003815ms)
Nov 11 21:54:05.925: INFO: (1) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 15.126123ms)
Nov 11 21:54:05.925: INFO: (1) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 15.391327ms)
Nov 11 21:54:05.925: INFO: (1) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 15.233615ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 15.599901ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 15.426383ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 15.557579ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 15.529119ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 15.8588ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 15.772166ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 15.836576ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 16.150958ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 16.000565ms)
Nov 11 21:54:05.926: INFO: (1) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 16.330412ms)
Nov 11 21:54:05.933: INFO: (2) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 6.336353ms)
Nov 11 21:54:05.933: INFO: (2) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 6.650538ms)
Nov 11 21:54:05.934: INFO: (2) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 6.954708ms)
Nov 11 21:54:05.934: INFO: (2) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 7.035594ms)
Nov 11 21:54:05.934: INFO: (2) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 7.195781ms)
Nov 11 21:54:05.934: INFO: (2) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 7.350749ms)
Nov 11 21:54:05.934: INFO: (2) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 7.210398ms)
Nov 11 21:54:05.934: INFO: (2) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 7.319651ms)
Nov 11 21:54:05.938: INFO: (2) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 10.757725ms)
Nov 11 21:54:05.938: INFO: (2) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 10.918398ms)
Nov 11 21:54:05.938: INFO: (2) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 11.171076ms)
Nov 11 21:54:05.938: INFO: (2) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 11.219056ms)
Nov 11 21:54:05.941: INFO: (2) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 14.100628ms)
Nov 11 21:54:05.942: INFO: (2) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 15.235341ms)
Nov 11 21:54:05.943: INFO: (2) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 15.719094ms)
Nov 11 21:54:05.943: INFO: (2) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 15.532156ms)
Nov 11 21:54:05.947: INFO: (3) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 4.601586ms)
Nov 11 21:54:05.948: INFO: (3) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 4.845951ms)
Nov 11 21:54:05.949: INFO: (3) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 6.107479ms)
Nov 11 21:54:05.951: INFO: (3) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 7.706932ms)
Nov 11 21:54:05.953: INFO: (3) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 9.652509ms)
Nov 11 21:54:05.953: INFO: (3) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 10.278559ms)
Nov 11 21:54:05.954: INFO: (3) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 10.854058ms)
Nov 11 21:54:05.955: INFO: (3) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 11.463193ms)
Nov 11 21:54:05.955: INFO: (3) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 12.444186ms)
Nov 11 21:54:05.955: INFO: (3) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 12.074828ms)
Nov 11 21:54:05.957: INFO: (3) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 13.197069ms)
Nov 11 21:54:05.957: INFO: (3) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 14.100722ms)
Nov 11 21:54:05.958: INFO: (3) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 14.323614ms)
Nov 11 21:54:05.960: INFO: (3) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 16.879402ms)
Nov 11 21:54:05.961: INFO: (3) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 17.362204ms)
Nov 11 21:54:05.961: INFO: (3) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 18.00501ms)
Nov 11 21:54:05.971: INFO: (4) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 9.760123ms)
Nov 11 21:54:05.971: INFO: (4) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 9.53221ms)
Nov 11 21:54:05.971: INFO: (4) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 10.066038ms)
Nov 11 21:54:05.972: INFO: (4) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 10.537585ms)
Nov 11 21:54:05.973: INFO: (4) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 11.049145ms)
Nov 11 21:54:05.973: INFO: (4) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 11.599913ms)
Nov 11 21:54:05.973: INFO: (4) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 11.542112ms)
Nov 11 21:54:05.975: INFO: (4) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 12.963907ms)
Nov 11 21:54:05.975: INFO: (4) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 13.437023ms)
Nov 11 21:54:05.975: INFO: (4) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 13.455312ms)
Nov 11 21:54:05.975: INFO: (4) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 13.667892ms)
Nov 11 21:54:05.975: INFO: (4) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 13.643731ms)
Nov 11 21:54:05.976: INFO: (4) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 13.924656ms)
Nov 11 21:54:05.976: INFO: (4) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 13.867959ms)
Nov 11 21:54:05.976: INFO: (4) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 14.169081ms)
Nov 11 21:54:05.976: INFO: (4) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 14.293091ms)
Nov 11 21:54:05.981: INFO: (5) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 4.95662ms)
Nov 11 21:54:05.988: INFO: (5) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 11.212779ms)
Nov 11 21:54:05.988: INFO: (5) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 11.703026ms)
Nov 11 21:54:05.989: INFO: (5) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 12.2303ms)
Nov 11 21:54:05.990: INFO: (5) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 13.88845ms)
Nov 11 21:54:05.990: INFO: (5) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 14.111512ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 14.384494ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 14.303141ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 14.010497ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 14.29211ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 14.227926ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 14.021963ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 13.921408ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 14.178064ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 14.640294ms)
Nov 11 21:54:05.991: INFO: (5) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 14.822326ms)
Nov 11 21:54:06.001: INFO: (6) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 9.311307ms)
Nov 11 21:54:06.001: INFO: (6) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 9.669985ms)
Nov 11 21:54:06.002: INFO: (6) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 10.223176ms)
Nov 11 21:54:06.002: INFO: (6) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 10.624321ms)
Nov 11 21:54:06.002: INFO: (6) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 10.509379ms)
Nov 11 21:54:06.002: INFO: (6) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 10.979726ms)
Nov 11 21:54:06.003: INFO: (6) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 11.380461ms)
Nov 11 21:54:06.003: INFO: (6) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 11.290127ms)
Nov 11 21:54:06.003: INFO: (6) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 11.277144ms)
Nov 11 21:54:06.004: INFO: (6) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 12.495197ms)
Nov 11 21:54:06.004: INFO: (6) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 12.884649ms)
Nov 11 21:54:06.004: INFO: (6) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 12.464887ms)
Nov 11 21:54:06.005: INFO: (6) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 12.754294ms)
Nov 11 21:54:06.005: INFO: (6) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 13.672499ms)
Nov 11 21:54:06.006: INFO: (6) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 14.227275ms)
Nov 11 21:54:06.006: INFO: (6) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 13.956574ms)
Nov 11 21:54:06.012: INFO: (7) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 5.796932ms)
Nov 11 21:54:06.012: INFO: (7) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 6.262101ms)
Nov 11 21:54:06.012: INFO: (7) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 6.591613ms)
Nov 11 21:54:06.013: INFO: (7) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 7.304928ms)
Nov 11 21:54:06.014: INFO: (7) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 7.808385ms)
Nov 11 21:54:06.015: INFO: (7) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 9.219153ms)
Nov 11 21:54:06.015: INFO: (7) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 9.402944ms)
Nov 11 21:54:06.018: INFO: (7) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 11.81846ms)
Nov 11 21:54:06.018: INFO: (7) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 12.198782ms)
Nov 11 21:54:06.018: INFO: (7) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 12.233213ms)
Nov 11 21:54:06.020: INFO: (7) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 14.287559ms)
Nov 11 21:54:06.020: INFO: (7) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 14.428557ms)
Nov 11 21:54:06.021: INFO: (7) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 14.744636ms)
Nov 11 21:54:06.021: INFO: (7) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 14.809894ms)
Nov 11 21:54:06.021: INFO: (7) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 14.767746ms)
Nov 11 21:54:06.021: INFO: (7) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 14.942713ms)
Nov 11 21:54:06.030: INFO: (8) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 8.518349ms)
Nov 11 21:54:06.030: INFO: (8) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 9.053859ms)
Nov 11 21:54:06.033: INFO: (8) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 11.38336ms)
Nov 11 21:54:06.033: INFO: (8) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 11.671681ms)
Nov 11 21:54:06.033: INFO: (8) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 11.638769ms)
Nov 11 21:54:06.033: INFO: (8) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 12.251681ms)
Nov 11 21:54:06.033: INFO: (8) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 12.180713ms)
Nov 11 21:54:06.034: INFO: (8) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 12.510734ms)
Nov 11 21:54:06.034: INFO: (8) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 12.279441ms)
Nov 11 21:54:06.034: INFO: (8) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 12.438026ms)
Nov 11 21:54:06.034: INFO: (8) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 12.508734ms)
Nov 11 21:54:06.034: INFO: (8) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 12.599833ms)
Nov 11 21:54:06.034: INFO: (8) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 12.965981ms)
Nov 11 21:54:06.034: INFO: (8) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 12.570759ms)
Nov 11 21:54:06.034: INFO: (8) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 12.672398ms)
Nov 11 21:54:06.035: INFO: (8) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 12.887233ms)
Nov 11 21:54:06.045: INFO: (9) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 10.645652ms)
Nov 11 21:54:06.045: INFO: (9) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 10.460979ms)
Nov 11 21:54:06.045: INFO: (9) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 10.728368ms)
Nov 11 21:54:06.046: INFO: (9) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 10.670516ms)
Nov 11 21:54:06.046: INFO: (9) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 10.717822ms)
Nov 11 21:54:06.046: INFO: (9) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 11.356122ms)
Nov 11 21:54:06.047: INFO: (9) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 12.072631ms)
Nov 11 21:54:06.047: INFO: (9) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 12.352785ms)
Nov 11 21:54:06.047: INFO: (9) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 12.299878ms)
Nov 11 21:54:06.047: INFO: (9) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 12.236629ms)
Nov 11 21:54:06.048: INFO: (9) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 12.971718ms)
Nov 11 21:54:06.048: INFO: (9) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 13.105464ms)
Nov 11 21:54:06.048: INFO: (9) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 13.158129ms)
Nov 11 21:54:06.048: INFO: (9) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 13.082155ms)
Nov 11 21:54:06.049: INFO: (9) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 13.858617ms)
Nov 11 21:54:06.049: INFO: (9) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 14.487167ms)
Nov 11 21:54:06.059: INFO: (10) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 9.010057ms)
Nov 11 21:54:06.060: INFO: (10) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 10.59505ms)
Nov 11 21:54:06.060: INFO: (10) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 10.829886ms)
Nov 11 21:54:06.061: INFO: (10) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 10.94575ms)
Nov 11 21:54:06.061: INFO: (10) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 11.257125ms)
Nov 11 21:54:06.061: INFO: (10) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 11.310044ms)
Nov 11 21:54:06.061: INFO: (10) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 11.287993ms)
Nov 11 21:54:06.061: INFO: (10) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 11.678534ms)
Nov 11 21:54:06.062: INFO: (10) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 12.235604ms)
Nov 11 21:54:06.063: INFO: (10) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 13.156133ms)
Nov 11 21:54:06.063: INFO: (10) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 13.49153ms)
Nov 11 21:54:06.063: INFO: (10) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 13.744027ms)
Nov 11 21:54:06.063: INFO: (10) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 13.835574ms)
Nov 11 21:54:06.064: INFO: (10) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 13.881857ms)
Nov 11 21:54:06.064: INFO: (10) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 13.939466ms)
Nov 11 21:54:06.064: INFO: (10) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 14.21395ms)
Nov 11 21:54:06.073: INFO: (11) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 9.309815ms)
Nov 11 21:54:06.074: INFO: (11) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 9.360901ms)
Nov 11 21:54:06.074: INFO: (11) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 9.431216ms)
Nov 11 21:54:06.074: INFO: (11) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 9.769028ms)
Nov 11 21:54:06.074: INFO: (11) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 9.594366ms)
Nov 11 21:54:06.074: INFO: (11) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 9.746512ms)
Nov 11 21:54:06.074: INFO: (11) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 9.985629ms)
Nov 11 21:54:06.074: INFO: (11) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 10.315536ms)
Nov 11 21:54:06.075: INFO: (11) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 10.443579ms)
Nov 11 21:54:06.075: INFO: (11) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 11.349231ms)
Nov 11 21:54:06.076: INFO: (11) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 12.588559ms)
Nov 11 21:54:06.076: INFO: (11) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 12.386065ms)
Nov 11 21:54:06.077: INFO: (11) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 13.177123ms)
Nov 11 21:54:06.078: INFO: (11) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 13.57012ms)
Nov 11 21:54:06.081: INFO: (11) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 17.272062ms)
Nov 11 21:54:06.081: INFO: (11) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 17.474194ms)
Nov 11 21:54:06.086: INFO: (12) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 4.044772ms)
Nov 11 21:54:06.086: INFO: (12) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 4.180188ms)
Nov 11 21:54:06.089: INFO: (12) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 6.915433ms)
Nov 11 21:54:06.089: INFO: (12) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 7.056048ms)
Nov 11 21:54:06.089: INFO: (12) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 7.138076ms)
Nov 11 21:54:06.089: INFO: (12) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 6.959305ms)
Nov 11 21:54:06.091: INFO: (12) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 9.438739ms)
Nov 11 21:54:06.092: INFO: (12) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 10.038497ms)
Nov 11 21:54:06.093: INFO: (12) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 10.849879ms)
Nov 11 21:54:06.095: INFO: (12) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 12.854123ms)
Nov 11 21:54:06.097: INFO: (12) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 14.382456ms)
Nov 11 21:54:06.097: INFO: (12) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 14.343094ms)
Nov 11 21:54:06.097: INFO: (12) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 14.445799ms)
Nov 11 21:54:06.097: INFO: (12) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 14.479553ms)
Nov 11 21:54:06.097: INFO: (12) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 14.549921ms)
Nov 11 21:54:06.097: INFO: (12) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 14.887524ms)
Nov 11 21:54:06.116: INFO: (13) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 18.544245ms)
Nov 11 21:54:06.116: INFO: (13) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 18.495096ms)
Nov 11 21:54:06.116: INFO: (13) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 18.685372ms)
Nov 11 21:54:06.116: INFO: (13) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 18.620914ms)
Nov 11 21:54:06.116: INFO: (13) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 18.71736ms)
Nov 11 21:54:06.116: INFO: (13) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 19.070703ms)
Nov 11 21:54:06.116: INFO: (13) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 19.151051ms)
Nov 11 21:54:06.117: INFO: (13) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 19.321635ms)
Nov 11 21:54:06.129: INFO: (13) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 31.341881ms)
Nov 11 21:54:06.141: INFO: (13) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 43.236059ms)
Nov 11 21:54:06.141: INFO: (13) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 43.810772ms)
Nov 11 21:54:06.141: INFO: (13) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 43.269477ms)
Nov 11 21:54:06.145: INFO: (13) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 47.384817ms)
Nov 11 21:54:06.145: INFO: (13) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 47.42617ms)
Nov 11 21:54:06.146: INFO: (13) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 47.958303ms)
Nov 11 21:54:06.146: INFO: (13) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 48.970517ms)
Nov 11 21:54:06.158: INFO: (14) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 11.766331ms)
Nov 11 21:54:06.160: INFO: (14) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 13.085478ms)
Nov 11 21:54:06.161: INFO: (14) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 14.482017ms)
Nov 11 21:54:06.163: INFO: (14) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 16.243643ms)
Nov 11 21:54:06.163: INFO: (14) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 16.144084ms)
Nov 11 21:54:06.163: INFO: (14) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 16.367227ms)
Nov 11 21:54:06.163: INFO: (14) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 16.847334ms)
Nov 11 21:54:06.164: INFO: (14) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 16.886681ms)
Nov 11 21:54:06.164: INFO: (14) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 16.958962ms)
Nov 11 21:54:06.167: INFO: (14) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 19.999002ms)
Nov 11 21:54:06.168: INFO: (14) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 21.685351ms)
Nov 11 21:54:06.168: INFO: (14) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 21.040133ms)
Nov 11 21:54:06.168: INFO: (14) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 20.978254ms)
Nov 11 21:54:06.168: INFO: (14) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 21.117716ms)
Nov 11 21:54:06.168: INFO: (14) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 21.374498ms)
Nov 11 21:54:06.168: INFO: (14) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 21.600292ms)
Nov 11 21:54:06.178: INFO: (15) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 9.34143ms)
Nov 11 21:54:06.180: INFO: (15) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 10.95739ms)
Nov 11 21:54:06.180: INFO: (15) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 11.293638ms)
Nov 11 21:54:06.180: INFO: (15) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 11.510446ms)
Nov 11 21:54:06.180: INFO: (15) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 11.793892ms)
Nov 11 21:54:06.181: INFO: (15) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 11.833579ms)
Nov 11 21:54:06.182: INFO: (15) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 13.442985ms)
Nov 11 21:54:06.182: INFO: (15) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 13.439571ms)
Nov 11 21:54:06.182: INFO: (15) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 13.113659ms)
Nov 11 21:54:06.182: INFO: (15) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 13.370936ms)
Nov 11 21:54:06.182: INFO: (15) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 13.347742ms)
Nov 11 21:54:06.182: INFO: (15) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 13.723911ms)
Nov 11 21:54:06.184: INFO: (15) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 15.44075ms)
Nov 11 21:54:06.184: INFO: (15) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 15.558464ms)
Nov 11 21:54:06.185: INFO: (15) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 16.026712ms)
Nov 11 21:54:06.185: INFO: (15) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 16.145385ms)
Nov 11 21:54:06.203: INFO: (16) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 17.771697ms)
Nov 11 21:54:06.204: INFO: (16) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 18.620594ms)
Nov 11 21:54:06.204: INFO: (16) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 18.462768ms)
Nov 11 21:54:06.205: INFO: (16) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 18.966524ms)
Nov 11 21:54:06.207: INFO: (16) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 21.52255ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 22.145112ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 22.244063ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 22.429658ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 22.845495ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 22.800035ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 22.55962ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 22.625027ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 22.610815ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 23.070694ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 23.020978ms)
Nov 11 21:54:06.208: INFO: (16) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 23.07473ms)
Nov 11 21:54:06.222: INFO: (17) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 12.981244ms)
Nov 11 21:54:06.223: INFO: (17) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 14.080418ms)
Nov 11 21:54:06.223: INFO: (17) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 13.911048ms)
Nov 11 21:54:06.223: INFO: (17) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 14.102516ms)
Nov 11 21:54:06.223: INFO: (17) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 13.885389ms)
Nov 11 21:54:06.223: INFO: (17) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 14.191886ms)
Nov 11 21:54:06.223: INFO: (17) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 14.015036ms)
Nov 11 21:54:06.224: INFO: (17) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 14.667593ms)
Nov 11 21:54:06.224: INFO: (17) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 14.949901ms)
Nov 11 21:54:06.224: INFO: (17) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 15.27519ms)
Nov 11 21:54:06.224: INFO: (17) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 15.356479ms)
Nov 11 21:54:06.225: INFO: (17) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 15.871442ms)
Nov 11 21:54:06.225: INFO: (17) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 16.320701ms)
Nov 11 21:54:06.225: INFO: (17) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 16.576803ms)
Nov 11 21:54:06.226: INFO: (17) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 17.038319ms)
Nov 11 21:54:06.226: INFO: (17) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 17.410556ms)
Nov 11 21:54:06.233: INFO: (18) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 7.086529ms)
Nov 11 21:54:06.234: INFO: (18) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 7.317183ms)
Nov 11 21:54:06.235: INFO: (18) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 8.396591ms)
Nov 11 21:54:06.237: INFO: (18) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 9.903236ms)
Nov 11 21:54:06.237: INFO: (18) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 10.336105ms)
Nov 11 21:54:06.237: INFO: (18) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 10.52831ms)
Nov 11 21:54:06.237: INFO: (18) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 10.473069ms)
Nov 11 21:54:06.237: INFO: (18) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 10.70648ms)
Nov 11 21:54:06.237: INFO: (18) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 10.664043ms)
Nov 11 21:54:06.239: INFO: (18) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 12.008956ms)
Nov 11 21:54:06.239: INFO: (18) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 12.553259ms)
Nov 11 21:54:06.240: INFO: (18) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 13.032496ms)
Nov 11 21:54:06.240: INFO: (18) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 13.290585ms)
Nov 11 21:54:06.240: INFO: (18) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 13.246189ms)
Nov 11 21:54:06.240: INFO: (18) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 13.609157ms)
Nov 11 21:54:06.240: INFO: (18) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 13.312683ms)
Nov 11 21:54:06.250: INFO: (19) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:162/proxy/: bar (200; 9.424077ms)
Nov 11 21:54:06.250: INFO: (19) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:1080/proxy/rewriteme">... (200; 9.682455ms)
Nov 11 21:54:06.250: INFO: (19) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:462/proxy/: tls qux (200; 9.893248ms)
Nov 11 21:54:06.250: INFO: (19) /api/v1/namespaces/proxy-7762/pods/http:proxy-service-swt7d-59w7r:160/proxy/: foo (200; 9.910013ms)
Nov 11 21:54:06.251: INFO: (19) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r/proxy/rewriteme">test</a> (200; 10.489815ms)
Nov 11 21:54:06.251: INFO: (19) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:1080/proxy/rewriteme">test<... (200; 10.718346ms)
Nov 11 21:54:06.251: INFO: (19) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:162/proxy/: bar (200; 11.025795ms)
Nov 11 21:54:06.252: INFO: (19) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/: <a href="/api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:443/proxy/tlsrewritem... (200; 10.896092ms)
Nov 11 21:54:06.252: INFO: (19) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname1/proxy/: foo (200; 11.065943ms)
Nov 11 21:54:06.252: INFO: (19) /api/v1/namespaces/proxy-7762/services/proxy-service-swt7d:portname2/proxy/: bar (200; 11.206077ms)
Nov 11 21:54:06.252: INFO: (19) /api/v1/namespaces/proxy-7762/pods/proxy-service-swt7d-59w7r:160/proxy/: foo (200; 11.236399ms)
Nov 11 21:54:06.252: INFO: (19) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname1/proxy/: tls baz (200; 11.535458ms)
Nov 11 21:54:06.253: INFO: (19) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname1/proxy/: foo (200; 12.446432ms)
Nov 11 21:54:06.254: INFO: (19) /api/v1/namespaces/proxy-7762/pods/https:proxy-service-swt7d-59w7r:460/proxy/: tls baz (200; 13.712337ms)
Nov 11 21:54:06.256: INFO: (19) /api/v1/namespaces/proxy-7762/services/https:proxy-service-swt7d:tlsportname2/proxy/: tls qux (200; 15.764334ms)
Nov 11 21:54:06.258: INFO: (19) /api/v1/namespaces/proxy-7762/services/http:proxy-service-swt7d:portname2/proxy/: bar (200; 17.248207ms)
STEP: deleting ReplicationController proxy-service-swt7d in namespace proxy-7762, will wait for the garbage collector to delete the pods
Nov 11 21:54:06.314: INFO: Deleting ReplicationController proxy-service-swt7d took: 4.085379ms
Nov 11 21:54:07.214: INFO: Terminating ReplicationController proxy-service-swt7d pods took: 900.144886ms
[AfterEach] version v1
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:54:18.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7762" for this suite.

• [SLOW TEST:19.450 seconds]
[sig-network] Proxy
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":277,"completed":205,"skipped":3396,"failed":0}
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:54:18.721: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7365
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:54:19.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7365" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":277,"completed":206,"skipped":3396,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:54:19.278: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Nov 11 21:54:19.849: INFO: Waiting up to 5m0s for pod "downward-api-ffa59122-2179-4d63-a795-e4dac67e4b33" in namespace "downward-api-956" to be "Succeeded or Failed"
Nov 11 21:54:19.850: INFO: Pod "downward-api-ffa59122-2179-4d63-a795-e4dac67e4b33": Phase="Pending", Reason="", readiness=false. Elapsed: 1.762712ms
Nov 11 21:54:21.853: INFO: Pod "downward-api-ffa59122-2179-4d63-a795-e4dac67e4b33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003953039s
Nov 11 21:54:23.855: INFO: Pod "downward-api-ffa59122-2179-4d63-a795-e4dac67e4b33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006474229s
STEP: Saw pod success
Nov 11 21:54:23.855: INFO: Pod "downward-api-ffa59122-2179-4d63-a795-e4dac67e4b33" satisfied condition "Succeeded or Failed"
Nov 11 21:54:23.857: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod downward-api-ffa59122-2179-4d63-a795-e4dac67e4b33 container dapi-container: <nil>
STEP: delete the pod
Nov 11 21:54:23.877: INFO: Waiting for pod downward-api-ffa59122-2179-4d63-a795-e4dac67e4b33 to disappear
Nov 11 21:54:23.883: INFO: Pod downward-api-ffa59122-2179-4d63-a795-e4dac67e4b33 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:54:23.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-956" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":277,"completed":207,"skipped":3415,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:54:23.894: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3531
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-3531/configmap-test-a4639871-f81c-44b0-bd0a-26ca8ca702ff
STEP: Creating a pod to test consume configMaps
Nov 11 21:54:24.618: INFO: Waiting up to 5m0s for pod "pod-configmaps-db971b62-15cb-442f-aa6d-3063db76a13c" in namespace "configmap-3531" to be "Succeeded or Failed"
Nov 11 21:54:24.621: INFO: Pod "pod-configmaps-db971b62-15cb-442f-aa6d-3063db76a13c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.902649ms
Nov 11 21:54:26.624: INFO: Pod "pod-configmaps-db971b62-15cb-442f-aa6d-3063db76a13c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005435496s
Nov 11 21:54:28.626: INFO: Pod "pod-configmaps-db971b62-15cb-442f-aa6d-3063db76a13c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00784283s
STEP: Saw pod success
Nov 11 21:54:28.626: INFO: Pod "pod-configmaps-db971b62-15cb-442f-aa6d-3063db76a13c" satisfied condition "Succeeded or Failed"
Nov 11 21:54:28.628: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-configmaps-db971b62-15cb-442f-aa6d-3063db76a13c container env-test: <nil>
STEP: delete the pod
Nov 11 21:54:28.641: INFO: Waiting for pod pod-configmaps-db971b62-15cb-442f-aa6d-3063db76a13c to disappear
Nov 11 21:54:28.643: INFO: Pod pod-configmaps-db971b62-15cb-442f-aa6d-3063db76a13c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:54:28.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3531" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":208,"skipped":3441,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:54:28.657: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-a4a50b7b-e05e-4d38-b42e-4b71d4a62264
STEP: Creating a pod to test consume configMaps
Nov 11 21:54:29.302: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6e0bbc04-5056-411d-a224-2455759d1b93" in namespace "projected-8329" to be "Succeeded or Failed"
Nov 11 21:54:29.305: INFO: Pod "pod-projected-configmaps-6e0bbc04-5056-411d-a224-2455759d1b93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.778832ms
Nov 11 21:54:31.307: INFO: Pod "pod-projected-configmaps-6e0bbc04-5056-411d-a224-2455759d1b93": Phase="Running", Reason="", readiness=true. Elapsed: 2.005038733s
Nov 11 21:54:33.310: INFO: Pod "pod-projected-configmaps-6e0bbc04-5056-411d-a224-2455759d1b93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007772644s
STEP: Saw pod success
Nov 11 21:54:33.310: INFO: Pod "pod-projected-configmaps-6e0bbc04-5056-411d-a224-2455759d1b93" satisfied condition "Succeeded or Failed"
Nov 11 21:54:33.312: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-projected-configmaps-6e0bbc04-5056-411d-a224-2455759d1b93 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 21:54:33.329: INFO: Waiting for pod pod-projected-configmaps-6e0bbc04-5056-411d-a224-2455759d1b93 to disappear
Nov 11 21:54:33.334: INFO: Pod pod-projected-configmaps-6e0bbc04-5056-411d-a224-2455759d1b93 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:54:33.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8329" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":209,"skipped":3445,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:54:33.343: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Nov 11 21:54:38.013: INFO: Pod pod-hostip-47e758ca-c0d0-4e8a-97b7-3ba66231a492 has hostIP: 172.31.1.177
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:54:38.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4572" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":277,"completed":210,"skipped":3474,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:54:38.019: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7091
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:54:38.588: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Nov 11 21:54:42.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-7091 create -f -'
Nov 11 21:54:42.752: INFO: stderr: ""
Nov 11 21:54:42.752: INFO: stdout: "e2e-test-crd-publish-openapi-7399-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 11 21:54:42.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-7091 delete e2e-test-crd-publish-openapi-7399-crds test-foo'
Nov 11 21:54:42.862: INFO: stderr: ""
Nov 11 21:54:42.862: INFO: stdout: "e2e-test-crd-publish-openapi-7399-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov 11 21:54:42.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-7091 apply -f -'
Nov 11 21:54:43.086: INFO: stderr: ""
Nov 11 21:54:43.086: INFO: stdout: "e2e-test-crd-publish-openapi-7399-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 11 21:54:43.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-7091 delete e2e-test-crd-publish-openapi-7399-crds test-foo'
Nov 11 21:54:43.164: INFO: stderr: ""
Nov 11 21:54:43.164: INFO: stdout: "e2e-test-crd-publish-openapi-7399-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Nov 11 21:54:43.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-7091 create -f -'
Nov 11 21:54:43.334: INFO: rc: 1
Nov 11 21:54:43.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-7091 apply -f -'
Nov 11 21:54:43.566: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Nov 11 21:54:43.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-7091 create -f -'
Nov 11 21:54:43.714: INFO: rc: 1
Nov 11 21:54:43.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 --namespace=crd-publish-openapi-7091 apply -f -'
Nov 11 21:54:43.888: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Nov 11 21:54:43.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 explain e2e-test-crd-publish-openapi-7399-crds'
Nov 11 21:54:44.094: INFO: stderr: ""
Nov 11 21:54:44.094: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7399-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Nov 11 21:54:44.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 explain e2e-test-crd-publish-openapi-7399-crds.metadata'
Nov 11 21:54:44.243: INFO: stderr: ""
Nov 11 21:54:44.243: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7399-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov 11 21:54:44.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 explain e2e-test-crd-publish-openapi-7399-crds.spec'
Nov 11 21:54:44.393: INFO: stderr: ""
Nov 11 21:54:44.393: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7399-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov 11 21:54:44.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 explain e2e-test-crd-publish-openapi-7399-crds.spec.bars'
Nov 11 21:54:44.544: INFO: stderr: ""
Nov 11 21:54:44.544: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7399-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Nov 11 21:54:44.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 explain e2e-test-crd-publish-openapi-7399-crds.spec.bars2'
Nov 11 21:54:44.709: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:54:48.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7091" for this suite.

• [SLOW TEST:10.250 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":277,"completed":211,"skipped":3479,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:54:48.269: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6513
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Nov 11 21:54:48.797: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:54:52.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6513" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":277,"completed":212,"skipped":3498,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:54:52.983: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5627
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 21:54:53.618: INFO: Waiting up to 5m0s for pod "downwardapi-volume-538ba51e-0945-4bc9-92c8-1f8b115403c8" in namespace "projected-5627" to be "Succeeded or Failed"
Nov 11 21:54:53.624: INFO: Pod "downwardapi-volume-538ba51e-0945-4bc9-92c8-1f8b115403c8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.408396ms
Nov 11 21:54:55.626: INFO: Pod "downwardapi-volume-538ba51e-0945-4bc9-92c8-1f8b115403c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007740818s
Nov 11 21:54:57.628: INFO: Pod "downwardapi-volume-538ba51e-0945-4bc9-92c8-1f8b115403c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009973643s
STEP: Saw pod success
Nov 11 21:54:57.628: INFO: Pod "downwardapi-volume-538ba51e-0945-4bc9-92c8-1f8b115403c8" satisfied condition "Succeeded or Failed"
Nov 11 21:54:57.630: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-538ba51e-0945-4bc9-92c8-1f8b115403c8 container client-container: <nil>
STEP: delete the pod
Nov 11 21:54:57.641: INFO: Waiting for pod downwardapi-volume-538ba51e-0945-4bc9-92c8-1f8b115403c8 to disappear
Nov 11 21:54:57.645: INFO: Pod downwardapi-volume-538ba51e-0945-4bc9-92c8-1f8b115403c8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:54:57.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5627" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":277,"completed":213,"skipped":3526,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:54:57.651: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3198
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Nov 11 21:54:58.180: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 11 21:54:58.195: INFO: Waiting for terminating namespaces to be deleted...
Nov 11 21:54:58.202: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-166.us-west-2.compute.internal before test
Nov 11 21:54:58.270: INFO: calico-node-vdd82 from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:54:58.270: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:54:58.270: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:54:58.270: INFO: ucp-nvidia-device-plugin-749cm from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:54:58.270: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:54:58.270: INFO: sonobuoy-e2e-job-9a557cfe0d894233 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:54:58.270: INFO: 	Container e2e ready: true, restart count 0
Nov 11 21:54:58.270: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:54:58.270: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-g728j from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:54:58.270: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:54:58.270: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:54:58.270: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-62.us-west-2.compute.internal before test
Nov 11 21:54:58.277: INFO: calico-node-7npjl from kube-system started at 2020-11-11 20:42:41 +0000 UTC (2 container statuses recorded)
Nov 11 21:54:58.277: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:54:58.277: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:54:58.277: INFO: ucp-nvidia-device-plugin-rwkzr from kube-system started at 2020-11-11 20:42:41 +0000 UTC (1 container statuses recorded)
Nov 11 21:54:58.277: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:54:58.277: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-wkssd from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:54:58.277: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:54:58.277: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:54:58.277: INFO: pod-init-aed1060f-573d-46e6-aa2f-bf0a2e3592fc from init-container-6513 started at 2020-11-11 21:54:49 +0000 UTC (1 container statuses recorded)
Nov 11 21:54:58.277: INFO: 	Container run1 ready: false, restart count 0
Nov 11 21:54:58.277: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-177.us-west-2.compute.internal before test
Nov 11 21:54:58.285: INFO: ucp-nvidia-device-plugin-nsr8m from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:54:58.285: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:54:58.285: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-9pcd4 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:54:58.285: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:54:58.285: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:54:58.285: INFO: calico-node-ppmtk from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:54:58.285: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:54:58.285: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:54:58.285: INFO: sonobuoy from sonobuoy started at 2020-11-11 20:59:16 +0000 UTC (1 container statuses recorded)
Nov 11 21:54:58.285: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-7a02e056-a8f0-42c5-8d39-35c011cee677 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-7a02e056-a8f0-42c5-8d39-35c011cee677 off the node ip-172-31-0-62.us-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7a02e056-a8f0-42c5-8d39-35c011cee677
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:55:02.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3198" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":277,"completed":214,"skipped":3528,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:55:02.489: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9913
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 21:55:03.782: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 21:55:05.788: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728504, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728504, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728504, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740728503, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 21:55:08.802: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:55:08.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9913" for this suite.
STEP: Destroying namespace "webhook-9913-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.568 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":277,"completed":215,"skipped":3532,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:55:09.058: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4875
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Nov 11 21:55:09.685: INFO: Waiting up to 5m0s for pod "downward-api-5abe468e-d658-42be-b84a-949703d7e87d" in namespace "downward-api-4875" to be "Succeeded or Failed"
Nov 11 21:55:09.687: INFO: Pod "downward-api-5abe468e-d658-42be-b84a-949703d7e87d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.728276ms
Nov 11 21:55:11.689: INFO: Pod "downward-api-5abe468e-d658-42be-b84a-949703d7e87d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004192448s
STEP: Saw pod success
Nov 11 21:55:11.689: INFO: Pod "downward-api-5abe468e-d658-42be-b84a-949703d7e87d" satisfied condition "Succeeded or Failed"
Nov 11 21:55:11.691: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downward-api-5abe468e-d658-42be-b84a-949703d7e87d container dapi-container: <nil>
STEP: delete the pod
Nov 11 21:55:11.704: INFO: Waiting for pod downward-api-5abe468e-d658-42be-b84a-949703d7e87d to disappear
Nov 11 21:55:11.707: INFO: Pod downward-api-5abe468e-d658-42be-b84a-949703d7e87d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:55:11.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4875" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":277,"completed":216,"skipped":3579,"failed":0}
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:55:11.714: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2159
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov 11 21:55:12.288: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2159 /api/v1/namespaces/watch-2159/configmaps/e2e-watch-test-resource-version e576f1cc-d2d1-4b8d-ac56-2223a1166e12 28908 0 2020-11-11 21:55:12 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-11-11 21:55:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:55:12.288: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2159 /api/v1/namespaces/watch-2159/configmaps/e2e-watch-test-resource-version e576f1cc-d2d1-4b8d-ac56-2223a1166e12 28909 0 2020-11-11 21:55:12 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-11-11 21:55:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:55:12.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2159" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":277,"completed":217,"skipped":3581,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:55:12.304: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Nov 11 21:55:12.870: INFO: Waiting up to 5m0s for pod "var-expansion-19935b6a-e6a3-4be5-9519-680eeb846574" in namespace "var-expansion-7102" to be "Succeeded or Failed"
Nov 11 21:55:12.873: INFO: Pod "var-expansion-19935b6a-e6a3-4be5-9519-680eeb846574": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123797ms
Nov 11 21:55:14.887: INFO: Pod "var-expansion-19935b6a-e6a3-4be5-9519-680eeb846574": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01604219s
STEP: Saw pod success
Nov 11 21:55:14.887: INFO: Pod "var-expansion-19935b6a-e6a3-4be5-9519-680eeb846574" satisfied condition "Succeeded or Failed"
Nov 11 21:55:14.890: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod var-expansion-19935b6a-e6a3-4be5-9519-680eeb846574 container dapi-container: <nil>
STEP: delete the pod
Nov 11 21:55:14.978: INFO: Waiting for pod var-expansion-19935b6a-e6a3-4be5-9519-680eeb846574 to disappear
Nov 11 21:55:14.989: INFO: Pod var-expansion-19935b6a-e6a3-4be5-9519-680eeb846574 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:55:14.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7102" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":277,"completed":218,"skipped":3608,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:55:15.014: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7537
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:55:15.698: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov 11 21:55:15.736: INFO: Number of nodes with available pods: 0
Nov 11 21:55:15.736: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov 11 21:55:15.755: INFO: Number of nodes with available pods: 0
Nov 11 21:55:15.755: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:16.758: INFO: Number of nodes with available pods: 0
Nov 11 21:55:16.758: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:17.760: INFO: Number of nodes with available pods: 1
Nov 11 21:55:17.760: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov 11 21:55:17.808: INFO: Number of nodes with available pods: 1
Nov 11 21:55:17.808: INFO: Number of running nodes: 0, number of available pods: 1
Nov 11 21:55:18.810: INFO: Number of nodes with available pods: 0
Nov 11 21:55:18.810: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov 11 21:55:18.846: INFO: Number of nodes with available pods: 0
Nov 11 21:55:18.846: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:19.849: INFO: Number of nodes with available pods: 0
Nov 11 21:55:19.849: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:20.849: INFO: Number of nodes with available pods: 0
Nov 11 21:55:20.849: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:21.850: INFO: Number of nodes with available pods: 0
Nov 11 21:55:21.850: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:22.849: INFO: Number of nodes with available pods: 0
Nov 11 21:55:22.849: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:23.852: INFO: Number of nodes with available pods: 0
Nov 11 21:55:23.852: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:24.849: INFO: Number of nodes with available pods: 0
Nov 11 21:55:24.849: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:25.848: INFO: Number of nodes with available pods: 0
Nov 11 21:55:25.848: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:26.848: INFO: Number of nodes with available pods: 0
Nov 11 21:55:26.848: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:27.848: INFO: Number of nodes with available pods: 0
Nov 11 21:55:27.848: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:28.848: INFO: Number of nodes with available pods: 0
Nov 11 21:55:28.848: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:29.849: INFO: Number of nodes with available pods: 0
Nov 11 21:55:29.849: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 21:55:30.850: INFO: Number of nodes with available pods: 1
Nov 11 21:55:30.850: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7537, will wait for the garbage collector to delete the pods
Nov 11 21:55:30.910: INFO: Deleting DaemonSet.extensions daemon-set took: 4.176014ms
Nov 11 21:55:31.110: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.147811ms
Nov 11 21:55:34.712: INFO: Number of nodes with available pods: 0
Nov 11 21:55:34.712: INFO: Number of running nodes: 0, number of available pods: 0
Nov 11 21:55:34.713: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7537/daemonsets","resourceVersion":"29119"},"items":null}

Nov 11 21:55:34.715: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7537/pods","resourceVersion":"29119"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:55:34.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7537" for this suite.

• [SLOW TEST:19.728 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":277,"completed":219,"skipped":3620,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:55:34.744: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3016
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3016
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-3016
I1111 21:55:35.334693      21 runners.go:190] Created replication controller with name: externalname-service, namespace: services-3016, replica count: 2
I1111 21:55:38.385279      21 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 21:55:38.385: INFO: Creating new exec pod
Nov 11 21:55:43.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-3016 execpod8nhsm -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov 11 21:55:43.656: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 11 21:55:43.656: INFO: stdout: ""
Nov 11 21:55:43.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-3016 execpod8nhsm -- /bin/sh -x -c nc -zv -t -w 2 10.96.126.215 80'
Nov 11 21:55:43.862: INFO: stderr: "+ nc -zv -t -w 2 10.96.126.215 80\nConnection to 10.96.126.215 80 port [tcp/http] succeeded!\n"
Nov 11 21:55:43.862: INFO: stdout: ""
Nov 11 21:55:43.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-3016 execpod8nhsm -- /bin/sh -x -c nc -zv -t -w 2 172.31.0.62 32108'
Nov 11 21:55:44.057: INFO: stderr: "+ nc -zv -t -w 2 172.31.0.62 32108\nConnection to 172.31.0.62 32108 port [tcp/32108] succeeded!\n"
Nov 11 21:55:44.057: INFO: stdout: ""
Nov 11 21:55:44.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-3016 execpod8nhsm -- /bin/sh -x -c nc -zv -t -w 2 172.31.1.177 32108'
Nov 11 21:55:44.253: INFO: stderr: "+ nc -zv -t -w 2 172.31.1.177 32108\nConnection to 172.31.1.177 32108 port [tcp/32108] succeeded!\n"
Nov 11 21:55:44.253: INFO: stdout: ""
Nov 11 21:55:44.253: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:55:44.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3016" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:9.531 seconds]
[sig-network] Services
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":277,"completed":220,"skipped":3662,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:55:44.276: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9991
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9991.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9991.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9991.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9991.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9991.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9991.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9991.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9991.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9991.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9991.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 11 21:55:46.970: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local from pod dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820: the server could not find the requested resource (get pods dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820)
Nov 11 21:55:46.972: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local from pod dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820: the server could not find the requested resource (get pods dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820)
Nov 11 21:55:46.975: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9991.svc.cluster.local from pod dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820: the server could not find the requested resource (get pods dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820)
Nov 11 21:55:46.978: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9991.svc.cluster.local from pod dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820: the server could not find the requested resource (get pods dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820)
Nov 11 21:55:46.985: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local from pod dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820: the server could not find the requested resource (get pods dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820)
Nov 11 21:55:46.987: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local from pod dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820: the server could not find the requested resource (get pods dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820)
Nov 11 21:55:46.990: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9991.svc.cluster.local from pod dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820: the server could not find the requested resource (get pods dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820)
Nov 11 21:55:46.992: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9991.svc.cluster.local from pod dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820: the server could not find the requested resource (get pods dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820)
Nov 11 21:55:46.997: INFO: Lookups using dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9991.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9991.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9991.svc.cluster.local jessie_udp@dns-test-service-2.dns-9991.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9991.svc.cluster.local]

Nov 11 21:55:52.027: INFO: DNS probes using dns-9991/dns-test-b3591cb6-a48b-4dcb-9e4e-eae28951a820 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:55:52.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9991" for this suite.

• [SLOW TEST:7.847 seconds]
[sig-network] DNS
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":277,"completed":221,"skipped":3703,"failed":0}
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:55:52.124: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1324
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov 11 21:55:52.687: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1324 /api/v1/namespaces/watch-1324/configmaps/e2e-watch-test-label-changed 6ac449af-2b3d-44ea-8279-781637133a11 29356 0 2020-11-11 21:55:52 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-11-11 21:55:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:55:52.687: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1324 /api/v1/namespaces/watch-1324/configmaps/e2e-watch-test-label-changed 6ac449af-2b3d-44ea-8279-781637133a11 29357 0 2020-11-11 21:55:52 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-11-11 21:55:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:55:52.687: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1324 /api/v1/namespaces/watch-1324/configmaps/e2e-watch-test-label-changed 6ac449af-2b3d-44ea-8279-781637133a11 29358 0 2020-11-11 21:55:52 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-11-11 21:55:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov 11 21:56:02.708: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1324 /api/v1/namespaces/watch-1324/configmaps/e2e-watch-test-label-changed 6ac449af-2b3d-44ea-8279-781637133a11 29414 0 2020-11-11 21:55:52 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-11-11 21:56:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:56:02.709: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1324 /api/v1/namespaces/watch-1324/configmaps/e2e-watch-test-label-changed 6ac449af-2b3d-44ea-8279-781637133a11 29415 0 2020-11-11 21:55:52 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-11-11 21:56:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 21:56:02.709: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1324 /api/v1/namespaces/watch-1324/configmaps/e2e-watch-test-label-changed 6ac449af-2b3d-44ea-8279-781637133a11 29416 0 2020-11-11 21:55:52 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-11-11 21:56:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:56:02.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1324" for this suite.

• [SLOW TEST:10.602 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":277,"completed":222,"skipped":3706,"failed":0}
SSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:56:02.726: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-8775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Nov 11 21:56:03.255: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 11 21:57:03.276: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 21:57:03.278: INFO: Starting informer...
STEP: Starting pod...
Nov 11 21:57:03.727: INFO: Pod is running on ip-172-31-0-62.us-west-2.compute.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Nov 11 21:57:03.744: INFO: Pod wasn't evicted. Proceeding
Nov 11 21:57:03.744: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Nov 11 21:58:18.790: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:58:18.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8775" for this suite.

• [SLOW TEST:136.072 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":277,"completed":223,"skipped":3711,"failed":0}
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:58:18.798: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6166
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 11 21:58:27.479: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 11 21:58:27.481: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 11 21:58:29.482: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 11 21:58:29.490: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 11 21:58:31.482: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 11 21:58:31.484: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:58:31.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6166" for this suite.

• [SLOW TEST:12.693 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":277,"completed":224,"skipped":3715,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:58:31.491: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 11 21:58:32.056: INFO: Waiting up to 5m0s for pod "pod-e00c297f-b9e0-49eb-b62b-87571c7d6c66" in namespace "emptydir-8443" to be "Succeeded or Failed"
Nov 11 21:58:32.059: INFO: Pod "pod-e00c297f-b9e0-49eb-b62b-87571c7d6c66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126938ms
Nov 11 21:58:34.061: INFO: Pod "pod-e00c297f-b9e0-49eb-b62b-87571c7d6c66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0044871s
STEP: Saw pod success
Nov 11 21:58:34.061: INFO: Pod "pod-e00c297f-b9e0-49eb-b62b-87571c7d6c66" satisfied condition "Succeeded or Failed"
Nov 11 21:58:34.063: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-e00c297f-b9e0-49eb-b62b-87571c7d6c66 container test-container: <nil>
STEP: delete the pod
Nov 11 21:58:34.076: INFO: Waiting for pod pod-e00c297f-b9e0-49eb-b62b-87571c7d6c66 to disappear
Nov 11 21:58:34.079: INFO: Pod pod-e00c297f-b9e0-49eb-b62b-87571c7d6c66 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 21:58:34.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8443" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":225,"skipped":3731,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 21:58:34.096: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9942
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Nov 11 21:58:34.629: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 11 21:58:34.638: INFO: Waiting for terminating namespaces to be deleted...
Nov 11 21:58:34.640: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-166.us-west-2.compute.internal before test
Nov 11 21:58:34.648: INFO: calico-node-vdd82 from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:58:34.648: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:58:34.648: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:58:34.648: INFO: ucp-nvidia-device-plugin-749cm from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:58:34.648: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:58:34.648: INFO: sonobuoy-e2e-job-9a557cfe0d894233 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:58:34.648: INFO: 	Container e2e ready: true, restart count 0
Nov 11 21:58:34.648: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:58:34.648: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-g728j from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:58:34.648: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:58:34.648: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:58:34.648: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-0-62.us-west-2.compute.internal before test
Nov 11 21:58:34.652: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-n2lkp from sonobuoy started at 2020-11-11 21:57:40 +0000 UTC (2 container statuses recorded)
Nov 11 21:58:34.652: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:58:34.652: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:58:34.652: INFO: calico-node-7npjl from kube-system started at 2020-11-11 20:42:41 +0000 UTC (2 container statuses recorded)
Nov 11 21:58:34.652: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:58:34.652: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:58:34.652: INFO: ucp-nvidia-device-plugin-rwkzr from kube-system started at 2020-11-11 20:42:41 +0000 UTC (1 container statuses recorded)
Nov 11 21:58:34.652: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:58:34.652: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-1-177.us-west-2.compute.internal before test
Nov 11 21:58:34.659: INFO: ucp-nvidia-device-plugin-nsr8m from kube-system started at 2020-11-11 20:42:38 +0000 UTC (1 container statuses recorded)
Nov 11 21:58:34.659: INFO: 	Container ucp-nvidia-device-plugin ready: true, restart count 0
Nov 11 21:58:34.659: INFO: sonobuoy-systemd-logs-daemon-set-4693c5d49cb04180-9pcd4 from sonobuoy started at 2020-11-11 20:59:21 +0000 UTC (2 container statuses recorded)
Nov 11 21:58:34.659: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 21:58:34.659: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 21:58:34.659: INFO: pod-handle-http-request from container-lifecycle-hook-6166 started at 2020-11-11 21:58:19 +0000 UTC (1 container statuses recorded)
Nov 11 21:58:34.659: INFO: 	Container pod-handle-http-request ready: true, restart count 0
Nov 11 21:58:34.659: INFO: calico-node-ppmtk from kube-system started at 2020-11-11 20:42:38 +0000 UTC (2 container statuses recorded)
Nov 11 21:58:34.659: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 21:58:34.659: INFO: 	Container install-cni ready: true, restart count 0
Nov 11 21:58:34.659: INFO: sonobuoy from sonobuoy started at 2020-11-11 20:59:16 +0000 UTC (1 container statuses recorded)
Nov 11 21:58:34.659: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3afcc45c-0bd4-463a-b98c-ce7e51f18980 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-3afcc45c-0bd4-463a-b98c-ce7e51f18980 off the node ip-172-31-0-62.us-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3afcc45c-0bd4-463a-b98c-ce7e51f18980
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:03:42.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9942" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:308.792 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":277,"completed":226,"skipped":3749,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:03:42.888: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9073
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-9073
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Nov 11 22:03:43.464: INFO: Found 0 stateful pods, waiting for 3
Nov 11 22:03:53.469: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 22:03:53.469: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 22:03:53.469: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov 11 22:03:53.520: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov 11 22:04:03.572: INFO: Updating stateful set ss2
Nov 11 22:04:03.576: INFO: Waiting for Pod statefulset-9073/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Nov 11 22:04:13.642: INFO: Found 1 stateful pods, waiting for 3
Nov 11 22:04:23.644: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 22:04:23.644: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 22:04:23.644: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov 11 22:04:23.689: INFO: Updating stateful set ss2
Nov 11 22:04:23.693: INFO: Waiting for Pod statefulset-9073/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 11 22:04:33.740: INFO: Updating stateful set ss2
Nov 11 22:04:33.743: INFO: Waiting for StatefulSet statefulset-9073/ss2 to complete update
Nov 11 22:04:33.743: INFO: Waiting for Pod statefulset-9073/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Nov 11 22:04:43.748: INFO: Deleting all statefulset in ns statefulset-9073
Nov 11 22:04:43.749: INFO: Scaling statefulset ss2 to 0
Nov 11 22:05:03.796: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 22:05:03.798: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:05:03.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9073" for this suite.

• [SLOW TEST:80.927 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":277,"completed":227,"skipped":3763,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:05:03.815: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Nov 11 22:05:04.393: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:05:08.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9700" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":277,"completed":228,"skipped":3837,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:05:08.671: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1858
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 22:05:09.641: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 22:05:11.647: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729110, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729110, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729110, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729109, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 22:05:14.658: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 22:05:14.662: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:05:15.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1858" for this suite.
STEP: Destroying namespace "webhook-1858-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.134 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":277,"completed":229,"skipped":3837,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:05:15.806: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3470
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-aa115162-2045-462b-a151-2e972200c77c in namespace container-probe-3470
Nov 11 22:05:20.352: INFO: Started pod busybox-aa115162-2045-462b-a151-2e972200c77c in namespace container-probe-3470
STEP: checking the pod's current state and verifying that restartCount is present
Nov 11 22:05:20.354: INFO: Initial restart count of pod busybox-aa115162-2045-462b-a151-2e972200c77c is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:09:20.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3470" for this suite.

• [SLOW TEST:244.886 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":230,"skipped":3861,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:09:20.693: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4273
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-4273/secret-test-8dce0c79-48c5-4764-a3a2-e1262baa9f38
STEP: Creating a pod to test consume secrets
Nov 11 22:09:21.266: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e182429-bfd8-479e-a0ea-627f319586cf" in namespace "secrets-4273" to be "Succeeded or Failed"
Nov 11 22:09:21.267: INFO: Pod "pod-configmaps-9e182429-bfd8-479e-a0ea-627f319586cf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.623307ms
Nov 11 22:09:23.270: INFO: Pod "pod-configmaps-9e182429-bfd8-479e-a0ea-627f319586cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003916125s
Nov 11 22:09:25.273: INFO: Pod "pod-configmaps-9e182429-bfd8-479e-a0ea-627f319586cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006832952s
STEP: Saw pod success
Nov 11 22:09:25.273: INFO: Pod "pod-configmaps-9e182429-bfd8-479e-a0ea-627f319586cf" satisfied condition "Succeeded or Failed"
Nov 11 22:09:25.274: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-configmaps-9e182429-bfd8-479e-a0ea-627f319586cf container env-test: <nil>
STEP: delete the pod
Nov 11 22:09:25.292: INFO: Waiting for pod pod-configmaps-9e182429-bfd8-479e-a0ea-627f319586cf to disappear
Nov 11 22:09:25.295: INFO: Pod pod-configmaps-9e182429-bfd8-479e-a0ea-627f319586cf no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:09:25.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4273" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":231,"skipped":3874,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:09:25.303: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4937
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 22:09:26.659: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 22:09:28.664: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729367, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729367, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729367, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729366, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 22:09:31.688: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Nov 11 22:09:31.704: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:09:31.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4937" for this suite.
STEP: Destroying namespace "webhook-4937-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.453 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":277,"completed":232,"skipped":3885,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:09:31.756: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-874
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Nov 11 22:09:32.251: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Nov 11 22:09:45.526: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 22:09:49.058: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:10:02.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-874" for this suite.

• [SLOW TEST:31.130 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":277,"completed":233,"skipped":3920,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:10:02.890: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4414
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:10:03.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4414" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":277,"completed":234,"skipped":3948,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:10:03.435: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3883
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 22:10:03.985: INFO: Creating deployment "test-recreate-deployment"
Nov 11 22:10:04.032: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 11 22:10:04.036: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Nov 11 22:10:06.040: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 11 22:10:06.042: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729404, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729404, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729404, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729404, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 22:10:08.044: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 11 22:10:08.083: INFO: Updating deployment test-recreate-deployment
Nov 11 22:10:08.083: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Nov 11 22:10:09.435: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-3883 /apis/apps/v1/namespaces/deployment-3883/deployments/test-recreate-deployment 557fecc9-35b5-411c-a430-c7c0abc3672a 32984 2 2020-11-11 22:10:04 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-11-11 22:10:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-11-11 22:10:09 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006aa62b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-11-11 22:10:08 +0000 UTC,LastTransitionTime:2020-11-11 22:10:08 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-11-11 22:10:09 +0000 UTC,LastTransitionTime:2020-11-11 22:10:04 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov 11 22:10:09.438: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-3883 /apis/apps/v1/namespaces/deployment-3883/replicasets/test-recreate-deployment-d5667d9c7 6b6e04c8-d1ee-48dc-8c2c-a2a904fe0b97 32978 1 2020-11-11 22:10:08 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 557fecc9-35b5-411c-a430-c7c0abc3672a 0xc006aa68c0 0xc006aa68c1}] []  [{kube-controller-manager Update apps/v1 2020-11-11 22:10:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 53 55 102 101 99 99 57 45 51 53 98 53 45 52 49 49 99 45 97 52 51 48 45 99 55 99 48 97 98 99 51 54 55 50 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006aa6938 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 11 22:10:09.438: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 11 22:10:09.439: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-3883 /apis/apps/v1/namespaces/deployment-3883/replicasets/test-recreate-deployment-74d98b5f7c d1850f3a-18ed-47aa-b2f2-886dc9ea41fa 32953 2 2020-11-11 22:10:04 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 557fecc9-35b5-411c-a430-c7c0abc3672a 0xc006aa67c7 0xc006aa67c8}] []  [{kube-controller-manager Update apps/v1 2020-11-11 22:10:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 53 55 102 101 99 99 57 45 51 53 98 53 45 52 49 49 99 45 97 52 51 48 45 99 55 99 48 97 98 99 51 54 55 50 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006aa6858 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 11 22:10:09.441: INFO: Pod "test-recreate-deployment-d5667d9c7-b74th" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-b74th test-recreate-deployment-d5667d9c7- deployment-3883 /api/v1/namespaces/deployment-3883/pods/test-recreate-deployment-d5667d9c7-b74th 6b3dd034-b108-4bac-a574-6b6aa93198d9 32983 0 2020-11-11 22:10:08 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 6b6e04c8-d1ee-48dc-8c2c-a2a904fe0b97 0xc006b76f50 0xc006b76f51}] []  [{kube-controller-manager Update v1 2020-11-11 22:10:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 98 54 101 48 52 99 56 45 100 49 101 101 45 52 56 100 99 45 56 99 50 99 45 97 50 97 57 48 52 102 101 48 98 57 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:10:09 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-f7628,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-f7628,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-f7628,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:10:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:10:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:10:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:10:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:,StartTime:2020-11-11 22:10:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:10:09.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3883" for this suite.

• [SLOW TEST:6.016 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":235,"skipped":3961,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:10:09.453: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5917
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-feceac42-2c8a-4f47-acf9-d0da8e2c22a8
STEP: Creating a pod to test consume configMaps
Nov 11 22:10:10.038: INFO: Waiting up to 5m0s for pod "pod-configmaps-414b0968-0f4c-48f2-a7d6-2e48b5fedc3a" in namespace "configmap-5917" to be "Succeeded or Failed"
Nov 11 22:10:10.041: INFO: Pod "pod-configmaps-414b0968-0f4c-48f2-a7d6-2e48b5fedc3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070878ms
Nov 11 22:10:12.043: INFO: Pod "pod-configmaps-414b0968-0f4c-48f2-a7d6-2e48b5fedc3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004394717s
STEP: Saw pod success
Nov 11 22:10:12.043: INFO: Pod "pod-configmaps-414b0968-0f4c-48f2-a7d6-2e48b5fedc3a" satisfied condition "Succeeded or Failed"
Nov 11 22:10:12.045: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod pod-configmaps-414b0968-0f4c-48f2-a7d6-2e48b5fedc3a container configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 22:10:12.067: INFO: Waiting for pod pod-configmaps-414b0968-0f4c-48f2-a7d6-2e48b5fedc3a to disappear
Nov 11 22:10:12.070: INFO: Pod pod-configmaps-414b0968-0f4c-48f2-a7d6-2e48b5fedc3a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:10:12.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5917" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":236,"skipped":4003,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:10:12.078: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2960
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-756ef6ae-8c38-4272-9b83-b5af1f5db29f
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:10:12.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2960" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":277,"completed":237,"skipped":4012,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:10:12.711: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2858
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:10:30.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2858" for this suite.

• [SLOW TEST:17.573 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":277,"completed":238,"skipped":4023,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:10:30.284: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8842
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-3def6168-dcb6-4964-8847-fdb39191e874
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:10:30.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8842" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":277,"completed":239,"skipped":4059,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:10:30.821: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 11 22:10:31.412: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:31.413: INFO: Number of nodes with available pods: 0
Nov 11 22:10:31.413: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:32.418: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:32.422: INFO: Number of nodes with available pods: 0
Nov 11 22:10:32.422: INFO: Node ip-172-31-0-166.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:33.429: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:33.433: INFO: Number of nodes with available pods: 1
Nov 11 22:10:33.433: INFO: Node ip-172-31-0-62.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:34.418: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:34.420: INFO: Number of nodes with available pods: 3
Nov 11 22:10:34.420: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov 11 22:10:34.431: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:34.433: INFO: Number of nodes with available pods: 2
Nov 11 22:10:34.433: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:35.438: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:35.442: INFO: Number of nodes with available pods: 2
Nov 11 22:10:35.442: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:36.440: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:36.443: INFO: Number of nodes with available pods: 2
Nov 11 22:10:36.443: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:37.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:37.439: INFO: Number of nodes with available pods: 2
Nov 11 22:10:37.439: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:38.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:38.442: INFO: Number of nodes with available pods: 2
Nov 11 22:10:38.442: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:39.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:39.440: INFO: Number of nodes with available pods: 2
Nov 11 22:10:39.440: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:40.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:40.439: INFO: Number of nodes with available pods: 2
Nov 11 22:10:40.440: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:41.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:41.439: INFO: Number of nodes with available pods: 2
Nov 11 22:10:41.439: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:42.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:42.439: INFO: Number of nodes with available pods: 2
Nov 11 22:10:42.439: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:43.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:43.439: INFO: Number of nodes with available pods: 2
Nov 11 22:10:43.439: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:44.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:44.442: INFO: Number of nodes with available pods: 2
Nov 11 22:10:44.442: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:45.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:45.439: INFO: Number of nodes with available pods: 2
Nov 11 22:10:45.439: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:46.438: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:46.441: INFO: Number of nodes with available pods: 2
Nov 11 22:10:46.441: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:47.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:47.439: INFO: Number of nodes with available pods: 2
Nov 11 22:10:47.439: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:48.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:48.439: INFO: Number of nodes with available pods: 2
Nov 11 22:10:48.439: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:49.438: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:49.440: INFO: Number of nodes with available pods: 2
Nov 11 22:10:49.440: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:50.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:50.439: INFO: Number of nodes with available pods: 2
Nov 11 22:10:50.439: INFO: Node ip-172-31-1-177.us-west-2.compute.internal is running more than one daemon pod
Nov 11 22:10:51.437: INFO: DaemonSet pods can't tolerate node ip-172-31-0-56.us-west-2.compute.internal with taints [{Key:com.docker.ucp.manager Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 11 22:10:51.439: INFO: Number of nodes with available pods: 3
Nov 11 22:10:51.439: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1252, will wait for the garbage collector to delete the pods
Nov 11 22:10:51.497: INFO: Deleting DaemonSet.extensions daemon-set took: 4.008509ms
Nov 11 22:10:52.397: INFO: Terminating DaemonSet.extensions daemon-set pods took: 900.195452ms
Nov 11 22:11:00.899: INFO: Number of nodes with available pods: 0
Nov 11 22:11:00.899: INFO: Number of running nodes: 0, number of available pods: 0
Nov 11 22:11:00.901: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1252/daemonsets","resourceVersion":"33352"},"items":null}

Nov 11 22:11:00.902: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1252/pods","resourceVersion":"33352"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:11:00.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1252" for this suite.

• [SLOW TEST:30.097 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":277,"completed":240,"skipped":4069,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:11:00.918: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-29
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 22:11:01.993: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 22:11:04.041: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729462, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729462, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729462, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729462, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 22:11:07.056: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:11:17.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-29" for this suite.
STEP: Destroying namespace "webhook-29-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.349 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":277,"completed":241,"skipped":4084,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:11:17.268: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 11 22:11:20.759: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:11:20.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8763" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":277,"completed":242,"skipped":4107,"failed":0}

------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:11:20.775: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Nov 11 22:11:21.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-9301'
Nov 11 22:11:21.726: INFO: stderr: ""
Nov 11 22:11:21.726: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 11 22:11:21.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9301'
Nov 11 22:11:21.797: INFO: stderr: ""
Nov 11 22:11:21.797: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Nov 11 22:11:26.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9301'
Nov 11 22:11:26.869: INFO: stderr: ""
Nov 11 22:11:26.869: INFO: stdout: "update-demo-nautilus-7bmxp update-demo-nautilus-986nx "
Nov 11 22:11:26.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-7bmxp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9301'
Nov 11 22:11:26.938: INFO: stderr: ""
Nov 11 22:11:26.938: INFO: stdout: "true"
Nov 11 22:11:26.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-7bmxp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9301'
Nov 11 22:11:27.006: INFO: stderr: ""
Nov 11 22:11:27.006: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 11 22:11:27.006: INFO: validating pod update-demo-nautilus-7bmxp
Nov 11 22:11:27.011: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 22:11:27.011: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 22:11:27.011: INFO: update-demo-nautilus-7bmxp is verified up and running
Nov 11 22:11:27.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-986nx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9301'
Nov 11 22:11:27.079: INFO: stderr: ""
Nov 11 22:11:27.079: INFO: stdout: "true"
Nov 11 22:11:27.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods update-demo-nautilus-986nx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9301'
Nov 11 22:11:27.149: INFO: stderr: ""
Nov 11 22:11:27.149: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 11 22:11:27.149: INFO: validating pod update-demo-nautilus-986nx
Nov 11 22:11:27.152: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 22:11:27.152: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 22:11:27.152: INFO: update-demo-nautilus-986nx is verified up and running
STEP: using delete to clean up resources
Nov 11 22:11:27.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 delete --grace-period=0 --force -f - --namespace=kubectl-9301'
Nov 11 22:11:27.230: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 22:11:27.230: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 11 22:11:27.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9301'
Nov 11 22:11:27.304: INFO: stderr: "No resources found in kubectl-9301 namespace.\n"
Nov 11 22:11:27.304: INFO: stdout: ""
Nov 11 22:11:27.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -l name=update-demo --namespace=kubectl-9301 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 11 22:11:27.375: INFO: stderr: ""
Nov 11 22:11:27.375: INFO: stdout: "update-demo-nautilus-7bmxp\nupdate-demo-nautilus-986nx\n"
Nov 11 22:11:27.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9301'
Nov 11 22:11:27.956: INFO: stderr: "No resources found in kubectl-9301 namespace.\n"
Nov 11 22:11:27.956: INFO: stdout: ""
Nov 11 22:11:27.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 get pods -l name=update-demo --namespace=kubectl-9301 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 11 22:11:28.029: INFO: stderr: ""
Nov 11 22:11:28.029: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:11:28.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9301" for this suite.

• [SLOW TEST:7.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":277,"completed":243,"skipped":4107,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:11:28.036: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3034
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-78
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1597
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:11:43.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3034" for this suite.
STEP: Destroying namespace "nsdeletetest-78" for this suite.
Nov 11 22:11:43.794: INFO: Namespace nsdeletetest-78 was already deleted
STEP: Destroying namespace "nsdeletetest-1597" for this suite.

• [SLOW TEST:15.761 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":277,"completed":244,"skipped":4119,"failed":0}
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:11:43.797: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-182
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:09.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-182" for this suite.

• [SLOW TEST:25.797 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    when starting a container that exits
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":277,"completed":245,"skipped":4121,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:09.594: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9285
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 22:12:10.165: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72bbbee7-5eae-4f8f-99a0-870f204beaba" in namespace "projected-9285" to be "Succeeded or Failed"
Nov 11 22:12:10.167: INFO: Pod "downwardapi-volume-72bbbee7-5eae-4f8f-99a0-870f204beaba": Phase="Pending", Reason="", readiness=false. Elapsed: 1.757822ms
Nov 11 22:12:12.169: INFO: Pod "downwardapi-volume-72bbbee7-5eae-4f8f-99a0-870f204beaba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004492341s
STEP: Saw pod success
Nov 11 22:12:12.169: INFO: Pod "downwardapi-volume-72bbbee7-5eae-4f8f-99a0-870f204beaba" satisfied condition "Succeeded or Failed"
Nov 11 22:12:12.171: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-72bbbee7-5eae-4f8f-99a0-870f204beaba container client-container: <nil>
STEP: delete the pod
Nov 11 22:12:12.186: INFO: Waiting for pod downwardapi-volume-72bbbee7-5eae-4f8f-99a0-870f204beaba to disappear
Nov 11 22:12:12.190: INFO: Pod downwardapi-volume-72bbbee7-5eae-4f8f-99a0-870f204beaba no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:12.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9285" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":246,"skipped":4128,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:12.197: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Nov 11 22:12:12.781: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-504766910 proxy --unix-socket=/tmp/kubectl-proxy-unix327726221/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:12.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4091" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":277,"completed":247,"skipped":4129,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:12.834: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6353
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-6353
STEP: creating replication controller nodeport-test in namespace services-6353
I1111 22:12:13.409744      21 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-6353, replica count: 2
I1111 22:12:16.460215      21 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 22:12:16.460: INFO: Creating new exec pod
Nov 11 22:12:21.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-6353 execpod557vr -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Nov 11 22:12:21.701: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 11 22:12:21.701: INFO: stdout: ""
Nov 11 22:12:21.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-6353 execpod557vr -- /bin/sh -x -c nc -zv -t -w 2 10.96.34.124 80'
Nov 11 22:12:21.896: INFO: stderr: "+ nc -zv -t -w 2 10.96.34.124 80\nConnection to 10.96.34.124 80 port [tcp/http] succeeded!\n"
Nov 11 22:12:21.896: INFO: stdout: ""
Nov 11 22:12:21.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-6353 execpod557vr -- /bin/sh -x -c nc -zv -t -w 2 172.31.1.177 30368'
Nov 11 22:12:22.095: INFO: stderr: "+ nc -zv -t -w 2 172.31.1.177 30368\nConnection to 172.31.1.177 30368 port [tcp/30368] succeeded!\n"
Nov 11 22:12:22.095: INFO: stdout: ""
Nov 11 22:12:22.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=services-6353 execpod557vr -- /bin/sh -x -c nc -zv -t -w 2 172.31.0.166 30368'
Nov 11 22:12:22.296: INFO: stderr: "+ nc -zv -t -w 2 172.31.0.166 30368\nConnection to 172.31.0.166 30368 port [tcp/30368] succeeded!\n"
Nov 11 22:12:22.296: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:22.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6353" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:9.469 seconds]
[sig-network] Services
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":277,"completed":248,"skipped":4141,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:22.303: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-40
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:22.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-40" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":277,"completed":249,"skipped":4201,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:22.892: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1698
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:27.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1698" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":277,"completed":250,"skipped":4211,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:27.489: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3537
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Nov 11 22:12:28.617: INFO: Waiting up to 5m0s for pod "client-containers-79aa45e7-703a-4281-9576-11a834f347a4" in namespace "containers-3537" to be "Succeeded or Failed"
Nov 11 22:12:28.629: INFO: Pod "client-containers-79aa45e7-703a-4281-9576-11a834f347a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.539172ms
Nov 11 22:12:30.631: INFO: Pod "client-containers-79aa45e7-703a-4281-9576-11a834f347a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014017115s
Nov 11 22:12:32.634: INFO: Pod "client-containers-79aa45e7-703a-4281-9576-11a834f347a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016329206s
STEP: Saw pod success
Nov 11 22:12:32.634: INFO: Pod "client-containers-79aa45e7-703a-4281-9576-11a834f347a4" satisfied condition "Succeeded or Failed"
Nov 11 22:12:32.635: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod client-containers-79aa45e7-703a-4281-9576-11a834f347a4 container test-container: <nil>
STEP: delete the pod
Nov 11 22:12:32.648: INFO: Waiting for pod client-containers-79aa45e7-703a-4281-9576-11a834f347a4 to disappear
Nov 11 22:12:32.651: INFO: Pod client-containers-79aa45e7-703a-4281-9576-11a834f347a4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:32.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3537" for this suite.

• [SLOW TEST:5.168 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":277,"completed":251,"skipped":4241,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:32.658: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-5537
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:41.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5537" for this suite.

• [SLOW TEST:8.638 seconds]
[sig-apps] Job
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":277,"completed":252,"skipped":4272,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:41.297: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5551
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 22:12:41.865: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-07c9c578-cea1-44cf-97cf-6194c7318af0" in namespace "security-context-test-5551" to be "Succeeded or Failed"
Nov 11 22:12:41.867: INFO: Pod "busybox-readonly-false-07c9c578-cea1-44cf-97cf-6194c7318af0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.927856ms
Nov 11 22:12:43.870: INFO: Pod "busybox-readonly-false-07c9c578-cea1-44cf-97cf-6194c7318af0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004584235s
Nov 11 22:12:43.870: INFO: Pod "busybox-readonly-false-07c9c578-cea1-44cf-97cf-6194c7318af0" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:43.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5551" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":277,"completed":253,"skipped":4330,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:43.877: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9935
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1111 22:12:54.455527      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 11 22:12:54.455: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:12:54.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9935" for this suite.

• [SLOW TEST:10.586 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":277,"completed":254,"skipped":4335,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:12:54.463: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-7576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov 11 22:12:55.447: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Nov 11 22:12:57.454: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729575, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729575, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729576, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729575, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 22:13:00.466: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 22:13:00.468: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:13:01.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7576" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:7.170 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":277,"completed":255,"skipped":4355,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:13:01.634: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6703
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov 11 22:13:02.222: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6703 /api/v1/namespaces/watch-6703/configmaps/e2e-watch-test-watch-closed d2ee882e-300a-43c9-b80f-32fdb3752a02 34672 0 2020-11-11 22:13:02 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-11-11 22:13:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 22:13:02.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6703 /api/v1/namespaces/watch-6703/configmaps/e2e-watch-test-watch-closed d2ee882e-300a-43c9-b80f-32fdb3752a02 34673 0 2020-11-11 22:13:02 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-11-11 22:13:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov 11 22:13:02.284: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6703 /api/v1/namespaces/watch-6703/configmaps/e2e-watch-test-watch-closed d2ee882e-300a-43c9-b80f-32fdb3752a02 34674 0 2020-11-11 22:13:02 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-11-11 22:13:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 22:13:02.285: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6703 /api/v1/namespaces/watch-6703/configmaps/e2e-watch-test-watch-closed d2ee882e-300a-43c9-b80f-32fdb3752a02 34676 0 2020-11-11 22:13:02 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-11-11 22:13:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:13:02.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6703" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":277,"completed":256,"skipped":4363,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:13:02.293: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-3821
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-3821
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3821
Nov 11 22:13:02.860: INFO: Found 0 stateful pods, waiting for 1
Nov 11 22:13:12.863: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov 11 22:13:12.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 22:13:13.073: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 22:13:13.073: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 22:13:13.073: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 22:13:13.076: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 11 22:13:23.079: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 22:13:23.079: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 22:13:23.113: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Nov 11 22:13:23.113: INFO: ss-0  ip-172-31-0-62.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  }]
Nov 11 22:13:23.113: INFO: 
Nov 11 22:13:23.113: INFO: StatefulSet ss has not reached scale 3, at 1
Nov 11 22:13:24.117: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997869351s
Nov 11 22:13:25.119: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994161594s
Nov 11 22:13:26.123: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991357518s
Nov 11 22:13:27.126: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987522742s
Nov 11 22:13:28.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984901645s
Nov 11 22:13:29.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982695506s
Nov 11 22:13:30.134: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979735794s
Nov 11 22:13:31.136: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976990726s
Nov 11 22:13:32.139: INFO: Verifying statefulset ss doesn't scale past 3 for another 974.27931ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3821
Nov 11 22:13:33.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:13:33.371: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 22:13:33.371: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 22:13:33.371: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 22:13:33.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:13:33.652: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 11 22:13:33.652: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 22:13:33.652: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 22:13:33.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:13:33.874: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 11 22:13:33.875: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 22:13:33.875: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 22:13:33.883: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 22:13:33.883: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 22:13:33.883: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov 11 22:13:33.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 22:13:34.074: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 22:13:34.074: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 22:13:34.074: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 22:13:34.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 22:13:34.271: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 22:13:34.271: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 22:13:34.271: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 22:13:34.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 22:13:34.460: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 22:13:34.460: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 22:13:34.460: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 22:13:34.460: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 22:13:34.462: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov 11 22:13:44.467: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 22:13:44.467: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 22:13:44.467: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 22:13:44.500: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:44.500: INFO: ss-0  ip-172-31-0-62.us-west-2.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  }]
Nov 11 22:13:44.500: INFO: ss-1  ip-172-31-1-177.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:44.500: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:44.500: INFO: 
Nov 11 22:13:44.500: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 11 22:13:45.508: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:45.508: INFO: ss-0  ip-172-31-0-62.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  }]
Nov 11 22:13:45.508: INFO: ss-1  ip-172-31-1-177.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:45.508: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:45.508: INFO: 
Nov 11 22:13:45.508: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 11 22:13:46.512: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:46.512: INFO: ss-0  ip-172-31-0-62.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  }]
Nov 11 22:13:46.512: INFO: ss-1  ip-172-31-1-177.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:46.512: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:46.512: INFO: 
Nov 11 22:13:46.512: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 11 22:13:47.515: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:47.515: INFO: ss-0  ip-172-31-0-62.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  }]
Nov 11 22:13:47.515: INFO: ss-1  ip-172-31-1-177.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:47.515: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:47.515: INFO: 
Nov 11 22:13:47.515: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 11 22:13:48.518: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:48.518: INFO: ss-0  ip-172-31-0-62.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  }]
Nov 11 22:13:48.518: INFO: ss-1  ip-172-31-1-177.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:48.519: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:48.519: INFO: 
Nov 11 22:13:48.519: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 11 22:13:49.521: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:49.521: INFO: ss-0  ip-172-31-0-62.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  }]
Nov 11 22:13:49.521: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:49.521: INFO: 
Nov 11 22:13:49.521: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 11 22:13:50.524: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:50.524: INFO: ss-0  ip-172-31-0-62.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:03 +0000 UTC  }]
Nov 11 22:13:50.524: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:50.524: INFO: 
Nov 11 22:13:50.524: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 11 22:13:51.526: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:51.526: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:51.526: INFO: 
Nov 11 22:13:51.526: INFO: StatefulSet ss has not reached scale 0, at 1
Nov 11 22:13:52.529: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:52.529: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:52.529: INFO: 
Nov 11 22:13:52.529: INFO: StatefulSet ss has not reached scale 0, at 1
Nov 11 22:13:53.532: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Nov 11 22:13:53.532: INFO: ss-2  ip-172-31-0-166.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-11 22:13:23 +0000 UTC  }]
Nov 11 22:13:53.532: INFO: 
Nov 11 22:13:53.532: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3821
Nov 11 22:13:54.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:13:54.617: INFO: rc: 1
Nov 11 22:13:54.617: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Nov 11 22:14:04.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:14:04.688: INFO: rc: 1
Nov 11 22:14:04.688: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:14:14.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:14:14.758: INFO: rc: 1
Nov 11 22:14:14.758: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:14:24.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:14:24.828: INFO: rc: 1
Nov 11 22:14:24.828: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:14:34.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:14:34.898: INFO: rc: 1
Nov 11 22:14:34.898: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:14:44.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:14:44.966: INFO: rc: 1
Nov 11 22:14:44.966: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:14:54.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:14:55.035: INFO: rc: 1
Nov 11 22:14:55.035: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:15:05.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:15:05.106: INFO: rc: 1
Nov 11 22:15:05.106: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:15:15.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:15:15.178: INFO: rc: 1
Nov 11 22:15:15.178: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:15:25.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:15:25.248: INFO: rc: 1
Nov 11 22:15:25.248: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:15:35.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:15:35.316: INFO: rc: 1
Nov 11 22:15:35.316: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:15:45.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:15:45.390: INFO: rc: 1
Nov 11 22:15:45.390: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:15:55.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:15:55.461: INFO: rc: 1
Nov 11 22:15:55.461: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:16:05.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:16:05.532: INFO: rc: 1
Nov 11 22:16:05.532: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:16:15.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:16:15.603: INFO: rc: 1
Nov 11 22:16:15.603: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:16:25.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:16:25.673: INFO: rc: 1
Nov 11 22:16:25.673: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:16:35.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:16:35.744: INFO: rc: 1
Nov 11 22:16:35.744: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:16:45.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:16:45.813: INFO: rc: 1
Nov 11 22:16:45.813: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:16:55.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:16:55.888: INFO: rc: 1
Nov 11 22:16:55.888: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:17:05.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:17:05.965: INFO: rc: 1
Nov 11 22:17:05.965: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:17:15.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:17:16.037: INFO: rc: 1
Nov 11 22:17:16.037: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:17:26.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:17:26.114: INFO: rc: 1
Nov 11 22:17:26.114: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:17:36.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:17:36.184: INFO: rc: 1
Nov 11 22:17:36.184: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:17:46.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:17:46.260: INFO: rc: 1
Nov 11 22:17:46.260: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:17:56.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:17:56.330: INFO: rc: 1
Nov 11 22:17:56.330: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:18:06.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:18:06.401: INFO: rc: 1
Nov 11 22:18:06.401: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:18:16.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:18:16.471: INFO: rc: 1
Nov 11 22:18:16.471: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:18:26.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:18:26.542: INFO: rc: 1
Nov 11 22:18:26.542: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:18:36.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:18:36.617: INFO: rc: 1
Nov 11 22:18:36.617: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:18:46.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:18:46.689: INFO: rc: 1
Nov 11 22:18:46.689: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 11 22:18:56.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 exec --namespace=statefulset-3821 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 22:18:56.758: INFO: rc: 1
Nov 11 22:18:56.759: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Nov 11 22:18:56.759: INFO: Scaling statefulset ss to 0
Nov 11 22:18:56.836: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Nov 11 22:18:56.838: INFO: Deleting all statefulset in ns statefulset-3821
Nov 11 22:18:56.839: INFO: Scaling statefulset ss to 0
Nov 11 22:18:56.935: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 22:18:56.938: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:18:56.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3821" for this suite.

• [SLOW TEST:354.672 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":277,"completed":257,"skipped":4394,"failed":0}
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:18:56.965: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-566
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov 11 22:18:57.574: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov 11 22:19:06.630: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:19:06.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-566" for this suite.

• [SLOW TEST:9.673 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":277,"completed":258,"skipped":4397,"failed":0}
SSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:19:06.638: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-2227
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Nov 11 22:19:07.172: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Nov 11 22:19:07.176: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 11 22:19:07.176: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Nov 11 22:19:07.210: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 11 22:19:07.210: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Nov 11 22:19:07.246: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Nov 11 22:19:07.246: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Nov 11 22:19:14.391: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:19:14.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-2227" for this suite.

• [SLOW TEST:7.796 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":277,"completed":259,"skipped":4403,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:19:14.435: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7587
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:19:19.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7587" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":277,"completed":260,"skipped":4415,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:19:19.058: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 11 22:19:20.010: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 22:19:22.016: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729960, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729960, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729960, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729960, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 11 22:19:25.027: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:19:25.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8583" for this suite.
STEP: Destroying namespace "webhook-8583-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.091 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":277,"completed":261,"skipped":4425,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:19:25.149: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-541
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 22:19:25.872: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a291543-9c9a-4aeb-a10e-11337b5120c0" in namespace "projected-541" to be "Succeeded or Failed"
Nov 11 22:19:25.881: INFO: Pod "downwardapi-volume-5a291543-9c9a-4aeb-a10e-11337b5120c0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.386112ms
Nov 11 22:19:27.883: INFO: Pod "downwardapi-volume-5a291543-9c9a-4aeb-a10e-11337b5120c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010688678s
Nov 11 22:19:29.885: INFO: Pod "downwardapi-volume-5a291543-9c9a-4aeb-a10e-11337b5120c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012974099s
STEP: Saw pod success
Nov 11 22:19:29.885: INFO: Pod "downwardapi-volume-5a291543-9c9a-4aeb-a10e-11337b5120c0" satisfied condition "Succeeded or Failed"
Nov 11 22:19:29.887: INFO: Trying to get logs from node ip-172-31-1-177.us-west-2.compute.internal pod downwardapi-volume-5a291543-9c9a-4aeb-a10e-11337b5120c0 container client-container: <nil>
STEP: delete the pod
Nov 11 22:19:29.907: INFO: Waiting for pod downwardapi-volume-5a291543-9c9a-4aeb-a10e-11337b5120c0 to disappear
Nov 11 22:19:29.909: INFO: Pod downwardapi-volume-5a291543-9c9a-4aeb-a10e-11337b5120c0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:19:29.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-541" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":262,"skipped":4426,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:19:29.916: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5671
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Nov 11 22:19:30.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 create -f - --namespace=kubectl-5671'
Nov 11 22:19:31.194: INFO: stderr: ""
Nov 11 22:19:31.194: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Nov 11 22:19:32.197: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 22:19:32.197: INFO: Found 0 / 1
Nov 11 22:19:33.198: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 22:19:33.198: INFO: Found 0 / 1
Nov 11 22:19:34.197: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 22:19:34.197: INFO: Found 1 / 1
Nov 11 22:19:34.197: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov 11 22:19:34.199: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 22:19:34.199: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 11 22:19:34.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-504766910 patch pod agnhost-master-g8jr7 --namespace=kubectl-5671 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 11 22:19:34.277: INFO: stderr: ""
Nov 11 22:19:34.277: INFO: stdout: "pod/agnhost-master-g8jr7 patched\n"
STEP: checking annotations
Nov 11 22:19:34.279: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 11 22:19:34.279: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:19:34.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5671" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":277,"completed":263,"skipped":4428,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:19:34.286: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5174
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-6c2f808a-91b6-4b93-b318-1f635e4fa6ce
STEP: Creating a pod to test consume configMaps
Nov 11 22:19:34.913: INFO: Waiting up to 5m0s for pod "pod-configmaps-4db7b4e8-77f9-45ee-9736-f914585ef6c2" in namespace "configmap-5174" to be "Succeeded or Failed"
Nov 11 22:19:34.915: INFO: Pod "pod-configmaps-4db7b4e8-77f9-45ee-9736-f914585ef6c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.451773ms
Nov 11 22:19:36.920: INFO: Pod "pod-configmaps-4db7b4e8-77f9-45ee-9736-f914585ef6c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006647891s
STEP: Saw pod success
Nov 11 22:19:36.920: INFO: Pod "pod-configmaps-4db7b4e8-77f9-45ee-9736-f914585ef6c2" satisfied condition "Succeeded or Failed"
Nov 11 22:19:36.921: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-configmaps-4db7b4e8-77f9-45ee-9736-f914585ef6c2 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 11 22:19:36.936: INFO: Waiting for pod pod-configmaps-4db7b4e8-77f9-45ee-9736-f914585ef6c2 to disappear
Nov 11 22:19:36.938: INFO: Pod pod-configmaps-4db7b4e8-77f9-45ee-9736-f914585ef6c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:19:36.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5174" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":264,"skipped":4442,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:19:36.945: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1114
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 22:19:37.473: INFO: Creating deployment "webserver-deployment"
Nov 11 22:19:37.502: INFO: Waiting for observed generation 1
Nov 11 22:19:39.664: INFO: Waiting for all required pods to come up
Nov 11 22:19:39.697: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov 11 22:19:41.741: INFO: Waiting for deployment "webserver-deployment" to complete
Nov 11 22:19:41.745: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov 11 22:19:41.783: INFO: Updating deployment webserver-deployment
Nov 11 22:19:41.783: INFO: Waiting for observed generation 2
Nov 11 22:19:43.787: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 11 22:19:43.790: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 11 22:19:43.791: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 11 22:19:43.796: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 11 22:19:43.796: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 11 22:19:43.798: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 11 22:19:43.801: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov 11 22:19:43.801: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov 11 22:19:43.843: INFO: Updating deployment webserver-deployment
Nov 11 22:19:43.843: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov 11 22:19:43.846: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 11 22:19:45.857: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Nov 11 22:19:45.862: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-1114 /apis/apps/v1/namespaces/deployment-1114/deployments/webserver-deployment ddff9f32-5b86-4085-8cc4-e064be6e644c 36814 3 2020-11-11 22:19:37 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-11-11 22:19:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005132e58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-11-11 22:19:44 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-11-11 22:19:45 +0000 UTC,LastTransitionTime:2020-11-11 22:19:37 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov 11 22:19:45.869: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-1114 /apis/apps/v1/namespaces/deployment-1114/replicasets/webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 36792 3 2020-11-11 22:19:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment ddff9f32-5b86-4085-8cc4-e064be6e644c 0xc00517b087 0xc00517b088}] []  [{kube-controller-manager Update apps/v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 100 102 102 57 102 51 50 45 53 98 56 54 45 52 48 56 53 45 56 99 99 52 45 101 48 54 52 98 101 54 101 54 52 52 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00517b108 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 11 22:19:45.869: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov 11 22:19:45.869: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-1114 /apis/apps/v1/namespaces/deployment-1114/replicasets/webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 36790 3 2020-11-11 22:19:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment ddff9f32-5b86-4085-8cc4-e064be6e644c 0xc00517b167 0xc00517b168}] []  [{kube-controller-manager Update apps/v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 100 102 102 57 102 51 50 45 53 98 56 54 45 52 48 56 53 45 56 99 99 52 45 101 48 54 52 98 101 54 101 54 52 52 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00517b1d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov 11 22:19:45.898: INFO: Pod "webserver-deployment-6676bcd6d4-5825j" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-5825j webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-5825j 6d3d0e08-6af1-4b1e-82e7-8b168a8562f2 36818 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc0051332f7 0xc0051332f8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.905: INFO: Pod "webserver-deployment-6676bcd6d4-5qwrs" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-5qwrs webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-5qwrs e5eea22a-26c9-43dc-9877-3f0e116accfb 36799 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc005133497 0xc005133498}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.913: INFO: Pod "webserver-deployment-6676bcd6d4-9fsxx" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-9fsxx webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-9fsxx ead9b609-35cf-4db0-a896-2acd73165e85 36653 0 2020-11-11 22:19:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc005133637 0xc005133638}] []  [{hyperkube Update v1 2020-11-11 22:19:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:42 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:,StartTime:2020-11-11 22:19:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.913: INFO: Pod "webserver-deployment-6676bcd6d4-9rrcj" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-9rrcj webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-9rrcj 32704ff6-f5bf-44c1-b9b4-411d00529cc5 36646 0 2020-11-11 22:19:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc0051337d0 0xc0051337d1}] []  [{hyperkube Update v1 2020-11-11 22:19:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:42 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:,StartTime:2020-11-11 22:19:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.914: INFO: Pod "webserver-deployment-6676bcd6d4-9t2f8" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-9t2f8 webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-9t2f8 d4753a10-e70e-4232-a898-171a6ca44124 36780 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc005133967 0xc005133968}] []  [{hyperkube Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.914: INFO: Pod "webserver-deployment-6676bcd6d4-d9p5b" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-d9p5b webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-d9p5b 01458583-0974-4265-9eed-94235e93abed 36759 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc005133b07 0xc005133b08}] []  [{hyperkube Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.914: INFO: Pod "webserver-deployment-6676bcd6d4-hdstd" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-hdstd webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-hdstd 00cbaa61-10f3-4ba2-a50c-038a051c0177 36647 0 2020-11-11 22:19:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc005133ca7 0xc005133ca8}] []  [{hyperkube Update v1 2020-11-11 22:19:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:42 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:,StartTime:2020-11-11 22:19:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.921: INFO: Pod "webserver-deployment-6676bcd6d4-hzkgq" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-hzkgq webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-hzkgq 4c7308ad-143d-487e-b2ed-96aec6f65857 36801 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc005133e47 0xc005133e48}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.921: INFO: Pod "webserver-deployment-6676bcd6d4-kdrzs" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-kdrzs webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-kdrzs 394b4794-61e0-4df8-abbc-eae3cc88baa0 36791 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc005133fe0 0xc005133fe1}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.921: INFO: Pod "webserver-deployment-6676bcd6d4-s52sz" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-s52sz webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-s52sz 82918a1b-ce55-42b6-8348-0b64dbb03b4e 36807 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc0050f8180 0xc0050f8181}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.922: INFO: Pod "webserver-deployment-6676bcd6d4-sb7s7" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-sb7s7 webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-sb7s7 0357b2d7-db7f-43b5-ba49-bb2e4a3f8554 36786 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc0050f8327 0xc0050f8328}] []  [{hyperkube Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.929: INFO: Pod "webserver-deployment-6676bcd6d4-tlphs" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-tlphs webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-tlphs 2ceba836-511d-4cd6-9068-9d72fb0a81ac 36809 0 2020-11-11 22:19:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc0050f84c7 0xc0050f84c8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 50 49 49 46 49 49 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:192.168.211.110,StartTime:2020-11-11 22:19:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.211.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.929: INFO: Pod "webserver-deployment-6676bcd6d4-zr6wx" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-zr6wx webserver-deployment-6676bcd6d4- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-6676bcd6d4-zr6wx 0bd42faf-b2aa-450f-a3af-4a6f94baa701 36810 0 2020-11-11 22:19:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 67203ad4-366c-40c2-9192-6e7336d3270e 0xc0050f8690 0xc0050f8691}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 50 48 51 97 100 52 45 51 54 54 99 45 52 48 99 50 45 57 49 57 50 45 54 101 55 51 51 54 100 51 50 55 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 49 48 46 49 48 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:192.168.10.103,StartTime:2020-11-11 22:19:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.10.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.929: INFO: Pod "webserver-deployment-84855cf797-2x4t8" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-2x4t8 webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-2x4t8 12e07c14-fde1-47e3-b9bc-838f5c0a9054 36815 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f8867 0xc0050f8868}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.930: INFO: Pod "webserver-deployment-84855cf797-52rjl" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-52rjl webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-52rjl 8f475500-e717-473f-b47e-1394eb850988 36573 0 2020-11-11 22:19:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f89e7 0xc0050f89e8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 49 48 46 49 48 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:192.168.10.101,StartTime:2020-11-11 22:19:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 22:19:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://c6bae2f5c0477fbb5141b93b11df0dd72c2fbd1d72d389d503f61659db1144f3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.10.101,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.930: INFO: Pod "webserver-deployment-84855cf797-5kz6r" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-5kz6r webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-5kz6r 7b9c5966-89c0-4d66-96f2-bf634d24eee0 36760 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f8b87 0xc0050f8b88}] []  [{hyperkube Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.930: INFO: Pod "webserver-deployment-84855cf797-6s8tj" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6s8tj webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-6s8tj a92dd5a1-08ce-472d-aa50-4f55c77701cc 36817 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f8d07 0xc0050f8d08}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.931: INFO: Pod "webserver-deployment-84855cf797-6w8xg" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6w8xg webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-6w8xg 04eef319-3e35-4ad8-89ec-03c0ae712209 36559 0 2020-11-11 22:19:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f8e87 0xc0050f8e88}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 54 52 46 50 52 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:192.168.64.243,StartTime:2020-11-11 22:19:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 22:19:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://fd1e11f4e1d3e7dd1daa68c2a2ce08a3fc2e1e772cf83ada309b0950d9c8a1d4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.64.243,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.931: INFO: Pod "webserver-deployment-84855cf797-6wpgn" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6wpgn webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-6wpgn c3d825b2-7256-4e3d-b37c-55592a982323 36782 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f9027 0xc0050f9028}] []  [{hyperkube Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.931: INFO: Pod "webserver-deployment-84855cf797-86nwc" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-86nwc webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-86nwc 3f7bf3ba-82df-4b3e-9e6d-f2ca2a256c8e 36797 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f91a7 0xc0050f91a8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.941: INFO: Pod "webserver-deployment-84855cf797-99pz6" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-99pz6 webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-99pz6 0f1a2e7d-a04d-445e-9f53-6c8bf952c0fa 36560 0 2020-11-11 22:19:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f9327 0xc0050f9328}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 54 52 46 50 52 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:192.168.64.241,StartTime:2020-11-11 22:19:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 22:19:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6de8422448e326c9f22e09cd8d1ba74d9281c4bb241608282169f447c38c6758,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.64.241,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.941: INFO: Pod "webserver-deployment-84855cf797-9q775" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9q775 webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-9q775 539e268b-f672-4af0-be72-afc98e50f279 36584 0 2020-11-11 22:19:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f94c7 0xc0050f94c8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 50 49 49 46 49 49 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:192.168.211.111,StartTime:2020-11-11 22:19:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 22:19:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://606312d56181ea54a6e5e1f9203539938719458f30999cce469c742db9ba16f2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.211.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.942: INFO: Pod "webserver-deployment-84855cf797-9qkjt" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9qkjt webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-9qkjt eb130e91-c064-409d-9a3a-7f749a81c50d 36788 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f9667 0xc0050f9668}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.942: INFO: Pod "webserver-deployment-84855cf797-blnlh" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-blnlh webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-blnlh 05319e90-e548-4bba-9ef2-c5149a837af3 36562 0 2020-11-11 22:19:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f97f7 0xc0050f97f8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:38 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 54 52 46 50 52 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-166.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.166,PodIP:192.168.64.242,StartTime:2020-11-11 22:19:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 22:19:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://54416e1220089c54f5fb57c08a6bb7ff8aeea476445fdb655e06be07f3f47ca7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.64.242,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.942: INFO: Pod "webserver-deployment-84855cf797-bz8px" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-bz8px webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-bz8px 66f18e0a-38fa-4302-ae55-c1ea440c2438 36805 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f9997 0xc0050f9998}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.942: INFO: Pod "webserver-deployment-84855cf797-dxgt7" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-dxgt7 webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-dxgt7 8cb6fe8e-ad60-4313-891c-084e1ec7bf06 36585 0 2020-11-11 22:19:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f9b17 0xc0050f9b18}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 50 49 49 46 49 48 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:192.168.211.108,StartTime:2020-11-11 22:19:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 22:19:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://d3a041d4950237dafb02c92d699004e12e88da8a68087dd0927f21cd39437a94,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.211.108,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.943: INFO: Pod "webserver-deployment-84855cf797-j45cg" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-j45cg webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-j45cg 5689c4d5-c475-4093-9e57-dd215dad2316 36828 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f9cb7 0xc0050f9cb8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.949: INFO: Pod "webserver-deployment-84855cf797-mhxjm" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-mhxjm webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-mhxjm 4c87345c-2886-4edb-b980-4bcc9484bb05 36820 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f9e37 0xc0050f9e38}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.949: INFO: Pod "webserver-deployment-84855cf797-n8wxr" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-n8wxr webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-n8wxr 807ff0a8-9a3a-4c05-af88-4ae6d05f00c5 36795 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0050f9fb7 0xc0050f9fb8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.949: INFO: Pod "webserver-deployment-84855cf797-qsnfw" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-qsnfw webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-qsnfw 692035b0-cd42-4d49-ba4c-c2dd2ab785fc 36577 0 2020-11-11 22:19:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc004626287 0xc004626288}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 49 48 46 49 48 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:192.168.10.100,StartTime:2020-11-11 22:19:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 22:19:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://910af246dfdb80fea9ff1a67e1a32fdd02d44cde863331acdc82d7c678694c57,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.10.100,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.950: INFO: Pod "webserver-deployment-84855cf797-rrcst" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rrcst webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-rrcst 027e1583-5be2-47c2-88ea-2c5c49300800 36766 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0046264a7 0xc0046264a8}] []  [{hyperkube Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.950: INFO: Pod "webserver-deployment-84855cf797-whjwc" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-whjwc webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-whjwc 704a1002-d30d-43cb-b8db-6c3050da4a48 36587 0 2020-11-11 22:19:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc0046267a7 0xc0046267a8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:38 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 50 49 49 46 49 48 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-62.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.62,PodIP:192.168.211.109,StartTime:2020-11-11 22:19:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 22:19:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://130fac24e9b9d66fd0420f75b8726f51659c1359deab2cd9c42cc973196bd278,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.211.109,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 22:19:45.950: INFO: Pod "webserver-deployment-84855cf797-xfvc5" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-xfvc5 webserver-deployment-84855cf797- deployment-1114 /api/v1/namespaces/deployment-1114/pods/webserver-deployment-84855cf797-xfvc5 ae885709-9cac-4de2-a225-6a86dfcc83d1 36744 0 2020-11-11 22:19:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 1e43e4ac-4b68-4756-b5a2-dd837abfb886 0xc004626b07 0xc004626b08}] []  [{hyperkube Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {kube-controller-manager Update v1 2020-11-11 22:19:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 101 52 51 101 52 97 99 45 52 98 54 56 45 52 55 53 54 45 98 53 97 50 45 100 100 56 51 55 97 98 102 98 56 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8rqn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8rqn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8rqn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:,StartTime:2020-11-11 22:19:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:19:45.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1114" for this suite.

• [SLOW TEST:9.021 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":277,"completed":265,"skipped":4461,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:19:45.966: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:19:50.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2636" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":277,"completed":266,"skipped":4503,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:19:50.569: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1321
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 22:19:51.098: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 11 22:19:51.130: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 11 22:19:56.135: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 11 22:19:56.135: INFO: Creating deployment "test-rolling-update-deployment"
Nov 11 22:19:56.200: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 11 22:19:56.205: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 11 22:19:58.209: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 11 22:19:58.211: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729996, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729996, loc:(*time.Location)(0x7b665e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729997, loc:(*time.Location)(0x7b665e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63740729996, loc:(*time.Location)(0x7b665e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 22:20:00.213: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Nov 11 22:20:00.219: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-1321 /apis/apps/v1/namespaces/deployment-1321/deployments/test-rolling-update-deployment c4aebf60-abdc-4874-92e6-260ed4163d04 37359 1 2020-11-11 22:19:56 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-11-11 22:19:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-11-11 22:19:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004262688 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-11-11 22:19:56 +0000 UTC,LastTransitionTime:2020-11-11 22:19:56 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-11-11 22:19:59 +0000 UTC,LastTransitionTime:2020-11-11 22:19:56 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 11 22:20:00.222: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-1321 /apis/apps/v1/namespaces/deployment-1321/replicasets/test-rolling-update-deployment-59d5cb45c7 80e45b23-c2dc-4e95-a72d-d756cf8527e9 37343 1 2020-11-11 22:19:56 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment c4aebf60-abdc-4874-92e6-260ed4163d04 0xc004263537 0xc004263538}] []  [{kube-controller-manager Update apps/v1 2020-11-11 22:19:59 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 97 101 98 102 54 48 45 97 98 100 99 45 52 56 55 52 45 57 50 101 54 45 50 54 48 101 100 52 49 54 51 100 48 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0042635d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 11 22:20:00.222: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 11 22:20:00.222: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-1321 /apis/apps/v1/namespaces/deployment-1321/replicasets/test-rolling-update-controller 34a6443d-e126-43cc-b1be-e75dd668bb7b 37356 2 2020-11-11 22:19:51 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment c4aebf60-abdc-4874-92e6-260ed4163d04 0xc004263377 0xc004263378}] []  [{e2e.test Update apps/v1 2020-11-11 22:19:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-11-11 22:19:59 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 52 97 101 98 102 54 48 45 97 98 100 99 45 52 56 55 52 45 57 50 101 54 45 50 54 48 101 100 52 49 54 51 100 48 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004263428 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 11 22:20:00.224: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-lzllc" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-lzllc test-rolling-update-deployment-59d5cb45c7- deployment-1321 /api/v1/namespaces/deployment-1321/pods/test-rolling-update-deployment-59d5cb45c7-lzllc 111b204e-96dc-4b37-b86c-da5be632052a 37342 0 2020-11-11 22:19:56 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 80e45b23-c2dc-4e95-a72d-d756cf8527e9 0xc0074138c7 0xc0074138c8}] []  [{kube-controller-manager Update v1 2020-11-11 22:19:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 48 101 52 53 98 50 51 45 99 50 100 99 45 52 101 57 53 45 97 55 50 100 45 100 55 53 54 99 102 56 53 50 55 101 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {hyperkube Update v1 2020-11-11 22:19:58 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 57 50 46 49 54 56 46 49 48 46 49 49 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jpp88,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jpp88,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jpp88,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-1-177.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-11 22:19:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.1.177,PodIP:192.168.10.112,StartTime:2020-11-11 22:19:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-11 22:19:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://5722920c7db2ba0402a0211a8bb3ce06e65c02b587cd39ec7be2d95351b437f3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.10.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:20:00.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1321" for this suite.

• [SLOW TEST:9.662 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":267,"skipped":4536,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:20:00.232: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2930
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-a8d12b24-f262-403a-a599-ef8b7b0b4bce-3700
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:20:01.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2930" for this suite.
STEP: Destroying namespace "nspatchtest-a8d12b24-f262-403a-a599-ef8b7b0b4bce-3700" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":277,"completed":268,"skipped":4570,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:20:01.348: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3593
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-3593
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 11 22:20:01.911: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 11 22:20:02.048: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 22:20:04.053: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 22:20:06.052: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 22:20:08.050: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 22:20:10.051: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 22:20:12.050: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 22:20:14.050: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 22:20:16.050: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 22:20:18.051: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 22:20:20.057: INFO: The status of Pod netserver-0 is Running (Ready = false)
Nov 11 22:20:22.050: INFO: The status of Pod netserver-0 is Running (Ready = true)
Nov 11 22:20:22.054: INFO: The status of Pod netserver-1 is Running (Ready = true)
Nov 11 22:20:22.058: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Nov 11 22:20:26.155: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.64.252 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3593 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 22:20:26.155: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 22:20:27.316: INFO: Found all expected endpoints: [netserver-0]
Nov 11 22:20:27.319: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.211.121 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3593 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 22:20:27.319: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 22:20:28.447: INFO: Found all expected endpoints: [netserver-1]
Nov 11 22:20:28.450: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.10.113 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3593 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 11 22:20:28.450: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
Nov 11 22:20:29.551: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:20:29.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3593" for this suite.

• [SLOW TEST:28.215 seconds]
[sig-network] Networking
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":269,"skipped":4583,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:20:29.563: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4921
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 22:20:30.192: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a44f1abf-847f-4ea6-8087-a95e049d3160" in namespace "downward-api-4921" to be "Succeeded or Failed"
Nov 11 22:20:30.195: INFO: Pod "downwardapi-volume-a44f1abf-847f-4ea6-8087-a95e049d3160": Phase="Pending", Reason="", readiness=false. Elapsed: 2.587809ms
Nov 11 22:20:32.197: INFO: Pod "downwardapi-volume-a44f1abf-847f-4ea6-8087-a95e049d3160": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005100527s
Nov 11 22:20:34.200: INFO: Pod "downwardapi-volume-a44f1abf-847f-4ea6-8087-a95e049d3160": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007549604s
STEP: Saw pod success
Nov 11 22:20:34.200: INFO: Pod "downwardapi-volume-a44f1abf-847f-4ea6-8087-a95e049d3160" satisfied condition "Succeeded or Failed"
Nov 11 22:20:34.202: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-a44f1abf-847f-4ea6-8087-a95e049d3160 container client-container: <nil>
STEP: delete the pod
Nov 11 22:20:34.213: INFO: Waiting for pod downwardapi-volume-a44f1abf-847f-4ea6-8087-a95e049d3160 to disappear
Nov 11 22:20:34.215: INFO: Pod downwardapi-volume-a44f1abf-847f-4ea6-8087-a95e049d3160 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:20:34.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4921" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":270,"skipped":4589,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:20:34.224: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:20:39.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6837" for this suite.

• [SLOW TEST:5.592 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":277,"completed":271,"skipped":4590,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:20:39.817: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9880
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Nov 11 22:20:40.104: INFO: Waiting up to 5m0s for pod "downwardapi-volume-219b617f-5f58-428e-a428-64d92be95cc3" in namespace "downward-api-9880" to be "Succeeded or Failed"
Nov 11 22:20:40.106: INFO: Pod "downwardapi-volume-219b617f-5f58-428e-a428-64d92be95cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.755072ms
Nov 11 22:20:42.112: INFO: Pod "downwardapi-volume-219b617f-5f58-428e-a428-64d92be95cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008010586s
Nov 11 22:20:44.121: INFO: Pod "downwardapi-volume-219b617f-5f58-428e-a428-64d92be95cc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01701398s
STEP: Saw pod success
Nov 11 22:20:44.121: INFO: Pod "downwardapi-volume-219b617f-5f58-428e-a428-64d92be95cc3" satisfied condition "Succeeded or Failed"
Nov 11 22:20:44.125: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod downwardapi-volume-219b617f-5f58-428e-a428-64d92be95cc3 container client-container: <nil>
STEP: delete the pod
Nov 11 22:20:44.142: INFO: Waiting for pod downwardapi-volume-219b617f-5f58-428e-a428-64d92be95cc3 to disappear
Nov 11 22:20:44.147: INFO: Pod downwardapi-volume-219b617f-5f58-428e-a428-64d92be95cc3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:20:44.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9880" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":272,"skipped":4609,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:20:44.155: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6680.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6680.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6680.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6680.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6680.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6680.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6680.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6680.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6680.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6680.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6680.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 202.47.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.47.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.47.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.47.202_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6680.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6680.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6680.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6680.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6680.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6680.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6680.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6680.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6680.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6680.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6680.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 202.47.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.47.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.47.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.47.202_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 11 22:20:46.795: INFO: Unable to read wheezy_udp@dns-test-service.dns-6680.svc.cluster.local from pod dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0: the server could not find the requested resource (get pods dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0)
Nov 11 22:20:46.798: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6680.svc.cluster.local from pod dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0: the server could not find the requested resource (get pods dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0)
Nov 11 22:20:46.800: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local from pod dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0: the server could not find the requested resource (get pods dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0)
Nov 11 22:20:46.802: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local from pod dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0: the server could not find the requested resource (get pods dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0)
Nov 11 22:20:46.831: INFO: Unable to read jessie_udp@dns-test-service.dns-6680.svc.cluster.local from pod dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0: the server could not find the requested resource (get pods dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0)
Nov 11 22:20:46.833: INFO: Unable to read jessie_tcp@dns-test-service.dns-6680.svc.cluster.local from pod dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0: the server could not find the requested resource (get pods dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0)
Nov 11 22:20:46.835: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local from pod dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0: the server could not find the requested resource (get pods dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0)
Nov 11 22:20:46.837: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local from pod dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0: the server could not find the requested resource (get pods dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0)
Nov 11 22:20:46.849: INFO: Lookups using dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0 failed for: [wheezy_udp@dns-test-service.dns-6680.svc.cluster.local wheezy_tcp@dns-test-service.dns-6680.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local jessie_udp@dns-test-service.dns-6680.svc.cluster.local jessie_tcp@dns-test-service.dns-6680.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6680.svc.cluster.local]

Nov 11 22:20:51.888: INFO: DNS probes using dns-6680/dns-test-14ff6694-7b33-4906-93ab-3a492ed512b0 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:20:51.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6680" for this suite.

• [SLOW TEST:7.850 seconds]
[sig-network] DNS
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":277,"completed":273,"skipped":4631,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:20:52.005: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-1575
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Nov 11 22:20:52.650: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 11 22:21:52.663: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 22:21:52.665: INFO: Starting informer...
STEP: Starting pods...
Nov 11 22:21:53.110: INFO: Pod1 is running on ip-172-31-0-62.us-west-2.compute.internal. Tainting Node
Nov 11 22:21:55.361: INFO: Pod2 is running on ip-172-31-0-62.us-west-2.compute.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Nov 11 22:22:10.885: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov 11 22:22:22.984: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:22:23.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-1575" for this suite.

• [SLOW TEST:91.006 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":277,"completed":274,"skipped":4669,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:22:23.012: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5907
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 11 22:22:23.583: INFO: Waiting up to 5m0s for pod "pod-09cf888d-d6d2-4601-882e-7ff97a6f7227" in namespace "emptydir-5907" to be "Succeeded or Failed"
Nov 11 22:22:23.594: INFO: Pod "pod-09cf888d-d6d2-4601-882e-7ff97a6f7227": Phase="Pending", Reason="", readiness=false. Elapsed: 10.6179ms
Nov 11 22:22:25.596: INFO: Pod "pod-09cf888d-d6d2-4601-882e-7ff97a6f7227": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012656206s
Nov 11 22:22:27.598: INFO: Pod "pod-09cf888d-d6d2-4601-882e-7ff97a6f7227": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015435505s
STEP: Saw pod success
Nov 11 22:22:27.598: INFO: Pod "pod-09cf888d-d6d2-4601-882e-7ff97a6f7227" satisfied condition "Succeeded or Failed"
Nov 11 22:22:27.602: INFO: Trying to get logs from node ip-172-31-0-62.us-west-2.compute.internal pod pod-09cf888d-d6d2-4601-882e-7ff97a6f7227 container test-container: <nil>
STEP: delete the pod
Nov 11 22:22:27.623: INFO: Waiting for pod pod-09cf888d-d6d2-4601-882e-7ff97a6f7227 to disappear
Nov 11 22:22:27.627: INFO: Pod pod-09cf888d-d6d2-4601-882e-7ff97a6f7227 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:22:27.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5907" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":275,"skipped":4680,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:22:27.638: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8225
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Nov 11 22:22:32.723: INFO: Successfully updated pod "labelsupdate71d70984-2c4f-4602-8c08-f2de6981b838"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:22:34.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8225" for this suite.

• [SLOW TEST:7.126 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":276,"skipped":4685,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Nov 11 22:22:34.764: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3919
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Nov 11 22:22:35.306: INFO: >>> kubeConfig: /tmp/kubeconfig-504766910
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.10-rc.0.43+cc9a451a45036b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Nov 11 22:22:39.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3919" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":277,"completed":277,"skipped":4687,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSNov 11 22:22:39.357: INFO: Running AfterSuite actions on all nodes
Nov 11 22:22:39.357: INFO: Running AfterSuite actions on node 1
Nov 11 22:22:39.357: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":277,"completed":277,"skipped":4716,"failed":0}

Ran 277 of 4993 Specs in 4980.446 seconds
SUCCESS! -- 277 Passed | 0 Failed | 0 Pending | 4716 Skipped
PASS

Ginkgo ran 1 suite in 1h23m2.710176684s
Test Suite Passed
