I0930 18:29:19.372736      21 test_context.go:410] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-424726105
I0930 18:29:19.372854      21 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0930 18:29:19.373064      21 e2e.go:124] Starting e2e run "ef588b00-5360-4397-9541-39b2f08d2f33" on Ginkgo node 1
{"msg":"Test Suite starting","total":275,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1601490558 - Will randomize all specs
Will run 275 of 4992 specs

Sep 30 18:29:19.432: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:29:19.434: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 30 18:29:19.446: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 30 18:29:19.465: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 30 18:29:19.465: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Sep 30 18:29:19.465: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 30 18:29:19.470: INFO: e2e test version: v1.18.6
Sep 30 18:29:19.471: INFO: kube-apiserver version: v1.18.8+vmware.1
Sep 30 18:29:19.471: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:29:19.475: INFO: Cluster IP family: ipv4
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:29:19.476: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename subpath
Sep 30 18:29:19.525: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Sep 30 18:29:19.537: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7006
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-955m
STEP: Creating a pod to test atomic-volume-subpath
Sep 30 18:29:19.660: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-955m" in namespace "subpath-7006" to be "Succeeded or Failed"
Sep 30 18:29:19.670: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Pending", Reason="", readiness=false. Elapsed: 9.810078ms
Sep 30 18:29:21.672: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012068694s
Sep 30 18:29:23.675: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014780944s
Sep 30 18:29:25.677: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Running", Reason="", readiness=true. Elapsed: 6.01686648s
Sep 30 18:29:27.679: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Running", Reason="", readiness=true. Elapsed: 8.018942407s
Sep 30 18:29:29.682: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Running", Reason="", readiness=true. Elapsed: 10.021641191s
Sep 30 18:29:31.684: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Running", Reason="", readiness=true. Elapsed: 12.024065309s
Sep 30 18:29:33.687: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Running", Reason="", readiness=true. Elapsed: 14.026653284s
Sep 30 18:29:35.689: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Running", Reason="", readiness=true. Elapsed: 16.028772443s
Sep 30 18:29:37.692: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Running", Reason="", readiness=true. Elapsed: 18.031374985s
Sep 30 18:29:39.694: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Running", Reason="", readiness=true. Elapsed: 20.033807302s
Sep 30 18:29:41.696: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Running", Reason="", readiness=true. Elapsed: 22.036198548s
Sep 30 18:29:43.699: INFO: Pod "pod-subpath-test-configmap-955m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.038697853s
STEP: Saw pod success
Sep 30 18:29:43.699: INFO: Pod "pod-subpath-test-configmap-955m" satisfied condition "Succeeded or Failed"
Sep 30 18:29:43.701: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-subpath-test-configmap-955m container test-container-subpath-configmap-955m: <nil>
STEP: delete the pod
Sep 30 18:29:43.728: INFO: Waiting for pod pod-subpath-test-configmap-955m to disappear
Sep 30 18:29:43.734: INFO: Pod pod-subpath-test-configmap-955m no longer exists
STEP: Deleting pod pod-subpath-test-configmap-955m
Sep 30 18:29:43.734: INFO: Deleting pod "pod-subpath-test-configmap-955m" in namespace "subpath-7006"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:29:43.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7006" for this suite.

â€¢ [SLOW TEST:24.265 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":275,"completed":1,"skipped":4,"failed":0}
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:29:43.742: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-2535
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 30 18:29:43.889: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 30 18:29:43.951: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 18:29:45.953: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 18:29:47.954: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 18:29:49.953: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 18:29:51.953: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:29:53.954: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:29:55.954: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:29:57.953: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:29:59.954: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:30:01.953: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:30:03.953: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:30:05.953: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:30:07.953: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 30 18:30:07.957: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 30 18:30:09.960: INFO: The status of Pod netserver-1 is Running (Ready = true)
Sep 30 18:30:09.963: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Sep 30 18:30:12.000: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.32.8 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2535 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 18:30:12.000: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:30:13.127: INFO: Found all expected endpoints: [netserver-0]
Sep 30 18:30:13.130: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.52.12 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2535 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 18:30:13.130: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:30:14.238: INFO: Found all expected endpoints: [netserver-1]
Sep 30 18:30:14.240: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.200.99.16 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2535 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 18:30:14.240: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:30:15.341: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:30:15.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2535" for this suite.

â€¢ [SLOW TEST:31.606 seconds]
[sig-network] Networking
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":2,"skipped":11,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:30:15.349: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6694
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:30:31.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6694" for this suite.

â€¢ [SLOW TEST:16.251 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":275,"completed":3,"skipped":23,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:30:31.601: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4820
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Sep 30 18:30:31.800: INFO: Created pod &Pod{ObjectMeta:{dns-4820  dns-4820 /api/v1/namespaces/dns-4820/pods/dns-4820 157e4f09-6f89-4365-8a60-0c0c35953d4b 203764 0 2020-09-30 18:30:31 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2020-09-30 18:30:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-75hsk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-75hsk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-75hsk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 18:30:31.814: INFO: The status of Pod dns-4820 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 18:30:33.817: INFO: The status of Pod dns-4820 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Sep 30 18:30:33.817: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4820 PodName:dns-4820 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 18:30:33.817: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Verifying customized DNS server is configured on pod...
Sep 30 18:30:33.911: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4820 PodName:dns-4820 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 18:30:33.911: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:30:34.017: INFO: Deleting pod dns-4820...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:30:34.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4820" for this suite.
â€¢{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":275,"completed":4,"skipped":70,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:30:34.056: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9725
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-004001c9-bdcd-414d-b264-bab505d3287a
STEP: Creating a pod to test consume secrets
Sep 30 18:30:34.212: INFO: Waiting up to 5m0s for pod "pod-secrets-955d9cba-d908-4acb-87e6-5c5ab2057f33" in namespace "secrets-9725" to be "Succeeded or Failed"
Sep 30 18:30:34.224: INFO: Pod "pod-secrets-955d9cba-d908-4acb-87e6-5c5ab2057f33": Phase="Pending", Reason="", readiness=false. Elapsed: 12.08926ms
Sep 30 18:30:36.227: INFO: Pod "pod-secrets-955d9cba-d908-4acb-87e6-5c5ab2057f33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014685512s
STEP: Saw pod success
Sep 30 18:30:36.227: INFO: Pod "pod-secrets-955d9cba-d908-4acb-87e6-5c5ab2057f33" satisfied condition "Succeeded or Failed"
Sep 30 18:30:36.228: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-secrets-955d9cba-d908-4acb-87e6-5c5ab2057f33 container secret-volume-test: <nil>
STEP: delete the pod
Sep 30 18:30:36.247: INFO: Waiting for pod pod-secrets-955d9cba-d908-4acb-87e6-5c5ab2057f33 to disappear
Sep 30 18:30:36.254: INFO: Pod pod-secrets-955d9cba-d908-4acb-87e6-5c5ab2057f33 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:30:36.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9725" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":5,"skipped":115,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:30:36.260: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-9351
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-9351
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9351
STEP: Deleting pre-stop pod
Sep 30 18:30:47.491: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:30:47.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9351" for this suite.

â€¢ [SLOW TEST:11.269 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":275,"completed":6,"skipped":130,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:30:47.530: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Sep 30 18:30:47.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 cluster-info'
Sep 30 18:30:48.894: INFO: stderr: ""
Sep 30 18:30:48.894: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:30:48.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8419" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":275,"completed":7,"skipped":142,"failed":0}
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:30:48.900: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-146
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:30:49.075: INFO: (0) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 11.52537ms)
Sep 30 18:30:49.078: INFO: (1) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.388ms)
Sep 30 18:30:49.080: INFO: (2) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.112923ms)
Sep 30 18:30:49.082: INFO: (3) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.332622ms)
Sep 30 18:30:49.085: INFO: (4) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.143424ms)
Sep 30 18:30:49.088: INFO: (5) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.019474ms)
Sep 30 18:30:49.090: INFO: (6) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.193481ms)
Sep 30 18:30:49.092: INFO: (7) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.235874ms)
Sep 30 18:30:49.094: INFO: (8) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.260171ms)
Sep 30 18:30:49.096: INFO: (9) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.99731ms)
Sep 30 18:30:49.098: INFO: (10) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.866476ms)
Sep 30 18:30:49.100: INFO: (11) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.105338ms)
Sep 30 18:30:49.103: INFO: (12) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.287527ms)
Sep 30 18:30:49.105: INFO: (13) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.29639ms)
Sep 30 18:30:49.108: INFO: (14) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.344834ms)
Sep 30 18:30:49.110: INFO: (15) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.768238ms)
Sep 30 18:30:49.113: INFO: (16) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.291207ms)
Sep 30 18:30:49.115: INFO: (17) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.252332ms)
Sep 30 18:30:49.117: INFO: (18) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.009973ms)
Sep 30 18:30:49.119: INFO: (19) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.162181ms)
[AfterEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:30:49.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-146" for this suite.
â€¢{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":275,"completed":8,"skipped":144,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:30:49.126: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1119
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 30 18:30:49.283: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 30 18:30:49.291: INFO: Waiting for terminating namespaces to be deleted...
Sep 30 18:30:49.292: INFO: 
Logging pods the kubelet thinks is on node 9b360f31-b888-42e4-807a-5f2a0fca8fae before test
Sep 30 18:30:49.301: INFO: sink-controller-7549dc74f7-4qx97 from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.301: INFO: 	Container sink-controller ready: true, restart count 0
Sep 30 18:30:49.301: INFO: wavefront-proxy-68d69454fc-pm5dv from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.301: INFO: 	Container wavefront-proxy ready: true, restart count 0
Sep 30 18:30:49.301: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-5zmhk from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:30:49.301: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 18:30:49.301: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 18:30:49.301: INFO: coredns-854d7dc8c-6rdh4 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.301: INFO: 	Container coredns ready: true, restart count 0
Sep 30 18:30:49.301: INFO: fluent-bit-lpcs8 from pks-system started at 2020-09-29 19:35:27 +0000 UTC (2 container statuses recorded)
Sep 30 18:30:49.301: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 18:30:49.301: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 18:30:49.301: INFO: node-exporter-ws8wb from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.301: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 18:30:49.301: INFO: telegraf-h5t2t from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.301: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 18:30:49.301: INFO: wavefront-collector-drm6c from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.301: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 18:30:49.301: INFO: 
Logging pods the kubelet thinks is on node c4ab02cf-8388-4ee7-9741-792b2ee511a4 before test
Sep 30 18:30:49.332: INFO: event-controller-7775f56b74-zgbbq from pks-system started at 2020-09-29 19:35:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:30:49.332: INFO: 	Container event-controller ready: true, restart count 0
Sep 30 18:30:49.332: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 18:30:49.332: INFO: fluent-bit-fbgsw from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 18:30:49.332: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 18:30:49.332: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 18:30:49.332: INFO: validator-6b476b98c9-d5g8r from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.332: INFO: 	Container validator ready: true, restart count 0
Sep 30 18:30:49.332: INFO: wavefront-collector-94rjj from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.332: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 18:30:49.332: INFO: sonobuoy-e2e-job-953b1e3c972143b8 from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:30:49.332: INFO: 	Container e2e ready: true, restart count 0
Sep 30 18:30:49.333: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 18:30:49.333: INFO: coredns-854d7dc8c-9w7v7 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.333: INFO: 	Container coredns ready: true, restart count 0
Sep 30 18:30:49.333: INFO: observability-manager-684c664cf4-nqrxv from pks-system started at 2020-09-29 19:35:04 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.333: INFO: 	Container observability-manager ready: true, restart count 0
Sep 30 18:30:49.333: INFO: node-exporter-75l6n from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.333: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 18:30:49.333: INFO: telegraf-k5gxd from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.333: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 18:30:49.333: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-gvhcn from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:30:49.333: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 18:30:49.333: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 18:30:49.333: INFO: 
Logging pods the kubelet thinks is on node eb106fc7-933d-47a1-a18a-16aa6514d845 before test
Sep 30 18:30:49.340: INFO: wavefront-collector-hms5p from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.340: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 18:30:49.340: INFO: sonobuoy from sonobuoy started at 2020-09-30 18:29:07 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.340: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 30 18:30:49.340: INFO: metrics-server-6967cb5487-z8t86 from kube-system started at 2020-09-29 19:35:01 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.340: INFO: 	Container metrics-server ready: true, restart count 0
Sep 30 18:30:49.340: INFO: metric-controller-7fd9d59567-hqvsc from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.340: INFO: 	Container metric-controller ready: true, restart count 0
Sep 30 18:30:49.340: INFO: telegraf-z8x2g from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.340: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 18:30:49.340: INFO: cert-generator-e484f2435fc830429fc9747bd002fcda56dd053e-cc5fz from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.341: INFO: 	Container cert-generator ready: false, restart count 0
Sep 30 18:30:49.341: INFO: telemetry-agent-6bcf5c56b-qmz52 from pks-system started at 2020-09-29 19:37:51 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.341: INFO: 	Container fluent-bit-telemetry ready: true, restart count 0
Sep 30 18:30:49.341: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-wgtws from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:30:49.341: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 18:30:49.341: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 18:30:49.341: INFO: server from prestop-9351 started at 2020-09-30 18:30:36 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.341: INFO: 	Container server ready: false, restart count 0
Sep 30 18:30:49.341: INFO: tester from prestop-9351 started at 2020-09-30 18:30:38 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.341: INFO: 	Container tester ready: true, restart count 0
Sep 30 18:30:49.341: INFO: coredns-854d7dc8c-lg4vh from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.341: INFO: 	Container coredns ready: true, restart count 0
Sep 30 18:30:49.341: INFO: fluent-bit-5x9vt from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 18:30:49.341: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 18:30:49.341: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 18:30:49.341: INFO: node-exporter-jgdvm from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:30:49.341: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0ce1481f-b9ae-4d17-a899-2a262bdc5588 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-0ce1481f-b9ae-4d17-a899-2a262bdc5588 off the node 9b360f31-b888-42e4-807a-5f2a0fca8fae
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0ce1481f-b9ae-4d17-a899-2a262bdc5588
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:35:55.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1119" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

â€¢ [SLOW TEST:306.314 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":275,"completed":9,"skipped":199,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:35:55.442: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1172
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:35:55.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1172" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":275,"completed":10,"skipped":227,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:35:55.647: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7211
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-41206728-9a94-4fd3-925a-d0d99be0690b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-41206728-9a94-4fd3-925a-d0d99be0690b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:35:59.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7211" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":275,"completed":11,"skipped":245,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:35:59.895: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1149
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-5a1977be-72dd-4af5-ae5c-2055aa6aa105
STEP: Creating a pod to test consume secrets
Sep 30 18:36:00.045: INFO: Waiting up to 5m0s for pod "pod-secrets-613ebed9-72e2-4a88-8f6f-e37df2ee1427" in namespace "secrets-1149" to be "Succeeded or Failed"
Sep 30 18:36:00.056: INFO: Pod "pod-secrets-613ebed9-72e2-4a88-8f6f-e37df2ee1427": Phase="Pending", Reason="", readiness=false. Elapsed: 11.222196ms
Sep 30 18:36:02.058: INFO: Pod "pod-secrets-613ebed9-72e2-4a88-8f6f-e37df2ee1427": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013316406s
STEP: Saw pod success
Sep 30 18:36:02.058: INFO: Pod "pod-secrets-613ebed9-72e2-4a88-8f6f-e37df2ee1427" satisfied condition "Succeeded or Failed"
Sep 30 18:36:02.060: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-secrets-613ebed9-72e2-4a88-8f6f-e37df2ee1427 container secret-volume-test: <nil>
STEP: delete the pod
Sep 30 18:36:02.097: INFO: Waiting for pod pod-secrets-613ebed9-72e2-4a88-8f6f-e37df2ee1427 to disappear
Sep 30 18:36:02.100: INFO: Pod pod-secrets-613ebed9-72e2-4a88-8f6f-e37df2ee1427 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:36:02.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1149" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":275,"completed":12,"skipped":253,"failed":0}

------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:36:02.109: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 18:36:02.269: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5083746-8282-44da-a791-7a2f6d845caf" in namespace "projected-2939" to be "Succeeded or Failed"
Sep 30 18:36:02.277: INFO: Pod "downwardapi-volume-d5083746-8282-44da-a791-7a2f6d845caf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.100024ms
Sep 30 18:36:04.280: INFO: Pod "downwardapi-volume-d5083746-8282-44da-a791-7a2f6d845caf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0107561s
STEP: Saw pod success
Sep 30 18:36:04.280: INFO: Pod "downwardapi-volume-d5083746-8282-44da-a791-7a2f6d845caf" satisfied condition "Succeeded or Failed"
Sep 30 18:36:04.282: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-d5083746-8282-44da-a791-7a2f6d845caf container client-container: <nil>
STEP: delete the pod
Sep 30 18:36:04.304: INFO: Waiting for pod downwardapi-volume-d5083746-8282-44da-a791-7a2f6d845caf to disappear
Sep 30 18:36:04.310: INFO: Pod downwardapi-volume-d5083746-8282-44da-a791-7a2f6d845caf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:36:04.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2939" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":275,"completed":13,"skipped":253,"failed":0}
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:36:04.317: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9306
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-9306/configmap-test-73a54765-c219-4bc4-8d37-f4bf9859264b
STEP: Creating a pod to test consume configMaps
Sep 30 18:36:04.482: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e6dff49-abdc-4721-a8ab-b73d433cbb6f" in namespace "configmap-9306" to be "Succeeded or Failed"
Sep 30 18:36:04.486: INFO: Pod "pod-configmaps-5e6dff49-abdc-4721-a8ab-b73d433cbb6f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.320947ms
Sep 30 18:36:06.489: INFO: Pod "pod-configmaps-5e6dff49-abdc-4721-a8ab-b73d433cbb6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006672433s
STEP: Saw pod success
Sep 30 18:36:06.489: INFO: Pod "pod-configmaps-5e6dff49-abdc-4721-a8ab-b73d433cbb6f" satisfied condition "Succeeded or Failed"
Sep 30 18:36:06.490: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-configmaps-5e6dff49-abdc-4721-a8ab-b73d433cbb6f container env-test: <nil>
STEP: delete the pod
Sep 30 18:36:06.507: INFO: Waiting for pod pod-configmaps-5e6dff49-abdc-4721-a8ab-b73d433cbb6f to disappear
Sep 30 18:36:06.521: INFO: Pod pod-configmaps-5e6dff49-abdc-4721-a8ab-b73d433cbb6f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:36:06.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9306" for this suite.
â€¢{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":275,"completed":14,"skipped":254,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:36:06.536: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8760
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-a33dc7dd-fea0-4dc9-a9f4-4beed395586c
STEP: Creating configMap with name cm-test-opt-upd-60c1d770-89a9-4b47-ac52-e5a1ae15cef4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a33dc7dd-fea0-4dc9-a9f4-4beed395586c
STEP: Updating configmap cm-test-opt-upd-60c1d770-89a9-4b47-ac52-e5a1ae15cef4
STEP: Creating configMap with name cm-test-opt-create-3af3ef01-a887-4967-9231-7de6db64e287
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:37:18.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8760" for this suite.

â€¢ [SLOW TEST:72.453 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":275,"completed":15,"skipped":277,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:37:18.989: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6933
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:37:19.140: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 30 18:37:22.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6933 create -f -'
Sep 30 18:37:23.542: INFO: stderr: ""
Sep 30 18:37:23.542: INFO: stdout: "e2e-test-crd-publish-openapi-9117-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 30 18:37:23.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6933 delete e2e-test-crd-publish-openapi-9117-crds test-cr'
Sep 30 18:37:23.607: INFO: stderr: ""
Sep 30 18:37:23.607: INFO: stdout: "e2e-test-crd-publish-openapi-9117-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Sep 30 18:37:23.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6933 apply -f -'
Sep 30 18:37:23.764: INFO: stderr: ""
Sep 30 18:37:23.764: INFO: stdout: "e2e-test-crd-publish-openapi-9117-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 30 18:37:23.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6933 delete e2e-test-crd-publish-openapi-9117-crds test-cr'
Sep 30 18:37:23.831: INFO: stderr: ""
Sep 30 18:37:23.831: INFO: stdout: "e2e-test-crd-publish-openapi-9117-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Sep 30 18:37:23.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 explain e2e-test-crd-publish-openapi-9117-crds'
Sep 30 18:37:23.974: INFO: stderr: ""
Sep 30 18:37:23.974: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9117-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:37:25.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6933" for this suite.

â€¢ [SLOW TEST:6.830 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":275,"completed":16,"skipped":284,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:37:25.821: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-5802
STEP: creating replication controller nodeport-test in namespace services-5802
I0930 18:37:26.006988      21 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-5802, replica count: 2
I0930 18:37:29.057336      21 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 30 18:37:29.057: INFO: Creating new exec pod
Sep 30 18:37:34.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5802 execpodpxpfp -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Sep 30 18:37:34.242: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Sep 30 18:37:34.242: INFO: stdout: ""
Sep 30 18:37:34.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5802 execpodpxpfp -- /bin/sh -x -c nc -zv -t -w 2 10.100.200.137 80'
Sep 30 18:37:34.393: INFO: stderr: "+ nc -zv -t -w 2 10.100.200.137 80\nConnection to 10.100.200.137 80 port [tcp/http] succeeded!\n"
Sep 30 18:37:34.393: INFO: stdout: ""
Sep 30 18:37:34.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5802 execpodpxpfp -- /bin/sh -x -c nc -zv -t -w 2 30.0.0.11 31551'
Sep 30 18:37:34.541: INFO: stderr: "+ nc -zv -t -w 2 30.0.0.11 31551\nConnection to 30.0.0.11 31551 port [tcp/31551] succeeded!\n"
Sep 30 18:37:34.541: INFO: stdout: ""
Sep 30 18:37:34.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5802 execpodpxpfp -- /bin/sh -x -c nc -zv -t -w 2 30.0.0.10 31551'
Sep 30 18:37:34.698: INFO: stderr: "+ nc -zv -t -w 2 30.0.0.10 31551\nConnection to 30.0.0.10 31551 port [tcp/31551] succeeded!\n"
Sep 30 18:37:34.698: INFO: stdout: ""
Sep 30 18:37:34.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5802 execpodpxpfp -- /bin/sh -x -c nc -zv -t -w 2 30.0.0.11 31551'
Sep 30 18:37:34.857: INFO: stderr: "+ nc -zv -t -w 2 30.0.0.11 31551\nConnection to 30.0.0.11 31551 port [tcp/31551] succeeded!\n"
Sep 30 18:37:34.857: INFO: stdout: ""
Sep 30 18:37:34.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5802 execpodpxpfp -- /bin/sh -x -c nc -zv -t -w 2 30.0.0.10 31551'
Sep 30 18:37:35.011: INFO: stderr: "+ nc -zv -t -w 2 30.0.0.10 31551\nConnection to 30.0.0.10 31551 port [tcp/31551] succeeded!\n"
Sep 30 18:37:35.011: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:37:35.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5802" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:9.196 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":275,"completed":17,"skipped":295,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:37:35.017: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6584
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 18:37:35.717: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 18:37:38.728: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:37:38.730: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6773-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:37:40.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6584" for this suite.
STEP: Destroying namespace "webhook-6584-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:5.094 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":275,"completed":18,"skipped":300,"failed":0}
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:37:40.111: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1042
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Sep 30 18:37:40.353: INFO: Waiting up to 5m0s for pod "client-containers-c7ed37d7-a0dc-423b-be2c-b4c18944903c" in namespace "containers-1042" to be "Succeeded or Failed"
Sep 30 18:37:40.357: INFO: Pod "client-containers-c7ed37d7-a0dc-423b-be2c-b4c18944903c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.983481ms
Sep 30 18:37:42.359: INFO: Pod "client-containers-c7ed37d7-a0dc-423b-be2c-b4c18944903c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00609045s
STEP: Saw pod success
Sep 30 18:37:42.359: INFO: Pod "client-containers-c7ed37d7-a0dc-423b-be2c-b4c18944903c" satisfied condition "Succeeded or Failed"
Sep 30 18:37:42.361: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod client-containers-c7ed37d7-a0dc-423b-be2c-b4c18944903c container test-container: <nil>
STEP: delete the pod
Sep 30 18:37:42.390: INFO: Waiting for pod client-containers-c7ed37d7-a0dc-423b-be2c-b4c18944903c to disappear
Sep 30 18:37:42.397: INFO: Pod client-containers-c7ed37d7-a0dc-423b-be2c-b4c18944903c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:37:42.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1042" for this suite.
â€¢{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":275,"completed":19,"skipped":305,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:37:42.404: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-11626af4-550e-45c9-9dd9-5fabfc23883c in namespace container-probe-4724
Sep 30 18:37:44.606: INFO: Started pod liveness-11626af4-550e-45c9-9dd9-5fabfc23883c in namespace container-probe-4724
STEP: checking the pod's current state and verifying that restartCount is present
Sep 30 18:37:44.608: INFO: Initial restart count of pod liveness-11626af4-550e-45c9-9dd9-5fabfc23883c is 0
Sep 30 18:38:00.639: INFO: Restart count of pod container-probe-4724/liveness-11626af4-550e-45c9-9dd9-5fabfc23883c is now 1 (16.031714225s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:00.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4724" for this suite.

â€¢ [SLOW TEST:18.277 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":275,"completed":20,"skipped":339,"failed":0}
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:00.683: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 30 18:38:00.888: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 30 18:38:00.902: INFO: Waiting for terminating namespaces to be deleted...
Sep 30 18:38:00.904: INFO: 
Logging pods the kubelet thinks is on node 9b360f31-b888-42e4-807a-5f2a0fca8fae before test
Sep 30 18:38:00.910: INFO: sink-controller-7549dc74f7-4qx97 from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.910: INFO: 	Container sink-controller ready: true, restart count 0
Sep 30 18:38:00.910: INFO: wavefront-proxy-68d69454fc-pm5dv from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.910: INFO: 	Container wavefront-proxy ready: true, restart count 0
Sep 30 18:38:00.910: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-5zmhk from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:38:00.910: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 18:38:00.910: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 18:38:00.910: INFO: coredns-854d7dc8c-6rdh4 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.910: INFO: 	Container coredns ready: true, restart count 0
Sep 30 18:38:00.910: INFO: fluent-bit-lpcs8 from pks-system started at 2020-09-29 19:35:27 +0000 UTC (2 container statuses recorded)
Sep 30 18:38:00.910: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 18:38:00.910: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 18:38:00.910: INFO: node-exporter-ws8wb from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.910: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 18:38:00.910: INFO: telegraf-h5t2t from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.910: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 18:38:00.910: INFO: wavefront-collector-drm6c from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.910: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 18:38:00.910: INFO: 
Logging pods the kubelet thinks is on node c4ab02cf-8388-4ee7-9741-792b2ee511a4 before test
Sep 30 18:38:00.927: INFO: telegraf-k5gxd from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.927: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 18:38:00.927: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-gvhcn from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:38:00.927: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 18:38:00.927: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 18:38:00.927: INFO: coredns-854d7dc8c-9w7v7 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.927: INFO: 	Container coredns ready: true, restart count 0
Sep 30 18:38:00.928: INFO: observability-manager-684c664cf4-nqrxv from pks-system started at 2020-09-29 19:35:04 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.928: INFO: 	Container observability-manager ready: true, restart count 0
Sep 30 18:38:00.928: INFO: node-exporter-75l6n from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.928: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 18:38:00.928: INFO: wavefront-collector-94rjj from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.928: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 18:38:00.928: INFO: sonobuoy-e2e-job-953b1e3c972143b8 from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:38:00.928: INFO: 	Container e2e ready: true, restart count 0
Sep 30 18:38:00.928: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 18:38:00.928: INFO: event-controller-7775f56b74-zgbbq from pks-system started at 2020-09-29 19:35:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:38:00.928: INFO: 	Container event-controller ready: true, restart count 0
Sep 30 18:38:00.928: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 18:38:00.928: INFO: fluent-bit-fbgsw from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 18:38:00.928: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 18:38:00.928: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 18:38:00.928: INFO: validator-6b476b98c9-d5g8r from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.928: INFO: 	Container validator ready: true, restart count 0
Sep 30 18:38:00.928: INFO: 
Logging pods the kubelet thinks is on node eb106fc7-933d-47a1-a18a-16aa6514d845 before test
Sep 30 18:38:00.935: INFO: telegraf-z8x2g from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.935: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 18:38:00.935: INFO: wavefront-collector-hms5p from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.935: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 18:38:00.935: INFO: sonobuoy from sonobuoy started at 2020-09-30 18:29:07 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.935: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 30 18:38:00.935: INFO: metrics-server-6967cb5487-z8t86 from kube-system started at 2020-09-29 19:35:01 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.935: INFO: 	Container metrics-server ready: true, restart count 0
Sep 30 18:38:00.935: INFO: metric-controller-7fd9d59567-hqvsc from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.935: INFO: 	Container metric-controller ready: true, restart count 0
Sep 30 18:38:00.936: INFO: node-exporter-jgdvm from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.936: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 18:38:00.936: INFO: cert-generator-e484f2435fc830429fc9747bd002fcda56dd053e-cc5fz from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.936: INFO: 	Container cert-generator ready: false, restart count 0
Sep 30 18:38:00.936: INFO: telemetry-agent-6bcf5c56b-qmz52 from pks-system started at 2020-09-29 19:37:51 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.936: INFO: 	Container fluent-bit-telemetry ready: true, restart count 0
Sep 30 18:38:00.936: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-wgtws from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 18:38:00.936: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 18:38:00.936: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 18:38:00.936: INFO: coredns-854d7dc8c-lg4vh from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 18:38:00.936: INFO: 	Container coredns ready: true, restart count 0
Sep 30 18:38:00.936: INFO: fluent-bit-5x9vt from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 18:38:00.936: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 18:38:00.936: INFO: 	Container ghostunnel ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-31af39b9-c914-4df7-8f30-ef2d24803c67 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-31af39b9-c914-4df7-8f30-ef2d24803c67 off the node eb106fc7-933d-47a1-a18a-16aa6514d845
STEP: verifying the node doesn't have the label kubernetes.io/e2e-31af39b9-c914-4df7-8f30-ef2d24803c67
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:11.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8768" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

â€¢ [SLOW TEST:10.372 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":275,"completed":21,"skipped":347,"failed":0}
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:11.054: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-936
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-9e4e546f-7edc-4fe2-a61a-35e0bb33ac86
STEP: Creating a pod to test consume configMaps
Sep 30 18:38:11.201: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4df37fdf-2e87-4fa8-92d2-0cfbf5bfd6d7" in namespace "projected-936" to be "Succeeded or Failed"
Sep 30 18:38:11.212: INFO: Pod "pod-projected-configmaps-4df37fdf-2e87-4fa8-92d2-0cfbf5bfd6d7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.399017ms
Sep 30 18:38:13.214: INFO: Pod "pod-projected-configmaps-4df37fdf-2e87-4fa8-92d2-0cfbf5bfd6d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012467754s
STEP: Saw pod success
Sep 30 18:38:13.214: INFO: Pod "pod-projected-configmaps-4df37fdf-2e87-4fa8-92d2-0cfbf5bfd6d7" satisfied condition "Succeeded or Failed"
Sep 30 18:38:13.216: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod pod-projected-configmaps-4df37fdf-2e87-4fa8-92d2-0cfbf5bfd6d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 18:38:13.237: INFO: Waiting for pod pod-projected-configmaps-4df37fdf-2e87-4fa8-92d2-0cfbf5bfd6d7 to disappear
Sep 30 18:38:13.245: INFO: Pod pod-projected-configmaps-4df37fdf-2e87-4fa8-92d2-0cfbf5bfd6d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:13.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-936" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":22,"skipped":347,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:13.251: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4452
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 18:38:13.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3e843026-5201-4443-be62-2e1db67ebdd5" in namespace "downward-api-4452" to be "Succeeded or Failed"
Sep 30 18:38:13.431: INFO: Pod "downwardapi-volume-3e843026-5201-4443-be62-2e1db67ebdd5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.201266ms
Sep 30 18:38:15.434: INFO: Pod "downwardapi-volume-3e843026-5201-4443-be62-2e1db67ebdd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005958709s
STEP: Saw pod success
Sep 30 18:38:15.434: INFO: Pod "downwardapi-volume-3e843026-5201-4443-be62-2e1db67ebdd5" satisfied condition "Succeeded or Failed"
Sep 30 18:38:15.436: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod downwardapi-volume-3e843026-5201-4443-be62-2e1db67ebdd5 container client-container: <nil>
STEP: delete the pod
Sep 30 18:38:15.453: INFO: Waiting for pod downwardapi-volume-3e843026-5201-4443-be62-2e1db67ebdd5 to disappear
Sep 30 18:38:15.460: INFO: Pod downwardapi-volume-3e843026-5201-4443-be62-2e1db67ebdd5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:15.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4452" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":275,"completed":23,"skipped":354,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:15.467: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9619
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-12e16796-25b5-4ab9-8583-b3a59379910b
STEP: Creating secret with name s-test-opt-upd-0d89f55e-6cbd-407d-9f91-e6ef70d69ab4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-12e16796-25b5-4ab9-8583-b3a59379910b
STEP: Updating secret s-test-opt-upd-0d89f55e-6cbd-407d-9f91-e6ef70d69ab4
STEP: Creating secret with name s-test-opt-create-0f29bbaf-92c7-4a3b-a08c-ebfc5156a753
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:19.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9619" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":275,"completed":24,"skipped":399,"failed":0}
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:19.714: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-559
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-973586e1-e1b0-403b-a904-a10fa845f7d6
STEP: Creating a pod to test consume secrets
Sep 30 18:38:19.911: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-920929f9-8263-4467-97a0-e719f901c54a" in namespace "projected-559" to be "Succeeded or Failed"
Sep 30 18:38:19.914: INFO: Pod "pod-projected-secrets-920929f9-8263-4467-97a0-e719f901c54a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.926252ms
Sep 30 18:38:21.918: INFO: Pod "pod-projected-secrets-920929f9-8263-4467-97a0-e719f901c54a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007674049s
STEP: Saw pod success
Sep 30 18:38:21.918: INFO: Pod "pod-projected-secrets-920929f9-8263-4467-97a0-e719f901c54a" satisfied condition "Succeeded or Failed"
Sep 30 18:38:21.920: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod pod-projected-secrets-920929f9-8263-4467-97a0-e719f901c54a container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 30 18:38:21.942: INFO: Waiting for pod pod-projected-secrets-920929f9-8263-4467-97a0-e719f901c54a to disappear
Sep 30 18:38:21.948: INFO: Pod pod-projected-secrets-920929f9-8263-4467-97a0-e719f901c54a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:21.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-559" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":25,"skipped":402,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:21.954: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7947
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Sep 30 18:38:22.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-7947'
Sep 30 18:38:22.340: INFO: stderr: ""
Sep 30 18:38:22.340: INFO: stdout: "pod/pause created\n"
Sep 30 18:38:22.340: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 30 18:38:22.340: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7947" to be "running and ready"
Sep 30 18:38:22.346: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.365106ms
Sep 30 18:38:24.348: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007856622s
Sep 30 18:38:24.348: INFO: Pod "pause" satisfied condition "running and ready"
Sep 30 18:38:24.348: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 30 18:38:24.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 label pods pause testing-label=testing-label-value --namespace=kubectl-7947'
Sep 30 18:38:24.416: INFO: stderr: ""
Sep 30 18:38:24.416: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 30 18:38:24.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pod pause -L testing-label --namespace=kubectl-7947'
Sep 30 18:38:24.477: INFO: stderr: ""
Sep 30 18:38:24.477: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 30 18:38:24.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 label pods pause testing-label- --namespace=kubectl-7947'
Sep 30 18:38:24.544: INFO: stderr: ""
Sep 30 18:38:24.544: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 30 18:38:24.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pod pause -L testing-label --namespace=kubectl-7947'
Sep 30 18:38:24.610: INFO: stderr: ""
Sep 30 18:38:24.610: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Sep 30 18:38:24.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete --grace-period=0 --force -f - --namespace=kubectl-7947'
Sep 30 18:38:24.688: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 30 18:38:24.688: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 30 18:38:24.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get rc,svc -l name=pause --no-headers --namespace=kubectl-7947'
Sep 30 18:38:24.755: INFO: stderr: "No resources found in kubectl-7947 namespace.\n"
Sep 30 18:38:24.755: INFO: stdout: ""
Sep 30 18:38:24.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -l name=pause --namespace=kubectl-7947 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 30 18:38:24.821: INFO: stderr: ""
Sep 30 18:38:24.821: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:24.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7947" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":275,"completed":26,"skipped":411,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:24.854: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4444
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Sep 30 18:38:25.003: INFO: namespace kubectl-4444
Sep 30 18:38:25.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-4444'
Sep 30 18:38:25.188: INFO: stderr: ""
Sep 30 18:38:25.188: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Sep 30 18:38:26.190: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 18:38:26.190: INFO: Found 0 / 1
Sep 30 18:38:27.191: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 18:38:27.191: INFO: Found 1 / 1
Sep 30 18:38:27.191: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 30 18:38:27.193: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 18:38:27.193: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 30 18:38:27.193: INFO: wait on agnhost-master startup in kubectl-4444 
Sep 30 18:38:27.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 logs agnhost-master-4b8z8 agnhost-master --namespace=kubectl-4444'
Sep 30 18:38:27.267: INFO: stderr: ""
Sep 30 18:38:27.267: INFO: stdout: "Paused\n"
STEP: exposing RC
Sep 30 18:38:27.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4444'
Sep 30 18:38:27.349: INFO: stderr: ""
Sep 30 18:38:27.349: INFO: stdout: "service/rm2 exposed\n"
Sep 30 18:38:27.352: INFO: Service rm2 in namespace kubectl-4444 found.
STEP: exposing service
Sep 30 18:38:29.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4444'
Sep 30 18:38:29.432: INFO: stderr: ""
Sep 30 18:38:29.432: INFO: stdout: "service/rm3 exposed\n"
Sep 30 18:38:29.437: INFO: Service rm3 in namespace kubectl-4444 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:31.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4444" for this suite.

â€¢ [SLOW TEST:6.590 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1119
    should create services for rc  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":275,"completed":27,"skipped":426,"failed":0}
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:31.444: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 30 18:38:33.626: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:33.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1837" for this suite.
â€¢{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":275,"completed":28,"skipped":426,"failed":0}

------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:33.655: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5682
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-29a47499-e4dc-47b0-b410-01980e366670
STEP: Creating a pod to test consume configMaps
Sep 30 18:38:33.858: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-47c2cbbd-52be-4de3-b88f-6da73e42d9e1" in namespace "projected-5682" to be "Succeeded or Failed"
Sep 30 18:38:33.866: INFO: Pod "pod-projected-configmaps-47c2cbbd-52be-4de3-b88f-6da73e42d9e1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.91984ms
Sep 30 18:38:35.868: INFO: Pod "pod-projected-configmaps-47c2cbbd-52be-4de3-b88f-6da73e42d9e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00998511s
STEP: Saw pod success
Sep 30 18:38:35.868: INFO: Pod "pod-projected-configmaps-47c2cbbd-52be-4de3-b88f-6da73e42d9e1" satisfied condition "Succeeded or Failed"
Sep 30 18:38:35.870: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-projected-configmaps-47c2cbbd-52be-4de3-b88f-6da73e42d9e1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 18:38:35.888: INFO: Waiting for pod pod-projected-configmaps-47c2cbbd-52be-4de3-b88f-6da73e42d9e1 to disappear
Sep 30 18:38:35.898: INFO: Pod pod-projected-configmaps-47c2cbbd-52be-4de3-b88f-6da73e42d9e1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:35.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5682" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":29,"skipped":426,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:35.903: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-9053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:36.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9053" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":275,"completed":30,"skipped":441,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:36.063: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4437
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 30 18:38:36.212: INFO: Waiting up to 5m0s for pod "pod-4591e57b-2c5f-480e-ab33-71e70002063f" in namespace "emptydir-4437" to be "Succeeded or Failed"
Sep 30 18:38:36.214: INFO: Pod "pod-4591e57b-2c5f-480e-ab33-71e70002063f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.105619ms
Sep 30 18:38:38.217: INFO: Pod "pod-4591e57b-2c5f-480e-ab33-71e70002063f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004882697s
STEP: Saw pod success
Sep 30 18:38:38.217: INFO: Pod "pod-4591e57b-2c5f-480e-ab33-71e70002063f" satisfied condition "Succeeded or Failed"
Sep 30 18:38:38.219: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-4591e57b-2c5f-480e-ab33-71e70002063f container test-container: <nil>
STEP: delete the pod
Sep 30 18:38:38.237: INFO: Waiting for pod pod-4591e57b-2c5f-480e-ab33-71e70002063f to disappear
Sep 30 18:38:38.245: INFO: Pod pod-4591e57b-2c5f-480e-ab33-71e70002063f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:38.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4437" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":31,"skipped":441,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:38.252: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1234
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-4479bd55-a73d-4c17-bc83-a1edf0de987e
STEP: Creating a pod to test consume secrets
Sep 30 18:38:38.413: INFO: Waiting up to 5m0s for pod "pod-secrets-83a0fbfc-0ca3-410b-8933-5b37f65f616d" in namespace "secrets-1234" to be "Succeeded or Failed"
Sep 30 18:38:38.424: INFO: Pod "pod-secrets-83a0fbfc-0ca3-410b-8933-5b37f65f616d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.962564ms
Sep 30 18:38:40.426: INFO: Pod "pod-secrets-83a0fbfc-0ca3-410b-8933-5b37f65f616d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013329696s
STEP: Saw pod success
Sep 30 18:38:40.427: INFO: Pod "pod-secrets-83a0fbfc-0ca3-410b-8933-5b37f65f616d" satisfied condition "Succeeded or Failed"
Sep 30 18:38:40.429: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-secrets-83a0fbfc-0ca3-410b-8933-5b37f65f616d container secret-volume-test: <nil>
STEP: delete the pod
Sep 30 18:38:40.452: INFO: Waiting for pod pod-secrets-83a0fbfc-0ca3-410b-8933-5b37f65f616d to disappear
Sep 30 18:38:40.462: INFO: Pod pod-secrets-83a0fbfc-0ca3-410b-8933-5b37f65f616d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:40.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1234" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":32,"skipped":460,"failed":0}
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:40.467: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-5619
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 30 18:38:42.639: INFO: &Pod{ObjectMeta:{send-events-ba163987-603c-4da3-8216-21ccc05e4e1c  events-5619 /api/v1/namespaces/events-5619/pods/send-events-ba163987-603c-4da3-8216-21ccc05e4e1c e4ce739b-1bcd-498d-8110-f14c84cf8137 206020 0 2020-09-30 18:38:40 +0000 UTC <nil> <nil> map[name:foo time:620303557] map[] [] []  [{e2e.test Update v1 2020-09-30 18:38:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 18:38:42 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 52 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ghl5k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ghl5k,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ghl5k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 18:38:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 18:38:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 18:38:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 18:38:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.43,StartTime:2020-09-30 18:38:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 18:38:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://0bb7a203413a86ab25f372cdabcc5c76636ca1ae949023c604d98bdcbcccdd74,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Sep 30 18:38:44.642: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 30 18:38:46.645: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:46.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5619" for this suite.

â€¢ [SLOW TEST:6.207 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":275,"completed":33,"skipped":464,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:46.675: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Sep 30 18:38:51.341: INFO: Successfully updated pod "adopt-release-2fmrb"
STEP: Checking that the Job readopts the Pod
Sep 30 18:38:51.341: INFO: Waiting up to 15m0s for pod "adopt-release-2fmrb" in namespace "job-7977" to be "adopted"
Sep 30 18:38:51.352: INFO: Pod "adopt-release-2fmrb": Phase="Running", Reason="", readiness=true. Elapsed: 10.592338ms
Sep 30 18:38:53.354: INFO: Pod "adopt-release-2fmrb": Phase="Running", Reason="", readiness=true. Elapsed: 2.013287767s
Sep 30 18:38:53.354: INFO: Pod "adopt-release-2fmrb" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Sep 30 18:38:53.862: INFO: Successfully updated pod "adopt-release-2fmrb"
STEP: Checking that the Job releases the Pod
Sep 30 18:38:53.862: INFO: Waiting up to 15m0s for pod "adopt-release-2fmrb" in namespace "job-7977" to be "released"
Sep 30 18:38:53.870: INFO: Pod "adopt-release-2fmrb": Phase="Running", Reason="", readiness=true. Elapsed: 7.22619ms
Sep 30 18:38:53.870: INFO: Pod "adopt-release-2fmrb" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:53.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7977" for this suite.

â€¢ [SLOW TEST:7.249 seconds]
[sig-apps] Job
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":275,"completed":34,"skipped":486,"failed":0}
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:53.926: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7471
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:38:54.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7471" for this suite.
â€¢{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":275,"completed":35,"skipped":487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:38:54.135: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5480
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 30 18:38:54.300: INFO: Waiting up to 5m0s for pod "pod-55e85976-75cf-46fa-9909-414d3de604c6" in namespace "emptydir-5480" to be "Succeeded or Failed"
Sep 30 18:38:54.310: INFO: Pod "pod-55e85976-75cf-46fa-9909-414d3de604c6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.451722ms
Sep 30 18:38:56.312: INFO: Pod "pod-55e85976-75cf-46fa-9909-414d3de604c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01150916s
Sep 30 18:38:58.314: INFO: Pod "pod-55e85976-75cf-46fa-9909-414d3de604c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013787463s
Sep 30 18:39:00.317: INFO: Pod "pod-55e85976-75cf-46fa-9909-414d3de604c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0164774s
STEP: Saw pod success
Sep 30 18:39:00.317: INFO: Pod "pod-55e85976-75cf-46fa-9909-414d3de604c6" satisfied condition "Succeeded or Failed"
Sep 30 18:39:00.319: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod pod-55e85976-75cf-46fa-9909-414d3de604c6 container test-container: <nil>
STEP: delete the pod
Sep 30 18:39:00.335: INFO: Waiting for pod pod-55e85976-75cf-46fa-9909-414d3de604c6 to disappear
Sep 30 18:39:00.342: INFO: Pod pod-55e85976-75cf-46fa-9909-414d3de604c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:39:00.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5480" for this suite.

â€¢ [SLOW TEST:6.212 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":36,"skipped":523,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:39:00.347: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2227
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:39:11.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2227" for this suite.

â€¢ [SLOW TEST:11.210 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":275,"completed":37,"skipped":571,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:39:11.558: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4848
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 18:39:12.016: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 18:39:14.023: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737087952, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737087952, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737087952, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737087952, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 18:39:17.032: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:39:17.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4848" for this suite.
STEP: Destroying namespace "webhook-4848-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:5.617 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":275,"completed":38,"skipped":593,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:39:17.176: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8713
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8713.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8713.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8713.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8713.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8713.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8713.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 30 18:39:27.381: INFO: DNS probes using dns-8713/dns-test-da520a55-2a82-465e-8028-ba927fc1e52e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:39:27.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8713" for this suite.

â€¢ [SLOW TEST:10.250 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":275,"completed":39,"skipped":631,"failed":0}
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:39:27.426: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2710
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-6m2z
STEP: Creating a pod to test atomic-volume-subpath
Sep 30 18:39:27.593: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-6m2z" in namespace "subpath-2710" to be "Succeeded or Failed"
Sep 30 18:39:27.613: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Pending", Reason="", readiness=false. Elapsed: 19.355937ms
Sep 30 18:39:29.615: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 2.021922838s
Sep 30 18:39:31.618: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 4.024260729s
Sep 30 18:39:33.620: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 6.026542166s
Sep 30 18:39:35.622: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 8.029142346s
Sep 30 18:39:37.625: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 10.031439134s
Sep 30 18:39:39.627: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 12.034004706s
Sep 30 18:39:41.630: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 14.036640241s
Sep 30 18:39:43.632: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 16.039077996s
Sep 30 18:39:45.637: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 18.043777105s
Sep 30 18:39:47.639: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Running", Reason="", readiness=true. Elapsed: 20.045831289s
Sep 30 18:39:49.642: INFO: Pod "pod-subpath-test-secret-6m2z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.048785121s
STEP: Saw pod success
Sep 30 18:39:49.642: INFO: Pod "pod-subpath-test-secret-6m2z" satisfied condition "Succeeded or Failed"
Sep 30 18:39:49.644: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-subpath-test-secret-6m2z container test-container-subpath-secret-6m2z: <nil>
STEP: delete the pod
Sep 30 18:39:49.663: INFO: Waiting for pod pod-subpath-test-secret-6m2z to disappear
Sep 30 18:39:49.670: INFO: Pod pod-subpath-test-secret-6m2z no longer exists
STEP: Deleting pod pod-subpath-test-secret-6m2z
Sep 30 18:39:49.670: INFO: Deleting pod "pod-subpath-test-secret-6m2z" in namespace "subpath-2710"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:39:49.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2710" for this suite.

â€¢ [SLOW TEST:22.250 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":275,"completed":40,"skipped":633,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:39:49.678: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3299
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-dfcdabae-5ec8-4f1b-b5e4-ce20750ccd47
STEP: Creating secret with name s-test-opt-upd-4c473495-8fb5-49a8-84ce-33756d8859ea
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-dfcdabae-5ec8-4f1b-b5e4-ce20750ccd47
STEP: Updating secret s-test-opt-upd-4c473495-8fb5-49a8-84ce-33756d8859ea
STEP: Creating secret with name s-test-opt-create-404109f1-35bc-4711-9069-794794088f05
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:39:53.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3299" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":275,"completed":41,"skipped":647,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:39:53.972: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4628
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 30 18:39:54.130: INFO: Waiting up to 5m0s for pod "pod-65b85a4f-3a6e-4dfe-b741-3cb43fc9e9a1" in namespace "emptydir-4628" to be "Succeeded or Failed"
Sep 30 18:39:54.137: INFO: Pod "pod-65b85a4f-3a6e-4dfe-b741-3cb43fc9e9a1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.452173ms
Sep 30 18:39:56.140: INFO: Pod "pod-65b85a4f-3a6e-4dfe-b741-3cb43fc9e9a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009995377s
Sep 30 18:39:58.142: INFO: Pod "pod-65b85a4f-3a6e-4dfe-b741-3cb43fc9e9a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012634932s
STEP: Saw pod success
Sep 30 18:39:58.142: INFO: Pod "pod-65b85a4f-3a6e-4dfe-b741-3cb43fc9e9a1" satisfied condition "Succeeded or Failed"
Sep 30 18:39:58.144: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-65b85a4f-3a6e-4dfe-b741-3cb43fc9e9a1 container test-container: <nil>
STEP: delete the pod
Sep 30 18:39:58.161: INFO: Waiting for pod pod-65b85a4f-3a6e-4dfe-b741-3cb43fc9e9a1 to disappear
Sep 30 18:39:58.168: INFO: Pod pod-65b85a4f-3a6e-4dfe-b741-3cb43fc9e9a1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:39:58.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4628" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":42,"skipped":682,"failed":0}

------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:39:58.175: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-1370
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Sep 30 18:39:58.338: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-1370" to be "Succeeded or Failed"
Sep 30 18:39:58.347: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.298032ms
Sep 30 18:40:00.349: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011000391s
STEP: Saw pod success
Sep 30 18:40:00.350: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Sep 30 18:40:00.351: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 30 18:40:00.370: INFO: Waiting for pod pod-host-path-test to disappear
Sep 30 18:40:00.377: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:40:00.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-1370" for this suite.
â€¢{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":43,"skipped":682,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:40:00.382: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5392
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 18:40:00.555: INFO: Waiting up to 5m0s for pod "downwardapi-volume-031a45c1-0b59-4542-8e37-7b4747155e0e" in namespace "projected-5392" to be "Succeeded or Failed"
Sep 30 18:40:00.563: INFO: Pod "downwardapi-volume-031a45c1-0b59-4542-8e37-7b4747155e0e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.457528ms
Sep 30 18:40:02.565: INFO: Pod "downwardapi-volume-031a45c1-0b59-4542-8e37-7b4747155e0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010106774s
STEP: Saw pod success
Sep 30 18:40:02.566: INFO: Pod "downwardapi-volume-031a45c1-0b59-4542-8e37-7b4747155e0e" satisfied condition "Succeeded or Failed"
Sep 30 18:40:02.567: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-031a45c1-0b59-4542-8e37-7b4747155e0e container client-container: <nil>
STEP: delete the pod
Sep 30 18:40:02.586: INFO: Waiting for pod downwardapi-volume-031a45c1-0b59-4542-8e37-7b4747155e0e to disappear
Sep 30 18:40:02.593: INFO: Pod downwardapi-volume-031a45c1-0b59-4542-8e37-7b4747155e0e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:40:02.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5392" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":275,"completed":44,"skipped":684,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:40:02.599: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 30 18:40:03.152: INFO: Pod name wrapped-volume-race-c503c1da-8f07-4b13-9484-feec74643206: Found 0 pods out of 5
Sep 30 18:40:08.158: INFO: Pod name wrapped-volume-race-c503c1da-8f07-4b13-9484-feec74643206: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c503c1da-8f07-4b13-9484-feec74643206 in namespace emptydir-wrapper-6417, will wait for the garbage collector to delete the pods
Sep 30 18:40:18.231: INFO: Deleting ReplicationController wrapped-volume-race-c503c1da-8f07-4b13-9484-feec74643206 took: 5.963121ms
Sep 30 18:40:18.731: INFO: Terminating ReplicationController wrapped-volume-race-c503c1da-8f07-4b13-9484-feec74643206 pods took: 500.216164ms
STEP: Creating RC which spawns configmap-volume pods
Sep 30 18:40:27.247: INFO: Pod name wrapped-volume-race-f5a0d5d7-90bf-4dc8-a69e-9828b4e94815: Found 0 pods out of 5
Sep 30 18:40:32.255: INFO: Pod name wrapped-volume-race-f5a0d5d7-90bf-4dc8-a69e-9828b4e94815: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f5a0d5d7-90bf-4dc8-a69e-9828b4e94815 in namespace emptydir-wrapper-6417, will wait for the garbage collector to delete the pods
Sep 30 18:40:42.331: INFO: Deleting ReplicationController wrapped-volume-race-f5a0d5d7-90bf-4dc8-a69e-9828b4e94815 took: 5.318382ms
Sep 30 18:40:42.832: INFO: Terminating ReplicationController wrapped-volume-race-f5a0d5d7-90bf-4dc8-a69e-9828b4e94815 pods took: 500.186911ms
STEP: Creating RC which spawns configmap-volume pods
Sep 30 18:40:57.268: INFO: Pod name wrapped-volume-race-51f853d6-4636-4a76-9ee4-ab9b3a3d033b: Found 0 pods out of 5
Sep 30 18:41:02.274: INFO: Pod name wrapped-volume-race-51f853d6-4636-4a76-9ee4-ab9b3a3d033b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-51f853d6-4636-4a76-9ee4-ab9b3a3d033b in namespace emptydir-wrapper-6417, will wait for the garbage collector to delete the pods
Sep 30 18:41:12.347: INFO: Deleting ReplicationController wrapped-volume-race-51f853d6-4636-4a76-9ee4-ab9b3a3d033b took: 6.979944ms
Sep 30 18:41:12.748: INFO: Terminating ReplicationController wrapped-volume-race-51f853d6-4636-4a76-9ee4-ab9b3a3d033b pods took: 400.360921ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:41:27.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6417" for this suite.

â€¢ [SLOW TEST:85.111 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":275,"completed":45,"skipped":693,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:41:27.712: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4723
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-fb12643b-af1b-425a-b800-1a5493eca8f0
STEP: Creating a pod to test consume configMaps
Sep 30 18:41:27.870: INFO: Waiting up to 5m0s for pod "pod-configmaps-4014b341-8653-4673-a240-d84429ee4ca2" in namespace "configmap-4723" to be "Succeeded or Failed"
Sep 30 18:41:27.880: INFO: Pod "pod-configmaps-4014b341-8653-4673-a240-d84429ee4ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.031474ms
Sep 30 18:41:29.883: INFO: Pod "pod-configmaps-4014b341-8653-4673-a240-d84429ee4ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012620706s
Sep 30 18:41:31.885: INFO: Pod "pod-configmaps-4014b341-8653-4673-a240-d84429ee4ca2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015209156s
STEP: Saw pod success
Sep 30 18:41:31.885: INFO: Pod "pod-configmaps-4014b341-8653-4673-a240-d84429ee4ca2" satisfied condition "Succeeded or Failed"
Sep 30 18:41:31.887: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-configmaps-4014b341-8653-4673-a240-d84429ee4ca2 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 18:41:31.907: INFO: Waiting for pod pod-configmaps-4014b341-8653-4673-a240-d84429ee4ca2 to disappear
Sep 30 18:41:31.914: INFO: Pod pod-configmaps-4014b341-8653-4673-a240-d84429ee4ca2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:41:31.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4723" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":46,"skipped":698,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:41:31.924: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 30 18:41:34.150: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:41:34.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5598" for this suite.
â€¢{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":275,"completed":47,"skipped":730,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:41:34.211: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7096
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-566e218f-6f9c-4483-a203-63cd88ac6568
STEP: Creating a pod to test consume configMaps
Sep 30 18:41:34.417: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bf84db2e-4d89-4dbe-b0cc-e26d81ee38f8" in namespace "projected-7096" to be "Succeeded or Failed"
Sep 30 18:41:34.445: INFO: Pod "pod-projected-configmaps-bf84db2e-4d89-4dbe-b0cc-e26d81ee38f8": Phase="Pending", Reason="", readiness=false. Elapsed: 27.749963ms
Sep 30 18:41:36.447: INFO: Pod "pod-projected-configmaps-bf84db2e-4d89-4dbe-b0cc-e26d81ee38f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03023934s
STEP: Saw pod success
Sep 30 18:41:36.448: INFO: Pod "pod-projected-configmaps-bf84db2e-4d89-4dbe-b0cc-e26d81ee38f8" satisfied condition "Succeeded or Failed"
Sep 30 18:41:36.450: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-projected-configmaps-bf84db2e-4d89-4dbe-b0cc-e26d81ee38f8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 18:41:36.468: INFO: Waiting for pod pod-projected-configmaps-bf84db2e-4d89-4dbe-b0cc-e26d81ee38f8 to disappear
Sep 30 18:41:36.481: INFO: Pod pod-projected-configmaps-bf84db2e-4d89-4dbe-b0cc-e26d81ee38f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:41:36.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7096" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":275,"completed":48,"skipped":731,"failed":0}
SSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:41:36.487: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-943
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:41:36.658: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-ebbc9973-1c2d-4b47-800a-d5decb0b735a" in namespace "security-context-test-943" to be "Succeeded or Failed"
Sep 30 18:41:36.662: INFO: Pod "busybox-privileged-false-ebbc9973-1c2d-4b47-800a-d5decb0b735a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.414175ms
Sep 30 18:41:38.680: INFO: Pod "busybox-privileged-false-ebbc9973-1c2d-4b47-800a-d5decb0b735a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021484973s
Sep 30 18:41:38.680: INFO: Pod "busybox-privileged-false-ebbc9973-1c2d-4b47-800a-d5decb0b735a" satisfied condition "Succeeded or Failed"
Sep 30 18:41:38.685: INFO: Got logs for pod "busybox-privileged-false-ebbc9973-1c2d-4b47-800a-d5decb0b735a": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:41:38.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-943" for this suite.
â€¢{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":49,"skipped":737,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:41:38.693: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8204
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:41:51.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8204" for this suite.

â€¢ [SLOW TEST:13.214 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":275,"completed":50,"skipped":784,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:41:51.908: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6719
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-0a913804-7141-4108-95a3-0a320e076e13
STEP: Creating a pod to test consume configMaps
Sep 30 18:41:52.075: INFO: Waiting up to 5m0s for pod "pod-configmaps-77cce7d4-6e80-4901-9520-4e5a9a43959a" in namespace "configmap-6719" to be "Succeeded or Failed"
Sep 30 18:41:52.082: INFO: Pod "pod-configmaps-77cce7d4-6e80-4901-9520-4e5a9a43959a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.604115ms
Sep 30 18:41:54.084: INFO: Pod "pod-configmaps-77cce7d4-6e80-4901-9520-4e5a9a43959a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008899685s
STEP: Saw pod success
Sep 30 18:41:54.084: INFO: Pod "pod-configmaps-77cce7d4-6e80-4901-9520-4e5a9a43959a" satisfied condition "Succeeded or Failed"
Sep 30 18:41:54.086: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-configmaps-77cce7d4-6e80-4901-9520-4e5a9a43959a container configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 18:41:54.102: INFO: Waiting for pod pod-configmaps-77cce7d4-6e80-4901-9520-4e5a9a43959a to disappear
Sep 30 18:41:54.109: INFO: Pod pod-configmaps-77cce7d4-6e80-4901-9520-4e5a9a43959a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:41:54.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6719" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":275,"completed":51,"skipped":808,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:41:54.116: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1474
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-1474
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 30 18:41:54.267: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 30 18:41:54.315: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 18:41:56.318: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:41:58.318: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:42:00.318: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:42:02.318: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:42:04.318: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:42:06.318: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:42:08.318: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:42:10.318: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:42:12.318: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 18:42:14.318: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 30 18:42:14.321: INFO: The status of Pod netserver-1 is Running (Ready = true)
Sep 30 18:42:14.324: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Sep 30 18:42:18.338: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.99.55:8080/dial?request=hostname&protocol=http&host=10.200.32.41&port=8080&tries=1'] Namespace:pod-network-test-1474 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 18:42:18.338: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:42:18.436: INFO: Waiting for responses: map[]
Sep 30 18:42:18.438: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.99.55:8080/dial?request=hostname&protocol=http&host=10.200.52.15&port=8080&tries=1'] Namespace:pod-network-test-1474 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 18:42:18.438: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:42:18.529: INFO: Waiting for responses: map[]
Sep 30 18:42:18.531: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.99.55:8080/dial?request=hostname&protocol=http&host=10.200.99.54&port=8080&tries=1'] Namespace:pod-network-test-1474 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 18:42:18.531: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:42:18.650: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:42:18.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1474" for this suite.

â€¢ [SLOW TEST:24.541 seconds]
[sig-network] Networking
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":275,"completed":52,"skipped":816,"failed":0}
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:42:18.656: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3176
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-3176
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Sep 30 18:42:18.862: INFO: Found 0 stateful pods, waiting for 3
Sep 30 18:42:28.865: INFO: Found 2 stateful pods, waiting for 3
Sep 30 18:42:38.865: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 18:42:38.865: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 18:42:38.865: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Sep 30 18:42:48.865: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 18:42:48.865: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 18:42:48.865: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 30 18:42:48.887: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 30 18:42:58.911: INFO: Updating stateful set ss2
Sep 30 18:42:58.929: INFO: Waiting for Pod statefulset-3176/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Sep 30 18:43:09.070: INFO: Found 2 stateful pods, waiting for 3
Sep 30 18:43:19.074: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 18:43:19.074: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 18:43:19.074: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 30 18:43:19.095: INFO: Updating stateful set ss2
Sep 30 18:43:19.118: INFO: Waiting for Pod statefulset-3176/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 30 18:43:29.138: INFO: Updating stateful set ss2
Sep 30 18:43:29.170: INFO: Waiting for StatefulSet statefulset-3176/ss2 to complete update
Sep 30 18:43:29.170: INFO: Waiting for Pod statefulset-3176/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 30 18:43:39.175: INFO: Waiting for StatefulSet statefulset-3176/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 30 18:43:49.185: INFO: Deleting all statefulset in ns statefulset-3176
Sep 30 18:43:49.186: INFO: Scaling statefulset ss2 to 0
Sep 30 18:43:59.199: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 18:43:59.201: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:43:59.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3176" for this suite.

â€¢ [SLOW TEST:100.568 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":275,"completed":53,"skipped":817,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:43:59.225: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-9583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Sep 30 18:43:59.412: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Sep 30 18:43:59.718: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep 30 18:44:01.787: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 18:44:03.790: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 18:44:05.790: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 18:44:07.796: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 18:44:09.790: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 18:44:11.790: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088239, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 18:44:14.509: INFO: Waited 715.283593ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:44:15.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9583" for this suite.

â€¢ [SLOW TEST:15.932 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":275,"completed":54,"skipped":824,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:44:15.159: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 18:44:15.367: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1f930935-0d0a-4e9a-aa79-8a6b11224a3b" in namespace "downward-api-949" to be "Succeeded or Failed"
Sep 30 18:44:15.373: INFO: Pod "downwardapi-volume-1f930935-0d0a-4e9a-aa79-8a6b11224a3b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.809362ms
Sep 30 18:44:17.376: INFO: Pod "downwardapi-volume-1f930935-0d0a-4e9a-aa79-8a6b11224a3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008503971s
STEP: Saw pod success
Sep 30 18:44:17.376: INFO: Pod "downwardapi-volume-1f930935-0d0a-4e9a-aa79-8a6b11224a3b" satisfied condition "Succeeded or Failed"
Sep 30 18:44:17.378: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-1f930935-0d0a-4e9a-aa79-8a6b11224a3b container client-container: <nil>
STEP: delete the pod
Sep 30 18:44:17.408: INFO: Waiting for pod downwardapi-volume-1f930935-0d0a-4e9a-aa79-8a6b11224a3b to disappear
Sep 30 18:44:17.416: INFO: Pod downwardapi-volume-1f930935-0d0a-4e9a-aa79-8a6b11224a3b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:44:17.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-949" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":275,"completed":55,"skipped":838,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:44:17.431: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7063
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 30 18:44:17.642: INFO: Number of nodes with available pods: 0
Sep 30 18:44:17.642: INFO: Node 9b360f31-b888-42e4-807a-5f2a0fca8fae is running more than one daemon pod
Sep 30 18:44:18.647: INFO: Number of nodes with available pods: 0
Sep 30 18:44:18.647: INFO: Node 9b360f31-b888-42e4-807a-5f2a0fca8fae is running more than one daemon pod
Sep 30 18:44:19.647: INFO: Number of nodes with available pods: 1
Sep 30 18:44:19.647: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 18:44:20.648: INFO: Number of nodes with available pods: 2
Sep 30 18:44:20.648: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 18:44:21.647: INFO: Number of nodes with available pods: 2
Sep 30 18:44:21.647: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 18:44:22.648: INFO: Number of nodes with available pods: 2
Sep 30 18:44:22.648: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 18:44:23.652: INFO: Number of nodes with available pods: 2
Sep 30 18:44:23.652: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 18:44:24.648: INFO: Number of nodes with available pods: 2
Sep 30 18:44:24.648: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 18:44:25.647: INFO: Number of nodes with available pods: 2
Sep 30 18:44:25.647: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 18:44:26.646: INFO: Number of nodes with available pods: 3
Sep 30 18:44:26.646: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 30 18:44:26.684: INFO: Number of nodes with available pods: 3
Sep 30 18:44:26.684: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7063, will wait for the garbage collector to delete the pods
Sep 30 18:44:27.769: INFO: Deleting DaemonSet.extensions daemon-set took: 3.770904ms
Sep 30 18:44:27.869: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.338897ms
Sep 30 18:44:43.171: INFO: Number of nodes with available pods: 0
Sep 30 18:44:43.171: INFO: Number of running nodes: 0, number of available pods: 0
Sep 30 18:44:43.174: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7063/daemonsets","resourceVersion":"208943"},"items":null}

Sep 30 18:44:43.175: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7063/pods","resourceVersion":"208943"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:44:43.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7063" for this suite.

â€¢ [SLOW TEST:25.756 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":275,"completed":56,"skipped":850,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:44:43.187: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9196
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-ckqw
STEP: Creating a pod to test atomic-volume-subpath
Sep 30 18:44:43.348: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-ckqw" in namespace "subpath-9196" to be "Succeeded or Failed"
Sep 30 18:44:43.362: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Pending", Reason="", readiness=false. Elapsed: 14.022629ms
Sep 30 18:44:45.365: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 2.016490069s
Sep 30 18:44:47.367: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 4.019240298s
Sep 30 18:44:49.370: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 6.022010422s
Sep 30 18:44:51.373: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 8.024724469s
Sep 30 18:44:53.375: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 10.027364555s
Sep 30 18:44:55.378: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 12.030433227s
Sep 30 18:44:57.381: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 14.032974354s
Sep 30 18:44:59.384: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 16.035527033s
Sep 30 18:45:01.386: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 18.038206966s
Sep 30 18:45:03.389: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Running", Reason="", readiness=true. Elapsed: 20.041020425s
Sep 30 18:45:05.392: INFO: Pod "pod-subpath-test-projected-ckqw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.043620354s
STEP: Saw pod success
Sep 30 18:45:05.392: INFO: Pod "pod-subpath-test-projected-ckqw" satisfied condition "Succeeded or Failed"
Sep 30 18:45:05.393: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-subpath-test-projected-ckqw container test-container-subpath-projected-ckqw: <nil>
STEP: delete the pod
Sep 30 18:45:05.412: INFO: Waiting for pod pod-subpath-test-projected-ckqw to disappear
Sep 30 18:45:05.420: INFO: Pod pod-subpath-test-projected-ckqw no longer exists
STEP: Deleting pod pod-subpath-test-projected-ckqw
Sep 30 18:45:05.420: INFO: Deleting pod "pod-subpath-test-projected-ckqw" in namespace "subpath-9196"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:45:05.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9196" for this suite.

â€¢ [SLOW TEST:22.244 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":275,"completed":57,"skipped":853,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:45:05.433: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3847
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 18:45:05.956: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 18:45:08.972: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:45:08.974: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:45:10.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3847" for this suite.
STEP: Destroying namespace "webhook-3847-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":275,"completed":58,"skipped":876,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:45:10.185: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4573
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:45:14.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4573" for this suite.
â€¢{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":59,"skipped":1005,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:45:14.359: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:45:14.537: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-5b013d23-779c-414c-8299-3c1c9802563d" in namespace "security-context-test-6740" to be "Succeeded or Failed"
Sep 30 18:45:14.545: INFO: Pod "busybox-readonly-false-5b013d23-779c-414c-8299-3c1c9802563d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.18084ms
Sep 30 18:45:16.548: INFO: Pod "busybox-readonly-false-5b013d23-779c-414c-8299-3c1c9802563d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010879966s
Sep 30 18:45:18.550: INFO: Pod "busybox-readonly-false-5b013d23-779c-414c-8299-3c1c9802563d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013439167s
Sep 30 18:45:18.550: INFO: Pod "busybox-readonly-false-5b013d23-779c-414c-8299-3c1c9802563d" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:45:18.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6740" for this suite.
â€¢{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":275,"completed":60,"skipped":1012,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:45:18.557: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-3978
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:45:18.700: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Creating first CR 
Sep 30 18:45:19.280: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-30T18:45:19Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-30T18:45:19Z]] name:name1 resourceVersion:209217 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:12c89a7d-5e88-4957-b036-42ff098cf87c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Sep 30 18:45:29.283: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-30T18:45:29Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-30T18:45:29Z]] name:name2 resourceVersion:209264 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:0c4afd12-1524-4a95-9bf5-5ddc6c2c593b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Sep 30 18:45:39.288: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-30T18:45:19Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-30T18:45:39Z]] name:name1 resourceVersion:209290 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:12c89a7d-5e88-4957-b036-42ff098cf87c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Sep 30 18:45:49.292: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-30T18:45:29Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-30T18:45:49Z]] name:name2 resourceVersion:209315 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:0c4afd12-1524-4a95-9bf5-5ddc6c2c593b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Sep 30 18:45:59.297: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-30T18:45:19Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-30T18:45:39Z]] name:name1 resourceVersion:209345 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:12c89a7d-5e88-4957-b036-42ff098cf87c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Sep 30 18:46:09.302: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-30T18:45:29Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-30T18:45:49Z]] name:name2 resourceVersion:209371 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:0c4afd12-1524-4a95-9bf5-5ddc6c2c593b] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:46:19.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-3978" for this suite.

â€¢ [SLOW TEST:61.284 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":275,"completed":61,"skipped":1014,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:46:19.841: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4311
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-c4bb368d-3118-471c-ae7c-e08cf4829a82
STEP: Creating a pod to test consume configMaps
Sep 30 18:46:20.041: INFO: Waiting up to 5m0s for pod "pod-configmaps-dd668a19-1f40-4892-aec3-ad77beb49749" in namespace "configmap-4311" to be "Succeeded or Failed"
Sep 30 18:46:20.053: INFO: Pod "pod-configmaps-dd668a19-1f40-4892-aec3-ad77beb49749": Phase="Pending", Reason="", readiness=false. Elapsed: 12.18878ms
Sep 30 18:46:22.055: INFO: Pod "pod-configmaps-dd668a19-1f40-4892-aec3-ad77beb49749": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014339816s
Sep 30 18:46:24.057: INFO: Pod "pod-configmaps-dd668a19-1f40-4892-aec3-ad77beb49749": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016907945s
STEP: Saw pod success
Sep 30 18:46:24.057: INFO: Pod "pod-configmaps-dd668a19-1f40-4892-aec3-ad77beb49749" satisfied condition "Succeeded or Failed"
Sep 30 18:46:24.059: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-configmaps-dd668a19-1f40-4892-aec3-ad77beb49749 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 18:46:24.076: INFO: Waiting for pod pod-configmaps-dd668a19-1f40-4892-aec3-ad77beb49749 to disappear
Sep 30 18:46:24.083: INFO: Pod pod-configmaps-dd668a19-1f40-4892-aec3-ad77beb49749 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:46:24.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4311" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":275,"completed":62,"skipped":1030,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:46:24.089: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2837
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2837
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2837
STEP: creating replication controller externalsvc in namespace services-2837
I0930 18:46:24.293226      21 runners.go:190] Created replication controller with name: externalsvc, namespace: services-2837, replica count: 2
I0930 18:46:27.343656      21 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Sep 30 18:46:27.360: INFO: Creating new exec pod
Sep 30 18:46:29.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-2837 execpod8d88g -- /bin/sh -x -c nslookup nodeport-service'
Sep 30 18:46:29.562: INFO: stderr: "+ nslookup nodeport-service\n"
Sep 30 18:46:29.562: INFO: stdout: "Server:\t\t10.100.200.2\nAddress:\t10.100.200.2#53\n\nnodeport-service.services-2837.svc.cluster.local\tcanonical name = externalsvc.services-2837.svc.cluster.local.\nName:\texternalsvc.services-2837.svc.cluster.local\nAddress: 10.100.200.236\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2837, will wait for the garbage collector to delete the pods
Sep 30 18:46:29.620: INFO: Deleting ReplicationController externalsvc took: 5.252258ms
Sep 30 18:46:30.020: INFO: Terminating ReplicationController externalsvc pods took: 400.186256ms
Sep 30 18:46:43.235: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:46:43.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2837" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:19.166 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":275,"completed":63,"skipped":1036,"failed":0}
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:46:43.255: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 30 18:46:45.954: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5270 pod-service-account-ad25ad30-c473-46e4-85ba-676fece5ebeb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 30 18:46:46.120: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5270 pod-service-account-ad25ad30-c473-46e4-85ba-676fece5ebeb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 30 18:46:46.275: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5270 pod-service-account-ad25ad30-c473-46e4-85ba-676fece5ebeb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:46:46.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5270" for this suite.
â€¢{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":275,"completed":64,"skipped":1041,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:46:46.452: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4208
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:46:53.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4208" for this suite.

â€¢ [SLOW TEST:7.203 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":275,"completed":65,"skipped":1043,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:46:53.656: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1086
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-a0970041-0dbc-477c-a1d6-368e0aeb01f3
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:46:55.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1086" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":275,"completed":66,"skipped":1055,"failed":0}
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:46:55.846: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9462
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:46:58.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9462" for this suite.
â€¢{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":275,"completed":67,"skipped":1056,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:46:58.059: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-278
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:47:00.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-278" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":275,"completed":68,"skipped":1078,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:47:00.293: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1848
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-e13745c1-5d57-4da3-bb21-67b009a0a633
STEP: Creating a pod to test consume secrets
Sep 30 18:47:00.443: INFO: Waiting up to 5m0s for pod "pod-secrets-431eff8b-ab43-4848-b64e-de0391c3bbbd" in namespace "secrets-1848" to be "Succeeded or Failed"
Sep 30 18:47:00.449: INFO: Pod "pod-secrets-431eff8b-ab43-4848-b64e-de0391c3bbbd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12886ms
Sep 30 18:47:02.464: INFO: Pod "pod-secrets-431eff8b-ab43-4848-b64e-de0391c3bbbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020816195s
STEP: Saw pod success
Sep 30 18:47:02.464: INFO: Pod "pod-secrets-431eff8b-ab43-4848-b64e-de0391c3bbbd" satisfied condition "Succeeded or Failed"
Sep 30 18:47:02.466: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod pod-secrets-431eff8b-ab43-4848-b64e-de0391c3bbbd container secret-env-test: <nil>
STEP: delete the pod
Sep 30 18:47:02.483: INFO: Waiting for pod pod-secrets-431eff8b-ab43-4848-b64e-de0391c3bbbd to disappear
Sep 30 18:47:02.491: INFO: Pod pod-secrets-431eff8b-ab43-4848-b64e-de0391c3bbbd no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:47:02.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1848" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":275,"completed":69,"skipped":1085,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:47:02.496: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-6180
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Sep 30 18:47:02.688: INFO: Found 0 stateful pods, waiting for 3
Sep 30 18:47:12.694: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 18:47:12.694: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 18:47:12.694: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 18:47:12.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-6180 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 18:47:12.862: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 18:47:12.862: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 18:47:12.862: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 30 18:47:22.884: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 30 18:47:32.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-6180 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 18:47:34.345: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 30 18:47:34.345: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 30 18:47:34.345: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 30 18:47:44.357: INFO: Waiting for StatefulSet statefulset-6180/ss2 to complete update
Sep 30 18:47:44.357: INFO: Waiting for Pod statefulset-6180/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 30 18:47:44.357: INFO: Waiting for Pod statefulset-6180/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 30 18:47:44.357: INFO: Waiting for Pod statefulset-6180/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 30 18:47:54.362: INFO: Waiting for StatefulSet statefulset-6180/ss2 to complete update
Sep 30 18:47:54.362: INFO: Waiting for Pod statefulset-6180/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Sep 30 18:48:04.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-6180 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 18:48:04.522: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 18:48:04.522: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 18:48:04.522: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 30 18:48:14.546: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 30 18:48:24.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-6180 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 18:48:24.762: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 30 18:48:24.762: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 30 18:48:24.762: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 30 18:48:44.774: INFO: Waiting for StatefulSet statefulset-6180/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 30 18:48:54.779: INFO: Deleting all statefulset in ns statefulset-6180
Sep 30 18:48:54.780: INFO: Scaling statefulset ss2 to 0
Sep 30 18:49:14.791: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 18:49:14.793: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:49:14.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6180" for this suite.

â€¢ [SLOW TEST:132.317 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":275,"completed":70,"skipped":1111,"failed":0}
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:49:14.814: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7543
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0930 18:49:21.000238      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 30 18:49:21.000: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:49:21.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7543" for this suite.

â€¢ [SLOW TEST:6.192 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":275,"completed":71,"skipped":1113,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:49:21.007: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5978
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:49:25.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5978" for this suite.
â€¢{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":275,"completed":72,"skipped":1173,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:49:25.201: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 18:49:25.742: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 18:49:27.747: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088565, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088565, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088565, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088565, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 18:49:30.757: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:49:30.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6765" for this suite.
STEP: Destroying namespace "webhook-6765-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:5.721 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":275,"completed":73,"skipped":1210,"failed":0}
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:49:30.922: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3131
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0930 18:49:41.224533      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 30 18:49:41.224: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:49:41.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3131" for this suite.

â€¢ [SLOW TEST:10.314 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":275,"completed":74,"skipped":1213,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:49:41.237: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-369
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-dcd26e02-38f9-4c04-9e95-d3c224f6e8fd
STEP: Creating a pod to test consume secrets
Sep 30 18:49:41.428: INFO: Waiting up to 5m0s for pod "pod-secrets-d0ba9de2-ad7c-4b45-b689-6b85c4964840" in namespace "secrets-369" to be "Succeeded or Failed"
Sep 30 18:49:41.438: INFO: Pod "pod-secrets-d0ba9de2-ad7c-4b45-b689-6b85c4964840": Phase="Pending", Reason="", readiness=false. Elapsed: 10.494384ms
Sep 30 18:49:43.441: INFO: Pod "pod-secrets-d0ba9de2-ad7c-4b45-b689-6b85c4964840": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013633069s
Sep 30 18:49:45.445: INFO: Pod "pod-secrets-d0ba9de2-ad7c-4b45-b689-6b85c4964840": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017174694s
STEP: Saw pod success
Sep 30 18:49:45.445: INFO: Pod "pod-secrets-d0ba9de2-ad7c-4b45-b689-6b85c4964840" satisfied condition "Succeeded or Failed"
Sep 30 18:49:45.449: INFO: Trying to get logs from node c4ab02cf-8388-4ee7-9741-792b2ee511a4 pod pod-secrets-d0ba9de2-ad7c-4b45-b689-6b85c4964840 container secret-volume-test: <nil>
STEP: delete the pod
Sep 30 18:49:45.481: INFO: Waiting for pod pod-secrets-d0ba9de2-ad7c-4b45-b689-6b85c4964840 to disappear
Sep 30 18:49:45.488: INFO: Pod pod-secrets-d0ba9de2-ad7c-4b45-b689-6b85c4964840 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:49:45.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-369" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":275,"completed":75,"skipped":1223,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:49:45.494: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:50:01.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9623" for this suite.

â€¢ [SLOW TEST:16.234 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":275,"completed":76,"skipped":1224,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:50:01.728: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8756
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 30 18:50:01.885: INFO: Waiting up to 5m0s for pod "downward-api-dd8d4031-3975-44e9-b639-db6869dbb3ab" in namespace "downward-api-8756" to be "Succeeded or Failed"
Sep 30 18:50:01.893: INFO: Pod "downward-api-dd8d4031-3975-44e9-b639-db6869dbb3ab": Phase="Pending", Reason="", readiness=false. Elapsed: 7.571133ms
Sep 30 18:50:03.895: INFO: Pod "downward-api-dd8d4031-3975-44e9-b639-db6869dbb3ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009923134s
STEP: Saw pod success
Sep 30 18:50:03.895: INFO: Pod "downward-api-dd8d4031-3975-44e9-b639-db6869dbb3ab" satisfied condition "Succeeded or Failed"
Sep 30 18:50:03.897: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downward-api-dd8d4031-3975-44e9-b639-db6869dbb3ab container dapi-container: <nil>
STEP: delete the pod
Sep 30 18:50:03.927: INFO: Waiting for pod downward-api-dd8d4031-3975-44e9-b639-db6869dbb3ab to disappear
Sep 30 18:50:03.931: INFO: Pod downward-api-dd8d4031-3975-44e9-b639-db6869dbb3ab no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:50:03.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8756" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":275,"completed":77,"skipped":1239,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:50:03.937: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:50:08.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7791" for this suite.
â€¢{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":78,"skipped":1293,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:50:08.168: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9161
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:50:08.364: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 30 18:50:11.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-9161 create -f -'
Sep 30 18:50:12.731: INFO: stderr: ""
Sep 30 18:50:12.731: INFO: stdout: "e2e-test-crd-publish-openapi-2933-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 30 18:50:12.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-9161 delete e2e-test-crd-publish-openapi-2933-crds test-cr'
Sep 30 18:50:12.799: INFO: stderr: ""
Sep 30 18:50:12.799: INFO: stdout: "e2e-test-crd-publish-openapi-2933-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Sep 30 18:50:12.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-9161 apply -f -'
Sep 30 18:50:12.957: INFO: stderr: ""
Sep 30 18:50:12.957: INFO: stdout: "e2e-test-crd-publish-openapi-2933-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 30 18:50:12.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-9161 delete e2e-test-crd-publish-openapi-2933-crds test-cr'
Sep 30 18:50:13.035: INFO: stderr: ""
Sep 30 18:50:13.035: INFO: stdout: "e2e-test-crd-publish-openapi-2933-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 30 18:50:13.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 explain e2e-test-crd-publish-openapi-2933-crds'
Sep 30 18:50:13.187: INFO: stderr: ""
Sep 30 18:50:13.187: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2933-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:50:16.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9161" for this suite.

â€¢ [SLOW TEST:7.911 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":275,"completed":79,"skipped":1325,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:50:16.080: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 18:50:16.585: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 18:50:18.593: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088616, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088616, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088616, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088616, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 18:50:21.600: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Sep 30 18:50:23.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 attach --namespace=webhook-6213 to-be-attached-pod -i -c=container1'
Sep 30 18:50:23.727: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:50:23.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6213" for this suite.
STEP: Destroying namespace "webhook-6213-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:7.725 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":275,"completed":80,"skipped":1338,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:50:23.804: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3987
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 30 18:50:24.715: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Sep 30 18:50:26.720: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088624, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088624, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088624, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088624, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 18:50:29.728: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:50:29.731: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:50:30.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3987" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:7.171 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":275,"completed":81,"skipped":1340,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:50:30.975: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4298
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Sep 30 18:50:31.138: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 18:50:34.000: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:50:45.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4298" for this suite.

â€¢ [SLOW TEST:14.391 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":275,"completed":82,"skipped":1351,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:50:45.367: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2650
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-eef4af6f-f54b-4472-82ce-ad7a0da72af5
STEP: Creating a pod to test consume configMaps
Sep 30 18:50:45.564: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-02029910-ac76-4cd9-99aa-3beba172688c" in namespace "projected-2650" to be "Succeeded or Failed"
Sep 30 18:50:45.569: INFO: Pod "pod-projected-configmaps-02029910-ac76-4cd9-99aa-3beba172688c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.178245ms
Sep 30 18:50:47.572: INFO: Pod "pod-projected-configmaps-02029910-ac76-4cd9-99aa-3beba172688c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007886894s
STEP: Saw pod success
Sep 30 18:50:47.572: INFO: Pod "pod-projected-configmaps-02029910-ac76-4cd9-99aa-3beba172688c" satisfied condition "Succeeded or Failed"
Sep 30 18:50:47.573: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-projected-configmaps-02029910-ac76-4cd9-99aa-3beba172688c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 18:50:47.595: INFO: Waiting for pod pod-projected-configmaps-02029910-ac76-4cd9-99aa-3beba172688c to disappear
Sep 30 18:50:47.600: INFO: Pod pod-projected-configmaps-02029910-ac76-4cd9-99aa-3beba172688c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:50:47.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2650" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":275,"completed":83,"skipped":1368,"failed":0}
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:50:47.605: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:50:47.757: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: creating replication controller svc-latency-rc in namespace svc-latency-944
I0930 18:50:47.766093      21 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-944, replica count: 1
I0930 18:50:48.816513      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0930 18:50:49.816735      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0930 18:50:50.816910      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 30 18:50:50.929: INFO: Created: latency-svc-6575n
Sep 30 18:50:50.936: INFO: Got endpoints: latency-svc-6575n [19.287987ms]
Sep 30 18:50:50.956: INFO: Created: latency-svc-m8lbj
Sep 30 18:50:50.962: INFO: Got endpoints: latency-svc-m8lbj [26.096742ms]
Sep 30 18:50:50.974: INFO: Created: latency-svc-j9jvg
Sep 30 18:50:50.988: INFO: Got endpoints: latency-svc-j9jvg [52.155938ms]
Sep 30 18:50:51.004: INFO: Created: latency-svc-28cph
Sep 30 18:50:51.025: INFO: Got endpoints: latency-svc-28cph [88.894466ms]
Sep 30 18:50:51.027: INFO: Created: latency-svc-ksggx
Sep 30 18:50:51.038: INFO: Got endpoints: latency-svc-ksggx [101.56301ms]
Sep 30 18:50:51.052: INFO: Created: latency-svc-slbdg
Sep 30 18:50:51.065: INFO: Got endpoints: latency-svc-slbdg [128.454831ms]
Sep 30 18:50:51.080: INFO: Created: latency-svc-ww67m
Sep 30 18:50:51.089: INFO: Got endpoints: latency-svc-ww67m [149.106573ms]
Sep 30 18:50:51.111: INFO: Created: latency-svc-bzxbb
Sep 30 18:50:51.116: INFO: Got endpoints: latency-svc-bzxbb [179.463431ms]
Sep 30 18:50:51.140: INFO: Created: latency-svc-5w89l
Sep 30 18:50:51.146: INFO: Got endpoints: latency-svc-5w89l [206.734212ms]
Sep 30 18:50:51.148: INFO: Created: latency-svc-js68l
Sep 30 18:50:51.160: INFO: Got endpoints: latency-svc-js68l [219.40352ms]
Sep 30 18:50:51.183: INFO: Created: latency-svc-xgfbc
Sep 30 18:50:51.190: INFO: Got endpoints: latency-svc-xgfbc [248.882882ms]
Sep 30 18:50:51.202: INFO: Created: latency-svc-9bkkt
Sep 30 18:50:51.211: INFO: Got endpoints: latency-svc-9bkkt [269.614801ms]
Sep 30 18:50:51.223: INFO: Created: latency-svc-znr62
Sep 30 18:50:51.231: INFO: Got endpoints: latency-svc-znr62 [290.416751ms]
Sep 30 18:50:51.253: INFO: Created: latency-svc-xxrz7
Sep 30 18:50:51.260: INFO: Created: latency-svc-4x48p
Sep 30 18:50:51.260: INFO: Got endpoints: latency-svc-xxrz7 [318.89616ms]
Sep 30 18:50:51.272: INFO: Got endpoints: latency-svc-4x48p [330.126088ms]
Sep 30 18:50:51.286: INFO: Created: latency-svc-rpmmh
Sep 30 18:50:51.297: INFO: Got endpoints: latency-svc-rpmmh [355.413752ms]
Sep 30 18:50:51.308: INFO: Created: latency-svc-p48hb
Sep 30 18:50:51.317: INFO: Got endpoints: latency-svc-p48hb [354.491129ms]
Sep 30 18:50:51.329: INFO: Created: latency-svc-hc4k7
Sep 30 18:50:51.345: INFO: Got endpoints: latency-svc-hc4k7 [356.568823ms]
Sep 30 18:50:51.359: INFO: Created: latency-svc-mbr4k
Sep 30 18:50:51.368: INFO: Got endpoints: latency-svc-mbr4k [342.251413ms]
Sep 30 18:50:51.374: INFO: Created: latency-svc-znlgp
Sep 30 18:50:51.387: INFO: Got endpoints: latency-svc-znlgp [41.431944ms]
Sep 30 18:50:51.395: INFO: Created: latency-svc-q4cvk
Sep 30 18:50:51.409: INFO: Got endpoints: latency-svc-q4cvk [370.63573ms]
Sep 30 18:50:51.424: INFO: Created: latency-svc-xflxb
Sep 30 18:50:51.433: INFO: Got endpoints: latency-svc-xflxb [367.523049ms]
Sep 30 18:50:51.453: INFO: Created: latency-svc-xqm6v
Sep 30 18:50:51.465: INFO: Got endpoints: latency-svc-xqm6v [376.006139ms]
Sep 30 18:50:51.469: INFO: Created: latency-svc-78gct
Sep 30 18:50:51.477: INFO: Got endpoints: latency-svc-78gct [360.758605ms]
Sep 30 18:50:51.490: INFO: Created: latency-svc-j98rn
Sep 30 18:50:51.499: INFO: Got endpoints: latency-svc-j98rn [352.634391ms]
Sep 30 18:50:51.513: INFO: Created: latency-svc-xq8hw
Sep 30 18:50:51.519: INFO: Got endpoints: latency-svc-xq8hw [359.150444ms]
Sep 30 18:50:51.532: INFO: Created: latency-svc-jfl75
Sep 30 18:50:51.541: INFO: Got endpoints: latency-svc-jfl75 [350.991887ms]
Sep 30 18:50:51.553: INFO: Created: latency-svc-rmcqz
Sep 30 18:50:51.562: INFO: Got endpoints: latency-svc-rmcqz [351.434394ms]
Sep 30 18:50:51.588: INFO: Created: latency-svc-6rqnn
Sep 30 18:50:51.588: INFO: Created: latency-svc-25wv6
Sep 30 18:50:51.600: INFO: Got endpoints: latency-svc-25wv6 [340.199229ms]
Sep 30 18:50:51.601: INFO: Got endpoints: latency-svc-6rqnn [369.34291ms]
Sep 30 18:50:51.615: INFO: Created: latency-svc-4dww2
Sep 30 18:50:51.623: INFO: Got endpoints: latency-svc-4dww2 [351.450132ms]
Sep 30 18:50:51.635: INFO: Created: latency-svc-chq5r
Sep 30 18:50:51.646: INFO: Got endpoints: latency-svc-chq5r [349.403349ms]
Sep 30 18:50:51.658: INFO: Created: latency-svc-295xt
Sep 30 18:50:51.673: INFO: Got endpoints: latency-svc-295xt [356.537142ms]
Sep 30 18:50:51.688: INFO: Created: latency-svc-g7hgh
Sep 30 18:50:51.694: INFO: Got endpoints: latency-svc-g7hgh [326.451217ms]
Sep 30 18:50:51.708: INFO: Created: latency-svc-t5jxj
Sep 30 18:50:51.720: INFO: Got endpoints: latency-svc-t5jxj [333.409673ms]
Sep 30 18:50:51.731: INFO: Created: latency-svc-zsbnp
Sep 30 18:50:51.763: INFO: Created: latency-svc-dphhn
Sep 30 18:50:51.765: INFO: Got endpoints: latency-svc-zsbnp [356.380294ms]
Sep 30 18:50:51.825: INFO: Got endpoints: latency-svc-dphhn [392.376644ms]
Sep 30 18:50:51.836: INFO: Created: latency-svc-xgfwp
Sep 30 18:50:51.837: INFO: Created: latency-svc-rrhdr
Sep 30 18:50:51.841: INFO: Created: latency-svc-68v77
Sep 30 18:50:51.854: INFO: Got endpoints: latency-svc-68v77 [354.648951ms]
Sep 30 18:50:51.854: INFO: Got endpoints: latency-svc-rrhdr [389.362067ms]
Sep 30 18:50:51.854: INFO: Got endpoints: latency-svc-xgfwp [376.877409ms]
Sep 30 18:50:51.880: INFO: Created: latency-svc-44p4t
Sep 30 18:50:51.891: INFO: Created: latency-svc-m8hgj
Sep 30 18:50:51.892: INFO: Got endpoints: latency-svc-44p4t [372.240751ms]
Sep 30 18:50:51.902: INFO: Got endpoints: latency-svc-m8hgj [361.254093ms]
Sep 30 18:50:51.929: INFO: Created: latency-svc-blg2x
Sep 30 18:50:51.933: INFO: Got endpoints: latency-svc-blg2x [371.4367ms]
Sep 30 18:50:51.947: INFO: Created: latency-svc-cl5kq
Sep 30 18:50:51.953: INFO: Got endpoints: latency-svc-cl5kq [352.297655ms]
Sep 30 18:50:51.965: INFO: Created: latency-svc-bcdz5
Sep 30 18:50:51.976: INFO: Got endpoints: latency-svc-bcdz5 [375.508432ms]
Sep 30 18:50:51.988: INFO: Created: latency-svc-58zbs
Sep 30 18:50:51.997: INFO: Got endpoints: latency-svc-58zbs [373.501001ms]
Sep 30 18:50:52.008: INFO: Created: latency-svc-bn65z
Sep 30 18:50:52.024: INFO: Got endpoints: latency-svc-bn65z [377.353828ms]
Sep 30 18:50:52.036: INFO: Created: latency-svc-n9jhc
Sep 30 18:50:52.042: INFO: Got endpoints: latency-svc-n9jhc [368.417155ms]
Sep 30 18:50:52.051: INFO: Created: latency-svc-sjfwj
Sep 30 18:50:52.065: INFO: Got endpoints: latency-svc-sjfwj [370.483428ms]
Sep 30 18:50:52.073: INFO: Created: latency-svc-l8blq
Sep 30 18:50:52.085: INFO: Got endpoints: latency-svc-l8blq [364.866106ms]
Sep 30 18:50:52.105: INFO: Created: latency-svc-wbv64
Sep 30 18:50:52.116: INFO: Got endpoints: latency-svc-wbv64 [350.445674ms]
Sep 30 18:50:52.123: INFO: Created: latency-svc-vh4wg
Sep 30 18:50:52.133: INFO: Got endpoints: latency-svc-vh4wg [307.488346ms]
Sep 30 18:50:52.154: INFO: Created: latency-svc-5wxkp
Sep 30 18:50:52.161: INFO: Got endpoints: latency-svc-5wxkp [307.130834ms]
Sep 30 18:50:52.161: INFO: Created: latency-svc-tgxll
Sep 30 18:50:52.172: INFO: Got endpoints: latency-svc-tgxll [317.649424ms]
Sep 30 18:50:52.187: INFO: Created: latency-svc-2hk9n
Sep 30 18:50:52.197: INFO: Got endpoints: latency-svc-2hk9n [342.716177ms]
Sep 30 18:50:52.209: INFO: Created: latency-svc-vv9wh
Sep 30 18:50:52.222: INFO: Created: latency-svc-g8nfp
Sep 30 18:50:52.241: INFO: Got endpoints: latency-svc-vv9wh [349.306261ms]
Sep 30 18:50:52.241: INFO: Created: latency-svc-2nmwt
Sep 30 18:50:52.268: INFO: Created: latency-svc-6bdwg
Sep 30 18:50:52.279: INFO: Created: latency-svc-5v874
Sep 30 18:50:52.291: INFO: Got endpoints: latency-svc-g8nfp [388.479553ms]
Sep 30 18:50:52.306: INFO: Created: latency-svc-8vqlt
Sep 30 18:50:52.322: INFO: Created: latency-svc-kpjqv
Sep 30 18:50:52.335: INFO: Created: latency-svc-7qpwc
Sep 30 18:50:52.336: INFO: Got endpoints: latency-svc-2nmwt [402.645213ms]
Sep 30 18:50:52.355: INFO: Created: latency-svc-kq8bd
Sep 30 18:50:52.381: INFO: Created: latency-svc-t7v9r
Sep 30 18:50:52.385: INFO: Got endpoints: latency-svc-6bdwg [431.881111ms]
Sep 30 18:50:52.397: INFO: Created: latency-svc-rm5dz
Sep 30 18:50:52.412: INFO: Created: latency-svc-56jmj
Sep 30 18:50:52.425: INFO: Created: latency-svc-wvl79
Sep 30 18:50:52.439: INFO: Got endpoints: latency-svc-5v874 [462.726515ms]
Sep 30 18:50:52.452: INFO: Created: latency-svc-dvkhq
Sep 30 18:50:52.473: INFO: Created: latency-svc-4nqhj
Sep 30 18:50:52.497: INFO: Got endpoints: latency-svc-8vqlt [500.338933ms]
Sep 30 18:50:52.500: INFO: Created: latency-svc-v6wwb
Sep 30 18:50:52.522: INFO: Created: latency-svc-twvmv
Sep 30 18:50:52.534: INFO: Got endpoints: latency-svc-kpjqv [510.003984ms]
Sep 30 18:50:52.535: INFO: Created: latency-svc-rn67s
Sep 30 18:50:52.555: INFO: Created: latency-svc-mxdlc
Sep 30 18:50:52.567: INFO: Created: latency-svc-k2hhr
Sep 30 18:50:52.588: INFO: Got endpoints: latency-svc-7qpwc [546.032069ms]
Sep 30 18:50:52.590: INFO: Created: latency-svc-trnbc
Sep 30 18:50:52.614: INFO: Created: latency-svc-th5sp
Sep 30 18:50:52.635: INFO: Created: latency-svc-49mhf
Sep 30 18:50:52.652: INFO: Got endpoints: latency-svc-kq8bd [587.314124ms]
Sep 30 18:50:52.667: INFO: Created: latency-svc-5t68g
Sep 30 18:50:52.683: INFO: Got endpoints: latency-svc-t7v9r [597.540755ms]
Sep 30 18:50:52.701: INFO: Created: latency-svc-jk94s
Sep 30 18:50:52.735: INFO: Got endpoints: latency-svc-rm5dz [619.369855ms]
Sep 30 18:50:52.757: INFO: Created: latency-svc-gg5x7
Sep 30 18:50:52.782: INFO: Got endpoints: latency-svc-56jmj [649.018266ms]
Sep 30 18:50:52.807: INFO: Created: latency-svc-wvksh
Sep 30 18:50:52.840: INFO: Got endpoints: latency-svc-wvl79 [679.205593ms]
Sep 30 18:50:52.859: INFO: Created: latency-svc-dz6rr
Sep 30 18:50:52.881: INFO: Got endpoints: latency-svc-dvkhq [709.223297ms]
Sep 30 18:50:52.895: INFO: Created: latency-svc-rwn5l
Sep 30 18:50:52.934: INFO: Got endpoints: latency-svc-4nqhj [736.985548ms]
Sep 30 18:50:52.952: INFO: Created: latency-svc-5559d
Sep 30 18:50:52.983: INFO: Got endpoints: latency-svc-v6wwb [742.12629ms]
Sep 30 18:50:53.008: INFO: Created: latency-svc-rk64x
Sep 30 18:50:53.049: INFO: Got endpoints: latency-svc-twvmv [758.386742ms]
Sep 30 18:50:53.060: INFO: Created: latency-svc-v866n
Sep 30 18:50:53.084: INFO: Got endpoints: latency-svc-rn67s [747.781437ms]
Sep 30 18:50:53.114: INFO: Created: latency-svc-fg6zf
Sep 30 18:50:53.132: INFO: Got endpoints: latency-svc-mxdlc [746.491244ms]
Sep 30 18:50:53.172: INFO: Created: latency-svc-76sbg
Sep 30 18:50:53.183: INFO: Got endpoints: latency-svc-k2hhr [744.235698ms]
Sep 30 18:50:53.208: INFO: Created: latency-svc-572q6
Sep 30 18:50:53.232: INFO: Got endpoints: latency-svc-trnbc [734.691187ms]
Sep 30 18:50:53.256: INFO: Created: latency-svc-qjfs5
Sep 30 18:50:53.283: INFO: Got endpoints: latency-svc-th5sp [748.80305ms]
Sep 30 18:50:53.305: INFO: Created: latency-svc-mx7sx
Sep 30 18:50:53.332: INFO: Got endpoints: latency-svc-49mhf [744.011426ms]
Sep 30 18:50:53.356: INFO: Created: latency-svc-mm8pb
Sep 30 18:50:53.381: INFO: Got endpoints: latency-svc-5t68g [729.202576ms]
Sep 30 18:50:53.405: INFO: Created: latency-svc-4x65n
Sep 30 18:50:53.431: INFO: Got endpoints: latency-svc-jk94s [748.391721ms]
Sep 30 18:50:53.447: INFO: Created: latency-svc-9vf4t
Sep 30 18:50:53.487: INFO: Got endpoints: latency-svc-gg5x7 [751.436978ms]
Sep 30 18:50:53.506: INFO: Created: latency-svc-5wgpz
Sep 30 18:50:53.532: INFO: Got endpoints: latency-svc-wvksh [749.991762ms]
Sep 30 18:50:53.553: INFO: Created: latency-svc-2ks6f
Sep 30 18:50:53.582: INFO: Got endpoints: latency-svc-dz6rr [741.460785ms]
Sep 30 18:50:53.606: INFO: Created: latency-svc-lnmdx
Sep 30 18:50:53.633: INFO: Got endpoints: latency-svc-rwn5l [751.609144ms]
Sep 30 18:50:53.656: INFO: Created: latency-svc-m9hl5
Sep 30 18:50:53.682: INFO: Got endpoints: latency-svc-5559d [748.105256ms]
Sep 30 18:50:53.707: INFO: Created: latency-svc-5klkj
Sep 30 18:50:53.732: INFO: Got endpoints: latency-svc-rk64x [748.463308ms]
Sep 30 18:50:53.757: INFO: Created: latency-svc-gtr5s
Sep 30 18:50:53.782: INFO: Got endpoints: latency-svc-v866n [732.415248ms]
Sep 30 18:50:53.804: INFO: Created: latency-svc-6z54s
Sep 30 18:50:53.831: INFO: Got endpoints: latency-svc-fg6zf [747.341324ms]
Sep 30 18:50:53.845: INFO: Created: latency-svc-dlpmz
Sep 30 18:50:53.881: INFO: Got endpoints: latency-svc-76sbg [749.457534ms]
Sep 30 18:50:53.914: INFO: Created: latency-svc-lxm7g
Sep 30 18:50:53.931: INFO: Got endpoints: latency-svc-572q6 [747.620091ms]
Sep 30 18:50:53.954: INFO: Created: latency-svc-fsd6k
Sep 30 18:50:53.982: INFO: Got endpoints: latency-svc-qjfs5 [750.159652ms]
Sep 30 18:50:54.006: INFO: Created: latency-svc-8zfqz
Sep 30 18:50:54.031: INFO: Got endpoints: latency-svc-mx7sx [748.45325ms]
Sep 30 18:50:54.054: INFO: Created: latency-svc-x7sk4
Sep 30 18:50:54.091: INFO: Got endpoints: latency-svc-mm8pb [758.93392ms]
Sep 30 18:50:54.106: INFO: Created: latency-svc-cqkrk
Sep 30 18:50:54.131: INFO: Got endpoints: latency-svc-4x65n [749.445091ms]
Sep 30 18:50:54.155: INFO: Created: latency-svc-jw792
Sep 30 18:50:54.188: INFO: Got endpoints: latency-svc-9vf4t [756.867994ms]
Sep 30 18:50:54.203: INFO: Created: latency-svc-fqsz7
Sep 30 18:50:54.234: INFO: Got endpoints: latency-svc-5wgpz [746.760466ms]
Sep 30 18:50:54.254: INFO: Created: latency-svc-6frx2
Sep 30 18:50:54.287: INFO: Got endpoints: latency-svc-2ks6f [754.821873ms]
Sep 30 18:50:54.316: INFO: Created: latency-svc-44sd8
Sep 30 18:50:54.331: INFO: Got endpoints: latency-svc-lnmdx [749.467357ms]
Sep 30 18:50:54.355: INFO: Created: latency-svc-lbz5m
Sep 30 18:50:54.381: INFO: Got endpoints: latency-svc-m9hl5 [748.669186ms]
Sep 30 18:50:54.403: INFO: Created: latency-svc-jrbvq
Sep 30 18:50:54.431: INFO: Got endpoints: latency-svc-5klkj [749.65193ms]
Sep 30 18:50:54.457: INFO: Created: latency-svc-n5d6c
Sep 30 18:50:54.488: INFO: Got endpoints: latency-svc-gtr5s [755.878461ms]
Sep 30 18:50:54.503: INFO: Created: latency-svc-rtxhz
Sep 30 18:50:54.535: INFO: Got endpoints: latency-svc-6z54s [752.935097ms]
Sep 30 18:50:54.562: INFO: Created: latency-svc-kcsf6
Sep 30 18:50:54.582: INFO: Got endpoints: latency-svc-dlpmz [750.542401ms]
Sep 30 18:50:54.611: INFO: Created: latency-svc-n6zsq
Sep 30 18:50:54.631: INFO: Got endpoints: latency-svc-lxm7g [749.838536ms]
Sep 30 18:50:54.656: INFO: Created: latency-svc-hwn55
Sep 30 18:50:54.681: INFO: Got endpoints: latency-svc-fsd6k [750.315211ms]
Sep 30 18:50:54.695: INFO: Created: latency-svc-wps9p
Sep 30 18:50:54.731: INFO: Got endpoints: latency-svc-8zfqz [749.281806ms]
Sep 30 18:50:54.750: INFO: Created: latency-svc-4lv2f
Sep 30 18:50:54.784: INFO: Got endpoints: latency-svc-x7sk4 [752.273636ms]
Sep 30 18:50:54.799: INFO: Created: latency-svc-m6rpt
Sep 30 18:50:54.833: INFO: Got endpoints: latency-svc-cqkrk [741.644745ms]
Sep 30 18:50:54.853: INFO: Created: latency-svc-nvrhs
Sep 30 18:50:54.891: INFO: Got endpoints: latency-svc-jw792 [759.660494ms]
Sep 30 18:50:54.905: INFO: Created: latency-svc-sj8p7
Sep 30 18:50:54.932: INFO: Got endpoints: latency-svc-fqsz7 [743.474691ms]
Sep 30 18:50:54.955: INFO: Created: latency-svc-tjw5q
Sep 30 18:50:54.982: INFO: Got endpoints: latency-svc-6frx2 [747.908263ms]
Sep 30 18:50:55.007: INFO: Created: latency-svc-grj8x
Sep 30 18:50:55.032: INFO: Got endpoints: latency-svc-44sd8 [744.558599ms]
Sep 30 18:50:55.054: INFO: Created: latency-svc-vtrx9
Sep 30 18:50:55.082: INFO: Got endpoints: latency-svc-lbz5m [750.84257ms]
Sep 30 18:50:55.112: INFO: Created: latency-svc-bq7c2
Sep 30 18:50:55.133: INFO: Got endpoints: latency-svc-jrbvq [751.639518ms]
Sep 30 18:50:55.154: INFO: Created: latency-svc-djq5g
Sep 30 18:50:55.183: INFO: Got endpoints: latency-svc-n5d6c [751.102937ms]
Sep 30 18:50:55.206: INFO: Created: latency-svc-78sks
Sep 30 18:50:55.232: INFO: Got endpoints: latency-svc-rtxhz [744.374012ms]
Sep 30 18:50:55.246: INFO: Created: latency-svc-sttcd
Sep 30 18:50:55.283: INFO: Got endpoints: latency-svc-kcsf6 [747.778442ms]
Sep 30 18:50:55.295: INFO: Created: latency-svc-qmb8p
Sep 30 18:50:55.333: INFO: Got endpoints: latency-svc-n6zsq [750.687969ms]
Sep 30 18:50:55.352: INFO: Created: latency-svc-jzpsx
Sep 30 18:50:55.382: INFO: Got endpoints: latency-svc-hwn55 [751.033967ms]
Sep 30 18:50:55.404: INFO: Created: latency-svc-tbb52
Sep 30 18:50:55.437: INFO: Got endpoints: latency-svc-wps9p [756.35824ms]
Sep 30 18:50:55.459: INFO: Created: latency-svc-j9dvl
Sep 30 18:50:55.482: INFO: Got endpoints: latency-svc-4lv2f [751.214471ms]
Sep 30 18:50:55.504: INFO: Created: latency-svc-q646r
Sep 30 18:50:55.539: INFO: Got endpoints: latency-svc-m6rpt [755.051399ms]
Sep 30 18:50:55.556: INFO: Created: latency-svc-hstwh
Sep 30 18:50:55.581: INFO: Got endpoints: latency-svc-nvrhs [748.767523ms]
Sep 30 18:50:55.605: INFO: Created: latency-svc-rpdhg
Sep 30 18:50:55.654: INFO: Got endpoints: latency-svc-sj8p7 [762.961842ms]
Sep 30 18:50:55.664: INFO: Created: latency-svc-qlwfq
Sep 30 18:50:55.682: INFO: Got endpoints: latency-svc-tjw5q [749.53811ms]
Sep 30 18:50:55.708: INFO: Created: latency-svc-5chcn
Sep 30 18:50:55.733: INFO: Got endpoints: latency-svc-grj8x [751.684474ms]
Sep 30 18:50:55.746: INFO: Created: latency-svc-584km
Sep 30 18:50:55.781: INFO: Got endpoints: latency-svc-vtrx9 [749.307294ms]
Sep 30 18:50:55.797: INFO: Created: latency-svc-rhdbz
Sep 30 18:50:55.831: INFO: Got endpoints: latency-svc-bq7c2 [749.170174ms]
Sep 30 18:50:55.851: INFO: Created: latency-svc-k2pf8
Sep 30 18:50:55.884: INFO: Got endpoints: latency-svc-djq5g [751.239104ms]
Sep 30 18:50:55.906: INFO: Created: latency-svc-jp6ln
Sep 30 18:50:55.932: INFO: Got endpoints: latency-svc-78sks [748.993452ms]
Sep 30 18:50:55.955: INFO: Created: latency-svc-plzx5
Sep 30 18:50:55.982: INFO: Got endpoints: latency-svc-sttcd [749.707454ms]
Sep 30 18:50:56.003: INFO: Created: latency-svc-p5kpj
Sep 30 18:50:56.040: INFO: Got endpoints: latency-svc-qmb8p [756.540352ms]
Sep 30 18:50:56.055: INFO: Created: latency-svc-5qrkc
Sep 30 18:50:56.098: INFO: Got endpoints: latency-svc-jzpsx [765.152665ms]
Sep 30 18:50:56.107: INFO: Created: latency-svc-4v27s
Sep 30 18:50:56.140: INFO: Got endpoints: latency-svc-tbb52 [757.77692ms]
Sep 30 18:50:56.156: INFO: Created: latency-svc-29fq8
Sep 30 18:50:56.189: INFO: Got endpoints: latency-svc-j9dvl [751.139861ms]
Sep 30 18:50:56.208: INFO: Created: latency-svc-bk8mp
Sep 30 18:50:56.231: INFO: Got endpoints: latency-svc-q646r [748.634553ms]
Sep 30 18:50:56.253: INFO: Created: latency-svc-fmz7p
Sep 30 18:50:56.283: INFO: Got endpoints: latency-svc-hstwh [743.935808ms]
Sep 30 18:50:56.296: INFO: Created: latency-svc-qrgl4
Sep 30 18:50:56.332: INFO: Got endpoints: latency-svc-rpdhg [750.718764ms]
Sep 30 18:50:56.359: INFO: Created: latency-svc-g9mdf
Sep 30 18:50:56.381: INFO: Got endpoints: latency-svc-qlwfq [727.443076ms]
Sep 30 18:50:56.405: INFO: Created: latency-svc-r6gxz
Sep 30 18:50:56.431: INFO: Got endpoints: latency-svc-5chcn [749.51009ms]
Sep 30 18:50:56.457: INFO: Created: latency-svc-snv8f
Sep 30 18:50:56.491: INFO: Got endpoints: latency-svc-584km [757.392144ms]
Sep 30 18:50:56.513: INFO: Created: latency-svc-hkvpk
Sep 30 18:50:56.537: INFO: Got endpoints: latency-svc-rhdbz [756.284466ms]
Sep 30 18:50:56.554: INFO: Created: latency-svc-fpbfg
Sep 30 18:50:56.581: INFO: Got endpoints: latency-svc-k2pf8 [749.691787ms]
Sep 30 18:50:56.605: INFO: Created: latency-svc-56zdq
Sep 30 18:50:56.631: INFO: Got endpoints: latency-svc-jp6ln [746.332742ms]
Sep 30 18:50:56.657: INFO: Created: latency-svc-k24sb
Sep 30 18:50:56.681: INFO: Got endpoints: latency-svc-plzx5 [748.73354ms]
Sep 30 18:50:56.703: INFO: Created: latency-svc-v5kbd
Sep 30 18:50:56.732: INFO: Got endpoints: latency-svc-p5kpj [749.759728ms]
Sep 30 18:50:56.761: INFO: Created: latency-svc-jfczl
Sep 30 18:50:56.781: INFO: Got endpoints: latency-svc-5qrkc [740.72504ms]
Sep 30 18:50:56.809: INFO: Created: latency-svc-9dc74
Sep 30 18:50:56.831: INFO: Got endpoints: latency-svc-4v27s [732.349092ms]
Sep 30 18:50:56.855: INFO: Created: latency-svc-wwkhv
Sep 30 18:50:56.890: INFO: Got endpoints: latency-svc-29fq8 [750.406522ms]
Sep 30 18:50:56.904: INFO: Created: latency-svc-t6mdh
Sep 30 18:50:56.931: INFO: Got endpoints: latency-svc-bk8mp [742.081532ms]
Sep 30 18:50:56.952: INFO: Created: latency-svc-jfcn2
Sep 30 18:50:56.983: INFO: Got endpoints: latency-svc-fmz7p [751.930445ms]
Sep 30 18:50:57.004: INFO: Created: latency-svc-cvnlx
Sep 30 18:50:57.031: INFO: Got endpoints: latency-svc-qrgl4 [747.176545ms]
Sep 30 18:50:57.055: INFO: Created: latency-svc-ssr78
Sep 30 18:50:57.082: INFO: Got endpoints: latency-svc-g9mdf [749.111835ms]
Sep 30 18:50:57.105: INFO: Created: latency-svc-2qw7c
Sep 30 18:50:57.135: INFO: Got endpoints: latency-svc-r6gxz [753.805042ms]
Sep 30 18:50:57.153: INFO: Created: latency-svc-h6lz2
Sep 30 18:50:57.181: INFO: Got endpoints: latency-svc-snv8f [749.829519ms]
Sep 30 18:50:57.208: INFO: Created: latency-svc-r9pw5
Sep 30 18:50:57.232: INFO: Got endpoints: latency-svc-hkvpk [740.825742ms]
Sep 30 18:50:57.253: INFO: Created: latency-svc-4624z
Sep 30 18:50:57.281: INFO: Got endpoints: latency-svc-fpbfg [743.775592ms]
Sep 30 18:50:57.311: INFO: Created: latency-svc-j6vnd
Sep 30 18:50:57.338: INFO: Got endpoints: latency-svc-56zdq [756.626602ms]
Sep 30 18:50:57.353: INFO: Created: latency-svc-ps6k7
Sep 30 18:50:57.390: INFO: Got endpoints: latency-svc-k24sb [759.502213ms]
Sep 30 18:50:57.406: INFO: Created: latency-svc-xhcgs
Sep 30 18:50:57.431: INFO: Got endpoints: latency-svc-v5kbd [750.582769ms]
Sep 30 18:50:57.447: INFO: Created: latency-svc-swpgx
Sep 30 18:50:57.481: INFO: Got endpoints: latency-svc-jfczl [749.812686ms]
Sep 30 18:50:57.496: INFO: Created: latency-svc-d8zwk
Sep 30 18:50:57.533: INFO: Got endpoints: latency-svc-9dc74 [752.265209ms]
Sep 30 18:50:57.551: INFO: Created: latency-svc-878zw
Sep 30 18:50:57.584: INFO: Got endpoints: latency-svc-wwkhv [753.180593ms]
Sep 30 18:50:57.606: INFO: Created: latency-svc-256vg
Sep 30 18:50:57.632: INFO: Got endpoints: latency-svc-t6mdh [741.116885ms]
Sep 30 18:50:57.651: INFO: Created: latency-svc-dhgcf
Sep 30 18:50:57.682: INFO: Got endpoints: latency-svc-jfcn2 [750.791356ms]
Sep 30 18:50:57.706: INFO: Created: latency-svc-vm9vl
Sep 30 18:50:57.731: INFO: Got endpoints: latency-svc-cvnlx [747.611924ms]
Sep 30 18:50:57.755: INFO: Created: latency-svc-lh5cn
Sep 30 18:50:57.783: INFO: Got endpoints: latency-svc-ssr78 [752.178976ms]
Sep 30 18:50:57.803: INFO: Created: latency-svc-dqjqp
Sep 30 18:50:57.831: INFO: Got endpoints: latency-svc-2qw7c [749.505407ms]
Sep 30 18:50:57.862: INFO: Created: latency-svc-swv5t
Sep 30 18:50:57.883: INFO: Got endpoints: latency-svc-h6lz2 [747.680693ms]
Sep 30 18:50:57.898: INFO: Created: latency-svc-df2w4
Sep 30 18:50:57.931: INFO: Got endpoints: latency-svc-r9pw5 [750.112431ms]
Sep 30 18:50:57.952: INFO: Created: latency-svc-j5r2v
Sep 30 18:50:57.981: INFO: Got endpoints: latency-svc-4624z [749.489741ms]
Sep 30 18:50:58.004: INFO: Created: latency-svc-ln8sw
Sep 30 18:50:58.031: INFO: Got endpoints: latency-svc-j6vnd [749.460225ms]
Sep 30 18:50:58.055: INFO: Created: latency-svc-jnwrr
Sep 30 18:50:58.081: INFO: Got endpoints: latency-svc-ps6k7 [743.450695ms]
Sep 30 18:50:58.104: INFO: Created: latency-svc-n78nq
Sep 30 18:50:58.131: INFO: Got endpoints: latency-svc-xhcgs [740.649289ms]
Sep 30 18:50:58.150: INFO: Created: latency-svc-5f4xm
Sep 30 18:50:58.182: INFO: Got endpoints: latency-svc-swpgx [750.552694ms]
Sep 30 18:50:58.205: INFO: Created: latency-svc-qgp8l
Sep 30 18:50:58.238: INFO: Got endpoints: latency-svc-d8zwk [756.914966ms]
Sep 30 18:50:58.254: INFO: Created: latency-svc-f9gzf
Sep 30 18:50:58.287: INFO: Got endpoints: latency-svc-878zw [754.050444ms]
Sep 30 18:50:58.306: INFO: Created: latency-svc-rhddl
Sep 30 18:50:58.333: INFO: Got endpoints: latency-svc-256vg [748.546826ms]
Sep 30 18:50:58.367: INFO: Created: latency-svc-9rqgc
Sep 30 18:50:58.393: INFO: Got endpoints: latency-svc-dhgcf [761.073325ms]
Sep 30 18:50:58.408: INFO: Created: latency-svc-6q2f5
Sep 30 18:50:58.432: INFO: Got endpoints: latency-svc-vm9vl [750.142334ms]
Sep 30 18:50:58.454: INFO: Created: latency-svc-pqdw5
Sep 30 18:50:58.482: INFO: Got endpoints: latency-svc-lh5cn [750.882957ms]
Sep 30 18:50:58.511: INFO: Created: latency-svc-wcq5j
Sep 30 18:50:58.532: INFO: Got endpoints: latency-svc-dqjqp [749.397117ms]
Sep 30 18:50:58.561: INFO: Created: latency-svc-xgzvs
Sep 30 18:50:58.581: INFO: Got endpoints: latency-svc-swv5t [749.931361ms]
Sep 30 18:50:58.603: INFO: Created: latency-svc-2fmmw
Sep 30 18:50:58.634: INFO: Got endpoints: latency-svc-df2w4 [750.949641ms]
Sep 30 18:50:58.655: INFO: Created: latency-svc-b6rvp
Sep 30 18:50:58.692: INFO: Got endpoints: latency-svc-j5r2v [760.669148ms]
Sep 30 18:50:58.708: INFO: Created: latency-svc-mk2wb
Sep 30 18:50:58.733: INFO: Got endpoints: latency-svc-ln8sw [751.288483ms]
Sep 30 18:50:58.757: INFO: Created: latency-svc-sqn2x
Sep 30 18:50:58.789: INFO: Got endpoints: latency-svc-jnwrr [758.466145ms]
Sep 30 18:50:58.831: INFO: Got endpoints: latency-svc-n78nq [750.200919ms]
Sep 30 18:50:58.882: INFO: Got endpoints: latency-svc-5f4xm [750.171694ms]
Sep 30 18:50:58.941: INFO: Got endpoints: latency-svc-qgp8l [759.013207ms]
Sep 30 18:50:58.981: INFO: Got endpoints: latency-svc-f9gzf [742.867837ms]
Sep 30 18:50:59.031: INFO: Got endpoints: latency-svc-rhddl [743.854304ms]
Sep 30 18:50:59.081: INFO: Got endpoints: latency-svc-9rqgc [748.495903ms]
Sep 30 18:50:59.132: INFO: Got endpoints: latency-svc-6q2f5 [739.399383ms]
Sep 30 18:50:59.182: INFO: Got endpoints: latency-svc-pqdw5 [749.895713ms]
Sep 30 18:50:59.236: INFO: Got endpoints: latency-svc-wcq5j [754.264977ms]
Sep 30 18:50:59.282: INFO: Got endpoints: latency-svc-xgzvs [749.043963ms]
Sep 30 18:50:59.333: INFO: Got endpoints: latency-svc-2fmmw [751.925797ms]
Sep 30 18:50:59.383: INFO: Got endpoints: latency-svc-b6rvp [749.26436ms]
Sep 30 18:50:59.432: INFO: Got endpoints: latency-svc-mk2wb [739.506203ms]
Sep 30 18:50:59.485: INFO: Got endpoints: latency-svc-sqn2x [752.549858ms]
Sep 30 18:50:59.486: INFO: Latencies: [26.096742ms 41.431944ms 52.155938ms 88.894466ms 101.56301ms 128.454831ms 149.106573ms 179.463431ms 206.734212ms 219.40352ms 248.882882ms 269.614801ms 290.416751ms 307.130834ms 307.488346ms 317.649424ms 318.89616ms 326.451217ms 330.126088ms 333.409673ms 340.199229ms 342.251413ms 342.716177ms 349.306261ms 349.403349ms 350.445674ms 350.991887ms 351.434394ms 351.450132ms 352.297655ms 352.634391ms 354.491129ms 354.648951ms 355.413752ms 356.380294ms 356.537142ms 356.568823ms 359.150444ms 360.758605ms 361.254093ms 364.866106ms 367.523049ms 368.417155ms 369.34291ms 370.483428ms 370.63573ms 371.4367ms 372.240751ms 373.501001ms 375.508432ms 376.006139ms 376.877409ms 377.353828ms 388.479553ms 389.362067ms 392.376644ms 402.645213ms 431.881111ms 462.726515ms 500.338933ms 510.003984ms 546.032069ms 587.314124ms 597.540755ms 619.369855ms 649.018266ms 679.205593ms 709.223297ms 727.443076ms 729.202576ms 732.349092ms 732.415248ms 734.691187ms 736.985548ms 739.399383ms 739.506203ms 740.649289ms 740.72504ms 740.825742ms 741.116885ms 741.460785ms 741.644745ms 742.081532ms 742.12629ms 742.867837ms 743.450695ms 743.474691ms 743.775592ms 743.854304ms 743.935808ms 744.011426ms 744.235698ms 744.374012ms 744.558599ms 746.332742ms 746.491244ms 746.760466ms 747.176545ms 747.341324ms 747.611924ms 747.620091ms 747.680693ms 747.778442ms 747.781437ms 747.908263ms 748.105256ms 748.391721ms 748.45325ms 748.463308ms 748.495903ms 748.546826ms 748.634553ms 748.669186ms 748.73354ms 748.767523ms 748.80305ms 748.993452ms 749.043963ms 749.111835ms 749.170174ms 749.26436ms 749.281806ms 749.307294ms 749.397117ms 749.445091ms 749.457534ms 749.460225ms 749.467357ms 749.489741ms 749.505407ms 749.51009ms 749.53811ms 749.65193ms 749.691787ms 749.707454ms 749.759728ms 749.812686ms 749.829519ms 749.838536ms 749.895713ms 749.931361ms 749.991762ms 750.112431ms 750.142334ms 750.159652ms 750.171694ms 750.200919ms 750.315211ms 750.406522ms 750.542401ms 750.552694ms 750.582769ms 750.687969ms 750.718764ms 750.791356ms 750.84257ms 750.882957ms 750.949641ms 751.033967ms 751.102937ms 751.139861ms 751.214471ms 751.239104ms 751.288483ms 751.436978ms 751.609144ms 751.639518ms 751.684474ms 751.925797ms 751.930445ms 752.178976ms 752.265209ms 752.273636ms 752.549858ms 752.935097ms 753.180593ms 753.805042ms 754.050444ms 754.264977ms 754.821873ms 755.051399ms 755.878461ms 756.284466ms 756.35824ms 756.540352ms 756.626602ms 756.867994ms 756.914966ms 757.392144ms 757.77692ms 758.386742ms 758.466145ms 758.93392ms 759.013207ms 759.502213ms 759.660494ms 760.669148ms 761.073325ms 762.961842ms 765.152665ms]
Sep 30 18:50:59.486: INFO: 50 %ile: 747.620091ms
Sep 30 18:50:59.486: INFO: 90 %ile: 755.051399ms
Sep 30 18:50:59.486: INFO: 99 %ile: 762.961842ms
Sep 30 18:50:59.486: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:50:59.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-944" for this suite.

â€¢ [SLOW TEST:11.891 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":275,"completed":84,"skipped":1374,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:50:59.496: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2547
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 18:51:00.107: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 18:51:02.114: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088660, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088660, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088660, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737088660, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 18:51:05.127: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:51:05.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2547" for this suite.
STEP: Destroying namespace "webhook-2547-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:5.905 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":275,"completed":85,"skipped":1375,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:51:05.401: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5166
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-78bf7995-1fd2-4139-b02b-285dfe3fd1e1 in namespace container-probe-5166
Sep 30 18:51:09.630: INFO: Started pod test-webserver-78bf7995-1fd2-4139-b02b-285dfe3fd1e1 in namespace container-probe-5166
STEP: checking the pod's current state and verifying that restartCount is present
Sep 30 18:51:09.633: INFO: Initial restart count of pod test-webserver-78bf7995-1fd2-4139-b02b-285dfe3fd1e1 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:55:09.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5166" for this suite.

â€¢ [SLOW TEST:244.607 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":275,"completed":86,"skipped":1394,"failed":0}
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:55:10.009: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-4b388737-eb8f-493f-a3dc-a34e30d0b8aa in namespace container-probe-4399
Sep 30 18:55:14.188: INFO: Started pod busybox-4b388737-eb8f-493f-a3dc-a34e30d0b8aa in namespace container-probe-4399
STEP: checking the pod's current state and verifying that restartCount is present
Sep 30 18:55:14.190: INFO: Initial restart count of pod busybox-4b388737-eb8f-493f-a3dc-a34e30d0b8aa is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:59:14.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4399" for this suite.

â€¢ [SLOW TEST:244.541 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":275,"completed":87,"skipped":1398,"failed":0}
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:59:14.550: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 30 18:59:19.217: INFO: Successfully updated pod "pod-update-47df9403-a5d9-4071-bd31-6d0313f38891"
STEP: verifying the updated pod is in kubernetes
Sep 30 18:59:19.236: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:59:19.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1688" for this suite.
â€¢{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":275,"completed":88,"skipped":1402,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:59:19.242: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5803
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 18:59:19.402: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 30 18:59:19.428: INFO: Number of nodes with available pods: 0
Sep 30 18:59:19.428: INFO: Node 9b360f31-b888-42e4-807a-5f2a0fca8fae is running more than one daemon pod
Sep 30 18:59:20.433: INFO: Number of nodes with available pods: 0
Sep 30 18:59:20.433: INFO: Node 9b360f31-b888-42e4-807a-5f2a0fca8fae is running more than one daemon pod
Sep 30 18:59:21.433: INFO: Number of nodes with available pods: 3
Sep 30 18:59:21.433: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 30 18:59:21.482: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:21.482: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:21.482: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:22.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:22.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:22.500: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:23.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:23.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:23.500: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:24.499: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:24.499: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:24.499: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:24.499: INFO: Pod daemon-set-tkxhr is not available
Sep 30 18:59:25.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:25.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:25.500: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:25.500: INFO: Pod daemon-set-tkxhr is not available
Sep 30 18:59:26.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:26.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:26.500: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:26.500: INFO: Pod daemon-set-tkxhr is not available
Sep 30 18:59:27.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:27.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:27.500: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:27.500: INFO: Pod daemon-set-tkxhr is not available
Sep 30 18:59:28.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:28.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:28.500: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:28.500: INFO: Pod daemon-set-tkxhr is not available
Sep 30 18:59:29.501: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:29.501: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:29.501: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:29.501: INFO: Pod daemon-set-tkxhr is not available
Sep 30 18:59:30.501: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:30.501: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:30.501: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:30.501: INFO: Pod daemon-set-tkxhr is not available
Sep 30 18:59:31.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:31.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:31.500: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:31.500: INFO: Pod daemon-set-tkxhr is not available
Sep 30 18:59:32.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:32.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:32.500: INFO: Wrong image for pod: daemon-set-tkxhr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:32.500: INFO: Pod daemon-set-tkxhr is not available
Sep 30 18:59:33.499: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:33.499: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:33.499: INFO: Pod daemon-set-mx4pf is not available
Sep 30 18:59:34.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:34.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:34.500: INFO: Pod daemon-set-mx4pf is not available
Sep 30 18:59:35.517: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:35.517: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:36.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:36.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:37.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:37.500: INFO: Wrong image for pod: daemon-set-lrkg9. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:37.500: INFO: Pod daemon-set-lrkg9 is not available
Sep 30 18:59:38.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:38.500: INFO: Pod daemon-set-qhrcm is not available
Sep 30 18:59:39.500: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:39.500: INFO: Pod daemon-set-qhrcm is not available
Sep 30 18:59:40.505: INFO: Wrong image for pod: daemon-set-l4m9l. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 30 18:59:40.505: INFO: Pod daemon-set-l4m9l is not available
Sep 30 18:59:41.507: INFO: Pod daemon-set-tkswb is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 30 18:59:41.537: INFO: Number of nodes with available pods: 2
Sep 30 18:59:41.537: INFO: Node eb106fc7-933d-47a1-a18a-16aa6514d845 is running more than one daemon pod
Sep 30 18:59:42.542: INFO: Number of nodes with available pods: 2
Sep 30 18:59:42.542: INFO: Node eb106fc7-933d-47a1-a18a-16aa6514d845 is running more than one daemon pod
Sep 30 18:59:43.562: INFO: Number of nodes with available pods: 3
Sep 30 18:59:43.562: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5803, will wait for the garbage collector to delete the pods
Sep 30 18:59:43.629: INFO: Deleting DaemonSet.extensions daemon-set took: 3.177264ms
Sep 30 18:59:44.029: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.168042ms
Sep 30 18:59:47.631: INFO: Number of nodes with available pods: 0
Sep 30 18:59:47.631: INFO: Number of running nodes: 0, number of available pods: 0
Sep 30 18:59:47.632: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5803/daemonsets","resourceVersion":"215051"},"items":null}

Sep 30 18:59:47.633: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5803/pods","resourceVersion":"215051"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 18:59:47.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5803" for this suite.

â€¢ [SLOW TEST:28.405 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":275,"completed":89,"skipped":1414,"failed":0}
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 18:59:47.648: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5306
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-5306
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5306
Sep 30 18:59:47.824: INFO: Found 0 stateful pods, waiting for 1
Sep 30 18:59:57.832: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 30 18:59:57.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 18:59:58.002: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 18:59:58.002: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 18:59:58.002: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 30 18:59:58.004: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 30 19:00:08.007: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 30 19:00:08.007: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 19:00:08.016: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:08.016: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:08.016: INFO: 
Sep 30 19:00:08.016: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 30 19:00:09.018: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997365612s
Sep 30 19:00:10.021: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994713538s
Sep 30 19:00:11.025: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.99179692s
Sep 30 19:00:12.027: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988708118s
Sep 30 19:00:13.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.986294673s
Sep 30 19:00:14.033: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.983181377s
Sep 30 19:00:15.036: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.980255803s
Sep 30 19:00:16.039: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.977247576s
Sep 30 19:00:17.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 974.542402ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5306
Sep 30 19:00:18.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:00:19.467: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 30 19:00:19.467: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 30 19:00:19.467: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 30 19:00:19.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:00:19.625: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 30 19:00:19.625: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 30 19:00:19.625: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 30 19:00:19.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:00:19.788: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 30 19:00:19.788: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 30 19:00:19.788: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 30 19:00:19.791: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 30 19:00:29.794: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 19:00:29.794: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 19:00:29.794: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 30 19:00:29.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 19:00:29.976: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 19:00:29.976: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 19:00:29.976: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 30 19:00:29.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 19:00:30.138: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 19:00:30.138: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 19:00:30.138: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 30 19:00:30.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 19:00:30.314: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 19:00:30.314: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 19:00:30.314: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 30 19:00:30.314: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 19:00:30.316: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep 30 19:00:40.320: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 30 19:00:40.320: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 30 19:00:40.320: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 30 19:00:40.334: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:40.334: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:40.334: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:40.334: INFO: ss-2  9b360f31-b888-42e4-807a-5f2a0fca8fae  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:40.334: INFO: 
Sep 30 19:00:40.334: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 30 19:00:41.338: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:41.338: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:41.338: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:41.338: INFO: ss-2  9b360f31-b888-42e4-807a-5f2a0fca8fae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:41.338: INFO: 
Sep 30 19:00:41.338: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 30 19:00:42.341: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:42.341: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:42.341: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:42.341: INFO: ss-2  9b360f31-b888-42e4-807a-5f2a0fca8fae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:42.342: INFO: 
Sep 30 19:00:42.342: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 30 19:00:43.344: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:43.344: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:43.345: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:43.345: INFO: ss-2  9b360f31-b888-42e4-807a-5f2a0fca8fae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:43.345: INFO: 
Sep 30 19:00:43.345: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 30 19:00:44.347: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:44.347: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:44.347: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:44.347: INFO: ss-2  9b360f31-b888-42e4-807a-5f2a0fca8fae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:44.347: INFO: 
Sep 30 19:00:44.347: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 30 19:00:45.350: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:45.350: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:45.350: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:45.350: INFO: ss-2  9b360f31-b888-42e4-807a-5f2a0fca8fae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:45.350: INFO: 
Sep 30 19:00:45.350: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 30 19:00:46.354: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:46.354: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:46.354: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:46.354: INFO: ss-2  9b360f31-b888-42e4-807a-5f2a0fca8fae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:46.354: INFO: 
Sep 30 19:00:46.354: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 30 19:00:47.357: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:47.357: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:47.357: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:47.357: INFO: 
Sep 30 19:00:47.357: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 30 19:00:48.360: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:48.361: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:48.361: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:48.361: INFO: 
Sep 30 19:00:48.361: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 30 19:00:49.364: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Sep 30 19:00:49.364: INFO: ss-0  eb106fc7-933d-47a1-a18a-16aa6514d845  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 18:59:47 +0000 UTC  }]
Sep 30 19:00:49.364: INFO: ss-1  eb106fc7-933d-47a1-a18a-16aa6514d845  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-30 19:00:08 +0000 UTC  }]
Sep 30 19:00:49.364: INFO: 
Sep 30 19:00:49.364: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5306
Sep 30 19:00:50.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:00:50.457: INFO: rc: 1
Sep 30 19:00:50.457: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Sep 30 19:01:00.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:01:00.526: INFO: rc: 1
Sep 30 19:01:00.526: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:01:10.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:01:10.599: INFO: rc: 1
Sep 30 19:01:10.599: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:01:20.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:01:20.664: INFO: rc: 1
Sep 30 19:01:20.664: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:01:30.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:01:30.733: INFO: rc: 1
Sep 30 19:01:30.733: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:01:40.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:01:40.801: INFO: rc: 1
Sep 30 19:01:40.801: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:01:50.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:01:50.868: INFO: rc: 1
Sep 30 19:01:50.868: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:02:00.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:02:00.933: INFO: rc: 1
Sep 30 19:02:00.933: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:02:10.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:02:10.995: INFO: rc: 1
Sep 30 19:02:10.995: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:02:20.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:02:21.078: INFO: rc: 1
Sep 30 19:02:21.078: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:02:31.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:02:31.148: INFO: rc: 1
Sep 30 19:02:31.148: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:02:41.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:02:41.210: INFO: rc: 1
Sep 30 19:02:41.210: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:02:51.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:02:51.275: INFO: rc: 1
Sep 30 19:02:51.275: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:03:01.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:03:01.348: INFO: rc: 1
Sep 30 19:03:01.349: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:03:11.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:03:11.422: INFO: rc: 1
Sep 30 19:03:11.422: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:03:21.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:03:21.483: INFO: rc: 1
Sep 30 19:03:21.483: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:03:31.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:03:31.545: INFO: rc: 1
Sep 30 19:03:31.545: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:03:41.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:03:41.605: INFO: rc: 1
Sep 30 19:03:41.605: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:03:51.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:03:51.668: INFO: rc: 1
Sep 30 19:03:51.668: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:04:01.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:04:01.732: INFO: rc: 1
Sep 30 19:04:01.732: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:04:11.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:04:11.794: INFO: rc: 1
Sep 30 19:04:11.794: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:04:21.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:04:21.856: INFO: rc: 1
Sep 30 19:04:21.856: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:04:31.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:04:31.925: INFO: rc: 1
Sep 30 19:04:31.925: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:04:41.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:04:41.990: INFO: rc: 1
Sep 30 19:04:41.990: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:04:51.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:04:52.055: INFO: rc: 1
Sep 30 19:04:52.055: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:05:02.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:05:02.119: INFO: rc: 1
Sep 30 19:05:02.119: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:05:12.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:05:12.186: INFO: rc: 1
Sep 30 19:05:12.186: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:05:22.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:05:22.250: INFO: rc: 1
Sep 30 19:05:22.250: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:05:32.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:05:32.317: INFO: rc: 1
Sep 30 19:05:32.317: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:05:42.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:05:42.385: INFO: rc: 1
Sep 30 19:05:42.385: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Sep 30 19:05:52.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-5306 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:05:52.451: INFO: rc: 1
Sep 30 19:05:52.452: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Sep 30 19:05:52.452: INFO: Scaling statefulset ss to 0
Sep 30 19:05:52.462: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 30 19:05:52.464: INFO: Deleting all statefulset in ns statefulset-5306
Sep 30 19:05:52.465: INFO: Scaling statefulset ss to 0
Sep 30 19:05:52.470: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 19:05:52.472: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:05:52.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5306" for this suite.

â€¢ [SLOW TEST:364.842 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":275,"completed":90,"skipped":1417,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:05:52.492: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 30 19:05:56.673: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 30 19:05:56.680: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 30 19:05:58.680: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 30 19:05:58.683: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 30 19:06:00.680: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 30 19:06:00.683: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 30 19:06:02.680: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 30 19:06:02.683: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 30 19:06:04.680: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 30 19:06:04.683: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:06:04.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1055" for this suite.

â€¢ [SLOW TEST:12.210 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":275,"completed":91,"skipped":1439,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:06:04.703: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:06:08.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1395" for this suite.
â€¢{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":275,"completed":92,"skipped":1446,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:06:08.925: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-365
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 30 19:06:09.074: INFO: Waiting up to 5m0s for pod "downward-api-5ae0bec5-7248-40bd-b78d-20ca30aa158e" in namespace "downward-api-365" to be "Succeeded or Failed"
Sep 30 19:06:09.106: INFO: Pod "downward-api-5ae0bec5-7248-40bd-b78d-20ca30aa158e": Phase="Pending", Reason="", readiness=false. Elapsed: 31.942355ms
Sep 30 19:06:11.109: INFO: Pod "downward-api-5ae0bec5-7248-40bd-b78d-20ca30aa158e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034592201s
STEP: Saw pod success
Sep 30 19:06:11.109: INFO: Pod "downward-api-5ae0bec5-7248-40bd-b78d-20ca30aa158e" satisfied condition "Succeeded or Failed"
Sep 30 19:06:11.114: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downward-api-5ae0bec5-7248-40bd-b78d-20ca30aa158e container dapi-container: <nil>
STEP: delete the pod
Sep 30 19:06:11.146: INFO: Waiting for pod downward-api-5ae0bec5-7248-40bd-b78d-20ca30aa158e to disappear
Sep 30 19:06:11.149: INFO: Pod downward-api-5ae0bec5-7248-40bd-b78d-20ca30aa158e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:06:11.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-365" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":275,"completed":93,"skipped":1454,"failed":0}
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:06:11.156: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3295
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:07:11.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3295" for this suite.

â€¢ [SLOW TEST:60.164 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":275,"completed":94,"skipped":1457,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:07:11.321: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9803
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-67f1525e-8119-49b7-b03d-a20eacee9863
STEP: Creating a pod to test consume secrets
Sep 30 19:07:11.524: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f40f01b1-5b10-49f8-8e4e-ccf66fc5ff05" in namespace "projected-9803" to be "Succeeded or Failed"
Sep 30 19:07:11.531: INFO: Pod "pod-projected-secrets-f40f01b1-5b10-49f8-8e4e-ccf66fc5ff05": Phase="Pending", Reason="", readiness=false. Elapsed: 6.486741ms
Sep 30 19:07:13.533: INFO: Pod "pod-projected-secrets-f40f01b1-5b10-49f8-8e4e-ccf66fc5ff05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008825438s
Sep 30 19:07:15.536: INFO: Pod "pod-projected-secrets-f40f01b1-5b10-49f8-8e4e-ccf66fc5ff05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011394878s
STEP: Saw pod success
Sep 30 19:07:15.536: INFO: Pod "pod-projected-secrets-f40f01b1-5b10-49f8-8e4e-ccf66fc5ff05" satisfied condition "Succeeded or Failed"
Sep 30 19:07:15.537: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-projected-secrets-f40f01b1-5b10-49f8-8e4e-ccf66fc5ff05 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 30 19:07:15.553: INFO: Waiting for pod pod-projected-secrets-f40f01b1-5b10-49f8-8e4e-ccf66fc5ff05 to disappear
Sep 30 19:07:15.567: INFO: Pod pod-projected-secrets-f40f01b1-5b10-49f8-8e4e-ccf66fc5ff05 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:07:15.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9803" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":95,"skipped":1476,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:07:15.574: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2890
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-4fd3ecb7-ae6e-4ffb-b7aa-4db671ddfe0a
Sep 30 19:07:15.724: INFO: Pod name my-hostname-basic-4fd3ecb7-ae6e-4ffb-b7aa-4db671ddfe0a: Found 0 pods out of 1
Sep 30 19:07:20.727: INFO: Pod name my-hostname-basic-4fd3ecb7-ae6e-4ffb-b7aa-4db671ddfe0a: Found 1 pods out of 1
Sep 30 19:07:20.728: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-4fd3ecb7-ae6e-4ffb-b7aa-4db671ddfe0a" are running
Sep 30 19:07:20.730: INFO: Pod "my-hostname-basic-4fd3ecb7-ae6e-4ffb-b7aa-4db671ddfe0a-ktkcm" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-30 19:07:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-30 19:07:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-30 19:07:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-30 19:07:15 +0000 UTC Reason: Message:}])
Sep 30 19:07:20.730: INFO: Trying to dial the pod
Sep 30 19:07:25.745: INFO: Controller my-hostname-basic-4fd3ecb7-ae6e-4ffb-b7aa-4db671ddfe0a: Got expected result from replica 1 [my-hostname-basic-4fd3ecb7-ae6e-4ffb-b7aa-4db671ddfe0a-ktkcm]: "my-hostname-basic-4fd3ecb7-ae6e-4ffb-b7aa-4db671ddfe0a-ktkcm", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:07:25.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2890" for this suite.

â€¢ [SLOW TEST:10.177 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":275,"completed":96,"skipped":1525,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:07:25.751: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-84
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 30 19:07:25.895: INFO: PodSpec: initContainers in spec.initContainers
Sep 30 19:08:09.057: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-75053068-17ef-412d-a758-4ba15db5fc6b", GenerateName:"", Namespace:"init-container-84", SelfLink:"/api/v1/namespaces/init-container-84/pods/pod-init-75053068-17ef-412d-a758-4ba15db5fc6b", UID:"366cfadc-a196-4935-9c4f-2a1eebac50f1", ResourceVersion:"216744", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63737089645, loc:(*time.Location)(0x7b51220)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"895709183"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc002e1d3a0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002e1d3c0)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc002e1d3e0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002e1d420)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-zgvjj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc004e6e340), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-zgvjj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-zgvjj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-zgvjj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0056d3b38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"eb106fc7-933d-47a1-a18a-16aa6514d845", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000b872d0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0056d3bb0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0056d3be0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0056d3be8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0056d3bec), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737089645, loc:(*time.Location)(0x7b51220)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737089645, loc:(*time.Location)(0x7b51220)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737089645, loc:(*time.Location)(0x7b51220)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737089645, loc:(*time.Location)(0x7b51220)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"30.0.0.12", PodIP:"10.200.99.114", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.200.99.114"}}, StartTime:(*v1.Time)(0xc002e1d460), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000b873b0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000b87420)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://0df95f9c0ae149541efad08fa10fe003bec9139d84c61708a5db8f3ed3ba8b0c", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002e1d4c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002e1d4a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc0056d3c6f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:09.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-84" for this suite.

â€¢ [SLOW TEST:43.342 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":275,"completed":97,"skipped":1539,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:09.096: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-496
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 30 19:08:15.282: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 30 19:08:15.290: INFO: Pod pod-with-prestop-http-hook still exists
Sep 30 19:08:17.291: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 30 19:08:17.293: INFO: Pod pod-with-prestop-http-hook still exists
Sep 30 19:08:19.291: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 30 19:08:19.294: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:19.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-496" for this suite.

â€¢ [SLOW TEST:10.220 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":275,"completed":98,"skipped":1581,"failed":0}
SSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:19.317: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3728
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 30 19:08:19.471: INFO: Waiting up to 5m0s for pod "downward-api-bfdae936-67d1-4fd2-88c6-fee07bb69e3c" in namespace "downward-api-3728" to be "Succeeded or Failed"
Sep 30 19:08:19.479: INFO: Pod "downward-api-bfdae936-67d1-4fd2-88c6-fee07bb69e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.624364ms
Sep 30 19:08:21.482: INFO: Pod "downward-api-bfdae936-67d1-4fd2-88c6-fee07bb69e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010583709s
Sep 30 19:08:23.484: INFO: Pod "downward-api-bfdae936-67d1-4fd2-88c6-fee07bb69e3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012882123s
STEP: Saw pod success
Sep 30 19:08:23.484: INFO: Pod "downward-api-bfdae936-67d1-4fd2-88c6-fee07bb69e3c" satisfied condition "Succeeded or Failed"
Sep 30 19:08:23.486: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod downward-api-bfdae936-67d1-4fd2-88c6-fee07bb69e3c container dapi-container: <nil>
STEP: delete the pod
Sep 30 19:08:23.512: INFO: Waiting for pod downward-api-bfdae936-67d1-4fd2-88c6-fee07bb69e3c to disappear
Sep 30 19:08:23.519: INFO: Pod downward-api-bfdae936-67d1-4fd2-88c6-fee07bb69e3c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:23.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3728" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":275,"completed":99,"skipped":1586,"failed":0}

------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:23.525: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-3751922c-773b-4cfa-b3aa-d59f2db6aeb6-2577
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:23.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1535" for this suite.
STEP: Destroying namespace "nspatchtest-3751922c-773b-4cfa-b3aa-d59f2db6aeb6-2577" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":275,"completed":100,"skipped":1586,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:23.831: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1678
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1678.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1678.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 30 19:08:34.056: INFO: DNS probes using dns-1678/dns-test-f4346146-fe77-4f42-b9e0-b1120cb5b1a0 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:34.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1678" for this suite.

â€¢ [SLOW TEST:10.265 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":275,"completed":101,"skipped":1610,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:34.099: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:08:34.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 version'
Sep 30 19:08:34.328: INFO: stderr: ""
Sep 30 19:08:34.328: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.6\", GitCommit:\"dff82dc0de47299ab66c83c626e08b245ab19037\", GitTreeState:\"clean\", BuildDate:\"2020-07-15T16:58:53Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.8+vmware.1\", GitCommit:\"ed08d8795c8e9f9cc2f8e695d2361ae2b9757d0a\", GitTreeState:\"clean\", BuildDate:\"2020-08-19T23:47:02Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:34.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8091" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":275,"completed":102,"skipped":1623,"failed":0}
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:34.335: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5433
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 30 19:08:36.499: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:36.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5433" for this suite.
â€¢{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":275,"completed":103,"skipped":1625,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:36.546: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3749
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 30 19:08:36.715: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3749 /api/v1/namespaces/watch-3749/configmaps/e2e-watch-test-label-changed 6a008464-27ef-416e-b80e-2d91ffd62cfe 216979 0 2020-09-30 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-30 19:08:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:08:36.715: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3749 /api/v1/namespaces/watch-3749/configmaps/e2e-watch-test-label-changed 6a008464-27ef-416e-b80e-2d91ffd62cfe 216980 0 2020-09-30 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-30 19:08:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:08:36.715: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3749 /api/v1/namespaces/watch-3749/configmaps/e2e-watch-test-label-changed 6a008464-27ef-416e-b80e-2d91ffd62cfe 216981 0 2020-09-30 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-30 19:08:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 30 19:08:46.739: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3749 /api/v1/namespaces/watch-3749/configmaps/e2e-watch-test-label-changed 6a008464-27ef-416e-b80e-2d91ffd62cfe 217045 0 2020-09-30 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-30 19:08:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:08:46.739: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3749 /api/v1/namespaces/watch-3749/configmaps/e2e-watch-test-label-changed 6a008464-27ef-416e-b80e-2d91ffd62cfe 217046 0 2020-09-30 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-30 19:08:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:08:46.739: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3749 /api/v1/namespaces/watch-3749/configmaps/e2e-watch-test-label-changed 6a008464-27ef-416e-b80e-2d91ffd62cfe 217047 0 2020-09-30 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-30 19:08:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:46.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3749" for this suite.

â€¢ [SLOW TEST:10.201 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":275,"completed":104,"skipped":1641,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:46.748: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4179
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 30 19:08:49.471: INFO: Successfully updated pod "annotationupdate3e85ec9f-69c7-40e5-85ba-fb9b08930e76"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:51.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4179" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":275,"completed":105,"skipped":1643,"failed":0}

------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:51.493: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4145
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-0cef9727-091c-4942-8626-64819be9c2af
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:51.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4145" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":275,"completed":106,"skipped":1643,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:51.643: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9566
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Sep 30 19:08:51.793: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Sep 30 19:08:51.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-9566'
Sep 30 19:08:52.065: INFO: stderr: ""
Sep 30 19:08:52.065: INFO: stdout: "service/agnhost-slave created\n"
Sep 30 19:08:52.065: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Sep 30 19:08:52.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-9566'
Sep 30 19:08:52.254: INFO: stderr: ""
Sep 30 19:08:52.254: INFO: stdout: "service/agnhost-master created\n"
Sep 30 19:08:52.254: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 30 19:08:52.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-9566'
Sep 30 19:08:52.433: INFO: stderr: ""
Sep 30 19:08:52.433: INFO: stdout: "service/frontend created\n"
Sep 30 19:08:52.433: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Sep 30 19:08:52.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-9566'
Sep 30 19:08:52.612: INFO: stderr: ""
Sep 30 19:08:52.612: INFO: stdout: "deployment.apps/frontend created\n"
Sep 30 19:08:52.612: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 30 19:08:52.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-9566'
Sep 30 19:08:52.793: INFO: stderr: ""
Sep 30 19:08:52.793: INFO: stdout: "deployment.apps/agnhost-master created\n"
Sep 30 19:08:52.793: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 30 19:08:52.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-9566'
Sep 30 19:08:52.951: INFO: stderr: ""
Sep 30 19:08:52.951: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Sep 30 19:08:52.951: INFO: Waiting for all frontend pods to be Running.
Sep 30 19:08:58.001: INFO: Waiting for frontend to serve content.
Sep 30 19:08:58.008: INFO: Trying to add a new entry to the guestbook.
Sep 30 19:08:58.013: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep 30 19:08:58.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete --grace-period=0 --force -f - --namespace=kubectl-9566'
Sep 30 19:08:58.133: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 30 19:08:58.133: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 30 19:08:58.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete --grace-period=0 --force -f - --namespace=kubectl-9566'
Sep 30 19:08:58.229: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 30 19:08:58.229: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 30 19:08:58.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete --grace-period=0 --force -f - --namespace=kubectl-9566'
Sep 30 19:08:58.322: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 30 19:08:58.322: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 30 19:08:58.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete --grace-period=0 --force -f - --namespace=kubectl-9566'
Sep 30 19:08:58.405: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 30 19:08:58.405: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 30 19:08:58.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete --grace-period=0 --force -f - --namespace=kubectl-9566'
Sep 30 19:08:58.482: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 30 19:08:58.482: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 30 19:08:58.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete --grace-period=0 --force -f - --namespace=kubectl-9566'
Sep 30 19:08:58.576: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 30 19:08:58.576: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:08:58.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9566" for this suite.

â€¢ [SLOW TEST:6.943 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:310
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":275,"completed":107,"skipped":1686,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:08:58.586: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4793
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Sep 30 19:08:58.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-4793'
Sep 30 19:08:58.955: INFO: stderr: ""
Sep 30 19:08:58.955: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Sep 30 19:08:59.959: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 19:08:59.959: INFO: Found 0 / 1
Sep 30 19:09:00.958: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 19:09:00.958: INFO: Found 1 / 1
Sep 30 19:09:00.958: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 30 19:09:00.961: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 19:09:00.961: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 30 19:09:00.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 patch pod agnhost-master-bsv6k --namespace=kubectl-4793 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 30 19:09:01.034: INFO: stderr: ""
Sep 30 19:09:01.034: INFO: stdout: "pod/agnhost-master-bsv6k patched\n"
STEP: checking annotations
Sep 30 19:09:01.054: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 19:09:01.054: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:09:01.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4793" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":275,"completed":108,"skipped":1688,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:09:01.060: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-332e9b4b-5ebd-4773-b1ae-3fa28ce6e499
STEP: Creating a pod to test consume secrets
Sep 30 19:09:01.207: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f643d073-6806-4982-b3bb-aa1a46675e75" in namespace "projected-3240" to be "Succeeded or Failed"
Sep 30 19:09:01.219: INFO: Pod "pod-projected-secrets-f643d073-6806-4982-b3bb-aa1a46675e75": Phase="Pending", Reason="", readiness=false. Elapsed: 12.839617ms
Sep 30 19:09:03.222: INFO: Pod "pod-projected-secrets-f643d073-6806-4982-b3bb-aa1a46675e75": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015463365s
Sep 30 19:09:05.226: INFO: Pod "pod-projected-secrets-f643d073-6806-4982-b3bb-aa1a46675e75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01951525s
STEP: Saw pod success
Sep 30 19:09:05.226: INFO: Pod "pod-projected-secrets-f643d073-6806-4982-b3bb-aa1a46675e75" satisfied condition "Succeeded or Failed"
Sep 30 19:09:05.228: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod pod-projected-secrets-f643d073-6806-4982-b3bb-aa1a46675e75 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 30 19:09:05.248: INFO: Waiting for pod pod-projected-secrets-f643d073-6806-4982-b3bb-aa1a46675e75 to disappear
Sep 30 19:09:05.254: INFO: Pod pod-projected-secrets-f643d073-6806-4982-b3bb-aa1a46675e75 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:09:05.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3240" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":275,"completed":109,"skipped":1696,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:09:05.260: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7546
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 30 19:09:05.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7546'
Sep 30 19:09:05.476: INFO: stderr: ""
Sep 30 19:09:05.476: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Sep 30 19:09:05.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete pods e2e-test-httpd-pod --namespace=kubectl-7546'
Sep 30 19:09:07.409: INFO: stderr: ""
Sep 30 19:09:07.409: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:09:07.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7546" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":275,"completed":110,"skipped":1733,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:09:07.421: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9879
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:09:07.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9879" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":275,"completed":111,"skipped":1740,"failed":0}
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:09:07.621: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4506
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:09:07.775: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 30 19:09:12.778: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 30 19:09:12.778: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 30 19:09:16.823: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4506 /apis/apps/v1/namespaces/deployment-4506/deployments/test-cleanup-deployment b97f624a-d2a4-46da-9e78-b01a46a8e8c9 217531 1 2020-09-30 19:09:12 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2020-09-30 19:09:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-30 19:09:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0031dc208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-09-30 19:09:12 +0000 UTC,LastTransitionTime:2020-09-30 19:09:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-b4867b47f" has successfully progressed.,LastUpdateTime:2020-09-30 19:09:15 +0000 UTC,LastTransitionTime:2020-09-30 19:09:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 30 19:09:16.824: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-4506 /apis/apps/v1/namespaces/deployment-4506/replicasets/test-cleanup-deployment-b4867b47f 3e5581a7-ba5a-42ba-a726-6b47c5dc4e57 217520 1 2020-09-30 19:09:12 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment b97f624a-d2a4-46da-9e78-b01a46a8e8c9 0xc003190fd0 0xc003190fd1}] []  [{kube-controller-manager Update apps/v1 2020-09-30 19:09:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 57 55 102 54 50 52 97 45 100 50 97 52 45 52 54 100 97 45 57 101 55 56 45 98 48 49 97 52 54 97 56 101 56 99 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003191048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:09:16.827: INFO: Pod "test-cleanup-deployment-b4867b47f-bmhw5" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-bmhw5 test-cleanup-deployment-b4867b47f- deployment-4506 /api/v1/namespaces/deployment-4506/pods/test-cleanup-deployment-b4867b47f-bmhw5 70c5d660-b173-455d-8649-7baa0a116ee4 217519 0 2020-09-30 19:09:12 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f 3e5581a7-ba5a-42ba-a726-6b47c5dc4e57 0xc0031dc660 0xc0031dc661}] []  [{kube-controller-manager Update v1 2020-09-30 19:09:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 101 53 53 56 49 97 55 45 98 97 53 97 45 52 50 98 97 45 97 55 50 54 45 54 98 52 55 99 53 100 99 52 101 53 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:09:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 49 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ftg2p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ftg2p,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ftg2p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:09:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:09:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:09:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:09:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.121,StartTime:2020-09-30 19:09:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:09:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://9d64ff1fa5cc259fcc52f52972db8db362b8f342415cd5ee0e618e9edf4906cd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.121,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:09:16.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4506" for this suite.

â€¢ [SLOW TEST:9.212 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":275,"completed":112,"skipped":1741,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:09:16.835: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2482
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:09:16.993: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:09:23.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2482" for this suite.

â€¢ [SLOW TEST:6.327 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":275,"completed":113,"skipped":1770,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:09:23.162: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2794
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2794, will wait for the garbage collector to delete the pods
Sep 30 19:09:27.396: INFO: Deleting Job.batch foo took: 3.780161ms
Sep 30 19:09:27.496: INFO: Terminating Job.batch foo pods took: 100.177222ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:10:03.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2794" for this suite.

â€¢ [SLOW TEST:40.042 seconds]
[sig-apps] Job
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":275,"completed":114,"skipped":1781,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:10:03.206: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4286
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:10:04.021: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 19:10:06.028: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737089804, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737089804, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737089804, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737089803, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:10:09.036: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:10:09.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4286" for this suite.
STEP: Destroying namespace "webhook-4286-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:5.906 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":275,"completed":115,"skipped":1796,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:10:09.112: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1926
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:10:09.747: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:10:12.766: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:10:12.769: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9150-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:10:13.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1926" for this suite.
STEP: Destroying namespace "webhook-1926-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":275,"completed":116,"skipped":1799,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:10:13.959: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4350
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-nmbb
STEP: Creating a pod to test atomic-volume-subpath
Sep 30 19:10:14.177: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-nmbb" in namespace "subpath-4350" to be "Succeeded or Failed"
Sep 30 19:10:14.203: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Pending", Reason="", readiness=false. Elapsed: 26.040789ms
Sep 30 19:10:16.205: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 2.028646166s
Sep 30 19:10:18.208: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 4.030970746s
Sep 30 19:10:20.210: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 6.033405527s
Sep 30 19:10:22.212: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 8.035713217s
Sep 30 19:10:24.215: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 10.038182842s
Sep 30 19:10:26.217: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 12.040767324s
Sep 30 19:10:28.220: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 14.043278922s
Sep 30 19:10:30.223: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 16.046062741s
Sep 30 19:10:32.225: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 18.048835581s
Sep 30 19:10:34.228: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Running", Reason="", readiness=true. Elapsed: 20.051314494s
Sep 30 19:10:36.230: INFO: Pod "pod-subpath-test-downwardapi-nmbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.053808469s
STEP: Saw pod success
Sep 30 19:10:36.230: INFO: Pod "pod-subpath-test-downwardapi-nmbb" satisfied condition "Succeeded or Failed"
Sep 30 19:10:36.232: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-subpath-test-downwardapi-nmbb container test-container-subpath-downwardapi-nmbb: <nil>
STEP: delete the pod
Sep 30 19:10:36.258: INFO: Waiting for pod pod-subpath-test-downwardapi-nmbb to disappear
Sep 30 19:10:36.265: INFO: Pod pod-subpath-test-downwardapi-nmbb no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-nmbb
Sep 30 19:10:36.265: INFO: Deleting pod "pod-subpath-test-downwardapi-nmbb" in namespace "subpath-4350"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:10:36.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4350" for this suite.

â€¢ [SLOW TEST:22.313 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":275,"completed":117,"skipped":1901,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:10:36.272: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2473
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-26212612-ce7f-409b-8891-66a327e574c0
STEP: Creating a pod to test consume secrets
Sep 30 19:10:36.431: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-61b85c2a-322c-4266-8c76-2bc30df43850" in namespace "projected-2473" to be "Succeeded or Failed"
Sep 30 19:10:36.440: INFO: Pod "pod-projected-secrets-61b85c2a-322c-4266-8c76-2bc30df43850": Phase="Pending", Reason="", readiness=false. Elapsed: 8.454818ms
Sep 30 19:10:38.442: INFO: Pod "pod-projected-secrets-61b85c2a-322c-4266-8c76-2bc30df43850": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010381182s
STEP: Saw pod success
Sep 30 19:10:38.442: INFO: Pod "pod-projected-secrets-61b85c2a-322c-4266-8c76-2bc30df43850" satisfied condition "Succeeded or Failed"
Sep 30 19:10:38.444: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-projected-secrets-61b85c2a-322c-4266-8c76-2bc30df43850 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 30 19:10:38.461: INFO: Waiting for pod pod-projected-secrets-61b85c2a-322c-4266-8c76-2bc30df43850 to disappear
Sep 30 19:10:38.467: INFO: Pod pod-projected-secrets-61b85c2a-322c-4266-8c76-2bc30df43850 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:10:38.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2473" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":275,"completed":118,"skipped":1911,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:10:38.474: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-949
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-z8zl7 in namespace proxy-949
I0930 19:10:38.633930      21 runners.go:190] Created replication controller with name: proxy-service-z8zl7, namespace: proxy-949, replica count: 1
I0930 19:10:39.684339      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0930 19:10:40.684508      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0930 19:10:41.684672      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0930 19:10:42.684853      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0930 19:10:43.685000      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0930 19:10:44.685180      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0930 19:10:45.685369      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0930 19:10:46.686239      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0930 19:10:47.686439      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0930 19:10:48.686633      21 runners.go:190] proxy-service-z8zl7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 30 19:10:48.688: INFO: setup took 10.067110621s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 30 19:10:48.695: INFO: (0) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 6.553044ms)
Sep 30 19:10:48.698: INFO: (0) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 9.564066ms)
Sep 30 19:10:48.698: INFO: (0) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 9.356832ms)
Sep 30 19:10:48.698: INFO: (0) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 9.681281ms)
Sep 30 19:10:48.700: INFO: (0) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 11.471563ms)
Sep 30 19:10:48.703: INFO: (0) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 14.28881ms)
Sep 30 19:10:48.703: INFO: (0) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 14.502917ms)
Sep 30 19:10:48.703: INFO: (0) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 14.342468ms)
Sep 30 19:10:48.703: INFO: (0) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 14.443327ms)
Sep 30 19:10:48.706: INFO: (0) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 17.614494ms)
Sep 30 19:10:48.706: INFO: (0) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 17.391422ms)
Sep 30 19:10:48.710: INFO: (0) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 21.688968ms)
Sep 30 19:10:48.710: INFO: (0) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 21.615782ms)
Sep 30 19:10:48.711: INFO: (0) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 21.908509ms)
Sep 30 19:10:48.711: INFO: (0) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 22.741079ms)
Sep 30 19:10:48.712: INFO: (0) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 22.748866ms)
Sep 30 19:10:48.716: INFO: (1) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 4.004118ms)
Sep 30 19:10:48.719: INFO: (1) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 7.598186ms)
Sep 30 19:10:48.721: INFO: (1) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 8.617918ms)
Sep 30 19:10:48.721: INFO: (1) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 9.028233ms)
Sep 30 19:10:48.721: INFO: (1) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 9.303946ms)
Sep 30 19:10:48.721: INFO: (1) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 9.203408ms)
Sep 30 19:10:48.721: INFO: (1) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 9.185398ms)
Sep 30 19:10:48.721: INFO: (1) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 9.569474ms)
Sep 30 19:10:48.724: INFO: (1) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 11.304112ms)
Sep 30 19:10:48.724: INFO: (1) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 11.745627ms)
Sep 30 19:10:48.724: INFO: (1) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 11.876356ms)
Sep 30 19:10:48.724: INFO: (1) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 11.695872ms)
Sep 30 19:10:48.724: INFO: (1) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 12.006236ms)
Sep 30 19:10:48.724: INFO: (1) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 12.111613ms)
Sep 30 19:10:48.725: INFO: (1) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 13.072215ms)
Sep 30 19:10:48.726: INFO: (1) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 14.012285ms)
Sep 30 19:10:48.735: INFO: (2) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 8.978953ms)
Sep 30 19:10:48.740: INFO: (2) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 13.557138ms)
Sep 30 19:10:48.741: INFO: (2) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 15.248446ms)
Sep 30 19:10:48.741: INFO: (2) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 15.232605ms)
Sep 30 19:10:48.741: INFO: (2) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 15.237207ms)
Sep 30 19:10:48.742: INFO: (2) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 15.140316ms)
Sep 30 19:10:48.742: INFO: (2) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 15.344677ms)
Sep 30 19:10:48.742: INFO: (2) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 15.227592ms)
Sep 30 19:10:48.742: INFO: (2) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 15.317145ms)
Sep 30 19:10:48.742: INFO: (2) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 16.29925ms)
Sep 30 19:10:48.744: INFO: (2) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 17.770875ms)
Sep 30 19:10:48.744: INFO: (2) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 17.94483ms)
Sep 30 19:10:48.744: INFO: (2) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 17.892089ms)
Sep 30 19:10:48.744: INFO: (2) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 17.899305ms)
Sep 30 19:10:48.744: INFO: (2) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 17.95913ms)
Sep 30 19:10:48.745: INFO: (2) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 18.569996ms)
Sep 30 19:10:48.748: INFO: (3) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 2.500762ms)
Sep 30 19:10:48.749: INFO: (3) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 3.970296ms)
Sep 30 19:10:48.750: INFO: (3) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 4.847025ms)
Sep 30 19:10:48.750: INFO: (3) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 5.380214ms)
Sep 30 19:10:48.760: INFO: (3) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 14.897883ms)
Sep 30 19:10:48.760: INFO: (3) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 14.915594ms)
Sep 30 19:10:48.760: INFO: (3) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 15.136474ms)
Sep 30 19:10:48.767: INFO: (3) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 21.284573ms)
Sep 30 19:10:48.767: INFO: (3) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 21.513485ms)
Sep 30 19:10:48.767: INFO: (3) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 21.704032ms)
Sep 30 19:10:48.767: INFO: (3) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 22.090143ms)
Sep 30 19:10:48.767: INFO: (3) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 22.150678ms)
Sep 30 19:10:48.768: INFO: (3) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 22.512861ms)
Sep 30 19:10:48.769: INFO: (3) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 23.716331ms)
Sep 30 19:10:48.769: INFO: (3) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 23.949965ms)
Sep 30 19:10:48.769: INFO: (3) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 23.977392ms)
Sep 30 19:10:48.772: INFO: (4) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 2.467815ms)
Sep 30 19:10:48.775: INFO: (4) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 5.611508ms)
Sep 30 19:10:48.775: INFO: (4) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 5.988968ms)
Sep 30 19:10:48.777: INFO: (4) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 7.78104ms)
Sep 30 19:10:48.777: INFO: (4) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 7.379887ms)
Sep 30 19:10:48.778: INFO: (4) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 8.199696ms)
Sep 30 19:10:48.778: INFO: (4) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 7.764967ms)
Sep 30 19:10:48.778: INFO: (4) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 8.426673ms)
Sep 30 19:10:48.778: INFO: (4) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 8.93004ms)
Sep 30 19:10:48.779: INFO: (4) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 9.216462ms)
Sep 30 19:10:48.779: INFO: (4) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 9.321227ms)
Sep 30 19:10:48.779: INFO: (4) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 9.804197ms)
Sep 30 19:10:48.779: INFO: (4) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 9.712759ms)
Sep 30 19:10:48.779: INFO: (4) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 9.863715ms)
Sep 30 19:10:48.780: INFO: (4) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.211227ms)
Sep 30 19:10:48.780: INFO: (4) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 10.096476ms)
Sep 30 19:10:48.788: INFO: (5) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 7.296043ms)
Sep 30 19:10:48.788: INFO: (5) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 7.573469ms)
Sep 30 19:10:48.788: INFO: (5) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 8.045526ms)
Sep 30 19:10:48.788: INFO: (5) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 8.209424ms)
Sep 30 19:10:48.788: INFO: (5) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 8.356112ms)
Sep 30 19:10:48.788: INFO: (5) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 8.045476ms)
Sep 30 19:10:48.789: INFO: (5) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 8.670738ms)
Sep 30 19:10:48.789: INFO: (5) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 8.555485ms)
Sep 30 19:10:48.789: INFO: (5) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 8.718071ms)
Sep 30 19:10:48.789: INFO: (5) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 8.78139ms)
Sep 30 19:10:48.790: INFO: (5) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 9.478768ms)
Sep 30 19:10:48.790: INFO: (5) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 9.550911ms)
Sep 30 19:10:48.791: INFO: (5) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.893105ms)
Sep 30 19:10:48.791: INFO: (5) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 10.822037ms)
Sep 30 19:10:48.791: INFO: (5) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 10.716612ms)
Sep 30 19:10:48.791: INFO: (5) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 10.756127ms)
Sep 30 19:10:48.803: INFO: (6) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 12.279093ms)
Sep 30 19:10:48.805: INFO: (6) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 13.917225ms)
Sep 30 19:10:48.806: INFO: (6) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 14.697296ms)
Sep 30 19:10:48.806: INFO: (6) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 14.821184ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 15.047108ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 14.965592ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 15.05784ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 15.27346ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 15.716371ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 15.689907ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 15.240091ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 15.371007ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 16.059712ms)
Sep 30 19:10:48.807: INFO: (6) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 15.9632ms)
Sep 30 19:10:48.808: INFO: (6) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 16.332842ms)
Sep 30 19:10:48.808: INFO: (6) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 16.072432ms)
Sep 30 19:10:48.810: INFO: (7) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 2.300063ms)
Sep 30 19:10:48.814: INFO: (7) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 5.635422ms)
Sep 30 19:10:48.816: INFO: (7) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 7.023399ms)
Sep 30 19:10:48.816: INFO: (7) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 7.538183ms)
Sep 30 19:10:48.816: INFO: (7) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 7.466071ms)
Sep 30 19:10:48.816: INFO: (7) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 7.490452ms)
Sep 30 19:10:48.817: INFO: (7) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 8.630966ms)
Sep 30 19:10:48.818: INFO: (7) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 9.928033ms)
Sep 30 19:10:48.819: INFO: (7) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 10.585797ms)
Sep 30 19:10:48.819: INFO: (7) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 10.497184ms)
Sep 30 19:10:48.819: INFO: (7) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 10.398039ms)
Sep 30 19:10:48.819: INFO: (7) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 10.770652ms)
Sep 30 19:10:48.819: INFO: (7) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 10.637526ms)
Sep 30 19:10:48.819: INFO: (7) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 11.132063ms)
Sep 30 19:10:48.819: INFO: (7) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 10.756744ms)
Sep 30 19:10:48.819: INFO: (7) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.865038ms)
Sep 30 19:10:48.823: INFO: (8) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 3.32877ms)
Sep 30 19:10:48.823: INFO: (8) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 3.528151ms)
Sep 30 19:10:48.823: INFO: (8) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 3.446247ms)
Sep 30 19:10:48.825: INFO: (8) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 5.606062ms)
Sep 30 19:10:48.826: INFO: (8) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 5.809437ms)
Sep 30 19:10:48.826: INFO: (8) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 6.145477ms)
Sep 30 19:10:48.827: INFO: (8) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 7.524891ms)
Sep 30 19:10:48.828: INFO: (8) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 7.909199ms)
Sep 30 19:10:48.828: INFO: (8) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 8.697323ms)
Sep 30 19:10:48.829: INFO: (8) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 8.963967ms)
Sep 30 19:10:48.829: INFO: (8) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 8.738559ms)
Sep 30 19:10:48.829: INFO: (8) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 9.176968ms)
Sep 30 19:10:48.829: INFO: (8) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 8.987374ms)
Sep 30 19:10:48.829: INFO: (8) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 9.016225ms)
Sep 30 19:10:48.829: INFO: (8) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 9.117557ms)
Sep 30 19:10:48.830: INFO: (8) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 10.359442ms)
Sep 30 19:10:48.834: INFO: (9) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 3.281945ms)
Sep 30 19:10:48.834: INFO: (9) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 3.922252ms)
Sep 30 19:10:48.835: INFO: (9) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 4.312493ms)
Sep 30 19:10:48.837: INFO: (9) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 5.799359ms)
Sep 30 19:10:48.837: INFO: (9) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 6.624053ms)
Sep 30 19:10:48.837: INFO: (9) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 6.834313ms)
Sep 30 19:10:48.839: INFO: (9) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 7.663602ms)
Sep 30 19:10:48.839: INFO: (9) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 7.801812ms)
Sep 30 19:10:48.839: INFO: (9) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 8.240723ms)
Sep 30 19:10:48.840: INFO: (9) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 8.755078ms)
Sep 30 19:10:48.840: INFO: (9) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 9.197452ms)
Sep 30 19:10:48.840: INFO: (9) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 9.268749ms)
Sep 30 19:10:48.841: INFO: (9) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 10.324832ms)
Sep 30 19:10:48.841: INFO: (9) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 10.325267ms)
Sep 30 19:10:48.842: INFO: (9) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.796371ms)
Sep 30 19:10:48.842: INFO: (9) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 10.737095ms)
Sep 30 19:10:48.854: INFO: (10) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 12.048572ms)
Sep 30 19:10:48.854: INFO: (10) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 12.121094ms)
Sep 30 19:10:48.855: INFO: (10) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 12.685057ms)
Sep 30 19:10:48.855: INFO: (10) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 12.514755ms)
Sep 30 19:10:48.855: INFO: (10) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 12.687842ms)
Sep 30 19:10:48.855: INFO: (10) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 12.688739ms)
Sep 30 19:10:48.855: INFO: (10) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 13.218345ms)
Sep 30 19:10:48.855: INFO: (10) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 13.089155ms)
Sep 30 19:10:48.855: INFO: (10) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 13.278636ms)
Sep 30 19:10:48.855: INFO: (10) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 12.961472ms)
Sep 30 19:10:48.855: INFO: (10) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 13.419123ms)
Sep 30 19:10:48.856: INFO: (10) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 13.702639ms)
Sep 30 19:10:48.856: INFO: (10) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 13.75536ms)
Sep 30 19:10:48.857: INFO: (10) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 14.68689ms)
Sep 30 19:10:48.857: INFO: (10) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 14.100436ms)
Sep 30 19:10:48.857: INFO: (10) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 14.281418ms)
Sep 30 19:10:48.863: INFO: (11) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 5.631081ms)
Sep 30 19:10:48.863: INFO: (11) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 6.024187ms)
Sep 30 19:10:48.864: INFO: (11) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 6.755457ms)
Sep 30 19:10:48.865: INFO: (11) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 7.512179ms)
Sep 30 19:10:48.865: INFO: (11) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 7.322755ms)
Sep 30 19:10:48.865: INFO: (11) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 7.986228ms)
Sep 30 19:10:48.865: INFO: (11) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 8.210438ms)
Sep 30 19:10:48.865: INFO: (11) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 7.787635ms)
Sep 30 19:10:48.866: INFO: (11) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 8.143893ms)
Sep 30 19:10:48.866: INFO: (11) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 9.570147ms)
Sep 30 19:10:48.867: INFO: (11) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 10.009091ms)
Sep 30 19:10:48.867: INFO: (11) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 10.083481ms)
Sep 30 19:10:48.868: INFO: (11) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 10.629169ms)
Sep 30 19:10:48.868: INFO: (11) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 10.335477ms)
Sep 30 19:10:48.868: INFO: (11) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 10.636159ms)
Sep 30 19:10:48.868: INFO: (11) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.993083ms)
Sep 30 19:10:48.873: INFO: (12) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 4.269824ms)
Sep 30 19:10:48.874: INFO: (12) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 6.093959ms)
Sep 30 19:10:48.875: INFO: (12) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 6.518388ms)
Sep 30 19:10:48.875: INFO: (12) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 6.829765ms)
Sep 30 19:10:48.875: INFO: (12) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 6.615585ms)
Sep 30 19:10:48.875: INFO: (12) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 7.271424ms)
Sep 30 19:10:48.876: INFO: (12) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 7.301504ms)
Sep 30 19:10:48.876: INFO: (12) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 7.218902ms)
Sep 30 19:10:48.876: INFO: (12) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 7.080853ms)
Sep 30 19:10:48.876: INFO: (12) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 7.441054ms)
Sep 30 19:10:48.876: INFO: (12) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 7.619068ms)
Sep 30 19:10:48.877: INFO: (12) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 8.941507ms)
Sep 30 19:10:48.878: INFO: (12) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 9.29135ms)
Sep 30 19:10:48.878: INFO: (12) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 9.186072ms)
Sep 30 19:10:48.879: INFO: (12) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 10.242884ms)
Sep 30 19:10:48.879: INFO: (12) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.38017ms)
Sep 30 19:10:48.884: INFO: (13) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 5.109478ms)
Sep 30 19:10:48.885: INFO: (13) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 5.632788ms)
Sep 30 19:10:48.885: INFO: (13) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 5.439749ms)
Sep 30 19:10:48.885: INFO: (13) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 5.655067ms)
Sep 30 19:10:48.887: INFO: (13) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 7.989254ms)
Sep 30 19:10:48.888: INFO: (13) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 8.057152ms)
Sep 30 19:10:48.888: INFO: (13) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 8.314201ms)
Sep 30 19:10:48.888: INFO: (13) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 8.57927ms)
Sep 30 19:10:48.888: INFO: (13) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 8.712657ms)
Sep 30 19:10:48.888: INFO: (13) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 8.852089ms)
Sep 30 19:10:48.889: INFO: (13) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 9.260932ms)
Sep 30 19:10:48.889: INFO: (13) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 9.547477ms)
Sep 30 19:10:48.889: INFO: (13) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 9.813441ms)
Sep 30 19:10:48.889: INFO: (13) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 10.031441ms)
Sep 30 19:10:48.890: INFO: (13) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 10.223328ms)
Sep 30 19:10:48.890: INFO: (13) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.429873ms)
Sep 30 19:10:48.895: INFO: (14) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 5.052287ms)
Sep 30 19:10:48.898: INFO: (14) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 7.393194ms)
Sep 30 19:10:48.898: INFO: (14) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 7.872404ms)
Sep 30 19:10:48.898: INFO: (14) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 7.424732ms)
Sep 30 19:10:48.899: INFO: (14) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 8.19031ms)
Sep 30 19:10:48.899: INFO: (14) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 8.91876ms)
Sep 30 19:10:48.899: INFO: (14) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 9.134023ms)
Sep 30 19:10:48.899: INFO: (14) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 9.480188ms)
Sep 30 19:10:48.899: INFO: (14) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 9.179607ms)
Sep 30 19:10:48.900: INFO: (14) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 9.697073ms)
Sep 30 19:10:48.900: INFO: (14) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 9.229901ms)
Sep 30 19:10:48.900: INFO: (14) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 9.708447ms)
Sep 30 19:10:48.900: INFO: (14) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 9.456833ms)
Sep 30 19:10:48.900: INFO: (14) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.116371ms)
Sep 30 19:10:48.900: INFO: (14) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 10.46194ms)
Sep 30 19:10:48.901: INFO: (14) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 10.060749ms)
Sep 30 19:10:48.906: INFO: (15) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 5.411991ms)
Sep 30 19:10:48.913: INFO: (15) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 11.809133ms)
Sep 30 19:10:48.913: INFO: (15) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 12.078627ms)
Sep 30 19:10:48.913: INFO: (15) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 12.047162ms)
Sep 30 19:10:48.913: INFO: (15) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 12.623235ms)
Sep 30 19:10:48.913: INFO: (15) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 12.440699ms)
Sep 30 19:10:48.913: INFO: (15) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 12.558815ms)
Sep 30 19:10:48.914: INFO: (15) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 13.094707ms)
Sep 30 19:10:48.914: INFO: (15) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 13.091104ms)
Sep 30 19:10:48.915: INFO: (15) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 13.178447ms)
Sep 30 19:10:48.915: INFO: (15) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 13.141949ms)
Sep 30 19:10:48.915: INFO: (15) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 13.31899ms)
Sep 30 19:10:48.921: INFO: (15) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 19.822783ms)
Sep 30 19:10:48.921: INFO: (15) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 19.775871ms)
Sep 30 19:10:48.921: INFO: (15) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 19.759008ms)
Sep 30 19:10:48.921: INFO: (15) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 20.451887ms)
Sep 30 19:10:48.927: INFO: (16) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 5.204174ms)
Sep 30 19:10:48.927: INFO: (16) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 6.069286ms)
Sep 30 19:10:48.927: INFO: (16) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 5.750036ms)
Sep 30 19:10:48.927: INFO: (16) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 5.664884ms)
Sep 30 19:10:48.929: INFO: (16) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 6.775971ms)
Sep 30 19:10:48.929: INFO: (16) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 6.687478ms)
Sep 30 19:10:48.929: INFO: (16) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 7.427987ms)
Sep 30 19:10:48.930: INFO: (16) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 7.90501ms)
Sep 30 19:10:48.930: INFO: (16) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 7.723549ms)
Sep 30 19:10:48.930: INFO: (16) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 8.030892ms)
Sep 30 19:10:48.930: INFO: (16) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 8.362173ms)
Sep 30 19:10:48.930: INFO: (16) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 8.829495ms)
Sep 30 19:10:48.930: INFO: (16) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 8.410315ms)
Sep 30 19:10:48.931: INFO: (16) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 9.113539ms)
Sep 30 19:10:48.931: INFO: (16) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 9.159347ms)
Sep 30 19:10:48.931: INFO: (16) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 9.427637ms)
Sep 30 19:10:48.934: INFO: (17) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 3.507757ms)
Sep 30 19:10:48.935: INFO: (17) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 4.350914ms)
Sep 30 19:10:48.936: INFO: (17) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 4.272701ms)
Sep 30 19:10:48.936: INFO: (17) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 4.457575ms)
Sep 30 19:10:48.936: INFO: (17) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 4.546677ms)
Sep 30 19:10:48.940: INFO: (17) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 8.319147ms)
Sep 30 19:10:48.940: INFO: (17) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 8.040417ms)
Sep 30 19:10:48.940: INFO: (17) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 8.751238ms)
Sep 30 19:10:48.941: INFO: (17) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 8.788864ms)
Sep 30 19:10:48.941: INFO: (17) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 8.928801ms)
Sep 30 19:10:48.941: INFO: (17) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 9.286253ms)
Sep 30 19:10:48.941: INFO: (17) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 9.52247ms)
Sep 30 19:10:48.941: INFO: (17) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 9.853292ms)
Sep 30 19:10:48.941: INFO: (17) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 9.68292ms)
Sep 30 19:10:48.941: INFO: (17) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 9.617004ms)
Sep 30 19:10:48.941: INFO: (17) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 9.83128ms)
Sep 30 19:10:48.946: INFO: (18) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 4.927584ms)
Sep 30 19:10:48.947: INFO: (18) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 4.958484ms)
Sep 30 19:10:48.947: INFO: (18) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 5.562327ms)
Sep 30 19:10:48.949: INFO: (18) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 6.764505ms)
Sep 30 19:10:48.950: INFO: (18) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 7.480663ms)
Sep 30 19:10:48.950: INFO: (18) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 7.570686ms)
Sep 30 19:10:48.950: INFO: (18) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 7.380073ms)
Sep 30 19:10:48.950: INFO: (18) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 7.759711ms)
Sep 30 19:10:48.950: INFO: (18) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 7.815286ms)
Sep 30 19:10:48.952: INFO: (18) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 9.8057ms)
Sep 30 19:10:48.952: INFO: (18) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 9.868749ms)
Sep 30 19:10:48.952: INFO: (18) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 10.524936ms)
Sep 30 19:10:48.952: INFO: (18) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.419114ms)
Sep 30 19:10:48.953: INFO: (18) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 11.023283ms)
Sep 30 19:10:48.953: INFO: (18) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 10.44456ms)
Sep 30 19:10:48.953: INFO: (18) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 10.887228ms)
Sep 30 19:10:48.960: INFO: (19) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:462/proxy/: tls qux (200; 6.656219ms)
Sep 30 19:10:48.960: INFO: (19) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:460/proxy/: tls baz (200; 6.732389ms)
Sep 30 19:10:48.961: INFO: (19) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm/proxy/rewriteme">test</a> (200; 7.774677ms)
Sep 30 19:10:48.962: INFO: (19) /api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/https:proxy-service-z8zl7-25dfm:443/proxy/tlsrewriteme... (200; 8.726469ms)
Sep 30 19:10:48.962: INFO: (19) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 8.272649ms)
Sep 30 19:10:48.962: INFO: (19) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname2/proxy/: bar (200; 8.570172ms)
Sep 30 19:10:48.962: INFO: (19) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:160/proxy/: foo (200; 9.160417ms)
Sep 30 19:10:48.962: INFO: (19) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname1/proxy/: foo (200; 9.037695ms)
Sep 30 19:10:48.962: INFO: (19) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">test</... (200; 9.414101ms)
Sep 30 19:10:48.963: INFO: (19) /api/v1/namespaces/proxy-949/services/proxy-service-z8zl7:portname2/proxy/: bar (200; 9.767085ms)
Sep 30 19:10:48.963: INFO: (19) /api/v1/namespaces/proxy-949/pods/proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 9.678107ms)
Sep 30 19:10:48.964: INFO: (19) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname2/proxy/: tls qux (200; 10.345365ms)
Sep 30 19:10:48.964: INFO: (19) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/: <a href="/api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:1080/proxy/rewriteme">t... (200; 9.973084ms)
Sep 30 19:10:48.964: INFO: (19) /api/v1/namespaces/proxy-949/pods/http:proxy-service-z8zl7-25dfm:162/proxy/: bar (200; 10.946619ms)
Sep 30 19:10:48.964: INFO: (19) /api/v1/namespaces/proxy-949/services/https:proxy-service-z8zl7:tlsportname1/proxy/: tls baz (200; 10.91551ms)
Sep 30 19:10:48.964: INFO: (19) /api/v1/namespaces/proxy-949/services/http:proxy-service-z8zl7:portname1/proxy/: foo (200; 10.654943ms)
STEP: deleting ReplicationController proxy-service-z8zl7 in namespace proxy-949, will wait for the garbage collector to delete the pods
Sep 30 19:10:49.021: INFO: Deleting ReplicationController proxy-service-z8zl7 took: 4.827915ms
Sep 30 19:10:49.421: INFO: Terminating ReplicationController proxy-service-z8zl7 pods took: 400.254878ms
[AfterEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:10:51.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-949" for this suite.

â€¢ [SLOW TEST:13.152 seconds]
[sig-network] Proxy
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":275,"completed":119,"skipped":1939,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:10:51.627: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3984
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:10:51.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3984" for this suite.
â€¢{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":275,"completed":120,"skipped":1946,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:10:51.843: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9859
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:10:51.992: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3dab6952-b4fb-412c-a9bf-66b018eea480" in namespace "downward-api-9859" to be "Succeeded or Failed"
Sep 30 19:10:51.994: INFO: Pod "downwardapi-volume-3dab6952-b4fb-412c-a9bf-66b018eea480": Phase="Pending", Reason="", readiness=false. Elapsed: 2.402004ms
Sep 30 19:10:53.997: INFO: Pod "downwardapi-volume-3dab6952-b4fb-412c-a9bf-66b018eea480": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004836192s
STEP: Saw pod success
Sep 30 19:10:53.997: INFO: Pod "downwardapi-volume-3dab6952-b4fb-412c-a9bf-66b018eea480" satisfied condition "Succeeded or Failed"
Sep 30 19:10:53.999: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-3dab6952-b4fb-412c-a9bf-66b018eea480 container client-container: <nil>
STEP: delete the pod
Sep 30 19:10:54.016: INFO: Waiting for pod downwardapi-volume-3dab6952-b4fb-412c-a9bf-66b018eea480 to disappear
Sep 30 19:10:54.031: INFO: Pod downwardapi-volume-3dab6952-b4fb-412c-a9bf-66b018eea480 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:10:54.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9859" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":121,"skipped":1953,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:10:54.037: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2174
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 30 19:10:54.225: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:11:03.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2174" for this suite.

â€¢ [SLOW TEST:9.077 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":275,"completed":122,"skipped":1959,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:11:03.115: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6624
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:11:03.276: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 30 19:11:03.281: INFO: Number of nodes with available pods: 0
Sep 30 19:11:03.281: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 30 19:11:03.315: INFO: Number of nodes with available pods: 0
Sep 30 19:11:03.315: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:04.318: INFO: Number of nodes with available pods: 0
Sep 30 19:11:04.318: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:05.318: INFO: Number of nodes with available pods: 1
Sep 30 19:11:05.318: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 30 19:11:05.333: INFO: Number of nodes with available pods: 1
Sep 30 19:11:05.333: INFO: Number of running nodes: 0, number of available pods: 1
Sep 30 19:11:06.336: INFO: Number of nodes with available pods: 0
Sep 30 19:11:06.336: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 30 19:11:06.358: INFO: Number of nodes with available pods: 0
Sep 30 19:11:06.358: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:07.361: INFO: Number of nodes with available pods: 0
Sep 30 19:11:07.361: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:08.361: INFO: Number of nodes with available pods: 0
Sep 30 19:11:08.362: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:09.361: INFO: Number of nodes with available pods: 0
Sep 30 19:11:09.361: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:10.361: INFO: Number of nodes with available pods: 0
Sep 30 19:11:10.361: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:11.361: INFO: Number of nodes with available pods: 0
Sep 30 19:11:11.361: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:12.361: INFO: Number of nodes with available pods: 0
Sep 30 19:11:12.361: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:13.361: INFO: Number of nodes with available pods: 0
Sep 30 19:11:13.361: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:14.361: INFO: Number of nodes with available pods: 0
Sep 30 19:11:14.361: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:11:15.361: INFO: Number of nodes with available pods: 1
Sep 30 19:11:15.361: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6624, will wait for the garbage collector to delete the pods
Sep 30 19:11:15.420: INFO: Deleting DaemonSet.extensions daemon-set took: 3.838913ms
Sep 30 19:11:15.820: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.155682ms
Sep 30 19:11:23.522: INFO: Number of nodes with available pods: 0
Sep 30 19:11:23.522: INFO: Number of running nodes: 0, number of available pods: 0
Sep 30 19:11:23.523: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6624/daemonsets","resourceVersion":"218369"},"items":null}

Sep 30 19:11:23.531: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6624/pods","resourceVersion":"218369"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:11:23.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6624" for this suite.

â€¢ [SLOW TEST:20.438 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":275,"completed":123,"skipped":1972,"failed":0}
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:11:23.554: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1492
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:11:26.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1492" for this suite.
â€¢{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":275,"completed":124,"skipped":1978,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:11:26.722: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3624
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 30 19:11:26.883: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-a f0478a82-f687-4309-9aa8-a635e8d532e0 218406 0 2020-09-30 19:11:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-30 19:11:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:11:26.883: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-a f0478a82-f687-4309-9aa8-a635e8d532e0 218406 0 2020-09-30 19:11:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-30 19:11:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 30 19:11:36.888: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-a f0478a82-f687-4309-9aa8-a635e8d532e0 218466 0 2020-09-30 19:11:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-30 19:11:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:11:36.888: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-a f0478a82-f687-4309-9aa8-a635e8d532e0 218466 0 2020-09-30 19:11:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-30 19:11:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 30 19:11:46.893: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-a f0478a82-f687-4309-9aa8-a635e8d532e0 218493 0 2020-09-30 19:11:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-30 19:11:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:11:46.893: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-a f0478a82-f687-4309-9aa8-a635e8d532e0 218493 0 2020-09-30 19:11:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-30 19:11:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 30 19:11:56.898: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-a f0478a82-f687-4309-9aa8-a635e8d532e0 218518 0 2020-09-30 19:11:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-30 19:11:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:11:56.898: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-a f0478a82-f687-4309-9aa8-a635e8d532e0 218518 0 2020-09-30 19:11:26 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-30 19:11:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 30 19:12:06.903: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-b 738c9788-8626-48ac-9214-a3fcdbf38b0d 218544 0 2020-09-30 19:12:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-30 19:12:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:12:06.903: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-b 738c9788-8626-48ac-9214-a3fcdbf38b0d 218544 0 2020-09-30 19:12:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-30 19:12:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 30 19:12:16.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-b 738c9788-8626-48ac-9214-a3fcdbf38b0d 218569 0 2020-09-30 19:12:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-30 19:12:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:12:16.908: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3624 /api/v1/namespaces/watch-3624/configmaps/e2e-watch-test-configmap-b 738c9788-8626-48ac-9214-a3fcdbf38b0d 218569 0 2020-09-30 19:12:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-30 19:12:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:12:26.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3624" for this suite.

â€¢ [SLOW TEST:60.191 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":275,"completed":125,"skipped":2016,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:12:26.914: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5118
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:12:27.086: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a66845fa-a399-4b71-a1f1-47e3bf87640c" in namespace "projected-5118" to be "Succeeded or Failed"
Sep 30 19:12:27.093: INFO: Pod "downwardapi-volume-a66845fa-a399-4b71-a1f1-47e3bf87640c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.285039ms
Sep 30 19:12:29.096: INFO: Pod "downwardapi-volume-a66845fa-a399-4b71-a1f1-47e3bf87640c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009916164s
STEP: Saw pod success
Sep 30 19:12:29.096: INFO: Pod "downwardapi-volume-a66845fa-a399-4b71-a1f1-47e3bf87640c" satisfied condition "Succeeded or Failed"
Sep 30 19:12:29.098: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-a66845fa-a399-4b71-a1f1-47e3bf87640c container client-container: <nil>
STEP: delete the pod
Sep 30 19:12:29.124: INFO: Waiting for pod downwardapi-volume-a66845fa-a399-4b71-a1f1-47e3bf87640c to disappear
Sep 30 19:12:29.131: INFO: Pod downwardapi-volume-a66845fa-a399-4b71-a1f1-47e3bf87640c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:12:29.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5118" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":275,"completed":126,"skipped":2019,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:12:29.143: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2374
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:12:46.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2374" for this suite.

â€¢ [SLOW TEST:17.195 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":275,"completed":127,"skipped":2041,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:12:46.339: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2965.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2965.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2965.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2965.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2965.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2965.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 30 19:12:50.560: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local from pod dns-2965/dns-test-1a57db7c-660a-4b0b-a242-4c2899328426: the server could not find the requested resource (get pods dns-test-1a57db7c-660a-4b0b-a242-4c2899328426)
Sep 30 19:12:50.565: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-2965.svc.cluster.local from pod dns-2965/dns-test-1a57db7c-660a-4b0b-a242-4c2899328426: the server could not find the requested resource (get pods dns-test-1a57db7c-660a-4b0b-a242-4c2899328426)
Sep 30 19:12:50.567: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-2965.svc.cluster.local from pod dns-2965/dns-test-1a57db7c-660a-4b0b-a242-4c2899328426: the server could not find the requested resource (get pods dns-test-1a57db7c-660a-4b0b-a242-4c2899328426)
Sep 30 19:12:50.573: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local from pod dns-2965/dns-test-1a57db7c-660a-4b0b-a242-4c2899328426: the server could not find the requested resource (get pods dns-test-1a57db7c-660a-4b0b-a242-4c2899328426)
Sep 30 19:12:50.575: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local from pod dns-2965/dns-test-1a57db7c-660a-4b0b-a242-4c2899328426: the server could not find the requested resource (get pods dns-test-1a57db7c-660a-4b0b-a242-4c2899328426)
Sep 30 19:12:50.577: INFO: Unable to read jessie_udp@dns-test-service-2.dns-2965.svc.cluster.local from pod dns-2965/dns-test-1a57db7c-660a-4b0b-a242-4c2899328426: the server could not find the requested resource (get pods dns-test-1a57db7c-660a-4b0b-a242-4c2899328426)
Sep 30 19:12:50.579: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-2965.svc.cluster.local from pod dns-2965/dns-test-1a57db7c-660a-4b0b-a242-4c2899328426: the server could not find the requested resource (get pods dns-test-1a57db7c-660a-4b0b-a242-4c2899328426)
Sep 30 19:12:50.583: INFO: Lookups using dns-2965/dns-test-1a57db7c-660a-4b0b-a242-4c2899328426 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local wheezy_udp@dns-test-service-2.dns-2965.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-2965.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2965.svc.cluster.local jessie_udp@dns-test-service-2.dns-2965.svc.cluster.local jessie_tcp@dns-test-service-2.dns-2965.svc.cluster.local]

Sep 30 19:12:55.608: INFO: DNS probes using dns-2965/dns-test-1a57db7c-660a-4b0b-a242-4c2899328426 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:12:55.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2965" for this suite.

â€¢ [SLOW TEST:9.378 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":275,"completed":128,"skipped":2050,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:12:55.719: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-5115
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1594
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7145
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:13:02.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5115" for this suite.
STEP: Destroying namespace "nsdeletetest-1594" for this suite.
Sep 30 19:13:02.297: INFO: Namespace nsdeletetest-1594 was already deleted
STEP: Destroying namespace "nsdeletetest-7145" for this suite.

â€¢ [SLOW TEST:6.581 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":275,"completed":129,"skipped":2070,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:13:02.302: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4630
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:13:02.462: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba3599e6-1c0b-43b7-bca5-e3bb010c75ec" in namespace "projected-4630" to be "Succeeded or Failed"
Sep 30 19:13:02.470: INFO: Pod "downwardapi-volume-ba3599e6-1c0b-43b7-bca5-e3bb010c75ec": Phase="Pending", Reason="", readiness=false. Elapsed: 7.419182ms
Sep 30 19:13:04.472: INFO: Pod "downwardapi-volume-ba3599e6-1c0b-43b7-bca5-e3bb010c75ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010139737s
STEP: Saw pod success
Sep 30 19:13:04.473: INFO: Pod "downwardapi-volume-ba3599e6-1c0b-43b7-bca5-e3bb010c75ec" satisfied condition "Succeeded or Failed"
Sep 30 19:13:04.474: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-ba3599e6-1c0b-43b7-bca5-e3bb010c75ec container client-container: <nil>
STEP: delete the pod
Sep 30 19:13:04.491: INFO: Waiting for pod downwardapi-volume-ba3599e6-1c0b-43b7-bca5-e3bb010c75ec to disappear
Sep 30 19:13:04.498: INFO: Pod downwardapi-volume-ba3599e6-1c0b-43b7-bca5-e3bb010c75ec no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:13:04.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4630" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":275,"completed":130,"skipped":2085,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:13:04.505: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8042
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 30 19:13:07.188: INFO: Successfully updated pod "labelsupdate83a99787-ccc5-428b-ac4f-c0a5e072999e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:13:09.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8042" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":275,"completed":131,"skipped":2107,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:13:09.213: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8686
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:13:09.367: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1748f3e-e3d8-421d-94ae-2978835fe747" in namespace "projected-8686" to be "Succeeded or Failed"
Sep 30 19:13:09.376: INFO: Pod "downwardapi-volume-e1748f3e-e3d8-421d-94ae-2978835fe747": Phase="Pending", Reason="", readiness=false. Elapsed: 9.113991ms
Sep 30 19:13:11.379: INFO: Pod "downwardapi-volume-e1748f3e-e3d8-421d-94ae-2978835fe747": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011902854s
STEP: Saw pod success
Sep 30 19:13:11.379: INFO: Pod "downwardapi-volume-e1748f3e-e3d8-421d-94ae-2978835fe747" satisfied condition "Succeeded or Failed"
Sep 30 19:13:11.380: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-e1748f3e-e3d8-421d-94ae-2978835fe747 container client-container: <nil>
STEP: delete the pod
Sep 30 19:13:11.397: INFO: Waiting for pod downwardapi-volume-e1748f3e-e3d8-421d-94ae-2978835fe747 to disappear
Sep 30 19:13:11.408: INFO: Pod downwardapi-volume-e1748f3e-e3d8-421d-94ae-2978835fe747 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:13:11.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8686" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":275,"completed":132,"skipped":2184,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:13:11.414: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-768
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 30 19:13:14.597: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:13:14.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-768" for this suite.
â€¢{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":275,"completed":133,"skipped":2206,"failed":0}
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:13:14.621: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5100
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-9c0fb344-88dc-4689-ae4b-395f25521cf5
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:13:14.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5100" for this suite.
â€¢{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":275,"completed":134,"skipped":2213,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:13:14.775: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7952
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-7952
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-7952
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7952
Sep 30 19:13:14.954: INFO: Found 0 stateful pods, waiting for 1
Sep 30 19:13:24.957: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 30 19:13:24.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-7952 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 19:13:26.371: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 19:13:26.371: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 19:13:26.371: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 30 19:13:26.373: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 30 19:13:36.376: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 30 19:13:36.376: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 19:13:36.395: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999997s
Sep 30 19:13:37.398: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988564811s
Sep 30 19:13:38.401: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.985937172s
Sep 30 19:13:39.405: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982662361s
Sep 30 19:13:40.408: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978743912s
Sep 30 19:13:41.410: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975981049s
Sep 30 19:13:42.413: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.973548351s
Sep 30 19:13:43.418: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970791342s
Sep 30 19:13:44.420: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.966185154s
Sep 30 19:13:45.423: INFO: Verifying statefulset ss doesn't scale past 1 for another 963.748466ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7952
Sep 30 19:13:46.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-7952 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:13:46.597: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 30 19:13:46.597: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 30 19:13:46.597: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 30 19:13:46.600: INFO: Found 1 stateful pods, waiting for 3
Sep 30 19:13:56.603: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 19:13:56.603: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 30 19:13:56.603: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 30 19:13:56.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-7952 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 19:13:56.771: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 19:13:56.771: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 19:13:56.771: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 30 19:13:56.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-7952 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 19:13:56.930: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 19:13:56.930: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 19:13:56.930: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 30 19:13:56.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-7952 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 30 19:13:57.099: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 30 19:13:57.099: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 30 19:13:57.099: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 30 19:13:57.099: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 19:13:57.102: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 30 19:14:07.107: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 30 19:14:07.107: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 30 19:14:07.107: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 30 19:14:07.122: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999732s
Sep 30 19:14:08.125: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993115085s
Sep 30 19:14:09.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989838767s
Sep 30 19:14:10.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986536584s
Sep 30 19:14:11.134: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983535215s
Sep 30 19:14:12.137: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980595299s
Sep 30 19:14:13.141: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977494201s
Sep 30 19:14:14.144: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974082166s
Sep 30 19:14:15.147: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.970742913s
Sep 30 19:14:16.151: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.635096ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7952
Sep 30 19:14:17.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-7952 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:14:17.323: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 30 19:14:17.323: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 30 19:14:17.323: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 30 19:14:17.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-7952 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:14:17.504: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 30 19:14:17.504: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 30 19:14:17.504: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 30 19:14:17.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=statefulset-7952 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 30 19:14:17.657: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 30 19:14:17.657: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 30 19:14:17.657: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 30 19:14:17.657: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 30 19:14:37.670: INFO: Deleting all statefulset in ns statefulset-7952
Sep 30 19:14:37.672: INFO: Scaling statefulset ss to 0
Sep 30 19:14:37.687: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 19:14:37.689: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:14:37.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7952" for this suite.

â€¢ [SLOW TEST:82.940 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":275,"completed":135,"skipped":2237,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:14:37.718: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3019
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-ecaf65ac-b9c3-41f9-b614-5206dddedbde
STEP: Creating a pod to test consume configMaps
Sep 30 19:14:37.874: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c5b66760-f80d-44d0-adfc-4b7638995ff8" in namespace "projected-3019" to be "Succeeded or Failed"
Sep 30 19:14:37.880: INFO: Pod "pod-projected-configmaps-c5b66760-f80d-44d0-adfc-4b7638995ff8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.320216ms
Sep 30 19:14:39.883: INFO: Pod "pod-projected-configmaps-c5b66760-f80d-44d0-adfc-4b7638995ff8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008753296s
STEP: Saw pod success
Sep 30 19:14:39.883: INFO: Pod "pod-projected-configmaps-c5b66760-f80d-44d0-adfc-4b7638995ff8" satisfied condition "Succeeded or Failed"
Sep 30 19:14:39.885: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-projected-configmaps-c5b66760-f80d-44d0-adfc-4b7638995ff8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 19:14:39.904: INFO: Waiting for pod pod-projected-configmaps-c5b66760-f80d-44d0-adfc-4b7638995ff8 to disappear
Sep 30 19:14:39.911: INFO: Pod pod-projected-configmaps-c5b66760-f80d-44d0-adfc-4b7638995ff8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:14:39.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3019" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":275,"completed":136,"skipped":2266,"failed":0}
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:14:39.922: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:14:40.095: INFO: Create a RollingUpdate DaemonSet
Sep 30 19:14:40.098: INFO: Check that daemon pods launch on every node of the cluster
Sep 30 19:14:40.116: INFO: Number of nodes with available pods: 0
Sep 30 19:14:40.116: INFO: Node 9b360f31-b888-42e4-807a-5f2a0fca8fae is running more than one daemon pod
Sep 30 19:14:41.121: INFO: Number of nodes with available pods: 0
Sep 30 19:14:41.121: INFO: Node 9b360f31-b888-42e4-807a-5f2a0fca8fae is running more than one daemon pod
Sep 30 19:14:42.121: INFO: Number of nodes with available pods: 3
Sep 30 19:14:42.121: INFO: Number of running nodes: 3, number of available pods: 3
Sep 30 19:14:42.121: INFO: Update the DaemonSet to trigger a rollout
Sep 30 19:14:42.125: INFO: Updating DaemonSet daemon-set
Sep 30 19:14:46.142: INFO: Roll back the DaemonSet before rollout is complete
Sep 30 19:14:46.148: INFO: Updating DaemonSet daemon-set
Sep 30 19:14:46.148: INFO: Make sure DaemonSet rollback is complete
Sep 30 19:14:46.156: INFO: Wrong image for pod: daemon-set-zq5hf. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 30 19:14:46.156: INFO: Pod daemon-set-zq5hf is not available
Sep 30 19:14:47.169: INFO: Wrong image for pod: daemon-set-zq5hf. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 30 19:14:47.169: INFO: Pod daemon-set-zq5hf is not available
Sep 30 19:14:48.168: INFO: Pod daemon-set-xgpl2 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7797, will wait for the garbage collector to delete the pods
Sep 30 19:14:48.236: INFO: Deleting DaemonSet.extensions daemon-set took: 3.908921ms
Sep 30 19:14:48.336: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.232866ms
Sep 30 19:14:57.238: INFO: Number of nodes with available pods: 0
Sep 30 19:14:57.238: INFO: Number of running nodes: 0, number of available pods: 0
Sep 30 19:14:57.239: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7797/daemonsets","resourceVersion":"219588"},"items":null}

Sep 30 19:14:57.241: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7797/pods","resourceVersion":"219588"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:14:57.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7797" for this suite.

â€¢ [SLOW TEST:17.331 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":275,"completed":137,"skipped":2268,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:14:57.256: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7946
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-d8dbb3b5-e3d0-449d-a54d-31cc541c752c in namespace container-probe-7946
Sep 30 19:14:59.421: INFO: Started pod busybox-d8dbb3b5-e3d0-449d-a54d-31cc541c752c in namespace container-probe-7946
STEP: checking the pod's current state and verifying that restartCount is present
Sep 30 19:14:59.423: INFO: Initial restart count of pod busybox-d8dbb3b5-e3d0-449d-a54d-31cc541c752c is 0
Sep 30 19:15:47.486: INFO: Restart count of pod container-probe-7946/busybox-d8dbb3b5-e3d0-449d-a54d-31cc541c752c is now 1 (48.063255626s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:15:47.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7946" for this suite.

â€¢ [SLOW TEST:50.264 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":275,"completed":138,"skipped":2286,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:15:47.520: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3844
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-87460f54-5b28-413f-ae13-2fc1a4f6eb36
STEP: Creating a pod to test consume configMaps
Sep 30 19:15:47.675: INFO: Waiting up to 5m0s for pod "pod-configmaps-a3368bb1-4c27-4348-96d0-5d1984475087" in namespace "configmap-3844" to be "Succeeded or Failed"
Sep 30 19:15:47.687: INFO: Pod "pod-configmaps-a3368bb1-4c27-4348-96d0-5d1984475087": Phase="Pending", Reason="", readiness=false. Elapsed: 12.154717ms
Sep 30 19:15:49.689: INFO: Pod "pod-configmaps-a3368bb1-4c27-4348-96d0-5d1984475087": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014586248s
STEP: Saw pod success
Sep 30 19:15:49.689: INFO: Pod "pod-configmaps-a3368bb1-4c27-4348-96d0-5d1984475087" satisfied condition "Succeeded or Failed"
Sep 30 19:15:49.691: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-configmaps-a3368bb1-4c27-4348-96d0-5d1984475087 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 19:15:49.710: INFO: Waiting for pod pod-configmaps-a3368bb1-4c27-4348-96d0-5d1984475087 to disappear
Sep 30 19:15:49.717: INFO: Pod pod-configmaps-a3368bb1-4c27-4348-96d0-5d1984475087 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:15:49.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3844" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":275,"completed":139,"skipped":2292,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:15:49.723: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3747
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3747
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3747
I0930 19:15:49.970665      21 runners.go:190] Created replication controller with name: externalname-service, namespace: services-3747, replica count: 2
I0930 19:15:53.021402      21 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 30 19:15:53.022: INFO: Creating new exec pod
Sep 30 19:15:56.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-3747 execpodntqzr -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 30 19:15:56.185: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 30 19:15:56.186: INFO: stdout: ""
Sep 30 19:15:56.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-3747 execpodntqzr -- /bin/sh -x -c nc -zv -t -w 2 10.100.200.176 80'
Sep 30 19:15:56.364: INFO: stderr: "+ nc -zv -t -w 2 10.100.200.176 80\nConnection to 10.100.200.176 80 port [tcp/http] succeeded!\n"
Sep 30 19:15:56.364: INFO: stdout: ""
Sep 30 19:15:56.364: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:15:56.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3747" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:6.674 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":275,"completed":140,"skipped":2299,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:15:56.398: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3796
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:15:56.869: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 19:15:58.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090156, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090156, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090156, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090156, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:16:01.892: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:16:14.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3796" for this suite.
STEP: Destroying namespace "webhook-3796-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:17.691 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":275,"completed":141,"skipped":2312,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:16:14.090: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2749
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:16:14.248: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee9d7a11-fd00-43b7-9290-f4d12bc9d397" in namespace "downward-api-2749" to be "Succeeded or Failed"
Sep 30 19:16:14.273: INFO: Pod "downwardapi-volume-ee9d7a11-fd00-43b7-9290-f4d12bc9d397": Phase="Pending", Reason="", readiness=false. Elapsed: 24.64451ms
Sep 30 19:16:16.275: INFO: Pod "downwardapi-volume-ee9d7a11-fd00-43b7-9290-f4d12bc9d397": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027181241s
STEP: Saw pod success
Sep 30 19:16:16.275: INFO: Pod "downwardapi-volume-ee9d7a11-fd00-43b7-9290-f4d12bc9d397" satisfied condition "Succeeded or Failed"
Sep 30 19:16:16.277: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-ee9d7a11-fd00-43b7-9290-f4d12bc9d397 container client-container: <nil>
STEP: delete the pod
Sep 30 19:16:16.299: INFO: Waiting for pod downwardapi-volume-ee9d7a11-fd00-43b7-9290-f4d12bc9d397 to disappear
Sep 30 19:16:16.306: INFO: Pod downwardapi-volume-ee9d7a11-fd00-43b7-9290-f4d12bc9d397 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:16:16.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2749" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":142,"skipped":2321,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:16:16.312: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-3aeb928b-6e0d-43a0-9ba0-c63168444e98
STEP: Creating a pod to test consume secrets
Sep 30 19:16:16.508: INFO: Waiting up to 5m0s for pod "pod-secrets-08ab868e-0191-44f2-95a2-aee3af08940e" in namespace "secrets-4987" to be "Succeeded or Failed"
Sep 30 19:16:16.514: INFO: Pod "pod-secrets-08ab868e-0191-44f2-95a2-aee3af08940e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.28392ms
Sep 30 19:16:18.516: INFO: Pod "pod-secrets-08ab868e-0191-44f2-95a2-aee3af08940e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008530523s
STEP: Saw pod success
Sep 30 19:16:18.516: INFO: Pod "pod-secrets-08ab868e-0191-44f2-95a2-aee3af08940e" satisfied condition "Succeeded or Failed"
Sep 30 19:16:18.518: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-secrets-08ab868e-0191-44f2-95a2-aee3af08940e container secret-volume-test: <nil>
STEP: delete the pod
Sep 30 19:16:18.545: INFO: Waiting for pod pod-secrets-08ab868e-0191-44f2-95a2-aee3af08940e to disappear
Sep 30 19:16:18.549: INFO: Pod pod-secrets-08ab868e-0191-44f2-95a2-aee3af08940e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:16:18.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4987" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":275,"completed":143,"skipped":2332,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:16:18.557: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 30 19:16:18.704: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 30 19:16:18.712: INFO: Waiting for terminating namespaces to be deleted...
Sep 30 19:16:18.714: INFO: 
Logging pods the kubelet thinks is on node 9b360f31-b888-42e4-807a-5f2a0fca8fae before test
Sep 30 19:16:18.726: INFO: wavefront-proxy-68d69454fc-pm5dv from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.726: INFO: 	Container wavefront-proxy ready: true, restart count 0
Sep 30 19:16:18.726: INFO: fluent-bit-lpcs8 from pks-system started at 2020-09-29 19:35:27 +0000 UTC (2 container statuses recorded)
Sep 30 19:16:18.726: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 19:16:18.726: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:16:18.726: INFO: node-exporter-ws8wb from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.726: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 19:16:18.726: INFO: telegraf-h5t2t from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.726: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 19:16:18.726: INFO: sink-controller-7549dc74f7-4qx97 from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.726: INFO: 	Container sink-controller ready: true, restart count 0
Sep 30 19:16:18.726: INFO: coredns-854d7dc8c-6rdh4 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.727: INFO: 	Container coredns ready: true, restart count 0
Sep 30 19:16:18.727: INFO: wavefront-collector-drm6c from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.727: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 19:16:18.727: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-5zmhk from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:16:18.727: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:16:18.727: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 19:16:18.727: INFO: 
Logging pods the kubelet thinks is on node c4ab02cf-8388-4ee7-9741-792b2ee511a4 before test
Sep 30 19:16:18.740: INFO: sonobuoy-e2e-job-953b1e3c972143b8 from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container e2e ready: true, restart count 0
Sep 30 19:16:18.740: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:16:18.740: INFO: event-controller-7775f56b74-zgbbq from pks-system started at 2020-09-29 19:35:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container event-controller ready: true, restart count 0
Sep 30 19:16:18.740: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:16:18.740: INFO: fluent-bit-fbgsw from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 19:16:18.740: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:16:18.740: INFO: validator-6b476b98c9-d5g8r from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container validator ready: true, restart count 0
Sep 30 19:16:18.740: INFO: wavefront-collector-94rjj from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 19:16:18.740: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-gvhcn from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:16:18.740: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 19:16:18.740: INFO: coredns-854d7dc8c-9w7v7 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container coredns ready: true, restart count 0
Sep 30 19:16:18.740: INFO: observability-manager-684c664cf4-nqrxv from pks-system started at 2020-09-29 19:35:04 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container observability-manager ready: true, restart count 0
Sep 30 19:16:18.740: INFO: node-exporter-75l6n from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 19:16:18.740: INFO: telegraf-k5gxd from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.740: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 19:16:18.740: INFO: 
Logging pods the kubelet thinks is on node eb106fc7-933d-47a1-a18a-16aa6514d845 before test
Sep 30 19:16:18.746: INFO: sonobuoy from sonobuoy started at 2020-09-30 18:29:07 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.746: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 30 19:16:18.746: INFO: metric-controller-7fd9d59567-hqvsc from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.746: INFO: 	Container metric-controller ready: true, restart count 0
Sep 30 19:16:18.746: INFO: cert-generator-e484f2435fc830429fc9747bd002fcda56dd053e-cc5fz from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.746: INFO: 	Container cert-generator ready: false, restart count 0
Sep 30 19:16:18.746: INFO: telemetry-agent-6bcf5c56b-qmz52 from pks-system started at 2020-09-29 19:37:51 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.746: INFO: 	Container fluent-bit-telemetry ready: true, restart count 0
Sep 30 19:16:18.746: INFO: node-exporter-jgdvm from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.746: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 19:16:18.746: INFO: telegraf-z8x2g from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.746: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 19:16:18.746: INFO: wavefront-collector-hms5p from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.746: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 19:16:18.746: INFO: metrics-server-6967cb5487-z8t86 from kube-system started at 2020-09-29 19:35:01 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.746: INFO: 	Container metrics-server ready: true, restart count 0
Sep 30 19:16:18.746: INFO: fluent-bit-5x9vt from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 19:16:18.746: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 19:16:18.746: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:16:18.747: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-wgtws from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:16:18.747: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:16:18.747: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 19:16:18.747: INFO: coredns-854d7dc8c-lg4vh from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 19:16:18.747: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1639a5be300467c5], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1639a5be31763471], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:16:19.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1744" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
â€¢{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":275,"completed":144,"skipped":2379,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:16:19.786: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:16:21.976: INFO: Waiting up to 5m0s for pod "client-envvars-0d831234-23ce-4f17-ad82-fca26e02814f" in namespace "pods-6203" to be "Succeeded or Failed"
Sep 30 19:16:21.999: INFO: Pod "client-envvars-0d831234-23ce-4f17-ad82-fca26e02814f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.815047ms
Sep 30 19:16:24.001: INFO: Pod "client-envvars-0d831234-23ce-4f17-ad82-fca26e02814f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024865245s
STEP: Saw pod success
Sep 30 19:16:24.001: INFO: Pod "client-envvars-0d831234-23ce-4f17-ad82-fca26e02814f" satisfied condition "Succeeded or Failed"
Sep 30 19:16:24.003: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod client-envvars-0d831234-23ce-4f17-ad82-fca26e02814f container env3cont: <nil>
STEP: delete the pod
Sep 30 19:16:24.021: INFO: Waiting for pod client-envvars-0d831234-23ce-4f17-ad82-fca26e02814f to disappear
Sep 30 19:16:24.030: INFO: Pod client-envvars-0d831234-23ce-4f17-ad82-fca26e02814f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:16:24.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6203" for this suite.
â€¢{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":275,"completed":145,"skipped":2435,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:16:24.043: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4285
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-e6fdbcb9-06fb-4d9a-ae38-db7906fb6653
STEP: Creating a pod to test consume secrets
Sep 30 19:16:24.212: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ad0f0041-94bb-445e-bb36-e115c2282f6f" in namespace "projected-4285" to be "Succeeded or Failed"
Sep 30 19:16:24.223: INFO: Pod "pod-projected-secrets-ad0f0041-94bb-445e-bb36-e115c2282f6f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.278659ms
Sep 30 19:16:26.225: INFO: Pod "pod-projected-secrets-ad0f0041-94bb-445e-bb36-e115c2282f6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013742675s
STEP: Saw pod success
Sep 30 19:16:26.225: INFO: Pod "pod-projected-secrets-ad0f0041-94bb-445e-bb36-e115c2282f6f" satisfied condition "Succeeded or Failed"
Sep 30 19:16:26.227: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-projected-secrets-ad0f0041-94bb-445e-bb36-e115c2282f6f container secret-volume-test: <nil>
STEP: delete the pod
Sep 30 19:16:26.255: INFO: Waiting for pod pod-projected-secrets-ad0f0041-94bb-445e-bb36-e115c2282f6f to disappear
Sep 30 19:16:26.256: INFO: Pod pod-projected-secrets-ad0f0041-94bb-445e-bb36-e115c2282f6f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:16:26.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4285" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":275,"completed":146,"skipped":2508,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:16:26.264: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:16:37.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3110" for this suite.

â€¢ [SLOW TEST:11.225 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":275,"completed":147,"skipped":2548,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:16:37.492: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9482
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-9482
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9482 to expose endpoints map[]
Sep 30 19:16:37.658: INFO: successfully validated that service endpoint-test2 in namespace services-9482 exposes endpoints map[] (12.215107ms elapsed)
STEP: Creating pod pod1 in namespace services-9482
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9482 to expose endpoints map[pod1:[80]]
Sep 30 19:16:39.714: INFO: successfully validated that service endpoint-test2 in namespace services-9482 exposes endpoints map[pod1:[80]] (2.038477896s elapsed)
STEP: Creating pod pod2 in namespace services-9482
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9482 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 30 19:16:41.751: INFO: successfully validated that service endpoint-test2 in namespace services-9482 exposes endpoints map[pod1:[80] pod2:[80]] (2.033335999s elapsed)
STEP: Deleting pod pod1 in namespace services-9482
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9482 to expose endpoints map[pod2:[80]]
Sep 30 19:16:41.779: INFO: successfully validated that service endpoint-test2 in namespace services-9482 exposes endpoints map[pod2:[80]] (21.184202ms elapsed)
STEP: Deleting pod pod2 in namespace services-9482
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9482 to expose endpoints map[]
Sep 30 19:16:42.795: INFO: successfully validated that service endpoint-test2 in namespace services-9482 exposes endpoints map[] (1.013023532s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:16:42.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9482" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:5.337 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":275,"completed":148,"skipped":2627,"failed":0}
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:16:42.829: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9663
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 30 19:16:42.999: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9663 /api/v1/namespaces/watch-9663/configmaps/e2e-watch-test-resource-version 6018f142-d831-4ed5-8df4-1e0260a87811 220337 0 2020-09-30 19:16:42 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-09-30 19:16:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:16:42.999: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9663 /api/v1/namespaces/watch-9663/configmaps/e2e-watch-test-resource-version 6018f142-d831-4ed5-8df4-1e0260a87811 220338 0 2020-09-30 19:16:42 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-09-30 19:16:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:16:42.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9663" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":275,"completed":149,"skipped":2629,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:16:43.009: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1869
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-0d954f66-fea9-4936-97aa-e5580b06200e in namespace container-probe-1869
Sep 30 19:16:45.214: INFO: Started pod liveness-0d954f66-fea9-4936-97aa-e5580b06200e in namespace container-probe-1869
STEP: checking the pod's current state and verifying that restartCount is present
Sep 30 19:16:45.215: INFO: Initial restart count of pod liveness-0d954f66-fea9-4936-97aa-e5580b06200e is 0
Sep 30 19:17:03.240: INFO: Restart count of pod container-probe-1869/liveness-0d954f66-fea9-4936-97aa-e5580b06200e is now 1 (18.025087248s elapsed)
Sep 30 19:17:23.267: INFO: Restart count of pod container-probe-1869/liveness-0d954f66-fea9-4936-97aa-e5580b06200e is now 2 (38.051858815s elapsed)
Sep 30 19:17:45.296: INFO: Restart count of pod container-probe-1869/liveness-0d954f66-fea9-4936-97aa-e5580b06200e is now 3 (1m0.080535725s elapsed)
Sep 30 19:18:05.322: INFO: Restart count of pod container-probe-1869/liveness-0d954f66-fea9-4936-97aa-e5580b06200e is now 4 (1m20.106863243s elapsed)
Sep 30 19:19:17.442: INFO: Restart count of pod container-probe-1869/liveness-0d954f66-fea9-4936-97aa-e5580b06200e is now 5 (2m32.226687658s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:19:17.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1869" for this suite.

â€¢ [SLOW TEST:154.459 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":275,"completed":150,"skipped":2661,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:19:17.468: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7154
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:19:17.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-7154'
Sep 30 19:19:17.865: INFO: stderr: ""
Sep 30 19:19:17.865: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Sep 30 19:19:17.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-7154'
Sep 30 19:19:18.026: INFO: stderr: ""
Sep 30 19:19:18.026: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Sep 30 19:19:19.029: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 19:19:19.029: INFO: Found 0 / 1
Sep 30 19:19:20.029: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 19:19:20.029: INFO: Found 1 / 1
Sep 30 19:19:20.029: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 30 19:19:20.030: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 30 19:19:20.030: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 30 19:19:20.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 describe pod agnhost-master-gbzw5 --namespace=kubectl-7154'
Sep 30 19:19:20.102: INFO: stderr: ""
Sep 30 19:19:20.102: INFO: stdout: "Name:         agnhost-master-gbzw5\nNamespace:    kubectl-7154\nPriority:     0\nNode:         eb106fc7-933d-47a1-a18a-16aa6514d845/30.0.0.12\nStart Time:   Wed, 30 Sep 2020 19:19:17 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.200.99.152\nIPs:\n  IP:           10.200.99.152\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://34285fea3c7d1fee2b3aa473629fe23752b40b7a60f676415673a27361f9e5bb\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 30 Sep 2020 19:19:18 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xbc6b (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-xbc6b:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-xbc6b\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                           Message\n  ----    ------     ----       ----                                           -------\n  Normal  Scheduled  <unknown>  default-scheduler                              Successfully assigned kubectl-7154/agnhost-master-gbzw5 to eb106fc7-933d-47a1-a18a-16aa6514d845\n  Normal  Pulled     2s         kubelet, eb106fc7-933d-47a1-a18a-16aa6514d845  Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    2s         kubelet, eb106fc7-933d-47a1-a18a-16aa6514d845  Created container agnhost-master\n  Normal  Started    2s         kubelet, eb106fc7-933d-47a1-a18a-16aa6514d845  Started container agnhost-master\n"
Sep 30 19:19:20.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 describe rc agnhost-master --namespace=kubectl-7154'
Sep 30 19:19:20.178: INFO: stderr: ""
Sep 30 19:19:20.178: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-7154\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-master-gbzw5\n"
Sep 30 19:19:20.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 describe service agnhost-master --namespace=kubectl-7154'
Sep 30 19:19:20.247: INFO: stderr: ""
Sep 30 19:19:20.247: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-7154\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.100.200.41\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.200.99.152:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 30 19:19:20.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 describe node 9b360f31-b888-42e4-807a-5f2a0fca8fae'
Sep 30 19:19:20.339: INFO: stderr: ""
Sep 30 19:19:20.339: INFO: stdout: "Name:               9b360f31-b888-42e4-807a-5f2a0fca8fae\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    bosh.id=e89f343b-a206-45c6-b346-e6ec20cf8ff9\n                    bosh.zone=shepherd-175721-200929-101449-az\n                    failure-domain.beta.kubernetes.io/zone=shepherd-175721-200929-101449-az\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=30.0.0.10\n                    kubernetes.io/os=linux\n                    pks-system/cluster.name=752cae09-aec3-4203-9519-9a526fe21af0.internal\n                    pks-system/cluster.uuid=service-instance_ba9a36f7-e979-4de3-b2ae-5f99af576538\n                    spec.ip=30.0.0.10\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 29 Sep 2020 19:29:57 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  9b360f31-b888-42e4-807a-5f2a0fca8fae\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 30 Sep 2020 19:19:18 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 30 Sep 2020 19:18:43 +0000   Tue, 29 Sep 2020 19:29:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 30 Sep 2020 19:18:43 +0000   Tue, 29 Sep 2020 19:29:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 30 Sep 2020 19:18:43 +0000   Tue, 29 Sep 2020 19:29:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 30 Sep 2020 19:18:43 +0000   Tue, 29 Sep 2020 19:30:07 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  30.0.0.10\n  InternalIP:  30.0.0.10\n  Hostname:    30.0.0.10\nCapacity:\n  cpu:                2\n  ephemeral-storage:  28917748Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             4039720Ki\n  pods:               110\nAllocatable:\n  cpu:                1500m\n  ephemeral-storage:  25576854689\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             2479144Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 bae19f4f6dec3e5d1c75107f18bde4a5\n  System UUID:                4220D10B-9359-8ED8-45EA-C56972B34120\n  Boot ID:                    65ba0df1-34c5-4c1a-a67f-f60661fbfd38\n  Kernel Version:             4.15.0-118-generic\n  OS Image:                   Ubuntu 16.04.7 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://19.3.5\n  Kubelet Version:            v1.18.8+vmware.1\n  Kube-Proxy Version:         v1.18.8+vmware.1\nProviderID:                   vsphere://4220d10b-9359-8ed8-45ea-c56972b34120\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-854d7dc8c-6rdh4                                    100m (6%)     0 (0%)      70Mi (2%)        170Mi (7%)     23h\n  pks-system                  fluent-bit-lpcs8                                           0 (0%)        0 (0%)      100Mi (4%)       100Mi (4%)     23h\n  pks-system                  node-exporter-ws8wb                                        10m (0%)      10m (0%)    50Mi (2%)        50Mi (2%)      23h\n  pks-system                  sink-controller-7549dc74f7-4qx97                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         23h\n  pks-system                  telegraf-h5t2t                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         23h\n  pks-system                  wavefront-collector-drm6c                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         23h\n  pks-system                  wavefront-proxy-68d69454fc-pm5dv                           0 (0%)        0 (0%)      1500M (59%)      1500M (59%)    23h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-5zmhk    0 (0%)        0 (0%)      0 (0%)           0 (0%)         50m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests          Limits\n  --------           --------          ------\n  cpu                110m (7%)         10m (0%)\n  memory             1730686720 (68%)  1835544320 (72%)\n  ephemeral-storage  0 (0%)            0 (0%)\n  hugepages-1Gi      0 (0%)            0 (0%)\n  hugepages-2Mi      0 (0%)            0 (0%)\nEvents:              <none>\n"
Sep 30 19:19:20.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 describe namespace kubectl-7154'
Sep 30 19:19:20.404: INFO: stderr: ""
Sep 30 19:19:20.404: INFO: stdout: "Name:         kubectl-7154\nLabels:       e2e-framework=kubectl\n              e2e-run=ef588b00-5360-4397-9541-39b2f08d2f33\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:19:20.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7154" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":275,"completed":151,"skipped":2665,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:19:20.410: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Sep 30 19:19:30.587: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
W0930 19:19:30.587099      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 30 19:19:30.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6454" for this suite.

â€¢ [SLOW TEST:10.182 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":275,"completed":152,"skipped":2701,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:19:30.595: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5163
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Sep 30 19:19:30.741: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:19:33.613: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:19:42.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5163" for this suite.

â€¢ [SLOW TEST:12.303 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":275,"completed":153,"skipped":2716,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:19:42.897: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-2346
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:19:43.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-2346" for this suite.
â€¢{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":275,"completed":154,"skipped":2735,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:19:43.113: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2044
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2044.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2044.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2044.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2044.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2044.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2044.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 30 19:19:45.317: INFO: DNS probes using dns-2044/dns-test-29cd741f-cd6e-41a6-8603-370ef044c0ba succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:19:45.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2044" for this suite.
â€¢{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":275,"completed":155,"skipped":2745,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:19:45.415: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-8ddf8574-edef-4d6a-87c1-75ef8150c69d
STEP: Creating a pod to test consume configMaps
Sep 30 19:19:45.576: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5e2b54a4-c9ef-461b-a08e-662393954f34" in namespace "projected-9090" to be "Succeeded or Failed"
Sep 30 19:19:45.588: INFO: Pod "pod-projected-configmaps-5e2b54a4-c9ef-461b-a08e-662393954f34": Phase="Pending", Reason="", readiness=false. Elapsed: 12.273513ms
Sep 30 19:19:47.591: INFO: Pod "pod-projected-configmaps-5e2b54a4-c9ef-461b-a08e-662393954f34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014496659s
STEP: Saw pod success
Sep 30 19:19:47.591: INFO: Pod "pod-projected-configmaps-5e2b54a4-c9ef-461b-a08e-662393954f34" satisfied condition "Succeeded or Failed"
Sep 30 19:19:47.592: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-projected-configmaps-5e2b54a4-c9ef-461b-a08e-662393954f34 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 19:19:47.619: INFO: Waiting for pod pod-projected-configmaps-5e2b54a4-c9ef-461b-a08e-662393954f34 to disappear
Sep 30 19:19:47.626: INFO: Pod pod-projected-configmaps-5e2b54a4-c9ef-461b-a08e-662393954f34 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:19:47.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9090" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":275,"completed":156,"skipped":2767,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:19:47.636: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Sep 30 19:19:47.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-7051'
Sep 30 19:19:48.043: INFO: stderr: ""
Sep 30 19:19:48.043: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 30 19:19:48.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7051'
Sep 30 19:19:48.125: INFO: stderr: ""
Sep 30 19:19:48.125: INFO: stdout: "update-demo-nautilus-f6hps update-demo-nautilus-w6276 "
Sep 30 19:19:48.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-f6hps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:19:48.200: INFO: stderr: ""
Sep 30 19:19:48.200: INFO: stdout: ""
Sep 30 19:19:48.200: INFO: update-demo-nautilus-f6hps is created but not running
Sep 30 19:19:53.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7051'
Sep 30 19:19:53.272: INFO: stderr: ""
Sep 30 19:19:53.272: INFO: stdout: "update-demo-nautilus-f6hps update-demo-nautilus-w6276 "
Sep 30 19:19:53.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-f6hps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:19:53.335: INFO: stderr: ""
Sep 30 19:19:53.335: INFO: stdout: "true"
Sep 30 19:19:53.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-f6hps -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:19:53.396: INFO: stderr: ""
Sep 30 19:19:53.396: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 30 19:19:53.396: INFO: validating pod update-demo-nautilus-f6hps
Sep 30 19:19:53.399: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 30 19:19:53.399: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 30 19:19:53.399: INFO: update-demo-nautilus-f6hps is verified up and running
Sep 30 19:19:53.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-w6276 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:19:53.463: INFO: stderr: ""
Sep 30 19:19:53.463: INFO: stdout: "true"
Sep 30 19:19:53.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-w6276 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:19:53.524: INFO: stderr: ""
Sep 30 19:19:53.524: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 30 19:19:53.525: INFO: validating pod update-demo-nautilus-w6276
Sep 30 19:19:53.527: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 30 19:19:53.527: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 30 19:19:53.527: INFO: update-demo-nautilus-w6276 is verified up and running
STEP: scaling down the replication controller
Sep 30 19:19:53.529: INFO: scanned /root for discovery docs: <nil>
Sep 30 19:19:53.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7051'
Sep 30 19:19:54.607: INFO: stderr: ""
Sep 30 19:19:54.607: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 30 19:19:54.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7051'
Sep 30 19:19:54.674: INFO: stderr: ""
Sep 30 19:19:54.674: INFO: stdout: "update-demo-nautilus-f6hps update-demo-nautilus-w6276 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 30 19:19:59.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7051'
Sep 30 19:19:59.743: INFO: stderr: ""
Sep 30 19:19:59.743: INFO: stdout: "update-demo-nautilus-f6hps update-demo-nautilus-w6276 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 30 19:20:04.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7051'
Sep 30 19:20:04.806: INFO: stderr: ""
Sep 30 19:20:04.806: INFO: stdout: "update-demo-nautilus-f6hps "
Sep 30 19:20:04.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-f6hps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:20:04.869: INFO: stderr: ""
Sep 30 19:20:04.869: INFO: stdout: "true"
Sep 30 19:20:04.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-f6hps -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:20:04.933: INFO: stderr: ""
Sep 30 19:20:04.933: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 30 19:20:04.933: INFO: validating pod update-demo-nautilus-f6hps
Sep 30 19:20:04.936: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 30 19:20:04.936: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 30 19:20:04.936: INFO: update-demo-nautilus-f6hps is verified up and running
STEP: scaling up the replication controller
Sep 30 19:20:04.938: INFO: scanned /root for discovery docs: <nil>
Sep 30 19:20:04.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7051'
Sep 30 19:20:06.030: INFO: stderr: ""
Sep 30 19:20:06.030: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 30 19:20:06.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7051'
Sep 30 19:20:06.102: INFO: stderr: ""
Sep 30 19:20:06.102: INFO: stdout: "update-demo-nautilus-7qwsd update-demo-nautilus-f6hps "
Sep 30 19:20:06.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-7qwsd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:20:06.165: INFO: stderr: ""
Sep 30 19:20:06.165: INFO: stdout: ""
Sep 30 19:20:06.165: INFO: update-demo-nautilus-7qwsd is created but not running
Sep 30 19:20:11.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7051'
Sep 30 19:20:11.230: INFO: stderr: ""
Sep 30 19:20:11.230: INFO: stdout: "update-demo-nautilus-7qwsd update-demo-nautilus-f6hps "
Sep 30 19:20:11.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-7qwsd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:20:11.294: INFO: stderr: ""
Sep 30 19:20:11.294: INFO: stdout: "true"
Sep 30 19:20:11.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-7qwsd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:20:11.355: INFO: stderr: ""
Sep 30 19:20:11.355: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 30 19:20:11.355: INFO: validating pod update-demo-nautilus-7qwsd
Sep 30 19:20:11.358: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 30 19:20:11.358: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 30 19:20:11.358: INFO: update-demo-nautilus-7qwsd is verified up and running
Sep 30 19:20:11.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-f6hps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:20:11.426: INFO: stderr: ""
Sep 30 19:20:11.426: INFO: stdout: "true"
Sep 30 19:20:11.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-f6hps -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7051'
Sep 30 19:20:11.487: INFO: stderr: ""
Sep 30 19:20:11.487: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 30 19:20:11.487: INFO: validating pod update-demo-nautilus-f6hps
Sep 30 19:20:11.489: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 30 19:20:11.489: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 30 19:20:11.489: INFO: update-demo-nautilus-f6hps is verified up and running
STEP: using delete to clean up resources
Sep 30 19:20:11.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete --grace-period=0 --force -f - --namespace=kubectl-7051'
Sep 30 19:20:11.564: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 30 19:20:11.564: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 30 19:20:11.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7051'
Sep 30 19:20:11.631: INFO: stderr: "No resources found in kubectl-7051 namespace.\n"
Sep 30 19:20:11.631: INFO: stdout: ""
Sep 30 19:20:11.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -l name=update-demo --namespace=kubectl-7051 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 30 19:20:11.693: INFO: stderr: ""
Sep 30 19:20:11.693: INFO: stdout: "update-demo-nautilus-7qwsd\nupdate-demo-nautilus-f6hps\n"
Sep 30 19:20:12.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7051'
Sep 30 19:20:12.260: INFO: stderr: "No resources found in kubectl-7051 namespace.\n"
Sep 30 19:20:12.260: INFO: stdout: ""
Sep 30 19:20:12.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -l name=update-demo --namespace=kubectl-7051 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 30 19:20:12.326: INFO: stderr: ""
Sep 30 19:20:12.326: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:20:12.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7051" for this suite.

â€¢ [SLOW TEST:24.696 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":275,"completed":157,"skipped":2842,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:20:12.332: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-3bfff3bd-edd1-4114-b7b6-f3a87c319485
STEP: Creating a pod to test consume configMaps
Sep 30 19:20:12.489: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-64fbdaba-3b4d-4efd-8141-e3b3f6e6832d" in namespace "projected-8277" to be "Succeeded or Failed"
Sep 30 19:20:12.494: INFO: Pod "pod-projected-configmaps-64fbdaba-3b4d-4efd-8141-e3b3f6e6832d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.295813ms
Sep 30 19:20:14.497: INFO: Pod "pod-projected-configmaps-64fbdaba-3b4d-4efd-8141-e3b3f6e6832d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007811378s
STEP: Saw pod success
Sep 30 19:20:14.497: INFO: Pod "pod-projected-configmaps-64fbdaba-3b4d-4efd-8141-e3b3f6e6832d" satisfied condition "Succeeded or Failed"
Sep 30 19:20:14.499: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod pod-projected-configmaps-64fbdaba-3b4d-4efd-8141-e3b3f6e6832d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 19:20:14.532: INFO: Waiting for pod pod-projected-configmaps-64fbdaba-3b4d-4efd-8141-e3b3f6e6832d to disappear
Sep 30 19:20:14.539: INFO: Pod pod-projected-configmaps-64fbdaba-3b4d-4efd-8141-e3b3f6e6832d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:20:14.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8277" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":275,"completed":158,"skipped":2885,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:20:14.545: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0930 19:20:15.342197      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 30 19:20:15.342: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:20:15.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-108" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":275,"completed":159,"skipped":2886,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:20:15.348: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-395
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 30 19:20:15.494: INFO: Waiting up to 5m0s for pod "pod-6eda9819-08a7-46f8-aa0b-33ace7a23bce" in namespace "emptydir-395" to be "Succeeded or Failed"
Sep 30 19:20:15.508: INFO: Pod "pod-6eda9819-08a7-46f8-aa0b-33ace7a23bce": Phase="Pending", Reason="", readiness=false. Elapsed: 13.401731ms
Sep 30 19:20:17.510: INFO: Pod "pod-6eda9819-08a7-46f8-aa0b-33ace7a23bce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015516283s
Sep 30 19:20:19.513: INFO: Pod "pod-6eda9819-08a7-46f8-aa0b-33ace7a23bce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018294172s
STEP: Saw pod success
Sep 30 19:20:19.513: INFO: Pod "pod-6eda9819-08a7-46f8-aa0b-33ace7a23bce" satisfied condition "Succeeded or Failed"
Sep 30 19:20:19.515: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-6eda9819-08a7-46f8-aa0b-33ace7a23bce container test-container: <nil>
STEP: delete the pod
Sep 30 19:20:19.547: INFO: Waiting for pod pod-6eda9819-08a7-46f8-aa0b-33ace7a23bce to disappear
Sep 30 19:20:19.564: INFO: Pod pod-6eda9819-08a7-46f8-aa0b-33ace7a23bce no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:20:19.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-395" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":160,"skipped":2930,"failed":0}
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:20:19.573: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-7834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 30 19:20:22.764: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:20:23.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7834" for this suite.
â€¢{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":275,"completed":161,"skipped":2934,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:20:23.788: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5234
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep 30 19:20:25.946: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-5234 PodName:pod-sharedvolume-1ecab291-e054-442d-9534-3f2da8644921 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:20:25.946: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:20:26.034: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:20:26.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5234" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":275,"completed":162,"skipped":2946,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:20:26.044: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 30 19:20:28.738: INFO: Successfully updated pod "labelsupdate83dfc96c-0ee0-46f0-a333-4e52e2ca5e3c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:20:30.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2367" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":275,"completed":163,"skipped":2952,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:20:30.778: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-984
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-984 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-984;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-984 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-984;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-984.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-984.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-984.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-984.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-984.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-984.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-984.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-984.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-984.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-984.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-984.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-984.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-984.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 170.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.170_udp@PTR;check="$$(dig +tcp +noall +answer +search 170.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.170_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-984 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-984;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-984 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-984;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-984.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-984.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-984.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-984.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-984.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-984.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-984.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-984.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-984.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-984.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-984.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-984.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-984.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 170.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.170_udp@PTR;check="$$(dig +tcp +noall +answer +search 170.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.170_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 30 19:20:35.018: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.021: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.023: INFO: Unable to read wheezy_udp@dns-test-service.dns-984 from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.025: INFO: Unable to read wheezy_tcp@dns-test-service.dns-984 from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.027: INFO: Unable to read wheezy_udp@dns-test-service.dns-984.svc from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.029: INFO: Unable to read wheezy_tcp@dns-test-service.dns-984.svc from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.032: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-984.svc from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.034: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-984.svc from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.055: INFO: Unable to read jessie_udp@dns-test-service from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.057: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.059: INFO: Unable to read jessie_udp@dns-test-service.dns-984 from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.061: INFO: Unable to read jessie_tcp@dns-test-service.dns-984 from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.063: INFO: Unable to read jessie_udp@dns-test-service.dns-984.svc from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.065: INFO: Unable to read jessie_tcp@dns-test-service.dns-984.svc from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.067: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-984.svc from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.069: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-984.svc from pod dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def: the server could not find the requested resource (get pods dns-test-d03bc252-c419-48a3-899d-fd2212708def)
Sep 30 19:20:35.082: INFO: Lookups using dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-984 wheezy_tcp@dns-test-service.dns-984 wheezy_udp@dns-test-service.dns-984.svc wheezy_tcp@dns-test-service.dns-984.svc wheezy_udp@_http._tcp.dns-test-service.dns-984.svc wheezy_tcp@_http._tcp.dns-test-service.dns-984.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-984 jessie_tcp@dns-test-service.dns-984 jessie_udp@dns-test-service.dns-984.svc jessie_tcp@dns-test-service.dns-984.svc jessie_udp@_http._tcp.dns-test-service.dns-984.svc jessie_tcp@_http._tcp.dns-test-service.dns-984.svc]

Sep 30 19:20:40.179: INFO: DNS probes using dns-984/dns-test-d03bc252-c419-48a3-899d-fd2212708def succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:20:40.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-984" for this suite.

â€¢ [SLOW TEST:9.526 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":275,"completed":164,"skipped":2974,"failed":0}
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:20:40.304: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5840
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 30 19:20:40.463: INFO: Waiting up to 5m0s for pod "pod-47d11624-8f05-4f21-b39d-06dccfdf2927" in namespace "emptydir-5840" to be "Succeeded or Failed"
Sep 30 19:20:40.477: INFO: Pod "pod-47d11624-8f05-4f21-b39d-06dccfdf2927": Phase="Pending", Reason="", readiness=false. Elapsed: 13.666553ms
Sep 30 19:20:42.480: INFO: Pod "pod-47d11624-8f05-4f21-b39d-06dccfdf2927": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016219853s
STEP: Saw pod success
Sep 30 19:20:42.480: INFO: Pod "pod-47d11624-8f05-4f21-b39d-06dccfdf2927" satisfied condition "Succeeded or Failed"
Sep 30 19:20:42.483: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-47d11624-8f05-4f21-b39d-06dccfdf2927 container test-container: <nil>
STEP: delete the pod
Sep 30 19:20:42.503: INFO: Waiting for pod pod-47d11624-8f05-4f21-b39d-06dccfdf2927 to disappear
Sep 30 19:20:42.510: INFO: Pod pod-47d11624-8f05-4f21-b39d-06dccfdf2927 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:20:42.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5840" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":165,"skipped":2974,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:20:42.516: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6375
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-c8b1fa82-6dc0-4de6-a4a7-c71c246c7793 in namespace container-probe-6375
Sep 30 19:20:44.684: INFO: Started pod liveness-c8b1fa82-6dc0-4de6-a4a7-c71c246c7793 in namespace container-probe-6375
STEP: checking the pod's current state and verifying that restartCount is present
Sep 30 19:20:44.686: INFO: Initial restart count of pod liveness-c8b1fa82-6dc0-4de6-a4a7-c71c246c7793 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:24:45.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6375" for this suite.

â€¢ [SLOW TEST:242.545 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":275,"completed":166,"skipped":2983,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:24:45.062: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1310
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Sep 30 19:24:45.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 create -f - --namespace=kubectl-1310'
Sep 30 19:24:46.656: INFO: stderr: ""
Sep 30 19:24:46.656: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 30 19:24:46.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1310'
Sep 30 19:24:46.730: INFO: stderr: ""
Sep 30 19:24:46.730: INFO: stdout: "update-demo-nautilus-jp884 update-demo-nautilus-z6cfc "
Sep 30 19:24:46.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-jp884 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1310'
Sep 30 19:24:46.790: INFO: stderr: ""
Sep 30 19:24:46.790: INFO: stdout: ""
Sep 30 19:24:46.790: INFO: update-demo-nautilus-jp884 is created but not running
Sep 30 19:24:51.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1310'
Sep 30 19:24:51.856: INFO: stderr: ""
Sep 30 19:24:51.856: INFO: stdout: "update-demo-nautilus-jp884 update-demo-nautilus-z6cfc "
Sep 30 19:24:51.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-jp884 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1310'
Sep 30 19:24:51.918: INFO: stderr: ""
Sep 30 19:24:51.918: INFO: stdout: "true"
Sep 30 19:24:51.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-jp884 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1310'
Sep 30 19:24:51.979: INFO: stderr: ""
Sep 30 19:24:51.979: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 30 19:24:51.979: INFO: validating pod update-demo-nautilus-jp884
Sep 30 19:24:51.982: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 30 19:24:51.982: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 30 19:24:51.982: INFO: update-demo-nautilus-jp884 is verified up and running
Sep 30 19:24:51.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-z6cfc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1310'
Sep 30 19:24:52.047: INFO: stderr: ""
Sep 30 19:24:52.047: INFO: stdout: "true"
Sep 30 19:24:52.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods update-demo-nautilus-z6cfc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1310'
Sep 30 19:24:52.107: INFO: stderr: ""
Sep 30 19:24:52.107: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 30 19:24:52.107: INFO: validating pod update-demo-nautilus-z6cfc
Sep 30 19:24:52.109: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 30 19:24:52.109: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 30 19:24:52.109: INFO: update-demo-nautilus-z6cfc is verified up and running
STEP: using delete to clean up resources
Sep 30 19:24:52.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete --grace-period=0 --force -f - --namespace=kubectl-1310'
Sep 30 19:24:52.197: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 30 19:24:52.197: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 30 19:24:52.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1310'
Sep 30 19:24:52.263: INFO: stderr: "No resources found in kubectl-1310 namespace.\n"
Sep 30 19:24:52.263: INFO: stdout: ""
Sep 30 19:24:52.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -l name=update-demo --namespace=kubectl-1310 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 30 19:24:52.327: INFO: stderr: ""
Sep 30 19:24:52.327: INFO: stdout: "update-demo-nautilus-jp884\nupdate-demo-nautilus-z6cfc\n"
Sep 30 19:24:52.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1310'
Sep 30 19:24:52.894: INFO: stderr: "No resources found in kubectl-1310 namespace.\n"
Sep 30 19:24:52.894: INFO: stdout: ""
Sep 30 19:24:52.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pods -l name=update-demo --namespace=kubectl-1310 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 30 19:24:52.970: INFO: stderr: ""
Sep 30 19:24:52.970: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:24:52.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1310" for this suite.

â€¢ [SLOW TEST:7.914 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":275,"completed":167,"skipped":2989,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:24:52.976: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7035
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 30 19:24:53.122: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 30 19:24:53.130: INFO: Waiting for terminating namespaces to be deleted...
Sep 30 19:24:53.132: INFO: 
Logging pods the kubelet thinks is on node 9b360f31-b888-42e4-807a-5f2a0fca8fae before test
Sep 30 19:24:53.145: INFO: fluent-bit-lpcs8 from pks-system started at 2020-09-29 19:35:27 +0000 UTC (2 container statuses recorded)
Sep 30 19:24:53.145: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 19:24:53.145: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:24:53.145: INFO: node-exporter-ws8wb from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.145: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 19:24:53.145: INFO: telegraf-h5t2t from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.145: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 19:24:53.145: INFO: sink-controller-7549dc74f7-4qx97 from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.145: INFO: 	Container sink-controller ready: true, restart count 0
Sep 30 19:24:53.145: INFO: coredns-854d7dc8c-6rdh4 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.145: INFO: 	Container coredns ready: true, restart count 0
Sep 30 19:24:53.145: INFO: wavefront-collector-drm6c from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.145: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 19:24:53.145: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-5zmhk from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:24:53.145: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:24:53.145: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 19:24:53.145: INFO: wavefront-proxy-68d69454fc-pm5dv from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.145: INFO: 	Container wavefront-proxy ready: true, restart count 0
Sep 30 19:24:53.145: INFO: 
Logging pods the kubelet thinks is on node c4ab02cf-8388-4ee7-9741-792b2ee511a4 before test
Sep 30 19:24:53.162: INFO: coredns-854d7dc8c-9w7v7 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.162: INFO: 	Container coredns ready: true, restart count 0
Sep 30 19:24:53.162: INFO: observability-manager-684c664cf4-nqrxv from pks-system started at 2020-09-29 19:35:04 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.162: INFO: 	Container observability-manager ready: true, restart count 0
Sep 30 19:24:53.162: INFO: node-exporter-75l6n from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.162: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 19:24:53.163: INFO: telegraf-k5gxd from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.163: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 19:24:53.163: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-gvhcn from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:24:53.163: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:24:53.163: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 19:24:53.163: INFO: event-controller-7775f56b74-zgbbq from pks-system started at 2020-09-29 19:35:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:24:53.163: INFO: 	Container event-controller ready: true, restart count 0
Sep 30 19:24:53.163: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:24:53.163: INFO: fluent-bit-fbgsw from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 19:24:53.163: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 19:24:53.163: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:24:53.163: INFO: validator-6b476b98c9-d5g8r from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.163: INFO: 	Container validator ready: true, restart count 0
Sep 30 19:24:53.163: INFO: wavefront-collector-94rjj from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.163: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 19:24:53.163: INFO: sonobuoy-e2e-job-953b1e3c972143b8 from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:24:53.163: INFO: 	Container e2e ready: true, restart count 0
Sep 30 19:24:53.163: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:24:53.163: INFO: 
Logging pods the kubelet thinks is on node eb106fc7-933d-47a1-a18a-16aa6514d845 before test
Sep 30 19:24:53.177: INFO: metric-controller-7fd9d59567-hqvsc from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.177: INFO: 	Container metric-controller ready: true, restart count 0
Sep 30 19:24:53.177: INFO: sonobuoy from sonobuoy started at 2020-09-30 18:29:07 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.177: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 30 19:24:53.177: INFO: update-demo-nautilus-z6cfc from kubectl-1310 started at 2020-09-30 19:24:46 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.177: INFO: 	Container update-demo ready: true, restart count 0
Sep 30 19:24:53.177: INFO: node-exporter-jgdvm from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.177: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 19:24:53.177: INFO: cert-generator-e484f2435fc830429fc9747bd002fcda56dd053e-cc5fz from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.178: INFO: 	Container cert-generator ready: false, restart count 0
Sep 30 19:24:53.178: INFO: telemetry-agent-6bcf5c56b-qmz52 from pks-system started at 2020-09-29 19:37:51 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.178: INFO: 	Container fluent-bit-telemetry ready: true, restart count 0
Sep 30 19:24:53.178: INFO: update-demo-nautilus-jp884 from kubectl-1310 started at 2020-09-30 19:24:46 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.178: INFO: 	Container update-demo ready: true, restart count 0
Sep 30 19:24:53.178: INFO: metrics-server-6967cb5487-z8t86 from kube-system started at 2020-09-29 19:35:01 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.178: INFO: 	Container metrics-server ready: true, restart count 0
Sep 30 19:24:53.178: INFO: telegraf-z8x2g from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.178: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 19:24:53.178: INFO: wavefront-collector-hms5p from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.178: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 19:24:53.178: INFO: coredns-854d7dc8c-lg4vh from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 19:24:53.178: INFO: 	Container coredns ready: true, restart count 0
Sep 30 19:24:53.178: INFO: fluent-bit-5x9vt from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 19:24:53.178: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 19:24:53.178: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:24:53.178: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-wgtws from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:24:53.178: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:24:53.178: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node 9b360f31-b888-42e4-807a-5f2a0fca8fae
STEP: verifying the node has the label node c4ab02cf-8388-4ee7-9741-792b2ee511a4
STEP: verifying the node has the label node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.248: INFO: Pod coredns-854d7dc8c-6rdh4 requesting resource cpu=100m on Node 9b360f31-b888-42e4-807a-5f2a0fca8fae
Sep 30 19:24:53.248: INFO: Pod coredns-854d7dc8c-9w7v7 requesting resource cpu=100m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.248: INFO: Pod coredns-854d7dc8c-lg4vh requesting resource cpu=100m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.249: INFO: Pod metrics-server-6967cb5487-z8t86 requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.249: INFO: Pod update-demo-nautilus-jp884 requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.249: INFO: Pod update-demo-nautilus-z6cfc requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.249: INFO: Pod event-controller-7775f56b74-zgbbq requesting resource cpu=0m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.249: INFO: Pod fluent-bit-5x9vt requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.249: INFO: Pod fluent-bit-fbgsw requesting resource cpu=0m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.249: INFO: Pod fluent-bit-lpcs8 requesting resource cpu=0m on Node 9b360f31-b888-42e4-807a-5f2a0fca8fae
Sep 30 19:24:53.249: INFO: Pod metric-controller-7fd9d59567-hqvsc requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.249: INFO: Pod node-exporter-75l6n requesting resource cpu=10m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.249: INFO: Pod node-exporter-jgdvm requesting resource cpu=10m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.249: INFO: Pod node-exporter-ws8wb requesting resource cpu=10m on Node 9b360f31-b888-42e4-807a-5f2a0fca8fae
Sep 30 19:24:53.249: INFO: Pod observability-manager-684c664cf4-nqrxv requesting resource cpu=0m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.249: INFO: Pod sink-controller-7549dc74f7-4qx97 requesting resource cpu=0m on Node 9b360f31-b888-42e4-807a-5f2a0fca8fae
Sep 30 19:24:53.249: INFO: Pod telegraf-h5t2t requesting resource cpu=0m on Node 9b360f31-b888-42e4-807a-5f2a0fca8fae
Sep 30 19:24:53.249: INFO: Pod telegraf-k5gxd requesting resource cpu=0m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.249: INFO: Pod telegraf-z8x2g requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.250: INFO: Pod telemetry-agent-6bcf5c56b-qmz52 requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.250: INFO: Pod validator-6b476b98c9-d5g8r requesting resource cpu=0m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.250: INFO: Pod wavefront-collector-94rjj requesting resource cpu=0m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.250: INFO: Pod wavefront-collector-drm6c requesting resource cpu=0m on Node 9b360f31-b888-42e4-807a-5f2a0fca8fae
Sep 30 19:24:53.250: INFO: Pod wavefront-collector-hms5p requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.250: INFO: Pod wavefront-proxy-68d69454fc-pm5dv requesting resource cpu=0m on Node 9b360f31-b888-42e4-807a-5f2a0fca8fae
Sep 30 19:24:53.250: INFO: Pod sonobuoy requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
Sep 30 19:24:53.250: INFO: Pod sonobuoy-e2e-job-953b1e3c972143b8 requesting resource cpu=0m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.250: INFO: Pod sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-5zmhk requesting resource cpu=0m on Node 9b360f31-b888-42e4-807a-5f2a0fca8fae
Sep 30 19:24:53.250: INFO: Pod sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-gvhcn requesting resource cpu=0m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.250: INFO: Pod sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-wgtws requesting resource cpu=0m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
STEP: Starting Pods to consume most of the cluster CPU.
Sep 30 19:24:53.250: INFO: Creating a pod which consumes cpu=973m on Node 9b360f31-b888-42e4-807a-5f2a0fca8fae
Sep 30 19:24:53.259: INFO: Creating a pod which consumes cpu=973m on Node c4ab02cf-8388-4ee7-9741-792b2ee511a4
Sep 30 19:24:53.273: INFO: Creating a pod which consumes cpu=973m on Node eb106fc7-933d-47a1-a18a-16aa6514d845
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d419a55-e50f-4e5a-99ce-cfa71393374b.1639a635fb73d8d5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7035/filler-pod-3d419a55-e50f-4e5a-99ce-cfa71393374b to c4ab02cf-8388-4ee7-9741-792b2ee511a4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d419a55-e50f-4e5a-99ce-cfa71393374b.1639a63633d21931], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d419a55-e50f-4e5a-99ce-cfa71393374b.1639a6363a4132e9], Reason = [Created], Message = [Created container filler-pod-3d419a55-e50f-4e5a-99ce-cfa71393374b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d419a55-e50f-4e5a-99ce-cfa71393374b.1639a636444be269], Reason = [Started], Message = [Started container filler-pod-3d419a55-e50f-4e5a-99ce-cfa71393374b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb4aac9c-5f62-4df6-9070-37f97636349c.1639a635f9e68ec9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7035/filler-pod-bb4aac9c-5f62-4df6-9070-37f97636349c to 9b360f31-b888-42e4-807a-5f2a0fca8fae]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb4aac9c-5f62-4df6-9070-37f97636349c.1639a6362eb6cf6e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb4aac9c-5f62-4df6-9070-37f97636349c.1639a63633098b44], Reason = [Created], Message = [Created container filler-pod-bb4aac9c-5f62-4df6-9070-37f97636349c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb4aac9c-5f62-4df6-9070-37f97636349c.1639a6363beeee33], Reason = [Started], Message = [Started container filler-pod-bb4aac9c-5f62-4df6-9070-37f97636349c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-efc036d2-39d5-4137-968f-dcea0c8d5335.1639a635fc6137c5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7035/filler-pod-efc036d2-39d5-4137-968f-dcea0c8d5335 to eb106fc7-933d-47a1-a18a-16aa6514d845]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-efc036d2-39d5-4137-968f-dcea0c8d5335.1639a6362d68939c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-efc036d2-39d5-4137-968f-dcea0c8d5335.1639a636317378ea], Reason = [Created], Message = [Created container filler-pod-efc036d2-39d5-4137-968f-dcea0c8d5335]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-efc036d2-39d5-4137-968f-dcea0c8d5335.1639a6363aa1b140], Reason = [Started], Message = [Started container filler-pod-efc036d2-39d5-4137-968f-dcea0c8d5335]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1639a63674db8448], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1639a636763b4552], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 9b360f31-b888-42e4-807a-5f2a0fca8fae
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node c4ab02cf-8388-4ee7-9741-792b2ee511a4
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node eb106fc7-933d-47a1-a18a-16aa6514d845
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:24:56.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7035" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
â€¢{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":275,"completed":168,"skipped":3003,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:24:56.372: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2237
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 30 19:24:56.523: INFO: Waiting up to 5m0s for pod "pod-782438fa-49b7-44ba-a06a-d25cb14404bd" in namespace "emptydir-2237" to be "Succeeded or Failed"
Sep 30 19:24:56.524: INFO: Pod "pod-782438fa-49b7-44ba-a06a-d25cb14404bd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.4283ms
Sep 30 19:24:58.527: INFO: Pod "pod-782438fa-49b7-44ba-a06a-d25cb14404bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004036128s
STEP: Saw pod success
Sep 30 19:24:58.527: INFO: Pod "pod-782438fa-49b7-44ba-a06a-d25cb14404bd" satisfied condition "Succeeded or Failed"
Sep 30 19:24:58.529: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod pod-782438fa-49b7-44ba-a06a-d25cb14404bd container test-container: <nil>
STEP: delete the pod
Sep 30 19:24:58.558: INFO: Waiting for pod pod-782438fa-49b7-44ba-a06a-d25cb14404bd to disappear
Sep 30 19:24:58.559: INFO: Pod pod-782438fa-49b7-44ba-a06a-d25cb14404bd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:24:58.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2237" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":169,"skipped":3051,"failed":0}
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:24:58.565: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 30 19:24:58.717: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:00.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9740" for this suite.
â€¢{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":275,"completed":170,"skipped":3058,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:00.872: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8952
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:12.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8952" for this suite.

â€¢ [SLOW TEST:11.195 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":275,"completed":171,"skipped":3063,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:12.068: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-7c88f32c-27d8-41a0-8ee2-aba333873758
STEP: Creating a pod to test consume secrets
Sep 30 19:25:12.223: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2797c3eb-3e47-4d28-a062-07df59ec1e60" in namespace "projected-797" to be "Succeeded or Failed"
Sep 30 19:25:12.247: INFO: Pod "pod-projected-secrets-2797c3eb-3e47-4d28-a062-07df59ec1e60": Phase="Pending", Reason="", readiness=false. Elapsed: 23.202015ms
Sep 30 19:25:14.249: INFO: Pod "pod-projected-secrets-2797c3eb-3e47-4d28-a062-07df59ec1e60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02565707s
STEP: Saw pod success
Sep 30 19:25:14.249: INFO: Pod "pod-projected-secrets-2797c3eb-3e47-4d28-a062-07df59ec1e60" satisfied condition "Succeeded or Failed"
Sep 30 19:25:14.251: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-projected-secrets-2797c3eb-3e47-4d28-a062-07df59ec1e60 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 30 19:25:14.268: INFO: Waiting for pod pod-projected-secrets-2797c3eb-3e47-4d28-a062-07df59ec1e60 to disappear
Sep 30 19:25:14.275: INFO: Pod pod-projected-secrets-2797c3eb-3e47-4d28-a062-07df59ec1e60 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:14.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-797" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":172,"skipped":3083,"failed":0}
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:14.281: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 30 19:25:14.439: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 30 19:25:14.446: INFO: Waiting for terminating namespaces to be deleted...
Sep 30 19:25:14.448: INFO: 
Logging pods the kubelet thinks is on node 9b360f31-b888-42e4-807a-5f2a0fca8fae before test
Sep 30 19:25:14.453: INFO: wavefront-proxy-68d69454fc-pm5dv from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.453: INFO: 	Container wavefront-proxy ready: true, restart count 0
Sep 30 19:25:14.453: INFO: fluent-bit-lpcs8 from pks-system started at 2020-09-29 19:35:27 +0000 UTC (2 container statuses recorded)
Sep 30 19:25:14.453: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 19:25:14.453: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:25:14.453: INFO: node-exporter-ws8wb from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.453: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 19:25:14.453: INFO: telegraf-h5t2t from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.453: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 19:25:14.453: INFO: sink-controller-7549dc74f7-4qx97 from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.453: INFO: 	Container sink-controller ready: true, restart count 0
Sep 30 19:25:14.453: INFO: coredns-854d7dc8c-6rdh4 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.453: INFO: 	Container coredns ready: true, restart count 0
Sep 30 19:25:14.453: INFO: wavefront-collector-drm6c from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.453: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 19:25:14.453: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-5zmhk from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:25:14.453: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:25:14.453: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 19:25:14.453: INFO: 
Logging pods the kubelet thinks is on node c4ab02cf-8388-4ee7-9741-792b2ee511a4 before test
Sep 30 19:25:14.460: INFO: coredns-854d7dc8c-9w7v7 from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container coredns ready: true, restart count 0
Sep 30 19:25:14.460: INFO: observability-manager-684c664cf4-nqrxv from pks-system started at 2020-09-29 19:35:04 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container observability-manager ready: true, restart count 0
Sep 30 19:25:14.460: INFO: node-exporter-75l6n from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 19:25:14.460: INFO: telegraf-k5gxd from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 19:25:14.460: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-gvhcn from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:25:14.460: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 19:25:14.460: INFO: event-controller-7775f56b74-zgbbq from pks-system started at 2020-09-29 19:35:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container event-controller ready: true, restart count 0
Sep 30 19:25:14.460: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:25:14.460: INFO: fluent-bit-fbgsw from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 19:25:14.460: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:25:14.460: INFO: validator-6b476b98c9-d5g8r from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container validator ready: true, restart count 0
Sep 30 19:25:14.460: INFO: wavefront-collector-94rjj from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 19:25:14.460: INFO: sonobuoy-e2e-job-953b1e3c972143b8 from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:25:14.460: INFO: 	Container e2e ready: true, restart count 0
Sep 30 19:25:14.460: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:25:14.460: INFO: 
Logging pods the kubelet thinks is on node eb106fc7-933d-47a1-a18a-16aa6514d845 before test
Sep 30 19:25:14.465: INFO: node-exporter-jgdvm from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Sep 30 19:25:14.465: INFO: cert-generator-e484f2435fc830429fc9747bd002fcda56dd053e-cc5fz from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container cert-generator ready: false, restart count 0
Sep 30 19:25:14.465: INFO: telemetry-agent-6bcf5c56b-qmz52 from pks-system started at 2020-09-29 19:37:51 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container fluent-bit-telemetry ready: true, restart count 0
Sep 30 19:25:14.465: INFO: metrics-server-6967cb5487-z8t86 from kube-system started at 2020-09-29 19:35:01 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container metrics-server ready: true, restart count 0
Sep 30 19:25:14.465: INFO: telegraf-z8x2g from pks-system started at 2020-09-29 19:35:09 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container telegraf ready: true, restart count 0
Sep 30 19:25:14.465: INFO: wavefront-collector-hms5p from pks-system started at 2020-09-29 19:37:14 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container wavefront-collector ready: true, restart count 0
Sep 30 19:25:14.465: INFO: coredns-854d7dc8c-lg4vh from kube-system started at 2020-09-29 19:34:58 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container coredns ready: true, restart count 0
Sep 30 19:25:14.465: INFO: fluent-bit-5x9vt from pks-system started at 2020-09-29 19:35:13 +0000 UTC (2 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container fluent-bit ready: true, restart count 0
Sep 30 19:25:14.465: INFO: 	Container ghostunnel ready: true, restart count 0
Sep 30 19:25:14.465: INFO: sonobuoy-systemd-logs-daemon-set-ae3484a108d04678-wgtws from sonobuoy started at 2020-09-30 18:29:08 +0000 UTC (2 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 30 19:25:14.465: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 30 19:25:14.465: INFO: metric-controller-7fd9d59567-hqvsc from pks-system started at 2020-09-29 19:35:08 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.465: INFO: 	Container metric-controller ready: true, restart count 0
Sep 30 19:25:14.466: INFO: sonobuoy from sonobuoy started at 2020-09-30 18:29:07 +0000 UTC (1 container statuses recorded)
Sep 30 19:25:14.466: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-1782d32c-5bdd-4c38-8979-626b516619d6 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-1782d32c-5bdd-4c38-8979-626b516619d6 off the node eb106fc7-933d-47a1-a18a-16aa6514d845
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1782d32c-5bdd-4c38-8979-626b516619d6
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:18.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-920" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
â€¢{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":275,"completed":173,"skipped":3088,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:18.558: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5220
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:25:18.718: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40821e36-112d-415e-8e12-5cc90604d85a" in namespace "projected-5220" to be "Succeeded or Failed"
Sep 30 19:25:18.724: INFO: Pod "downwardapi-volume-40821e36-112d-415e-8e12-5cc90604d85a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.864477ms
Sep 30 19:25:20.726: INFO: Pod "downwardapi-volume-40821e36-112d-415e-8e12-5cc90604d85a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008319164s
STEP: Saw pod success
Sep 30 19:25:20.726: INFO: Pod "downwardapi-volume-40821e36-112d-415e-8e12-5cc90604d85a" satisfied condition "Succeeded or Failed"
Sep 30 19:25:20.728: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-40821e36-112d-415e-8e12-5cc90604d85a container client-container: <nil>
STEP: delete the pod
Sep 30 19:25:20.748: INFO: Waiting for pod downwardapi-volume-40821e36-112d-415e-8e12-5cc90604d85a to disappear
Sep 30 19:25:20.761: INFO: Pod downwardapi-volume-40821e36-112d-415e-8e12-5cc90604d85a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:20.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5220" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":174,"skipped":3098,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:20.767: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5938
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:25:20.918: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2574b42d-0257-4b2a-81ee-0837cb7e41fc" in namespace "projected-5938" to be "Succeeded or Failed"
Sep 30 19:25:20.928: INFO: Pod "downwardapi-volume-2574b42d-0257-4b2a-81ee-0837cb7e41fc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.939401ms
Sep 30 19:25:22.931: INFO: Pod "downwardapi-volume-2574b42d-0257-4b2a-81ee-0837cb7e41fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01244657s
STEP: Saw pod success
Sep 30 19:25:22.931: INFO: Pod "downwardapi-volume-2574b42d-0257-4b2a-81ee-0837cb7e41fc" satisfied condition "Succeeded or Failed"
Sep 30 19:25:22.933: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-2574b42d-0257-4b2a-81ee-0837cb7e41fc container client-container: <nil>
STEP: delete the pod
Sep 30 19:25:22.953: INFO: Waiting for pod downwardapi-volume-2574b42d-0257-4b2a-81ee-0837cb7e41fc to disappear
Sep 30 19:25:22.963: INFO: Pod downwardapi-volume-2574b42d-0257-4b2a-81ee-0837cb7e41fc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:22.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5938" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":275,"completed":175,"skipped":3135,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:22.969: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-495
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:31.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-495" for this suite.

â€¢ [SLOW TEST:8.164 seconds]
[sig-apps] Job
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":275,"completed":176,"skipped":3146,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:31.134: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2303
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 30 19:25:31.281: INFO: Waiting up to 5m0s for pod "downward-api-7ba1b4c6-8ef0-483b-91dd-d465f3893e74" in namespace "downward-api-2303" to be "Succeeded or Failed"
Sep 30 19:25:31.284: INFO: Pod "downward-api-7ba1b4c6-8ef0-483b-91dd-d465f3893e74": Phase="Pending", Reason="", readiness=false. Elapsed: 3.497283ms
Sep 30 19:25:33.287: INFO: Pod "downward-api-7ba1b4c6-8ef0-483b-91dd-d465f3893e74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005914493s
Sep 30 19:25:35.290: INFO: Pod "downward-api-7ba1b4c6-8ef0-483b-91dd-d465f3893e74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009554134s
STEP: Saw pod success
Sep 30 19:25:35.290: INFO: Pod "downward-api-7ba1b4c6-8ef0-483b-91dd-d465f3893e74" satisfied condition "Succeeded or Failed"
Sep 30 19:25:35.292: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downward-api-7ba1b4c6-8ef0-483b-91dd-d465f3893e74 container dapi-container: <nil>
STEP: delete the pod
Sep 30 19:25:35.337: INFO: Waiting for pod downward-api-7ba1b4c6-8ef0-483b-91dd-d465f3893e74 to disappear
Sep 30 19:25:35.338: INFO: Pod downward-api-7ba1b4c6-8ef0-483b-91dd-d465f3893e74 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:35.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2303" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":275,"completed":177,"skipped":3181,"failed":0}
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:35.344: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5980
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Sep 30 19:25:35.493: INFO: Waiting up to 5m0s for pod "client-containers-c9709836-4e78-4a37-824f-8e58680c3c16" in namespace "containers-5980" to be "Succeeded or Failed"
Sep 30 19:25:35.495: INFO: Pod "client-containers-c9709836-4e78-4a37-824f-8e58680c3c16": Phase="Pending", Reason="", readiness=false. Elapsed: 1.955303ms
Sep 30 19:25:37.497: INFO: Pod "client-containers-c9709836-4e78-4a37-824f-8e58680c3c16": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004353426s
Sep 30 19:25:39.500: INFO: Pod "client-containers-c9709836-4e78-4a37-824f-8e58680c3c16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007107463s
STEP: Saw pod success
Sep 30 19:25:39.500: INFO: Pod "client-containers-c9709836-4e78-4a37-824f-8e58680c3c16" satisfied condition "Succeeded or Failed"
Sep 30 19:25:39.502: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod client-containers-c9709836-4e78-4a37-824f-8e58680c3c16 container test-container: <nil>
STEP: delete the pod
Sep 30 19:25:39.520: INFO: Waiting for pod client-containers-c9709836-4e78-4a37-824f-8e58680c3c16 to disappear
Sep 30 19:25:39.526: INFO: Pod client-containers-c9709836-4e78-4a37-824f-8e58680c3c16 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:39.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5980" for this suite.
â€¢{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":275,"completed":178,"skipped":3186,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:39.534: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1781
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:25:39.692: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:40.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1781" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":275,"completed":179,"skipped":3209,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:40.292: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4392
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:25:40.444: INFO: Creating deployment "test-recreate-deployment"
Sep 30 19:25:40.450: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 30 19:25:40.480: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 30 19:25:42.484: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 30 19:25:42.486: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 30 19:25:42.491: INFO: Updating deployment test-recreate-deployment
Sep 30 19:25:42.491: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 30 19:25:42.689: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4392 /apis/apps/v1/namespaces/deployment-4392/deployments/test-recreate-deployment ab7321ea-8eed-47e6-86e0-a5319819fea5 222961 2 2020-09-30 19:25:40 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-09-30 19:25:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-30 19:25:42 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0032537c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-09-30 19:25:42 +0000 UTC,LastTransitionTime:2020-09-30 19:25:42 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-09-30 19:25:42 +0000 UTC,LastTransitionTime:2020-09-30 19:25:40 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Sep 30 19:25:42.692: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-4392 /apis/apps/v1/namespaces/deployment-4392/replicasets/test-recreate-deployment-d5667d9c7 b121a871-07c3-43a0-9dd1-e0e867fe735d 222959 1 2020-09-30 19:25:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment ab7321ea-8eed-47e6-86e0-a5319819fea5 0xc003253d00 0xc003253d01}] []  [{kube-controller-manager Update apps/v1 2020-09-30 19:25:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 55 51 50 49 101 97 45 56 101 101 100 45 52 55 101 54 45 56 54 101 48 45 97 53 51 49 57 56 49 57 102 101 97 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003253d78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:25:42.692: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 30 19:25:42.693: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-4392 /apis/apps/v1/namespaces/deployment-4392/replicasets/test-recreate-deployment-74d98b5f7c db719ec9-7ab9-4208-abb1-5ae8ef590797 222949 2 2020-09-30 19:25:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment ab7321ea-8eed-47e6-86e0-a5319819fea5 0xc003253c07 0xc003253c08}] []  [{kube-controller-manager Update apps/v1 2020-09-30 19:25:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 98 55 51 50 49 101 97 45 56 101 101 100 45 52 55 101 54 45 56 54 101 48 45 97 53 51 49 57 56 49 57 102 101 97 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003253c98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:25:42.695: INFO: Pod "test-recreate-deployment-d5667d9c7-n4fb7" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-n4fb7 test-recreate-deployment-d5667d9c7- deployment-4392 /api/v1/namespaces/deployment-4392/pods/test-recreate-deployment-d5667d9c7-n4fb7 68c84af3-5857-4de7-8457-cc952c1d2029 222960 0 2020-09-30 19:25:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 b121a871-07c3-43a0-9dd1-e0e867fe735d 0xc003446cc0 0xc003446cc1}] []  [{kube-controller-manager Update v1 2020-09-30 19:25:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 49 50 49 97 56 55 49 45 48 55 99 51 45 52 51 97 48 45 57 100 100 49 45 101 48 101 56 54 55 102 101 55 51 53 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:25:42 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-b6fdk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-b6fdk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-b6fdk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:25:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:25:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:25:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:25:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:,StartTime:2020-09-30 19:25:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:25:42.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4392" for this suite.
â€¢{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":275,"completed":180,"skipped":3229,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:25:42.702: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-2259
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 30 19:25:42.844: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 30 19:25:42.892: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 19:25:44.898: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 19:25:46.894: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:25:48.894: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:25:50.895: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:25:52.895: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:25:54.894: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 30 19:25:54.898: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 30 19:25:56.900: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 30 19:25:58.900: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 30 19:26:00.901: INFO: The status of Pod netserver-1 is Running (Ready = true)
Sep 30 19:26:00.904: INFO: The status of Pod netserver-2 is Running (Ready = false)
Sep 30 19:26:02.907: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Sep 30 19:26:06.945: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.32.96:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2259 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:06.945: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:07.037: INFO: Found all expected endpoints: [netserver-0]
Sep 30 19:26:07.039: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.52.32:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2259 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:07.039: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:07.158: INFO: Found all expected endpoints: [netserver-1]
Sep 30 19:26:07.161: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.200.99.181:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2259 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:07.161: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:07.280: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:07.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2259" for this suite.

â€¢ [SLOW TEST:24.586 seconds]
[sig-network] Networking
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":181,"skipped":3261,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:07.290: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5845
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5845
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-5845
I0930 19:26:07.495707      21 runners.go:190] Created replication controller with name: externalname-service, namespace: services-5845, replica count: 2
I0930 19:26:10.546158      21 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 30 19:26:10.546: INFO: Creating new exec pod
Sep 30 19:26:13.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5845 execpodnnrbn -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 30 19:26:13.726: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 30 19:26:13.726: INFO: stdout: ""
Sep 30 19:26:13.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5845 execpodnnrbn -- /bin/sh -x -c nc -zv -t -w 2 10.100.200.100 80'
Sep 30 19:26:13.870: INFO: stderr: "+ nc -zv -t -w 2 10.100.200.100 80\nConnection to 10.100.200.100 80 port [tcp/http] succeeded!\n"
Sep 30 19:26:13.870: INFO: stdout: ""
Sep 30 19:26:13.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5845 execpodnnrbn -- /bin/sh -x -c nc -zv -t -w 2 30.0.0.12 30174'
Sep 30 19:26:14.029: INFO: stderr: "+ nc -zv -t -w 2 30.0.0.12 30174\nConnection to 30.0.0.12 30174 port [tcp/30174] succeeded!\n"
Sep 30 19:26:14.029: INFO: stdout: ""
Sep 30 19:26:14.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5845 execpodnnrbn -- /bin/sh -x -c nc -zv -t -w 2 30.0.0.11 30174'
Sep 30 19:26:14.176: INFO: stderr: "+ nc -zv -t -w 2 30.0.0.11 30174\nConnection to 30.0.0.11 30174 port [tcp/30174] succeeded!\n"
Sep 30 19:26:14.176: INFO: stdout: ""
Sep 30 19:26:14.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5845 execpodnnrbn -- /bin/sh -x -c nc -zv -t -w 2 30.0.0.12 30174'
Sep 30 19:26:14.331: INFO: stderr: "+ nc -zv -t -w 2 30.0.0.12 30174\nConnection to 30.0.0.12 30174 port [tcp/30174] succeeded!\n"
Sep 30 19:26:14.331: INFO: stdout: ""
Sep 30 19:26:14.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-5845 execpodnnrbn -- /bin/sh -x -c nc -zv -t -w 2 30.0.0.11 30174'
Sep 30 19:26:14.489: INFO: stderr: "+ nc -zv -t -w 2 30.0.0.11 30174\nConnection to 30.0.0.11 30174 port [tcp/30174] succeeded!\n"
Sep 30 19:26:14.489: INFO: stdout: ""
Sep 30 19:26:14.489: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:14.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5845" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:7.231 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":275,"completed":182,"skipped":3265,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:14.521: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:26:14.690: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e130106b-1579-442a-868a-5b8bc63210ec" in namespace "projected-3113" to be "Succeeded or Failed"
Sep 30 19:26:14.698: INFO: Pod "downwardapi-volume-e130106b-1579-442a-868a-5b8bc63210ec": Phase="Pending", Reason="", readiness=false. Elapsed: 7.795004ms
Sep 30 19:26:16.700: INFO: Pod "downwardapi-volume-e130106b-1579-442a-868a-5b8bc63210ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010251278s
STEP: Saw pod success
Sep 30 19:26:16.700: INFO: Pod "downwardapi-volume-e130106b-1579-442a-868a-5b8bc63210ec" satisfied condition "Succeeded or Failed"
Sep 30 19:26:16.703: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-e130106b-1579-442a-868a-5b8bc63210ec container client-container: <nil>
STEP: delete the pod
Sep 30 19:26:16.720: INFO: Waiting for pod downwardapi-volume-e130106b-1579-442a-868a-5b8bc63210ec to disappear
Sep 30 19:26:16.727: INFO: Pod downwardapi-volume-e130106b-1579-442a-868a-5b8bc63210ec no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:16.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3113" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":183,"skipped":3269,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:16.738: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8847
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-768a8d52-f2ff-4c14-8897-f7b6df9b38c8
STEP: Creating configMap with name cm-test-opt-upd-0d5d0e76-0155-4906-8ad4-c9282d911f5b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-768a8d52-f2ff-4c14-8897-f7b6df9b38c8
STEP: Updating configmap cm-test-opt-upd-0d5d0e76-0155-4906-8ad4-c9282d911f5b
STEP: Creating configMap with name cm-test-opt-create-cb2177af-95bc-4376-a9d5-6d8f24824afe
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:20.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8847" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":275,"completed":184,"skipped":3285,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:21.003: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 30 19:26:21.153: INFO: Waiting up to 5m0s for pod "downward-api-58f69e6d-259a-41d3-ba9e-987bcaf6ae38" in namespace "downward-api-3691" to be "Succeeded or Failed"
Sep 30 19:26:21.154: INFO: Pod "downward-api-58f69e6d-259a-41d3-ba9e-987bcaf6ae38": Phase="Pending", Reason="", readiness=false. Elapsed: 1.390184ms
Sep 30 19:26:23.157: INFO: Pod "downward-api-58f69e6d-259a-41d3-ba9e-987bcaf6ae38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004236703s
STEP: Saw pod success
Sep 30 19:26:23.157: INFO: Pod "downward-api-58f69e6d-259a-41d3-ba9e-987bcaf6ae38" satisfied condition "Succeeded or Failed"
Sep 30 19:26:23.159: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downward-api-58f69e6d-259a-41d3-ba9e-987bcaf6ae38 container dapi-container: <nil>
STEP: delete the pod
Sep 30 19:26:23.177: INFO: Waiting for pod downward-api-58f69e6d-259a-41d3-ba9e-987bcaf6ae38 to disappear
Sep 30 19:26:23.184: INFO: Pod downward-api-58f69e6d-259a-41d3-ba9e-987bcaf6ae38 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:23.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3691" for this suite.
â€¢{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":275,"completed":185,"skipped":3410,"failed":0}

------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:23.189: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 30 19:26:23.386: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6878 /api/v1/namespaces/watch-6878/configmaps/e2e-watch-test-watch-closed 9fccd650-139b-460d-97fa-de9b1509b36e 223341 0 2020-09-30 19:26:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-30 19:26:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:26:23.387: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6878 /api/v1/namespaces/watch-6878/configmaps/e2e-watch-test-watch-closed 9fccd650-139b-460d-97fa-de9b1509b36e 223342 0 2020-09-30 19:26:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-30 19:26:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 30 19:26:23.405: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6878 /api/v1/namespaces/watch-6878/configmaps/e2e-watch-test-watch-closed 9fccd650-139b-460d-97fa-de9b1509b36e 223343 0 2020-09-30 19:26:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-30 19:26:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 30 19:26:23.405: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6878 /api/v1/namespaces/watch-6878/configmaps/e2e-watch-test-watch-closed 9fccd650-139b-460d-97fa-de9b1509b36e 223344 0 2020-09-30 19:26:23 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-30 19:26:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:23.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6878" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":275,"completed":186,"skipped":3410,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:23.423: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1882
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 30 19:26:23.576: INFO: Waiting up to 5m0s for pod "pod-377b7037-468d-4b2d-85ec-cd8b81a85e2f" in namespace "emptydir-1882" to be "Succeeded or Failed"
Sep 30 19:26:23.583: INFO: Pod "pod-377b7037-468d-4b2d-85ec-cd8b81a85e2f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.115498ms
Sep 30 19:26:25.585: INFO: Pod "pod-377b7037-468d-4b2d-85ec-cd8b81a85e2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00976717s
STEP: Saw pod success
Sep 30 19:26:25.585: INFO: Pod "pod-377b7037-468d-4b2d-85ec-cd8b81a85e2f" satisfied condition "Succeeded or Failed"
Sep 30 19:26:25.587: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-377b7037-468d-4b2d-85ec-cd8b81a85e2f container test-container: <nil>
STEP: delete the pod
Sep 30 19:26:25.604: INFO: Waiting for pod pod-377b7037-468d-4b2d-85ec-cd8b81a85e2f to disappear
Sep 30 19:26:25.611: INFO: Pod pod-377b7037-468d-4b2d-85ec-cd8b81a85e2f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:25.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1882" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":187,"skipped":3422,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:25.623: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-7241
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 30 19:26:29.806: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:29.806: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:29.902: INFO: Exec stderr: ""
Sep 30 19:26:29.902: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:29.902: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:30.009: INFO: Exec stderr: ""
Sep 30 19:26:30.010: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:30.010: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:30.114: INFO: Exec stderr: ""
Sep 30 19:26:30.114: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:30.114: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:30.219: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 30 19:26:30.220: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:30.220: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:30.308: INFO: Exec stderr: ""
Sep 30 19:26:30.308: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:30.308: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:30.399: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 30 19:26:30.399: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:30.399: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:30.490: INFO: Exec stderr: ""
Sep 30 19:26:30.491: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:30.491: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:30.584: INFO: Exec stderr: ""
Sep 30 19:26:30.585: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:30.585: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:30.719: INFO: Exec stderr: ""
Sep 30 19:26:30.720: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7241 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:26:30.720: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:26:30.819: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:30.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-7241" for this suite.

â€¢ [SLOW TEST:5.202 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":188,"skipped":3434,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:30.825: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6315
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:26:31.426: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 19:26:33.432: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090791, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090791, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090791, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090791, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:26:36.450: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Sep 30 19:26:36.464: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:36.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6315" for this suite.
STEP: Destroying namespace "webhook-6315-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:5.721 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":275,"completed":189,"skipped":3444,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:36.547: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1141
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:26:36.707: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 30 19:26:36.719: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 30 19:26:41.726: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 30 19:26:41.727: INFO: Creating deployment "test-rolling-update-deployment"
Sep 30 19:26:41.730: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 30 19:26:41.759: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 30 19:26:43.777: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 30 19:26:43.779: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 30 19:26:43.784: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-1141 /apis/apps/v1/namespaces/deployment-1141/deployments/test-rolling-update-deployment d33ca85e-6472-4923-bc1f-c66eb660d430 223626 1 2020-09-30 19:26:41 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-09-30 19:26:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-30 19:26:43 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002e8a378 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-09-30 19:26:41 +0000 UTC,LastTransitionTime:2020-09-30 19:26:41 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-09-30 19:26:43 +0000 UTC,LastTransitionTime:2020-09-30 19:26:41 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 30 19:26:43.786: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-1141 /apis/apps/v1/namespaces/deployment-1141/replicasets/test-rolling-update-deployment-59d5cb45c7 fe4d5ea9-904f-4526-9814-85f0970219e7 223615 1 2020-09-30 19:26:41 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment d33ca85e-6472-4923-bc1f-c66eb660d430 0xc002e8a907 0xc002e8a908}] []  [{kube-controller-manager Update apps/v1 2020-09-30 19:26:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 51 51 99 97 56 53 101 45 54 52 55 50 45 52 57 50 51 45 98 99 49 102 45 99 54 54 101 98 54 54 48 100 52 51 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002e8a998 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:26:43.786: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 30 19:26:43.786: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-1141 /apis/apps/v1/namespaces/deployment-1141/replicasets/test-rolling-update-controller 9f37585f-1174-4dc0-ab40-6a74a6e06bb4 223625 2 2020-09-30 19:26:36 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment d33ca85e-6472-4923-bc1f-c66eb660d430 0xc002e8a7e7 0xc002e8a7e8}] []  [{e2e.test Update apps/v1 2020-09-30 19:26:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-30 19:26:43 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 51 51 99 97 56 53 101 45 54 52 55 50 45 52 57 50 51 45 98 99 49 102 45 99 54 54 101 98 54 54 48 100 52 51 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002e8a898 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:26:43.788: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-dtw6w" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-dtw6w test-rolling-update-deployment-59d5cb45c7- deployment-1141 /api/v1/namespaces/deployment-1141/pods/test-rolling-update-deployment-59d5cb45c7-dtw6w 66dc429a-945c-46f9-912d-0070e0d4b793 223614 0 2020-09-30 19:26:41 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 fe4d5ea9-904f-4526-9814-85f0970219e7 0xc002e8ae87 0xc002e8ae88}] []  [{kube-controller-manager Update v1 2020-09-30 19:26:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 101 52 100 53 101 97 57 45 57 48 52 102 45 52 53 50 54 45 57 56 49 52 45 56 53 102 48 57 55 48 50 49 57 101 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:26:43 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 51 50 46 49 48 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fn64z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fn64z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fn64z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:26:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:26:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:26:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:26:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:10.200.32.102,StartTime:2020-09-30 19:26:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:26:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://5c298616e41bbe0eed784ae00e183408eb063a5eef64477930fe2a0751309ee4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.32.102,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:43.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1141" for this suite.

â€¢ [SLOW TEST:7.246 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":275,"completed":190,"skipped":3478,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:43.796: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Sep 30 19:26:45.959: INFO: Pod pod-hostip-5efa74f2-fdff-434b-89cf-d74c48d87195 has hostIP: 30.0.0.10
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:26:45.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4186" for this suite.
â€¢{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":275,"completed":191,"skipped":3495,"failed":0}

------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:26:45.966: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 30 19:26:46.151: INFO: Number of nodes with available pods: 0
Sep 30 19:26:46.151: INFO: Node 9b360f31-b888-42e4-807a-5f2a0fca8fae is running more than one daemon pod
Sep 30 19:26:47.163: INFO: Number of nodes with available pods: 0
Sep 30 19:26:47.164: INFO: Node 9b360f31-b888-42e4-807a-5f2a0fca8fae is running more than one daemon pod
Sep 30 19:26:48.158: INFO: Number of nodes with available pods: 2
Sep 30 19:26:48.158: INFO: Node c4ab02cf-8388-4ee7-9741-792b2ee511a4 is running more than one daemon pod
Sep 30 19:26:49.156: INFO: Number of nodes with available pods: 3
Sep 30 19:26:49.156: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 30 19:26:49.174: INFO: Number of nodes with available pods: 2
Sep 30 19:26:49.174: INFO: Node eb106fc7-933d-47a1-a18a-16aa6514d845 is running more than one daemon pod
Sep 30 19:26:50.182: INFO: Number of nodes with available pods: 2
Sep 30 19:26:50.182: INFO: Node eb106fc7-933d-47a1-a18a-16aa6514d845 is running more than one daemon pod
Sep 30 19:26:51.179: INFO: Number of nodes with available pods: 2
Sep 30 19:26:51.179: INFO: Node eb106fc7-933d-47a1-a18a-16aa6514d845 is running more than one daemon pod
Sep 30 19:26:52.191: INFO: Number of nodes with available pods: 2
Sep 30 19:26:52.191: INFO: Node eb106fc7-933d-47a1-a18a-16aa6514d845 is running more than one daemon pod
Sep 30 19:26:53.180: INFO: Number of nodes with available pods: 2
Sep 30 19:26:53.180: INFO: Node eb106fc7-933d-47a1-a18a-16aa6514d845 is running more than one daemon pod
Sep 30 19:26:54.193: INFO: Number of nodes with available pods: 3
Sep 30 19:26:54.193: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-272, will wait for the garbage collector to delete the pods
Sep 30 19:26:54.266: INFO: Deleting DaemonSet.extensions daemon-set took: 9.245443ms
Sep 30 19:26:54.367: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.159972ms
Sep 30 19:27:07.172: INFO: Number of nodes with available pods: 0
Sep 30 19:27:07.172: INFO: Number of running nodes: 0, number of available pods: 0
Sep 30 19:27:07.174: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-272/daemonsets","resourceVersion":"223813"},"items":null}

Sep 30 19:27:07.175: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-272/pods","resourceVersion":"223813"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:27:07.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-272" for this suite.

â€¢ [SLOW TEST:21.223 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":275,"completed":192,"skipped":3495,"failed":0}
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:27:07.189: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4079
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:27:31.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4079" for this suite.

â€¢ [SLOW TEST:24.349 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    when starting a container that exits
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":275,"completed":193,"skipped":3498,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:27:31.539: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4723
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 30 19:27:31.740: INFO: Waiting up to 5m0s for pod "pod-f4d0a1d3-4eb8-4a59-95d4-88e361066ebd" in namespace "emptydir-4723" to be "Succeeded or Failed"
Sep 30 19:27:31.742: INFO: Pod "pod-f4d0a1d3-4eb8-4a59-95d4-88e361066ebd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.706124ms
Sep 30 19:27:33.744: INFO: Pod "pod-f4d0a1d3-4eb8-4a59-95d4-88e361066ebd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003883387s
STEP: Saw pod success
Sep 30 19:27:33.744: INFO: Pod "pod-f4d0a1d3-4eb8-4a59-95d4-88e361066ebd" satisfied condition "Succeeded or Failed"
Sep 30 19:27:33.746: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-f4d0a1d3-4eb8-4a59-95d4-88e361066ebd container test-container: <nil>
STEP: delete the pod
Sep 30 19:27:33.776: INFO: Waiting for pod pod-f4d0a1d3-4eb8-4a59-95d4-88e361066ebd to disappear
Sep 30 19:27:33.778: INFO: Pod pod-f4d0a1d3-4eb8-4a59-95d4-88e361066ebd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:27:33.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4723" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":194,"skipped":3503,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:27:33.784: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2282
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:27:33.978: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2daa2075-b54c-405f-b085-cd7e6c0e371f" in namespace "downward-api-2282" to be "Succeeded or Failed"
Sep 30 19:27:33.984: INFO: Pod "downwardapi-volume-2daa2075-b54c-405f-b085-cd7e6c0e371f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.542711ms
Sep 30 19:27:35.987: INFO: Pod "downwardapi-volume-2daa2075-b54c-405f-b085-cd7e6c0e371f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009346523s
STEP: Saw pod success
Sep 30 19:27:35.987: INFO: Pod "downwardapi-volume-2daa2075-b54c-405f-b085-cd7e6c0e371f" satisfied condition "Succeeded or Failed"
Sep 30 19:27:35.989: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-2daa2075-b54c-405f-b085-cd7e6c0e371f container client-container: <nil>
STEP: delete the pod
Sep 30 19:27:36.006: INFO: Waiting for pod downwardapi-volume-2daa2075-b54c-405f-b085-cd7e6c0e371f to disappear
Sep 30 19:27:36.014: INFO: Pod downwardapi-volume-2daa2075-b54c-405f-b085-cd7e6c0e371f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:27:36.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2282" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":275,"completed":195,"skipped":3504,"failed":0}
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:27:36.020: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-gxp6
STEP: Creating a pod to test atomic-volume-subpath
Sep 30 19:27:36.186: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gxp6" in namespace "subpath-5829" to be "Succeeded or Failed"
Sep 30 19:27:36.190: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.002721ms
Sep 30 19:27:38.192: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 2.006423814s
Sep 30 19:27:40.195: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 4.008801819s
Sep 30 19:27:42.198: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 6.011774975s
Sep 30 19:27:44.200: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 8.014404207s
Sep 30 19:27:46.203: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 10.017188331s
Sep 30 19:27:48.206: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 12.020078674s
Sep 30 19:27:50.209: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 14.022806234s
Sep 30 19:27:52.211: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 16.025018794s
Sep 30 19:27:54.213: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 18.027295715s
Sep 30 19:27:56.216: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Running", Reason="", readiness=true. Elapsed: 20.02998954s
Sep 30 19:27:58.218: INFO: Pod "pod-subpath-test-configmap-gxp6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.032231496s
STEP: Saw pod success
Sep 30 19:27:58.218: INFO: Pod "pod-subpath-test-configmap-gxp6" satisfied condition "Succeeded or Failed"
Sep 30 19:27:58.220: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-subpath-test-configmap-gxp6 container test-container-subpath-configmap-gxp6: <nil>
STEP: delete the pod
Sep 30 19:27:58.261: INFO: Waiting for pod pod-subpath-test-configmap-gxp6 to disappear
Sep 30 19:27:58.266: INFO: Pod pod-subpath-test-configmap-gxp6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gxp6
Sep 30 19:27:58.266: INFO: Deleting pod "pod-subpath-test-configmap-gxp6" in namespace "subpath-5829"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:27:58.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5829" for this suite.

â€¢ [SLOW TEST:22.254 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":275,"completed":196,"skipped":3508,"failed":0}
SSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:27:58.275: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2291
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:27:58.427: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 30 19:27:59.462: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:27:59.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2291" for this suite.
â€¢{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":275,"completed":197,"skipped":3511,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:27:59.480: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-379
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-64d20ee7-ac87-4f0b-9ac1-9a1cfcfae8e4
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-64d20ee7-ac87-4f0b-9ac1-9a1cfcfae8e4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:29:25.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-379" for this suite.

â€¢ [SLOW TEST:86.477 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":275,"completed":198,"skipped":3514,"failed":0}
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:29:25.959: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8963
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Sep 30 19:29:26.113: INFO: Waiting up to 5m0s for pod "var-expansion-cfc13885-52c8-4683-83e5-247874781df2" in namespace "var-expansion-8963" to be "Succeeded or Failed"
Sep 30 19:29:26.122: INFO: Pod "var-expansion-cfc13885-52c8-4683-83e5-247874781df2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.204245ms
Sep 30 19:29:28.124: INFO: Pod "var-expansion-cfc13885-52c8-4683-83e5-247874781df2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011542631s
STEP: Saw pod success
Sep 30 19:29:28.124: INFO: Pod "var-expansion-cfc13885-52c8-4683-83e5-247874781df2" satisfied condition "Succeeded or Failed"
Sep 30 19:29:28.126: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod var-expansion-cfc13885-52c8-4683-83e5-247874781df2 container dapi-container: <nil>
STEP: delete the pod
Sep 30 19:29:28.148: INFO: Waiting for pod var-expansion-cfc13885-52c8-4683-83e5-247874781df2 to disappear
Sep 30 19:29:28.155: INFO: Pod var-expansion-cfc13885-52c8-4683-83e5-247874781df2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:29:28.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8963" for this suite.
â€¢{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":275,"completed":199,"skipped":3519,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:29:28.161: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9713
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:29:28.864: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 19:29:30.870: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090968, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090968, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090968, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737090968, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:29:33.886: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:29:33.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9713" for this suite.
STEP: Destroying namespace "webhook-9713-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:5.893 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":275,"completed":200,"skipped":3529,"failed":0}
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:29:34.054: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:29:34.222: INFO: Waiting up to 5m0s for pod "downwardapi-volume-31755a7e-54cc-40c0-b4b9-d7022ba917a2" in namespace "projected-7536" to be "Succeeded or Failed"
Sep 30 19:29:34.228: INFO: Pod "downwardapi-volume-31755a7e-54cc-40c0-b4b9-d7022ba917a2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.276ms
Sep 30 19:29:36.230: INFO: Pod "downwardapi-volume-31755a7e-54cc-40c0-b4b9-d7022ba917a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008174288s
STEP: Saw pod success
Sep 30 19:29:36.230: INFO: Pod "downwardapi-volume-31755a7e-54cc-40c0-b4b9-d7022ba917a2" satisfied condition "Succeeded or Failed"
Sep 30 19:29:36.232: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-31755a7e-54cc-40c0-b4b9-d7022ba917a2 container client-container: <nil>
STEP: delete the pod
Sep 30 19:29:36.252: INFO: Waiting for pod downwardapi-volume-31755a7e-54cc-40c0-b4b9-d7022ba917a2 to disappear
Sep 30 19:29:36.258: INFO: Pod downwardapi-volume-31755a7e-54cc-40c0-b4b9-d7022ba917a2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:29:36.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7536" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":275,"completed":201,"skipped":3529,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:29:36.267: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1381
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:29:36.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1381" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":275,"completed":202,"skipped":3538,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:29:36.435: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3029
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:29:36.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3029" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
â€¢{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":275,"completed":203,"skipped":3542,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:29:36.591: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6896
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:29:36.740: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Sep 30 19:29:39.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6896 create -f -'
Sep 30 19:29:41.128: INFO: stderr: ""
Sep 30 19:29:41.128: INFO: stdout: "e2e-test-crd-publish-openapi-7103-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 30 19:29:41.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6896 delete e2e-test-crd-publish-openapi-7103-crds test-foo'
Sep 30 19:29:41.193: INFO: stderr: ""
Sep 30 19:29:41.193: INFO: stdout: "e2e-test-crd-publish-openapi-7103-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Sep 30 19:29:41.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6896 apply -f -'
Sep 30 19:29:41.388: INFO: stderr: ""
Sep 30 19:29:41.388: INFO: stdout: "e2e-test-crd-publish-openapi-7103-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 30 19:29:41.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6896 delete e2e-test-crd-publish-openapi-7103-crds test-foo'
Sep 30 19:29:41.459: INFO: stderr: ""
Sep 30 19:29:41.459: INFO: stdout: "e2e-test-crd-publish-openapi-7103-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Sep 30 19:29:41.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6896 create -f -'
Sep 30 19:29:41.602: INFO: rc: 1
Sep 30 19:29:41.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6896 apply -f -'
Sep 30 19:29:41.755: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Sep 30 19:29:41.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6896 create -f -'
Sep 30 19:29:41.894: INFO: rc: 1
Sep 30 19:29:41.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-6896 apply -f -'
Sep 30 19:29:42.039: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Sep 30 19:29:42.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 explain e2e-test-crd-publish-openapi-7103-crds'
Sep 30 19:29:42.188: INFO: stderr: ""
Sep 30 19:29:42.188: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7103-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Sep 30 19:29:42.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 explain e2e-test-crd-publish-openapi-7103-crds.metadata'
Sep 30 19:29:42.342: INFO: stderr: ""
Sep 30 19:29:42.342: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7103-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Sep 30 19:29:42.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 explain e2e-test-crd-publish-openapi-7103-crds.spec'
Sep 30 19:29:42.492: INFO: stderr: ""
Sep 30 19:29:42.492: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7103-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Sep 30 19:29:42.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 explain e2e-test-crd-publish-openapi-7103-crds.spec.bars'
Sep 30 19:29:42.642: INFO: stderr: ""
Sep 30 19:29:42.642: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7103-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Sep 30 19:29:42.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 explain e2e-test-crd-publish-openapi-7103-crds.spec.bars2'
Sep 30 19:29:42.780: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:29:45.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6896" for this suite.

â€¢ [SLOW TEST:9.047 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":275,"completed":204,"skipped":3668,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:29:45.638: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 30 19:29:49.858: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 30 19:29:49.867: INFO: Pod pod-with-poststart-http-hook still exists
Sep 30 19:29:51.867: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 30 19:29:51.869: INFO: Pod pod-with-poststart-http-hook still exists
Sep 30 19:29:53.867: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 30 19:29:53.870: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:29:53.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-102" for this suite.

â€¢ [SLOW TEST:8.239 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":275,"completed":205,"skipped":3679,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:29:53.877: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9558
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:29:54.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9558" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
â€¢{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":275,"completed":206,"skipped":3705,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:29:54.034: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4446
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 30 19:29:58.709: INFO: Successfully updated pod "pod-update-activedeadlineseconds-235dda39-c905-4adb-a415-931bab36e612"
Sep 30 19:29:58.709: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-235dda39-c905-4adb-a415-931bab36e612" in namespace "pods-4446" to be "terminated due to deadline exceeded"
Sep 30 19:29:58.727: INFO: Pod "pod-update-activedeadlineseconds-235dda39-c905-4adb-a415-931bab36e612": Phase="Running", Reason="", readiness=true. Elapsed: 17.892351ms
Sep 30 19:30:00.731: INFO: Pod "pod-update-activedeadlineseconds-235dda39-c905-4adb-a415-931bab36e612": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.022010567s
Sep 30 19:30:00.732: INFO: Pod "pod-update-activedeadlineseconds-235dda39-c905-4adb-a415-931bab36e612" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:00.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4446" for this suite.

â€¢ [SLOW TEST:6.704 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":275,"completed":207,"skipped":3711,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:00.738: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:30:01.458: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 19:30:03.464: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091001, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091001, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091001, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091001, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:30:06.478: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:16.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6206" for this suite.
STEP: Destroying namespace "webhook-6206-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:15.944 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":275,"completed":208,"skipped":3713,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:16.683: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Sep 30 19:30:16.829: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-424726105 proxy --unix-socket=/tmp/kubectl-proxy-unix014727164/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:16.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8413" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":275,"completed":209,"skipped":3719,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:16.884: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5819
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 30 19:30:17.035: INFO: Waiting up to 5m0s for pod "pod-9d343c64-5816-4d98-9d47-59a8de136be9" in namespace "emptydir-5819" to be "Succeeded or Failed"
Sep 30 19:30:17.046: INFO: Pod "pod-9d343c64-5816-4d98-9d47-59a8de136be9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.801525ms
Sep 30 19:30:19.049: INFO: Pod "pod-9d343c64-5816-4d98-9d47-59a8de136be9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013469934s
STEP: Saw pod success
Sep 30 19:30:19.049: INFO: Pod "pod-9d343c64-5816-4d98-9d47-59a8de136be9" satisfied condition "Succeeded or Failed"
Sep 30 19:30:19.050: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-9d343c64-5816-4d98-9d47-59a8de136be9 container test-container: <nil>
STEP: delete the pod
Sep 30 19:30:19.068: INFO: Waiting for pod pod-9d343c64-5816-4d98-9d47-59a8de136be9 to disappear
Sep 30 19:30:19.075: INFO: Pod pod-9d343c64-5816-4d98-9d47-59a8de136be9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:19.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5819" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":210,"skipped":3720,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:19.081: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5523
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:35.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5523" for this suite.

â€¢ [SLOW TEST:16.187 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":275,"completed":211,"skipped":3727,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:35.269: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-938
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Sep 30 19:30:35.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 api-versions'
Sep 30 19:30:35.533: INFO: stderr: ""
Sep 30 19:30:35.533: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npksapi.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:35.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-938" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":275,"completed":212,"skipped":3737,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:35.539: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:30:36.201: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 19:30:38.207: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091036, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091036, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091036, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091036, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:30:41.216: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:41.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8882" for this suite.
STEP: Destroying namespace "webhook-8882-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:5.775 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":275,"completed":213,"skipped":3743,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:41.314: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 30 19:30:41.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-6743'
Sep 30 19:30:41.535: INFO: stderr: ""
Sep 30 19:30:41.535: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Sep 30 19:30:46.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 get pod e2e-test-httpd-pod --namespace=kubectl-6743 -o json'
Sep 30 19:30:46.649: INFO: stderr: ""
Sep 30 19:30:46.650: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-09-30T19:30:41Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-09-30T19:30:41Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"10.200.99.207\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-09-30T19:30:43Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6743\",\n        \"resourceVersion\": \"225139\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6743/pods/e2e-test-httpd-pod\",\n        \"uid\": \"dac983c0-6971-4499-b931-d38810921f42\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-4dqsr\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"eb106fc7-933d-47a1-a18a-16aa6514d845\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-4dqsr\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-4dqsr\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-30T19:30:41Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-30T19:30:43Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-30T19:30:43Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-30T19:30:41Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://61c101666674cc59eca16f4ff70a10900f7bceb770fca695bc63bfd0a0784ef8\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-09-30T19:30:42Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"30.0.0.12\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.200.99.207\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.200.99.207\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-09-30T19:30:41Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 30 19:30:46.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 replace -f - --namespace=kubectl-6743'
Sep 30 19:30:46.876: INFO: stderr: ""
Sep 30 19:30:46.876: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Sep 30 19:30:46.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete pods e2e-test-httpd-pod --namespace=kubectl-6743'
Sep 30 19:30:53.103: INFO: stderr: ""
Sep 30 19:30:53.103: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:53.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6743" for this suite.

â€¢ [SLOW TEST:11.798 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1450
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":275,"completed":214,"skipped":3784,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:53.113: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2354
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 30 19:30:53.256: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:56.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2354" for this suite.
â€¢{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":275,"completed":215,"skipped":3798,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:56.547: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3787
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:30:56.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9b83a7aa-2b4e-4375-a51a-44331e4864a3" in namespace "downward-api-3787" to be "Succeeded or Failed"
Sep 30 19:30:56.713: INFO: Pod "downwardapi-volume-9b83a7aa-2b4e-4375-a51a-44331e4864a3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.730927ms
Sep 30 19:30:58.715: INFO: Pod "downwardapi-volume-9b83a7aa-2b4e-4375-a51a-44331e4864a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014356899s
STEP: Saw pod success
Sep 30 19:30:58.715: INFO: Pod "downwardapi-volume-9b83a7aa-2b4e-4375-a51a-44331e4864a3" satisfied condition "Succeeded or Failed"
Sep 30 19:30:58.717: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-9b83a7aa-2b4e-4375-a51a-44331e4864a3 container client-container: <nil>
STEP: delete the pod
Sep 30 19:30:58.733: INFO: Waiting for pod downwardapi-volume-9b83a7aa-2b4e-4375-a51a-44331e4864a3 to disappear
Sep 30 19:30:58.740: INFO: Pod downwardapi-volume-9b83a7aa-2b4e-4375-a51a-44331e4864a3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:30:58.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3787" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":275,"completed":216,"skipped":3800,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:30:58.746: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6530
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6530
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6530
STEP: creating replication controller externalsvc in namespace services-6530
I0930 19:30:58.942468      21 runners.go:190] Created replication controller with name: externalsvc, namespace: services-6530, replica count: 2
I0930 19:31:01.992775      21 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Sep 30 19:31:02.002: INFO: Creating new exec pod
Sep 30 19:31:04.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 exec --namespace=services-6530 execpod27t95 -- /bin/sh -x -c nslookup clusterip-service'
Sep 30 19:31:04.177: INFO: stderr: "+ nslookup clusterip-service\n"
Sep 30 19:31:04.177: INFO: stdout: "Server:\t\t10.100.200.2\nAddress:\t10.100.200.2#53\n\nclusterip-service.services-6530.svc.cluster.local\tcanonical name = externalsvc.services-6530.svc.cluster.local.\nName:\texternalsvc.services-6530.svc.cluster.local\nAddress: 10.100.200.218\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6530, will wait for the garbage collector to delete the pods
Sep 30 19:31:04.233: INFO: Deleting ReplicationController externalsvc took: 3.971774ms
Sep 30 19:31:04.333: INFO: Terminating ReplicationController externalsvc pods took: 100.168091ms
Sep 30 19:31:13.250: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:31:13.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6530" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:14.526 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":275,"completed":217,"skipped":3812,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:31:13.274: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0930 19:31:13.985261      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 30 19:31:13.985: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:31:13.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8706" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":275,"completed":218,"skipped":3833,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:31:13.991: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8784
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Sep 30 19:31:14.137: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Sep 30 19:31:25.239: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:31:28.078: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:31:39.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8784" for this suite.

â€¢ [SLOW TEST:25.316 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":275,"completed":219,"skipped":3837,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:31:39.307: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4492
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 30 19:31:45.498: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 30 19:31:45.508: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 30 19:31:47.508: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 30 19:31:47.511: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 30 19:31:49.508: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 30 19:31:49.510: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:31:49.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4492" for this suite.

â€¢ [SLOW TEST:10.209 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":275,"completed":220,"skipped":3883,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:31:49.516: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2179
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:31:49.659: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:31:50.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2179" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":275,"completed":221,"skipped":3907,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:31:50.698: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8167
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 30 19:31:50.848: INFO: Waiting up to 5m0s for pod "pod-6a92348c-a5b6-4f57-a538-d3e08826447d" in namespace "emptydir-8167" to be "Succeeded or Failed"
Sep 30 19:31:50.854: INFO: Pod "pod-6a92348c-a5b6-4f57-a538-d3e08826447d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044369ms
Sep 30 19:31:52.856: INFO: Pod "pod-6a92348c-a5b6-4f57-a538-d3e08826447d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008098595s
STEP: Saw pod success
Sep 30 19:31:52.856: INFO: Pod "pod-6a92348c-a5b6-4f57-a538-d3e08826447d" satisfied condition "Succeeded or Failed"
Sep 30 19:31:52.858: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-6a92348c-a5b6-4f57-a538-d3e08826447d container test-container: <nil>
STEP: delete the pod
Sep 30 19:31:52.877: INFO: Waiting for pod pod-6a92348c-a5b6-4f57-a538-d3e08826447d to disappear
Sep 30 19:31:52.887: INFO: Pod pod-6a92348c-a5b6-4f57-a538-d3e08826447d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:31:52.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8167" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":222,"skipped":3915,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:31:52.892: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2850
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 30 19:31:53.036: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:31:56.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2850" for this suite.
â€¢{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":275,"completed":223,"skipped":3939,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:31:56.935: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:31:57.127: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"668baff9-2fa8-45d0-abf8-cf2cec757924", Controller:(*bool)(0xc007fba852), BlockOwnerDeletion:(*bool)(0xc007fba853)}}
Sep 30 19:31:57.140: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"9d23d5c4-41a0-44c6-ae3a-29e82cec1770", Controller:(*bool)(0xc007ffe7b2), BlockOwnerDeletion:(*bool)(0xc007ffe7b3)}}
Sep 30 19:31:57.155: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"be2d3513-f67e-4755-8348-95dce78fdbfa", Controller:(*bool)(0xc007ffe9b2), BlockOwnerDeletion:(*bool)(0xc007ffe9b3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:02.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7163" for this suite.

â€¢ [SLOW TEST:5.242 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":275,"completed":224,"skipped":3945,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:02.178: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1498
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Sep 30 19:32:02.332: INFO: Waiting up to 5m0s for pod "client-containers-8ac03e94-a49c-46e4-abd3-91ed32d24898" in namespace "containers-1498" to be "Succeeded or Failed"
Sep 30 19:32:02.341: INFO: Pod "client-containers-8ac03e94-a49c-46e4-abd3-91ed32d24898": Phase="Pending", Reason="", readiness=false. Elapsed: 9.552692ms
Sep 30 19:32:04.344: INFO: Pod "client-containers-8ac03e94-a49c-46e4-abd3-91ed32d24898": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011953257s
STEP: Saw pod success
Sep 30 19:32:04.344: INFO: Pod "client-containers-8ac03e94-a49c-46e4-abd3-91ed32d24898" satisfied condition "Succeeded or Failed"
Sep 30 19:32:04.346: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod client-containers-8ac03e94-a49c-46e4-abd3-91ed32d24898 container test-container: <nil>
STEP: delete the pod
Sep 30 19:32:04.369: INFO: Waiting for pod client-containers-8ac03e94-a49c-46e4-abd3-91ed32d24898 to disappear
Sep 30 19:32:04.380: INFO: Pod client-containers-8ac03e94-a49c-46e4-abd3-91ed32d24898 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:04.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1498" for this suite.
â€¢{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":275,"completed":225,"skipped":3985,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:04.386: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2184
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:32:04.543: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77b5eacb-c325-43f1-9e94-3d6d91e31d11" in namespace "downward-api-2184" to be "Succeeded or Failed"
Sep 30 19:32:04.551: INFO: Pod "downwardapi-volume-77b5eacb-c325-43f1-9e94-3d6d91e31d11": Phase="Pending", Reason="", readiness=false. Elapsed: 7.522826ms
Sep 30 19:32:06.554: INFO: Pod "downwardapi-volume-77b5eacb-c325-43f1-9e94-3d6d91e31d11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010528901s
STEP: Saw pod success
Sep 30 19:32:06.554: INFO: Pod "downwardapi-volume-77b5eacb-c325-43f1-9e94-3d6d91e31d11" satisfied condition "Succeeded or Failed"
Sep 30 19:32:06.555: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-77b5eacb-c325-43f1-9e94-3d6d91e31d11 container client-container: <nil>
STEP: delete the pod
Sep 30 19:32:06.574: INFO: Waiting for pod downwardapi-volume-77b5eacb-c325-43f1-9e94-3d6d91e31d11 to disappear
Sep 30 19:32:06.580: INFO: Pod downwardapi-volume-77b5eacb-c325-43f1-9e94-3d6d91e31d11 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:06.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2184" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":275,"completed":226,"skipped":3990,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:06.586: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8701
STEP: Creating secret with name secret-test-481b2655-e21d-40fa-9203-ff54ffaa05e5
STEP: Creating a pod to test consume secrets
Sep 30 19:32:06.965: INFO: Waiting up to 5m0s for pod "pod-secrets-43dacff2-acbf-40bf-86ad-a1caf63d030a" in namespace "secrets-6064" to be "Succeeded or Failed"
Sep 30 19:32:06.970: INFO: Pod "pod-secrets-43dacff2-acbf-40bf-86ad-a1caf63d030a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.070647ms
Sep 30 19:32:08.973: INFO: Pod "pod-secrets-43dacff2-acbf-40bf-86ad-a1caf63d030a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007440169s
STEP: Saw pod success
Sep 30 19:32:08.973: INFO: Pod "pod-secrets-43dacff2-acbf-40bf-86ad-a1caf63d030a" satisfied condition "Succeeded or Failed"
Sep 30 19:32:08.975: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-secrets-43dacff2-acbf-40bf-86ad-a1caf63d030a container secret-volume-test: <nil>
STEP: delete the pod
Sep 30 19:32:08.992: INFO: Waiting for pod pod-secrets-43dacff2-acbf-40bf-86ad-a1caf63d030a to disappear
Sep 30 19:32:08.998: INFO: Pod pod-secrets-43dacff2-acbf-40bf-86ad-a1caf63d030a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:08.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6064" for this suite.
STEP: Destroying namespace "secret-namespace-8701" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":275,"completed":227,"skipped":4007,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:09.008: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2247
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2247.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2247.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2247.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2247.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 30 19:32:13.194: INFO: DNS probes using dns-test-aea1018c-0e39-44f3-ae90-7b26cdaac1a3 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2247.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2247.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2247.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2247.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 30 19:32:17.273: INFO: DNS probes using dns-test-6e8cbe89-ada8-497d-9cd4-76fb77662f30 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2247.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2247.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2247.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2247.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 30 19:32:21.364: INFO: DNS probes using dns-test-a256ef2c-db32-4164-943a-e971dfdfe45e succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:21.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2247" for this suite.

â€¢ [SLOW TEST:12.422 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":275,"completed":228,"skipped":4010,"failed":0}
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:21.432: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-17
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Sep 30 19:32:21.582: INFO: Waiting up to 5m0s for pod "var-expansion-0d0505ba-fd33-4eec-bf77-b6297382f118" in namespace "var-expansion-17" to be "Succeeded or Failed"
Sep 30 19:32:21.590: INFO: Pod "var-expansion-0d0505ba-fd33-4eec-bf77-b6297382f118": Phase="Pending", Reason="", readiness=false. Elapsed: 8.026011ms
Sep 30 19:32:23.593: INFO: Pod "var-expansion-0d0505ba-fd33-4eec-bf77-b6297382f118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010692357s
STEP: Saw pod success
Sep 30 19:32:23.593: INFO: Pod "var-expansion-0d0505ba-fd33-4eec-bf77-b6297382f118" satisfied condition "Succeeded or Failed"
Sep 30 19:32:23.595: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod var-expansion-0d0505ba-fd33-4eec-bf77-b6297382f118 container dapi-container: <nil>
STEP: delete the pod
Sep 30 19:32:23.612: INFO: Waiting for pod var-expansion-0d0505ba-fd33-4eec-bf77-b6297382f118 to disappear
Sep 30 19:32:23.619: INFO: Pod var-expansion-0d0505ba-fd33-4eec-bf77-b6297382f118 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:23.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-17" for this suite.
â€¢{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":275,"completed":229,"skipped":4010,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:23.625: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:32:24.440: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 19:32:26.451: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091144, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091144, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091144, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091144, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:32:29.460: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:29.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8535" for this suite.
STEP: Destroying namespace "webhook-8535-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:6.206 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":275,"completed":230,"skipped":4021,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:29.832: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4678
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Sep 30 19:32:29.975: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:46.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4678" for this suite.

â€¢ [SLOW TEST:16.305 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":275,"completed":231,"skipped":4044,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:46.139: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-6031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:32:46.593: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Sep 30 19:32:48.599: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091166, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091166, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091166, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091166, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:32:51.609: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:32:51.612: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:52.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6031" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:6.616 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":275,"completed":232,"skipped":4057,"failed":0}
SSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:52.756: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9856
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 30 19:32:52.933: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 30 19:32:57.937: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:32:58.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9856" for this suite.

â€¢ [SLOW TEST:6.197 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":275,"completed":233,"skipped":4061,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:32:58.953: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3014
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 30 19:32:59.101: INFO: Waiting up to 5m0s for pod "pod-3ce10210-2f3f-4dcf-adaa-091164bcf284" in namespace "emptydir-3014" to be "Succeeded or Failed"
Sep 30 19:32:59.105: INFO: Pod "pod-3ce10210-2f3f-4dcf-adaa-091164bcf284": Phase="Pending", Reason="", readiness=false. Elapsed: 3.515392ms
Sep 30 19:33:01.108: INFO: Pod "pod-3ce10210-2f3f-4dcf-adaa-091164bcf284": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006167184s
Sep 30 19:33:03.111: INFO: Pod "pod-3ce10210-2f3f-4dcf-adaa-091164bcf284": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009459118s
STEP: Saw pod success
Sep 30 19:33:03.111: INFO: Pod "pod-3ce10210-2f3f-4dcf-adaa-091164bcf284" satisfied condition "Succeeded or Failed"
Sep 30 19:33:03.112: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod pod-3ce10210-2f3f-4dcf-adaa-091164bcf284 container test-container: <nil>
STEP: delete the pod
Sep 30 19:33:03.131: INFO: Waiting for pod pod-3ce10210-2f3f-4dcf-adaa-091164bcf284 to disappear
Sep 30 19:33:03.137: INFO: Pod pod-3ce10210-2f3f-4dcf-adaa-091164bcf284 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:33:03.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3014" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":234,"skipped":4071,"failed":0}
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:33:03.142: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6373
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-6373
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6373
STEP: Creating statefulset with conflicting port in namespace statefulset-6373
STEP: Waiting until pod test-pod will start running in namespace statefulset-6373
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6373
Sep 30 19:33:07.345: INFO: Observed stateful pod in namespace: statefulset-6373, name: ss-0, uid: fabbf7ea-2871-4c0d-a60d-a3b25fa4de7e, status phase: Pending. Waiting for statefulset controller to delete.
Sep 30 19:33:07.533: INFO: Observed stateful pod in namespace: statefulset-6373, name: ss-0, uid: fabbf7ea-2871-4c0d-a60d-a3b25fa4de7e, status phase: Failed. Waiting for statefulset controller to delete.
Sep 30 19:33:07.543: INFO: Observed stateful pod in namespace: statefulset-6373, name: ss-0, uid: fabbf7ea-2871-4c0d-a60d-a3b25fa4de7e, status phase: Failed. Waiting for statefulset controller to delete.
Sep 30 19:33:07.553: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6373
STEP: Removing pod with conflicting port in namespace statefulset-6373
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6373 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 30 19:33:11.622: INFO: Deleting all statefulset in ns statefulset-6373
Sep 30 19:33:11.624: INFO: Scaling statefulset ss to 0
Sep 30 19:33:21.647: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 19:33:21.649: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:33:21.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6373" for this suite.

â€¢ [SLOW TEST:18.523 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":275,"completed":235,"skipped":4078,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:33:21.665: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-116
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-116
Sep 30 19:33:21.837: INFO: Found 0 stateful pods, waiting for 1
Sep 30 19:33:31.840: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 30 19:33:31.857: INFO: Deleting all statefulset in ns statefulset-116
Sep 30 19:33:31.888: INFO: Scaling statefulset ss to 0
Sep 30 19:34:01.918: INFO: Waiting for statefulset status.replicas updated to 0
Sep 30 19:34:01.920: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:01.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-116" for this suite.

â€¢ [SLOW TEST:40.276 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":275,"completed":236,"skipped":4092,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:01.943: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2353
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 30 19:34:02.094: INFO: Waiting up to 5m0s for pod "pod-b24b96ac-3071-489c-b61f-d2e9485a8aa8" in namespace "emptydir-2353" to be "Succeeded or Failed"
Sep 30 19:34:02.104: INFO: Pod "pod-b24b96ac-3071-489c-b61f-d2e9485a8aa8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.341078ms
Sep 30 19:34:04.107: INFO: Pod "pod-b24b96ac-3071-489c-b61f-d2e9485a8aa8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012930388s
STEP: Saw pod success
Sep 30 19:34:04.107: INFO: Pod "pod-b24b96ac-3071-489c-b61f-d2e9485a8aa8" satisfied condition "Succeeded or Failed"
Sep 30 19:34:04.109: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-b24b96ac-3071-489c-b61f-d2e9485a8aa8 container test-container: <nil>
STEP: delete the pod
Sep 30 19:34:04.134: INFO: Waiting for pod pod-b24b96ac-3071-489c-b61f-d2e9485a8aa8 to disappear
Sep 30 19:34:04.141: INFO: Pod pod-b24b96ac-3071-489c-b61f-d2e9485a8aa8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:04.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2353" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":237,"skipped":4109,"failed":0}
SSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:04.153: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:34:04.349: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-56d99278-2b8c-4585-ae35-f7b943d07807" in namespace "security-context-test-6378" to be "Succeeded or Failed"
Sep 30 19:34:04.355: INFO: Pod "alpine-nnp-false-56d99278-2b8c-4585-ae35-f7b943d07807": Phase="Pending", Reason="", readiness=false. Elapsed: 5.885267ms
Sep 30 19:34:06.357: INFO: Pod "alpine-nnp-false-56d99278-2b8c-4585-ae35-f7b943d07807": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008418851s
Sep 30 19:34:08.360: INFO: Pod "alpine-nnp-false-56d99278-2b8c-4585-ae35-f7b943d07807": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011246772s
Sep 30 19:34:08.360: INFO: Pod "alpine-nnp-false-56d99278-2b8c-4585-ae35-f7b943d07807" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:08.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6378" for this suite.
â€¢{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":238,"skipped":4113,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:08.373: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8316
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-cb89c1e0-ed21-46ea-8312-5d572b9d7e36
STEP: Creating a pod to test consume secrets
Sep 30 19:34:08.536: INFO: Waiting up to 5m0s for pod "pod-secrets-1ab5ca59-d272-48e9-a12d-3fd8a2deb474" in namespace "secrets-8316" to be "Succeeded or Failed"
Sep 30 19:34:08.546: INFO: Pod "pod-secrets-1ab5ca59-d272-48e9-a12d-3fd8a2deb474": Phase="Pending", Reason="", readiness=false. Elapsed: 9.819524ms
Sep 30 19:34:10.548: INFO: Pod "pod-secrets-1ab5ca59-d272-48e9-a12d-3fd8a2deb474": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012709598s
STEP: Saw pod success
Sep 30 19:34:10.549: INFO: Pod "pod-secrets-1ab5ca59-d272-48e9-a12d-3fd8a2deb474" satisfied condition "Succeeded or Failed"
Sep 30 19:34:10.551: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-secrets-1ab5ca59-d272-48e9-a12d-3fd8a2deb474 container secret-volume-test: <nil>
STEP: delete the pod
Sep 30 19:34:10.581: INFO: Waiting for pod pod-secrets-1ab5ca59-d272-48e9-a12d-3fd8a2deb474 to disappear
Sep 30 19:34:10.583: INFO: Pod pod-secrets-1ab5ca59-d272-48e9-a12d-3fd8a2deb474 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:10.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8316" for this suite.
â€¢{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":239,"skipped":4116,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:10.590: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3370
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:34:10.741: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 30 19:34:13.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-3370 create -f -'
Sep 30 19:34:15.122: INFO: stderr: ""
Sep 30 19:34:15.122: INFO: stdout: "e2e-test-crd-publish-openapi-1513-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 30 19:34:15.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-3370 delete e2e-test-crd-publish-openapi-1513-crds test-cr'
Sep 30 19:34:15.193: INFO: stderr: ""
Sep 30 19:34:15.193: INFO: stdout: "e2e-test-crd-publish-openapi-1513-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Sep 30 19:34:15.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-3370 apply -f -'
Sep 30 19:34:15.356: INFO: stderr: ""
Sep 30 19:34:15.356: INFO: stdout: "e2e-test-crd-publish-openapi-1513-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 30 19:34:15.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 --namespace=crd-publish-openapi-3370 delete e2e-test-crd-publish-openapi-1513-crds test-cr'
Sep 30 19:34:15.436: INFO: stderr: ""
Sep 30 19:34:15.436: INFO: stdout: "e2e-test-crd-publish-openapi-1513-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 30 19:34:15.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 explain e2e-test-crd-publish-openapi-1513-crds'
Sep 30 19:34:15.587: INFO: stderr: ""
Sep 30 19:34:15.587: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1513-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:18.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3370" for this suite.

â€¢ [SLOW TEST:7.854 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":275,"completed":240,"skipped":4128,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:18.444: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1160
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-0762653e-0663-45ac-b0b9-99038d0d0f49
STEP: Creating a pod to test consume configMaps
Sep 30 19:34:18.601: INFO: Waiting up to 5m0s for pod "pod-configmaps-58269c25-17b1-4a84-9d08-ebe50146bfe8" in namespace "configmap-1160" to be "Succeeded or Failed"
Sep 30 19:34:18.612: INFO: Pod "pod-configmaps-58269c25-17b1-4a84-9d08-ebe50146bfe8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.555275ms
Sep 30 19:34:20.615: INFO: Pod "pod-configmaps-58269c25-17b1-4a84-9d08-ebe50146bfe8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014203484s
STEP: Saw pod success
Sep 30 19:34:20.615: INFO: Pod "pod-configmaps-58269c25-17b1-4a84-9d08-ebe50146bfe8" satisfied condition "Succeeded or Failed"
Sep 30 19:34:20.617: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-configmaps-58269c25-17b1-4a84-9d08-ebe50146bfe8 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 19:34:20.632: INFO: Waiting for pod pod-configmaps-58269c25-17b1-4a84-9d08-ebe50146bfe8 to disappear
Sep 30 19:34:20.640: INFO: Pod pod-configmaps-58269c25-17b1-4a84-9d08-ebe50146bfe8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:20.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1160" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":275,"completed":241,"skipped":4144,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:20.645: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6571
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-b17ab292-6a49-4410-85d8-6ede0a2513dc
STEP: Creating a pod to test consume configMaps
Sep 30 19:34:20.815: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c7d08f3-9cc5-4906-ab49-549ecb8d5621" in namespace "configmap-6571" to be "Succeeded or Failed"
Sep 30 19:34:20.826: INFO: Pod "pod-configmaps-3c7d08f3-9cc5-4906-ab49-549ecb8d5621": Phase="Pending", Reason="", readiness=false. Elapsed: 10.544311ms
Sep 30 19:34:22.828: INFO: Pod "pod-configmaps-3c7d08f3-9cc5-4906-ab49-549ecb8d5621": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013011007s
STEP: Saw pod success
Sep 30 19:34:22.828: INFO: Pod "pod-configmaps-3c7d08f3-9cc5-4906-ab49-549ecb8d5621" satisfied condition "Succeeded or Failed"
Sep 30 19:34:22.830: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-configmaps-3c7d08f3-9cc5-4906-ab49-549ecb8d5621 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 19:34:22.848: INFO: Waiting for pod pod-configmaps-3c7d08f3-9cc5-4906-ab49-549ecb8d5621 to disappear
Sep 30 19:34:22.855: INFO: Pod pod-configmaps-3c7d08f3-9cc5-4906-ab49-549ecb8d5621 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:22.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6571" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":242,"skipped":4174,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:22.861: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7403
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:34:23.282: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:34:26.300: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:34:26.302: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2742-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:27.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7403" for this suite.
STEP: Destroying namespace "webhook-7403-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":275,"completed":243,"skipped":4196,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:27.469: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2425
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 30 19:34:30.161: INFO: Successfully updated pod "annotationupdateb5bf1333-bac3-4825-bf70-dd3d137a2f20"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:34.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2425" for this suite.

â€¢ [SLOW TEST:6.734 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":275,"completed":244,"skipped":4204,"failed":0}
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:34.203: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-d127e3be-5866-4d07-bf15-12f80acf39a0
STEP: Creating secret with name secret-projected-all-test-volume-0834e1e5-7835-4da3-b89d-bc8ebc5305ba
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 30 19:34:34.369: INFO: Waiting up to 5m0s for pod "projected-volume-c6fb7df5-c624-4f35-a1f2-e08be967482b" in namespace "projected-8380" to be "Succeeded or Failed"
Sep 30 19:34:34.374: INFO: Pod "projected-volume-c6fb7df5-c624-4f35-a1f2-e08be967482b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.088372ms
Sep 30 19:34:36.377: INFO: Pod "projected-volume-c6fb7df5-c624-4f35-a1f2-e08be967482b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007719129s
STEP: Saw pod success
Sep 30 19:34:36.377: INFO: Pod "projected-volume-c6fb7df5-c624-4f35-a1f2-e08be967482b" satisfied condition "Succeeded or Failed"
Sep 30 19:34:36.379: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod projected-volume-c6fb7df5-c624-4f35-a1f2-e08be967482b container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 30 19:34:36.397: INFO: Waiting for pod projected-volume-c6fb7df5-c624-4f35-a1f2-e08be967482b to disappear
Sep 30 19:34:36.403: INFO: Pod projected-volume-c6fb7df5-c624-4f35-a1f2-e08be967482b no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:36.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8380" for this suite.
â€¢{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":275,"completed":245,"skipped":4206,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:36.409: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6878
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:34:36.574: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28754608-be76-4b39-8894-affb1543784c" in namespace "downward-api-6878" to be "Succeeded or Failed"
Sep 30 19:34:36.581: INFO: Pod "downwardapi-volume-28754608-be76-4b39-8894-affb1543784c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.471053ms
Sep 30 19:34:38.583: INFO: Pod "downwardapi-volume-28754608-be76-4b39-8894-affb1543784c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009123718s
STEP: Saw pod success
Sep 30 19:34:38.583: INFO: Pod "downwardapi-volume-28754608-be76-4b39-8894-affb1543784c" satisfied condition "Succeeded or Failed"
Sep 30 19:34:38.585: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-28754608-be76-4b39-8894-affb1543784c container client-container: <nil>
STEP: delete the pod
Sep 30 19:34:38.602: INFO: Waiting for pod downwardapi-volume-28754608-be76-4b39-8894-affb1543784c to disappear
Sep 30 19:34:38.609: INFO: Pod downwardapi-volume-28754608-be76-4b39-8894-affb1543784c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:38.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6878" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":275,"completed":246,"skipped":4208,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:38.616: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Sep 30 19:34:38.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-186 -- logs-generator --log-lines-total 100 --run-duration 20s'
Sep 30 19:34:38.825: INFO: stderr: ""
Sep 30 19:34:38.825: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Sep 30 19:34:38.825: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Sep 30 19:34:38.825: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-186" to be "running and ready, or succeeded"
Sep 30 19:34:38.832: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.281796ms
Sep 30 19:34:40.834: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008511085s
Sep 30 19:34:40.834: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Sep 30 19:34:40.834: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Sep 30 19:34:40.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 logs logs-generator logs-generator --namespace=kubectl-186'
Sep 30 19:34:40.909: INFO: stderr: ""
Sep 30 19:34:40.909: INFO: stdout: "I0930 19:34:39.798240       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/l8q4 526\nI0930 19:34:39.998376       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/b7v 476\nI0930 19:34:40.198339       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/dgz 342\nI0930 19:34:40.398346       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/9pq 521\nI0930 19:34:40.598340       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/m6g 297\nI0930 19:34:40.798338       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/xg7 404\n"
STEP: limiting log lines
Sep 30 19:34:40.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 logs logs-generator logs-generator --namespace=kubectl-186 --tail=1'
Sep 30 19:34:40.976: INFO: stderr: ""
Sep 30 19:34:40.976: INFO: stdout: "I0930 19:34:40.798338       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/xg7 404\n"
Sep 30 19:34:40.976: INFO: got output "I0930 19:34:40.798338       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/xg7 404\n"
STEP: limiting log bytes
Sep 30 19:34:40.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 logs logs-generator logs-generator --namespace=kubectl-186 --limit-bytes=1'
Sep 30 19:34:41.053: INFO: stderr: ""
Sep 30 19:34:41.053: INFO: stdout: "I"
Sep 30 19:34:41.053: INFO: got output "I"
STEP: exposing timestamps
Sep 30 19:34:41.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 logs logs-generator logs-generator --namespace=kubectl-186 --tail=1 --timestamps'
Sep 30 19:34:41.122: INFO: stderr: ""
Sep 30 19:34:41.122: INFO: stdout: "2020-09-30T19:34:40.998455498Z I0930 19:34:40.998339       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/xpmv 319\n"
Sep 30 19:34:41.122: INFO: got output "2020-09-30T19:34:40.998455498Z I0930 19:34:40.998339       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/xpmv 319\n"
STEP: restricting to a time range
Sep 30 19:34:43.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 logs logs-generator logs-generator --namespace=kubectl-186 --since=1s'
Sep 30 19:34:43.704: INFO: stderr: ""
Sep 30 19:34:43.704: INFO: stdout: "I0930 19:34:42.798340       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/nqm9 562\nI0930 19:34:42.998344       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/xcg6 232\nI0930 19:34:43.198350       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/msj 440\nI0930 19:34:43.398354       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/tx6 553\nI0930 19:34:43.600329       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/lj72 237\n"
Sep 30 19:34:43.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 logs logs-generator logs-generator --namespace=kubectl-186 --since=24h'
Sep 30 19:34:43.776: INFO: stderr: ""
Sep 30 19:34:43.776: INFO: stdout: "I0930 19:34:39.798240       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/l8q4 526\nI0930 19:34:39.998376       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/b7v 476\nI0930 19:34:40.198339       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/dgz 342\nI0930 19:34:40.398346       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/9pq 521\nI0930 19:34:40.598340       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/m6g 297\nI0930 19:34:40.798338       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/xg7 404\nI0930 19:34:40.998339       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/xpmv 319\nI0930 19:34:41.198338       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/66kr 466\nI0930 19:34:41.398334       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/pg7 205\nI0930 19:34:41.598335       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/m7x9 360\nI0930 19:34:41.798335       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/6bc9 238\nI0930 19:34:41.998335       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/tmbq 278\nI0930 19:34:42.199190       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/zp7 370\nI0930 19:34:42.398337       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/8ml5 524\nI0930 19:34:42.598340       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/kkl 282\nI0930 19:34:42.798340       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/nqm9 562\nI0930 19:34:42.998344       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/xcg6 232\nI0930 19:34:43.198350       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/msj 440\nI0930 19:34:43.398354       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/tx6 553\nI0930 19:34:43.600329       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/lj72 237\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Sep 30 19:34:43.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-424726105 delete pod logs-generator --namespace=kubectl-186'
Sep 30 19:34:45.657: INFO: stderr: ""
Sep 30 19:34:45.657: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:45.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-186" for this suite.

â€¢ [SLOW TEST:7.051 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1284
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":275,"completed":247,"skipped":4215,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:45.668: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5077
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:34:45.811: INFO: Creating deployment "webserver-deployment"
Sep 30 19:34:45.815: INFO: Waiting for observed generation 1
Sep 30 19:34:47.831: INFO: Waiting for all required pods to come up
Sep 30 19:34:47.834: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 30 19:34:49.842: INFO: Waiting for deployment "webserver-deployment" to complete
Sep 30 19:34:49.846: INFO: Updating deployment "webserver-deployment" with a non-existent image
Sep 30 19:34:49.851: INFO: Updating deployment webserver-deployment
Sep 30 19:34:49.851: INFO: Waiting for observed generation 2
Sep 30 19:34:51.862: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 30 19:34:51.864: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 30 19:34:51.865: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 30 19:34:51.870: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 30 19:34:51.870: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 30 19:34:51.871: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 30 19:34:51.874: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Sep 30 19:34:51.874: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Sep 30 19:34:51.879: INFO: Updating deployment webserver-deployment
Sep 30 19:34:51.879: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Sep 30 19:34:51.896: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 30 19:34:51.910: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 30 19:34:53.974: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5077 /apis/apps/v1/namespaces/deployment-5077/deployments/webserver-deployment b21faa7c-36e1-4a4f-8a5e-d9d802f25053 227692 3 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0068e85e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:11,UnavailableReplicas:22,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-09-30 19:34:51 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-09-30 19:34:53 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,},},ReadyReplicas:11,CollisionCount:nil,},}

Sep 30 19:34:53.989: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-5077 /apis/apps/v1/namespaces/deployment-5077/replicasets/webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 227600 3 2020-09-30 19:34:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment b21faa7c-36e1-4a4f-8a5e-d9d802f25053 0xc0068e8ba7 0xc0068e8ba8}] []  [{kube-controller-manager Update apps/v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 50 49 102 97 97 55 99 45 51 54 101 49 45 52 97 52 102 45 56 97 53 101 45 100 57 100 56 48 50 102 50 53 48 53 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0068e8c48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:34:53.990: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Sep 30 19:34:53.990: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-5077 /apis/apps/v1/namespaces/deployment-5077/replicasets/webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 227696 3 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment b21faa7c-36e1-4a4f-8a5e-d9d802f25053 0xc0068e8ca7 0xc0068e8ca8}] []  [{kube-controller-manager Update apps/v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 50 49 102 97 97 55 99 45 51 54 101 49 45 52 97 52 102 45 56 97 53 101 45 100 57 100 56 48 50 102 50 53 48 53 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0068e8d18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:12,AvailableReplicas:12,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:34:54.013: INFO: Pod "webserver-deployment-6676bcd6d4-5zrhh" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-5zrhh webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-5zrhh eca89818-270b-487e-9cbd-c92fe9580615 227672 0 2020-09-30 19:34:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0067df507 0xc0067df508}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 50 52 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.241,StartTime:2020-09-30 19:34:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.241,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.015: INFO: Pod "webserver-deployment-6676bcd6d4-7r6jm" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-7r6jm webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-7r6jm 8a726d2e-d603-4e44-9091-f1d340d5f846 227599 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0067df710 0xc0067df711}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.017: INFO: Pod "webserver-deployment-6676bcd6d4-95n6j" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-95n6j webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-95n6j 08f368ff-c5a8-46eb-a744-ba2e6c534ae9 227601 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0067df8a0 0xc0067df8a1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.019: INFO: Pod "webserver-deployment-6676bcd6d4-bmh2n" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-bmh2n webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-bmh2n d7430135-fe04-44bc-b35f-b55b9a350076 227607 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0067dfa30 0xc0067dfa31}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.020: INFO: Pod "webserver-deployment-6676bcd6d4-clrvs" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-clrvs webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-clrvs 64223cb5-1055-489d-bbc6-4cfae9f25fc1 227459 0 2020-09-30 19:34:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0067dfbc0 0xc0067dfbc1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:49 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:,StartTime:2020-09-30 19:34:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.022: INFO: Pod "webserver-deployment-6676bcd6d4-fbkp7" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-fbkp7 webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-fbkp7 8304a955-9cb5-440e-9600-cc5abe0a9d3d 227610 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0067dfd50 0xc0067dfd51}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.024: INFO: Pod "webserver-deployment-6676bcd6d4-flrg4" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-flrg4 webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-flrg4 3fef081f-f62b-4db9-9894-73c69b55da90 227640 0 2020-09-30 19:34:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0067dfee0 0xc0067dfee1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 50 52 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.240,StartTime:2020-09-30 19:34:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.240,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.028: INFO: Pod "webserver-deployment-6676bcd6d4-grtrg" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-grtrg webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-grtrg c7d28c14-e110-4fb8-8000-f1df7062dfa6 227584 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0069e80a0 0xc0069e80a1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.029: INFO: Pod "webserver-deployment-6676bcd6d4-jp5vs" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-jp5vs webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-jp5vs f8128ca0-a6ec-44c3-b127-746a013120d4 227639 0 2020-09-30 19:34:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0069e8230 0xc0069e8231}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 53 50 46 51 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:10.200.52.37,StartTime:2020-09-30 19:34:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.52.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.029: INFO: Pod "webserver-deployment-6676bcd6d4-mqmcx" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-mqmcx webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-mqmcx bc5796da-cb79-468b-9338-3a616a0e7edb 227637 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0069e83f0 0xc0069e83f1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.029: INFO: Pod "webserver-deployment-6676bcd6d4-sb6wv" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-sb6wv webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-sb6wv 85742db7-c343-4079-afb0-0e3611877676 227691 0 2020-09-30 19:34:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0069e8580 0xc0069e8581}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 51 50 46 49 50 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:10.200.32.123,StartTime:2020-09-30 19:34:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.32.123,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.029: INFO: Pod "webserver-deployment-6676bcd6d4-tb9ws" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-tb9ws webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-tb9ws d3c08b3f-8b0a-45f4-a24a-386653fe93aa 227650 0 2020-09-30 19:34:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0069e8740 0xc0069e8741}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.030: INFO: Pod "webserver-deployment-6676bcd6d4-xtwpn" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-xtwpn webserver-deployment-6676bcd6d4- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-6676bcd6d4-xtwpn 5912e4a5-7b00-43a4-bdab-d4d622c1e794 227581 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 93955892-2943-4ff7-bfc7-017fcb66ac4b 0xc0069e88d0 0xc0069e88d1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 57 53 53 56 57 50 45 50 57 52 51 45 52 102 102 55 45 98 102 99 55 45 48 49 55 102 99 98 54 54 97 99 52 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.030: INFO: Pod "webserver-deployment-84855cf797-5qj5b" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-5qj5b webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-5qj5b 13d01497-49ac-48e0-bc0a-b8620f0fbb1f 227605 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e8a60 0xc0069e8a61}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.030: INFO: Pod "webserver-deployment-84855cf797-5tgpx" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-5tgpx webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-5tgpx 8f9ed9bc-777b-4888-a4f4-18b6bcc71b84 227425 0 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e8bd0 0xc0069e8bd1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:48 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 53 50 46 51 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:10.200.52.36,StartTime:2020-09-30 19:34:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://74a24d5ad3616ef6785b474e19a92402a7793e4866a5be7c05e972d486aaf505,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.52.36,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.031: INFO: Pod "webserver-deployment-84855cf797-8g2hv" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-8g2hv webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-8g2hv 68d5d302-e6fb-4528-811e-0c40e4079df8 227626 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e8d60 0xc0069e8d61}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.032: INFO: Pod "webserver-deployment-84855cf797-965hj" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-965hj webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-965hj 6643b30a-1b84-4eab-bb93-8726593127eb 227428 0 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e8ed0 0xc0069e8ed1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:48 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 53 50 46 51 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:10.200.52.35,StartTime:2020-09-30 19:34:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://636cebf704acb2eee88daed5e5a00d05ccb529027928d00b17fde0a5af925211,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.52.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.032: INFO: Pod "webserver-deployment-84855cf797-97d75" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-97d75 webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-97d75 6d282145-0585-444c-8ea6-3a8f2d10c5a7 227385 0 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e9060 0xc0069e9061}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:47 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 50 51 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.237,StartTime:2020-09-30 19:34:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b4cfd7e2de350cb7242bb55a94c93e43fd9aeb3835a18306f6dec3fa37b92a2a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.237,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.032: INFO: Pod "webserver-deployment-84855cf797-cgwg8" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-cgwg8 webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-cgwg8 890721d1-2508-49c2-bdc9-e57d6f1faa8b 227664 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e9260 0xc0069e9261}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 50 52 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.242,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://63014ca12c704bf47f87ad4929bea684dc181641dac7dc019d87831a2aa8cd62,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.242,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.032: INFO: Pod "webserver-deployment-84855cf797-cr9vb" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-cr9vb webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-cr9vb db1d6537-de4e-4499-9b50-0915e2b4de5e 227686 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e9430 0xc0069e9431}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 53 50 46 51 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:10.200.52.39,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://22d0e385fd2bf5dad41f86ad8a688f9c526bb5cdd209ff6d20d12f6deef1fb64,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.52.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.033: INFO: Pod "webserver-deployment-84855cf797-cxhbb" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-cxhbb webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-cxhbb 96b9f5d9-0dd2-49ec-8a6f-de3bd3a9df69 227593 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e9620 0xc0069e9621}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.033: INFO: Pod "webserver-deployment-84855cf797-dbcf7" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-dbcf7 webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-dbcf7 1d11527a-2a79-408e-b39d-563ac734b4fc 227406 0 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e97e0 0xc0069e97e1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:47 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 51 50 46 49 49 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:10.200.32.118,StartTime:2020-09-30 19:34:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://7d8393f34ae302ce6e78358498bd8758786fa2a88390da9d2212a3c359bc4790,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.32.118,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.033: INFO: Pod "webserver-deployment-84855cf797-fkldj" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-fkldj webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-fkldj 66a3a152-c7a9-49e2-bfc0-1dcc70f94de5 227694 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e99d0 0xc0069e99d1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 51 50 46 49 50 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:10.200.32.124,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://901bff5aacd06d42bbe0836e7305377ece4cf839dc82e52512ccd4a24df57ec0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.32.124,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.033: INFO: Pod "webserver-deployment-84855cf797-hxr4c" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-hxr4c webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-hxr4c c0e66d89-12ac-4bd8-b21b-5b74f0c55c96 227402 0 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e9b70 0xc0069e9b71}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:47 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 51 50 46 49 49 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:10.200.32.119,StartTime:2020-09-30 19:34:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://c929b826a5344f8f86a1dbe2b4b80e37e1765949b08e0d89333761fa50f2f782,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.32.119,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.034: INFO: Pod "webserver-deployment-84855cf797-jffjl" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-jffjl webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-jffjl 0cd9309a-a4f3-4525-80f6-92df19475c29 227419 0 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e9d00 0xc0069e9d01}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:48 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 50 51 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.239,StartTime:2020-09-30 19:34:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://45ff7572374f4225c5b9333388129d07845ba2492973832366e7fc430f13334a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.239,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.034: INFO: Pod "webserver-deployment-84855cf797-k9npg" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-k9npg webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-k9npg 7c044dbf-c08f-4ada-877c-50b959b5af11 227628 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc0069e9ee0 0xc0069e9ee1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.034: INFO: Pod "webserver-deployment-84855cf797-m85g5" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-m85g5 webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-m85g5 14c2d87a-2f45-44e0-b78c-b66a9de8562f 227689 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc006b4a0c0 0xc006b4a0c1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 53 50 46 52 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:10.200.52.40,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://8cbdb7fc21fc722d6cbdb944e56f0852396ed0294a7a415ec16c8648ab9de117,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.52.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.034: INFO: Pod "webserver-deployment-84855cf797-qn82r" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-qn82r webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-qn82r a4e581e9-6e02-45e8-849b-b8f65bf6cb02 227395 0 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc006b4a2b0 0xc006b4a2b1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:47 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 53 50 46 51 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c4ab02cf-8388-4ee7-9741-792b2ee511a4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.11,PodIP:10.200.52.34,StartTime:2020-09-30 19:34:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a4626e9ba840ee82b4bdaf6a36bfdb4842b9a862cfa6b4f341dd3f3905d6c7dd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.52.34,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.034: INFO: Pod "webserver-deployment-84855cf797-rghsr" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rghsr webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-rghsr 478d7264-8ca9-4d46-a984-6cf31c01ff4d 227629 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc006b4a450 0xc006b4a451}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.035: INFO: Pod "webserver-deployment-84855cf797-sgpsk" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-sgpsk webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-sgpsk 783203bc-3da7-4a86-817e-35f3d19693d9 227695 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc006b4a5e0 0xc006b4a5e1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 50 52 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.243,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b72899bf8418bd8c4f8c6708fa38a915bc3989a7da738d4c6508f09cf3a5e4e4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.243,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.035: INFO: Pod "webserver-deployment-84855cf797-xtd48" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-xtd48 webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-xtd48 cb3b14cf-cd63-4585-8736-9f006076e07b 227422 0 2020-09-30 19:34:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc006b4a770 0xc006b4a771}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:48 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 50 51 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.238,StartTime:2020-09-30 19:34:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:34:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://07883f649fb8b5655ab9e6165ef5c1833ccc9001354ecacecf1e4798dcb3be91,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.238,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.035: INFO: Pod "webserver-deployment-84855cf797-xwdk7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-xwdk7 webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-xwdk7 717f45dd-d77b-444c-84a6-1e4eca88bf09 227603 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc006b4a9b0 0xc006b4a9b1}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:,StartTime:2020-09-30 19:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 30 19:34:54.036: INFO: Pod "webserver-deployment-84855cf797-z8qjp" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-z8qjp webserver-deployment-84855cf797- deployment-5077 /api/v1/namespaces/deployment-5077/pods/webserver-deployment-84855cf797-z8qjp b6dcf5c0-de39-4a11-ab38-b374e1703084 227580 0 2020-09-30 19:34:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 e44325c6-0c4d-46ff-811f-33ebf39b97e4 0xc006b4ab60 0xc006b4ab61}] []  [{kube-controller-manager Update v1 2020-09-30 19:34:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 52 52 51 50 53 99 54 45 48 99 52 100 45 52 54 102 102 45 56 49 49 102 45 51 51 101 98 102 51 57 98 57 55 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:34:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-544bj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-544bj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-544bj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9b360f31-b888-42e4-807a-5f2a0fca8fae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:34:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.10,PodIP:,StartTime:2020-09-30 19:34:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:54.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5077" for this suite.

â€¢ [SLOW TEST:8.377 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":275,"completed":248,"skipped":4290,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:54.045: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:34:54.529: INFO: (0) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 336.101323ms)
Sep 30 19:34:54.532: INFO: (1) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.337521ms)
Sep 30 19:34:54.537: INFO: (2) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.710811ms)
Sep 30 19:34:54.549: INFO: (3) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 11.614795ms)
Sep 30 19:34:54.563: INFO: (4) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 14.583752ms)
Sep 30 19:34:54.578: INFO: (5) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 15.02527ms)
Sep 30 19:34:54.581: INFO: (6) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.209249ms)
Sep 30 19:34:54.583: INFO: (7) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.246589ms)
Sep 30 19:34:54.585: INFO: (8) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.256277ms)
Sep 30 19:34:54.588: INFO: (9) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.182068ms)
Sep 30 19:34:54.590: INFO: (10) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.042606ms)
Sep 30 19:34:54.592: INFO: (11) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.129851ms)
Sep 30 19:34:54.594: INFO: (12) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 1.963894ms)
Sep 30 19:34:54.596: INFO: (13) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.266752ms)
Sep 30 19:34:54.598: INFO: (14) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.012267ms)
Sep 30 19:34:54.601: INFO: (15) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.692558ms)
Sep 30 19:34:54.609: INFO: (16) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.735767ms)
Sep 30 19:34:54.611: INFO: (17) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.166039ms)
Sep 30 19:34:54.613: INFO: (18) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.044958ms)
Sep 30 19:34:54.615: INFO: (19) /api/v1/nodes/9b360f31-b888-42e4-807a-5f2a0fca8fae/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.067721ms)
[AfterEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:54.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3706" for this suite.
â€¢{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":275,"completed":249,"skipped":4300,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:54.621: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-4987/configmap-test-d5bc1fff-8210-4fc2-ac17-7fdd1eafa8d5
STEP: Creating a pod to test consume configMaps
Sep 30 19:34:54.803: INFO: Waiting up to 5m0s for pod "pod-configmaps-4c3b73fe-b2d9-4c62-b469-b36404760ba4" in namespace "configmap-4987" to be "Succeeded or Failed"
Sep 30 19:34:54.831: INFO: Pod "pod-configmaps-4c3b73fe-b2d9-4c62-b469-b36404760ba4": Phase="Pending", Reason="", readiness=false. Elapsed: 28.036346ms
Sep 30 19:34:56.833: INFO: Pod "pod-configmaps-4c3b73fe-b2d9-4c62-b469-b36404760ba4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030431094s
Sep 30 19:34:58.835: INFO: Pod "pod-configmaps-4c3b73fe-b2d9-4c62-b469-b36404760ba4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03277978s
STEP: Saw pod success
Sep 30 19:34:58.835: INFO: Pod "pod-configmaps-4c3b73fe-b2d9-4c62-b469-b36404760ba4" satisfied condition "Succeeded or Failed"
Sep 30 19:34:58.837: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod pod-configmaps-4c3b73fe-b2d9-4c62-b469-b36404760ba4 container env-test: <nil>
STEP: delete the pod
Sep 30 19:34:58.855: INFO: Waiting for pod pod-configmaps-4c3b73fe-b2d9-4c62-b469-b36404760ba4 to disappear
Sep 30 19:34:58.862: INFO: Pod pod-configmaps-4c3b73fe-b2d9-4c62-b469-b36404760ba4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:34:58.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4987" for this suite.
â€¢{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":275,"completed":250,"skipped":4337,"failed":0}

------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:34:58.869: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-8335
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Sep 30 19:34:59.026: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Sep 30 19:34:59.033: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Sep 30 19:34:59.033: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Sep 30 19:34:59.040: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Sep 30 19:34:59.040: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Sep 30 19:34:59.070: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Sep 30 19:34:59.070: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Sep 30 19:35:06.132: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:35:06.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-8335" for this suite.

â€¢ [SLOW TEST:7.297 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":275,"completed":251,"skipped":4337,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:35:06.167: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3445
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:35:06.327: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 19:35:08.329: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = false)
Sep 30 19:35:10.341: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = false)
Sep 30 19:35:12.331: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = false)
Sep 30 19:35:14.329: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = false)
Sep 30 19:35:16.330: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = false)
Sep 30 19:35:18.330: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = false)
Sep 30 19:35:20.330: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = false)
Sep 30 19:35:22.330: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = false)
Sep 30 19:35:24.329: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = false)
Sep 30 19:35:26.329: INFO: The status of Pod test-webserver-932f9138-b717-4ebf-8a8f-099d54bb6913 is Running (Ready = true)
Sep 30 19:35:26.331: INFO: Container started at 2020-09-30 19:35:07 +0000 UTC, pod became ready at 2020-09-30 19:35:24 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:35:26.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3445" for this suite.

â€¢ [SLOW TEST:20.171 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":275,"completed":252,"skipped":4347,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:35:26.338: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-8401
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8401 to expose endpoints map[]
Sep 30 19:35:26.497: INFO: Get endpoints failed (7.679286ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep 30 19:35:27.500: INFO: successfully validated that service multi-endpoint-test in namespace services-8401 exposes endpoints map[] (1.010537258s elapsed)
STEP: Creating pod pod1 in namespace services-8401
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8401 to expose endpoints map[pod1:[100]]
Sep 30 19:35:29.538: INFO: successfully validated that service multi-endpoint-test in namespace services-8401 exposes endpoints map[pod1:[100]] (2.031175434s elapsed)
STEP: Creating pod pod2 in namespace services-8401
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8401 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 30 19:35:31.578: INFO: successfully validated that service multi-endpoint-test in namespace services-8401 exposes endpoints map[pod1:[100] pod2:[101]] (2.036170844s elapsed)
STEP: Deleting pod pod1 in namespace services-8401
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8401 to expose endpoints map[pod2:[101]]
Sep 30 19:35:31.602: INFO: successfully validated that service multi-endpoint-test in namespace services-8401 exposes endpoints map[pod2:[101]] (15.20872ms elapsed)
STEP: Deleting pod pod2 in namespace services-8401
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8401 to expose endpoints map[]
Sep 30 19:35:32.628: INFO: successfully validated that service multi-endpoint-test in namespace services-8401 exposes endpoints map[] (1.013920399s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:35:32.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8401" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:6.326 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":275,"completed":253,"skipped":4374,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:35:32.665: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4428
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:35:32.828: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:35:36.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4428" for this suite.
â€¢{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":275,"completed":254,"skipped":4381,"failed":0}
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:35:36.941: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1494
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4622
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-779
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:36:06.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1494" for this suite.
STEP: Destroying namespace "nsdeletetest-4622" for this suite.
Sep 30 19:36:06.457: INFO: Namespace nsdeletetest-4622 was already deleted
STEP: Destroying namespace "nsdeletetest-779" for this suite.

â€¢ [SLOW TEST:29.519 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":275,"completed":255,"skipped":4383,"failed":0}
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:36:06.461: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-226
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-226/secret-test-8725cf81-820f-47d6-87d0-99fb54cba663
STEP: Creating a pod to test consume secrets
Sep 30 19:36:06.610: INFO: Waiting up to 5m0s for pod "pod-configmaps-121fc389-ca24-4804-bed3-12abe37e3ad0" in namespace "secrets-226" to be "Succeeded or Failed"
Sep 30 19:36:06.614: INFO: Pod "pod-configmaps-121fc389-ca24-4804-bed3-12abe37e3ad0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.805327ms
Sep 30 19:36:08.617: INFO: Pod "pod-configmaps-121fc389-ca24-4804-bed3-12abe37e3ad0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006969446s
STEP: Saw pod success
Sep 30 19:36:08.617: INFO: Pod "pod-configmaps-121fc389-ca24-4804-bed3-12abe37e3ad0" satisfied condition "Succeeded or Failed"
Sep 30 19:36:08.619: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-configmaps-121fc389-ca24-4804-bed3-12abe37e3ad0 container env-test: <nil>
STEP: delete the pod
Sep 30 19:36:08.638: INFO: Waiting for pod pod-configmaps-121fc389-ca24-4804-bed3-12abe37e3ad0 to disappear
Sep 30 19:36:08.645: INFO: Pod pod-configmaps-121fc389-ca24-4804-bed3-12abe37e3ad0 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:36:08.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-226" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":275,"completed":256,"skipped":4385,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:36:08.651: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-2682
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Sep 30 19:36:09.316: INFO: created pod pod-service-account-defaultsa
Sep 30 19:36:09.316: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 30 19:36:09.324: INFO: created pod pod-service-account-mountsa
Sep 30 19:36:09.324: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 30 19:36:09.340: INFO: created pod pod-service-account-nomountsa
Sep 30 19:36:09.340: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 30 19:36:09.355: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 30 19:36:09.355: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 30 19:36:09.370: INFO: created pod pod-service-account-mountsa-mountspec
Sep 30 19:36:09.370: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 30 19:36:09.385: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 30 19:36:09.385: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 30 19:36:09.412: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 30 19:36:09.412: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 30 19:36:09.430: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 30 19:36:09.430: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 30 19:36:09.446: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 30 19:36:09.446: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:36:09.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2682" for this suite.
â€¢{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":275,"completed":257,"skipped":4410,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:36:09.497: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8206
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 30 19:36:09.679: INFO: Waiting up to 5m0s for pod "pod-c9a9f58e-f866-430f-a0cf-5fee8a966667" in namespace "emptydir-8206" to be "Succeeded or Failed"
Sep 30 19:36:09.692: INFO: Pod "pod-c9a9f58e-f866-430f-a0cf-5fee8a966667": Phase="Pending", Reason="", readiness=false. Elapsed: 12.85782ms
Sep 30 19:36:11.696: INFO: Pod "pod-c9a9f58e-f866-430f-a0cf-5fee8a966667": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016757855s
Sep 30 19:36:13.702: INFO: Pod "pod-c9a9f58e-f866-430f-a0cf-5fee8a966667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023090085s
STEP: Saw pod success
Sep 30 19:36:13.702: INFO: Pod "pod-c9a9f58e-f866-430f-a0cf-5fee8a966667" satisfied condition "Succeeded or Failed"
Sep 30 19:36:13.708: INFO: Trying to get logs from node c4ab02cf-8388-4ee7-9741-792b2ee511a4 pod pod-c9a9f58e-f866-430f-a0cf-5fee8a966667 container test-container: <nil>
STEP: delete the pod
Sep 30 19:36:13.740: INFO: Waiting for pod pod-c9a9f58e-f866-430f-a0cf-5fee8a966667 to disappear
Sep 30 19:36:13.750: INFO: Pod pod-c9a9f58e-f866-430f-a0cf-5fee8a966667 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:36:13.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8206" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":258,"skipped":4419,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:36:13.759: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:36:13.930: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:36:15.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2536" for this suite.
â€¢{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":275,"completed":259,"skipped":4426,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:36:15.962: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5276
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0930 19:36:56.180484      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 30 19:36:56.180: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:36:56.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5276" for this suite.

â€¢ [SLOW TEST:40.224 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":275,"completed":260,"skipped":4436,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:36:56.186: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3385
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:36:56.356: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 30 19:37:01.362: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 30 19:37:01.362: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 30 19:37:03.364: INFO: Creating deployment "test-rollover-deployment"
Sep 30 19:37:03.373: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 30 19:37:05.377: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 30 19:37:05.381: INFO: Ensure that both replica sets have 1 created replica
Sep 30 19:37:05.384: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 30 19:37:05.389: INFO: Updating deployment test-rollover-deployment
Sep 30 19:37:05.389: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 30 19:37:07.401: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 30 19:37:07.405: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 30 19:37:07.409: INFO: all replica sets need to contain the pod-template-hash label
Sep 30 19:37:07.409: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091427, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 19:37:09.413: INFO: all replica sets need to contain the pod-template-hash label
Sep 30 19:37:09.413: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091427, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 19:37:11.413: INFO: all replica sets need to contain the pod-template-hash label
Sep 30 19:37:11.413: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091427, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 19:37:13.413: INFO: all replica sets need to contain the pod-template-hash label
Sep 30 19:37:13.413: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091427, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 19:37:15.413: INFO: all replica sets need to contain the pod-template-hash label
Sep 30 19:37:15.413: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091427, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091423, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 30 19:37:17.435: INFO: 
Sep 30 19:37:17.435: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 30 19:37:17.440: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-3385 /apis/apps/v1/namespaces/deployment-3385/deployments/test-rollover-deployment 5495e153-98b3-4efc-a5b4-2f5d6b2dc607 229037 2 2020-09-30 19:37:03 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-09-30 19:37:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-30 19:37:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ce2fd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-09-30 19:37:03 +0000 UTC,LastTransitionTime:2020-09-30 19:37:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-09-30 19:37:17 +0000 UTC,LastTransitionTime:2020-09-30 19:37:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 30 19:37:17.442: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-3385 /apis/apps/v1/namespaces/deployment-3385/replicasets/test-rollover-deployment-84f7f6f64b 099dbe94-6af2-4b52-b889-ae8b9867d040 229026 2 2020-09-30 19:37:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 5495e153-98b3-4efc-a5b4-2f5d6b2dc607 0xc005ce3627 0xc005ce3628}] []  [{kube-controller-manager Update apps/v1 2020-09-30 19:37:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 52 57 53 101 49 53 51 45 57 56 98 51 45 52 101 102 99 45 97 53 98 52 45 50 102 53 100 54 98 50 100 99 54 48 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ce36b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:37:17.442: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 30 19:37:17.443: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3385 /apis/apps/v1/namespaces/deployment-3385/replicasets/test-rollover-controller 2c14c85d-f259-4e12-b113-07e3e31a0539 229036 2 2020-09-30 19:36:56 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 5495e153-98b3-4efc-a5b4-2f5d6b2dc607 0xc005ce3417 0xc005ce3418}] []  [{e2e.test Update apps/v1 2020-09-30 19:36:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-30 19:37:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 52 57 53 101 49 53 51 45 57 56 98 51 45 52 101 102 99 45 97 53 98 52 45 50 102 53 100 54 98 50 100 99 54 48 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005ce34b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:37:17.443: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-3385 /apis/apps/v1/namespaces/deployment-3385/replicasets/test-rollover-deployment-5686c4cfd5 ca7db6f8-86d7-4c9e-bbd6-116c1a95e6a1 228988 2 2020-09-30 19:37:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 5495e153-98b3-4efc-a5b4-2f5d6b2dc607 0xc005ce3527 0xc005ce3528}] []  [{kube-controller-manager Update apps/v1 2020-09-30 19:37:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 52 57 53 101 49 53 51 45 57 56 98 51 45 52 101 102 99 45 97 53 98 52 45 50 102 53 100 54 98 50 100 99 54 48 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ce35b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 30 19:37:17.445: INFO: Pod "test-rollover-deployment-84f7f6f64b-6nsgm" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-6nsgm test-rollover-deployment-84f7f6f64b- deployment-3385 /api/v1/namespaces/deployment-3385/pods/test-rollover-deployment-84f7f6f64b-6nsgm 99ed0059-c504-46a4-a1d2-4b06c579c1ae 228999 0 2020-09-30 19:37:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b 099dbe94-6af2-4b52-b889-ae8b9867d040 0xc0056ef437 0xc0056ef438}] []  [{kube-controller-manager Update v1 2020-09-30 19:37:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 57 57 100 98 101 57 52 45 54 97 102 50 45 52 98 53 50 45 98 56 56 57 45 97 101 56 98 57 56 54 55 100 48 52 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-30 19:37:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 48 48 46 57 57 46 49 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4g7fn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4g7fn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4g7fn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eb106fc7-933d-47a1-a18a-16aa6514d845,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:37:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:37:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:37:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-30 19:37:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:30.0.0.12,PodIP:10.200.99.15,StartTime:2020-09-30 19:37:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-30 19:37:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://26edafe22ca629b66908f813e276b2f6104b64a99d0b4c32272c60402f26028d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.200.99.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:37:17.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3385" for this suite.

â€¢ [SLOW TEST:21.263 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":275,"completed":261,"skipped":4445,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:37:17.450: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-471
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Sep 30 19:37:17.651: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:37:32.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-471" for this suite.

â€¢ [SLOW TEST:14.959 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":275,"completed":262,"skipped":4463,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:37:32.413: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8383
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:37:32.561: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:37:33.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8383" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":275,"completed":263,"skipped":4531,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:37:33.743: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5390
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:37:34.283: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:37:37.296: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:37:37.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5390" for this suite.
STEP: Destroying namespace "webhook-5390-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
â€¢{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":275,"completed":264,"skipped":4533,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:37:37.694: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7278
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 30 19:37:37.858: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ff6bf17-da44-46e9-91d2-4b13b3460098" in namespace "downward-api-7278" to be "Succeeded or Failed"
Sep 30 19:37:37.864: INFO: Pod "downwardapi-volume-5ff6bf17-da44-46e9-91d2-4b13b3460098": Phase="Pending", Reason="", readiness=false. Elapsed: 6.224033ms
Sep 30 19:37:39.866: INFO: Pod "downwardapi-volume-5ff6bf17-da44-46e9-91d2-4b13b3460098": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00876376s
STEP: Saw pod success
Sep 30 19:37:39.867: INFO: Pod "downwardapi-volume-5ff6bf17-da44-46e9-91d2-4b13b3460098" satisfied condition "Succeeded or Failed"
Sep 30 19:37:39.869: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod downwardapi-volume-5ff6bf17-da44-46e9-91d2-4b13b3460098 container client-container: <nil>
STEP: delete the pod
Sep 30 19:37:39.889: INFO: Waiting for pod downwardapi-volume-5ff6bf17-da44-46e9-91d2-4b13b3460098 to disappear
Sep 30 19:37:39.895: INFO: Pod downwardapi-volume-5ff6bf17-da44-46e9-91d2-4b13b3460098 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:37:39.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7278" for this suite.
â€¢{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":275,"completed":265,"skipped":4555,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:37:39.902: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-569
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:37:40.056: INFO: Creating ReplicaSet my-hostname-basic-7dc5799f-91dd-427e-bc97-fc3cba1bfa98
Sep 30 19:37:40.065: INFO: Pod name my-hostname-basic-7dc5799f-91dd-427e-bc97-fc3cba1bfa98: Found 0 pods out of 1
Sep 30 19:37:45.076: INFO: Pod name my-hostname-basic-7dc5799f-91dd-427e-bc97-fc3cba1bfa98: Found 1 pods out of 1
Sep 30 19:37:45.076: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-7dc5799f-91dd-427e-bc97-fc3cba1bfa98" is running
Sep 30 19:37:45.077: INFO: Pod "my-hostname-basic-7dc5799f-91dd-427e-bc97-fc3cba1bfa98-fsgk7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-30 19:37:40 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-30 19:37:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-30 19:37:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-30 19:37:40 +0000 UTC Reason: Message:}])
Sep 30 19:37:45.077: INFO: Trying to dial the pod
Sep 30 19:37:50.086: INFO: Controller my-hostname-basic-7dc5799f-91dd-427e-bc97-fc3cba1bfa98: Got expected result from replica 1 [my-hostname-basic-7dc5799f-91dd-427e-bc97-fc3cba1bfa98-fsgk7]: "my-hostname-basic-7dc5799f-91dd-427e-bc97-fc3cba1bfa98-fsgk7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:37:50.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-569" for this suite.

â€¢ [SLOW TEST:10.190 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":275,"completed":266,"skipped":4564,"failed":0}
SS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:37:50.092: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8153
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 30 19:37:50.253: INFO: Waiting up to 5m0s for pod "busybox-user-65534-81fcb67e-598b-47a5-960e-fc72e9211a08" in namespace "security-context-test-8153" to be "Succeeded or Failed"
Sep 30 19:37:50.260: INFO: Pod "busybox-user-65534-81fcb67e-598b-47a5-960e-fc72e9211a08": Phase="Pending", Reason="", readiness=false. Elapsed: 7.747699ms
Sep 30 19:37:52.263: INFO: Pod "busybox-user-65534-81fcb67e-598b-47a5-960e-fc72e9211a08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009986891s
Sep 30 19:37:52.263: INFO: Pod "busybox-user-65534-81fcb67e-598b-47a5-960e-fc72e9211a08" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:37:52.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8153" for this suite.
â€¢{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":267,"skipped":4566,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:37:52.269: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3440
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 30 19:37:52.462: INFO: Waiting up to 5m0s for pod "pod-6226f27e-4705-4744-b838-23f2cf4cdd58" in namespace "emptydir-3440" to be "Succeeded or Failed"
Sep 30 19:37:52.476: INFO: Pod "pod-6226f27e-4705-4744-b838-23f2cf4cdd58": Phase="Pending", Reason="", readiness=false. Elapsed: 13.275963ms
Sep 30 19:37:54.478: INFO: Pod "pod-6226f27e-4705-4744-b838-23f2cf4cdd58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015521756s
STEP: Saw pod success
Sep 30 19:37:54.478: INFO: Pod "pod-6226f27e-4705-4744-b838-23f2cf4cdd58" satisfied condition "Succeeded or Failed"
Sep 30 19:37:54.479: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-6226f27e-4705-4744-b838-23f2cf4cdd58 container test-container: <nil>
STEP: delete the pod
Sep 30 19:37:54.497: INFO: Waiting for pod pod-6226f27e-4705-4744-b838-23f2cf4cdd58 to disappear
Sep 30 19:37:54.510: INFO: Pod pod-6226f27e-4705-4744-b838-23f2cf4cdd58 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:37:54.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3440" for this suite.
â€¢{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":275,"completed":268,"skipped":4570,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:37:54.516: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6507
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-065c9d7a-d174-4991-8616-bcc7e2a2974f
STEP: Creating a pod to test consume configMaps
Sep 30 19:37:54.672: INFO: Waiting up to 5m0s for pod "pod-configmaps-788296fc-cdc0-4bf8-8d28-25dbf4b6e54e" in namespace "configmap-6507" to be "Succeeded or Failed"
Sep 30 19:37:54.681: INFO: Pod "pod-configmaps-788296fc-cdc0-4bf8-8d28-25dbf4b6e54e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.644162ms
Sep 30 19:37:56.683: INFO: Pod "pod-configmaps-788296fc-cdc0-4bf8-8d28-25dbf4b6e54e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011160232s
STEP: Saw pod success
Sep 30 19:37:56.683: INFO: Pod "pod-configmaps-788296fc-cdc0-4bf8-8d28-25dbf4b6e54e" satisfied condition "Succeeded or Failed"
Sep 30 19:37:56.685: INFO: Trying to get logs from node eb106fc7-933d-47a1-a18a-16aa6514d845 pod pod-configmaps-788296fc-cdc0-4bf8-8d28-25dbf4b6e54e container configmap-volume-test: <nil>
STEP: delete the pod
Sep 30 19:37:56.704: INFO: Waiting for pod pod-configmaps-788296fc-cdc0-4bf8-8d28-25dbf4b6e54e to disappear
Sep 30 19:37:56.714: INFO: Pod pod-configmaps-788296fc-cdc0-4bf8-8d28-25dbf4b6e54e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:37:56.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6507" for this suite.
â€¢{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":275,"completed":269,"skipped":4579,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:37:56.720: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-230
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-230
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 30 19:37:56.863: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 30 19:37:56.912: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 30 19:37:58.914: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:38:00.914: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:38:02.920: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:38:04.914: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:38:06.914: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:38:08.914: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:38:10.914: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:38:12.915: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 30 19:38:14.914: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 30 19:38:14.920: INFO: The status of Pod netserver-1 is Running (Ready = true)
Sep 30 19:38:14.923: INFO: The status of Pod netserver-2 is Running (Ready = false)
Sep 30 19:38:16.926: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Sep 30 19:38:18.938: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.99.23:8080/dial?request=hostname&protocol=udp&host=10.200.32.144&port=8081&tries=1'] Namespace:pod-network-test-230 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:38:18.939: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:38:19.050: INFO: Waiting for responses: map[]
Sep 30 19:38:19.052: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.99.23:8080/dial?request=hostname&protocol=udp&host=10.200.52.50&port=8081&tries=1'] Namespace:pod-network-test-230 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:38:19.052: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:38:19.205: INFO: Waiting for responses: map[]
Sep 30 19:38:19.207: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.99.23:8080/dial?request=hostname&protocol=udp&host=10.200.99.22&port=8081&tries=1'] Namespace:pod-network-test-230 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 30 19:38:19.207: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
Sep 30 19:38:19.307: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:38:19.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-230" for this suite.

â€¢ [SLOW TEST:22.594 seconds]
[sig-network] Networking
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":275,"completed":270,"skipped":4595,"failed":0}
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:38:19.315: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6820
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Sep 30 19:38:19.466: INFO: Waiting up to 5m0s for pod "var-expansion-0ea0336b-4317-4c2c-8297-027674f611a7" in namespace "var-expansion-6820" to be "Succeeded or Failed"
Sep 30 19:38:19.472: INFO: Pod "var-expansion-0ea0336b-4317-4c2c-8297-027674f611a7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.999683ms
Sep 30 19:38:21.475: INFO: Pod "var-expansion-0ea0336b-4317-4c2c-8297-027674f611a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008570976s
STEP: Saw pod success
Sep 30 19:38:21.475: INFO: Pod "var-expansion-0ea0336b-4317-4c2c-8297-027674f611a7" satisfied condition "Succeeded or Failed"
Sep 30 19:38:21.476: INFO: Trying to get logs from node 9b360f31-b888-42e4-807a-5f2a0fca8fae pod var-expansion-0ea0336b-4317-4c2c-8297-027674f611a7 container dapi-container: <nil>
STEP: delete the pod
Sep 30 19:38:21.499: INFO: Waiting for pod var-expansion-0ea0336b-4317-4c2c-8297-027674f611a7 to disappear
Sep 30 19:38:21.512: INFO: Pod var-expansion-0ea0336b-4317-4c2c-8297-027674f611a7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:38:21.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6820" for this suite.
â€¢{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":275,"completed":271,"skipped":4596,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:38:21.526: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7236
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7236.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7236.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7236.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7236.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7236.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7236.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7236.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7236.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7236.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7236.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7236.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 126.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.126_udp@PTR;check="$$(dig +tcp +noall +answer +search 126.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.126_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7236.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7236.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7236.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7236.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7236.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7236.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7236.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7236.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7236.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7236.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7236.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 126.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.126_udp@PTR;check="$$(dig +tcp +noall +answer +search 126.200.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.200.126_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 30 19:38:25.754: INFO: Unable to read wheezy_udp@dns-test-service.dns-7236.svc.cluster.local from pod dns-7236/dns-test-8f4dc374-0e48-4562-8578-10788326c97b: the server could not find the requested resource (get pods dns-test-8f4dc374-0e48-4562-8578-10788326c97b)
Sep 30 19:38:25.756: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7236.svc.cluster.local from pod dns-7236/dns-test-8f4dc374-0e48-4562-8578-10788326c97b: the server could not find the requested resource (get pods dns-test-8f4dc374-0e48-4562-8578-10788326c97b)
Sep 30 19:38:25.760: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local from pod dns-7236/dns-test-8f4dc374-0e48-4562-8578-10788326c97b: the server could not find the requested resource (get pods dns-test-8f4dc374-0e48-4562-8578-10788326c97b)
Sep 30 19:38:25.774: INFO: Unable to read jessie_udp@dns-test-service.dns-7236.svc.cluster.local from pod dns-7236/dns-test-8f4dc374-0e48-4562-8578-10788326c97b: the server could not find the requested resource (get pods dns-test-8f4dc374-0e48-4562-8578-10788326c97b)
Sep 30 19:38:25.776: INFO: Unable to read jessie_tcp@dns-test-service.dns-7236.svc.cluster.local from pod dns-7236/dns-test-8f4dc374-0e48-4562-8578-10788326c97b: the server could not find the requested resource (get pods dns-test-8f4dc374-0e48-4562-8578-10788326c97b)
Sep 30 19:38:25.778: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local from pod dns-7236/dns-test-8f4dc374-0e48-4562-8578-10788326c97b: the server could not find the requested resource (get pods dns-test-8f4dc374-0e48-4562-8578-10788326c97b)
Sep 30 19:38:25.780: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local from pod dns-7236/dns-test-8f4dc374-0e48-4562-8578-10788326c97b: the server could not find the requested resource (get pods dns-test-8f4dc374-0e48-4562-8578-10788326c97b)
Sep 30 19:38:25.793: INFO: Lookups using dns-7236/dns-test-8f4dc374-0e48-4562-8578-10788326c97b failed for: [wheezy_udp@dns-test-service.dns-7236.svc.cluster.local wheezy_tcp@dns-test-service.dns-7236.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local jessie_udp@dns-test-service.dns-7236.svc.cluster.local jessie_tcp@dns-test-service.dns-7236.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7236.svc.cluster.local]

Sep 30 19:38:30.839: INFO: DNS probes using dns-7236/dns-test-8f4dc374-0e48-4562-8578-10788326c97b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:38:30.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7236" for this suite.

â€¢ [SLOW TEST:9.449 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":275,"completed":272,"skipped":4631,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:38:30.975: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9473
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:38:35.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9473" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":275,"completed":273,"skipped":4645,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:38:35.832: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9199
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 30 19:38:36.711: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 30 19:38:38.717: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091516, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091516, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091516, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63737091516, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 30 19:38:41.727: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
Sep 30 19:38:41.753: INFO: Waiting for webhook configuration to be ready...
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:38:41.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9199" for this suite.
STEP: Destroying namespace "webhook-9199-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:6.167 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":275,"completed":274,"skipped":4695,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 30 19:38:42.000: INFO: >>> kubeConfig: /tmp/kubeconfig-424726105
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8715
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Sep 30 19:38:42.196: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-424726105 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 30 19:38:42.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8715" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":275,"completed":275,"skipped":4696,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSep 30 19:38:42.271: INFO: Running AfterSuite actions on all nodes
Sep 30 19:38:42.271: INFO: Running AfterSuite actions on node 1
Sep 30 19:38:42.271: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":275,"completed":275,"skipped":4717,"failed":0}

Ran 275 of 4992 Specs in 4162.843 seconds
SUCCESS! -- 275 Passed | 0 Failed | 0 Pending | 4717 Skipped
PASS

Ginkgo ran 1 suite in 1h9m24.244153503s
Test Suite Passed
