I0915 19:07:19.967280      23 test_context.go:410] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-692368794
I0915 19:07:19.967303      23 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0915 19:07:19.967386      23 e2e.go:124] Starting e2e run "72576d03-d72c-41ae-bd69-bb914be9f3bf" on Ginkgo node 1
{"msg":"Test Suite starting","total":277,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1600196838 - Will randomize all specs
Will run 277 of 4992 specs

Sep 15 19:07:19.977: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 19:07:19.979: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 15 19:07:19.991: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 15 19:07:20.021: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 15 19:07:20.021: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Sep 15 19:07:20.021: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 15 19:07:20.028: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Sep 15 19:07:20.028: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'nodelocaldns' (0 seconds elapsed)
Sep 15 19:07:20.028: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Sep 15 19:07:20.028: INFO: e2e test version: v1.18.6
Sep 15 19:07:20.030: INFO: kube-apiserver version: v1.18.6
Sep 15 19:07:20.030: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 19:07:20.033: INFO: Cluster IP family: ipv4
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:07:20.033: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename statefulset
Sep 15 19:07:20.064: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1125
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1125
STEP: Creating statefulset with conflicting port in namespace statefulset-1125
STEP: Waiting until pod test-pod will start running in namespace statefulset-1125
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1125
Sep 15 19:07:28.088: INFO: Observed stateful pod in namespace: statefulset-1125, name: ss-0, uid: 66c52281-aaea-4bc4-90b9-3cf652e513fc, status phase: Pending. Waiting for statefulset controller to delete.
Sep 15 19:07:28.283: INFO: Observed stateful pod in namespace: statefulset-1125, name: ss-0, uid: 66c52281-aaea-4bc4-90b9-3cf652e513fc, status phase: Failed. Waiting for statefulset controller to delete.
Sep 15 19:07:28.288: INFO: Observed stateful pod in namespace: statefulset-1125, name: ss-0, uid: 66c52281-aaea-4bc4-90b9-3cf652e513fc, status phase: Failed. Waiting for statefulset controller to delete.
Sep 15 19:07:28.297: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1125
STEP: Removing pod with conflicting port in namespace statefulset-1125
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1125 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 15 19:07:32.319: INFO: Deleting all statefulset in ns statefulset-1125
Sep 15 19:07:32.320: INFO: Scaling statefulset ss to 0
Sep 15 19:07:42.329: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 19:07:42.331: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:07:42.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1125" for this suite.

• [SLOW TEST:22.311 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":277,"completed":1,"skipped":0,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:07:42.345: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-cf083723-77fd-47a5-9e4e-3d732d7ef4fc
STEP: Creating a pod to test consume configMaps
Sep 15 19:07:42.374: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e2534feb-9fa2-4acb-ab40-370aa296cdac" in namespace "projected-4434" to be "Succeeded or Failed"
Sep 15 19:07:42.376: INFO: Pod "pod-projected-configmaps-e2534feb-9fa2-4acb-ab40-370aa296cdac": Phase="Pending", Reason="", readiness=false. Elapsed: 1.522275ms
Sep 15 19:07:44.379: INFO: Pod "pod-projected-configmaps-e2534feb-9fa2-4acb-ab40-370aa296cdac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004261123s
Sep 15 19:07:46.381: INFO: Pod "pod-projected-configmaps-e2534feb-9fa2-4acb-ab40-370aa296cdac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006931249s
STEP: Saw pod success
Sep 15 19:07:46.381: INFO: Pod "pod-projected-configmaps-e2534feb-9fa2-4acb-ab40-370aa296cdac" satisfied condition "Succeeded or Failed"
Sep 15 19:07:46.383: INFO: Trying to get logs from node minion1 pod pod-projected-configmaps-e2534feb-9fa2-4acb-ab40-370aa296cdac container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 19:07:46.403: INFO: Waiting for pod pod-projected-configmaps-e2534feb-9fa2-4acb-ab40-370aa296cdac to disappear
Sep 15 19:07:46.407: INFO: Pod pod-projected-configmaps-e2534feb-9fa2-4acb-ab40-370aa296cdac no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:07:46.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4434" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":2,"skipped":5,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:07:46.413: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:07:46.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3c614d5-744c-43e8-95b0-90ec317c6fd4" in namespace "projected-4393" to be "Succeeded or Failed"
Sep 15 19:07:46.441: INFO: Pod "downwardapi-volume-d3c614d5-744c-43e8-95b0-90ec317c6fd4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.695962ms
Sep 15 19:07:48.443: INFO: Pod "downwardapi-volume-d3c614d5-744c-43e8-95b0-90ec317c6fd4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004430133s
Sep 15 19:07:50.446: INFO: Pod "downwardapi-volume-d3c614d5-744c-43e8-95b0-90ec317c6fd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007202192s
STEP: Saw pod success
Sep 15 19:07:50.446: INFO: Pod "downwardapi-volume-d3c614d5-744c-43e8-95b0-90ec317c6fd4" satisfied condition "Succeeded or Failed"
Sep 15 19:07:50.448: INFO: Trying to get logs from node minion1 pod downwardapi-volume-d3c614d5-744c-43e8-95b0-90ec317c6fd4 container client-container: <nil>
STEP: delete the pod
Sep 15 19:07:50.459: INFO: Waiting for pod downwardapi-volume-d3c614d5-744c-43e8-95b0-90ec317c6fd4 to disappear
Sep 15 19:07:50.467: INFO: Pod downwardapi-volume-d3c614d5-744c-43e8-95b0-90ec317c6fd4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:07:50.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4393" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":3,"skipped":29,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:07:50.482: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-7762fffe-11c2-43bf-9aec-cedfa84f7bf1
STEP: Creating a pod to test consume configMaps
Sep 15 19:07:50.514: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d2a6a4ae-123b-4eba-b97e-7398a89d19e0" in namespace "projected-1864" to be "Succeeded or Failed"
Sep 15 19:07:50.516: INFO: Pod "pod-projected-configmaps-d2a6a4ae-123b-4eba-b97e-7398a89d19e0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.507324ms
Sep 15 19:07:52.519: INFO: Pod "pod-projected-configmaps-d2a6a4ae-123b-4eba-b97e-7398a89d19e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004260176s
Sep 15 19:07:54.521: INFO: Pod "pod-projected-configmaps-d2a6a4ae-123b-4eba-b97e-7398a89d19e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007004846s
STEP: Saw pod success
Sep 15 19:07:54.521: INFO: Pod "pod-projected-configmaps-d2a6a4ae-123b-4eba-b97e-7398a89d19e0" satisfied condition "Succeeded or Failed"
Sep 15 19:07:54.523: INFO: Trying to get logs from node minion1 pod pod-projected-configmaps-d2a6a4ae-123b-4eba-b97e-7398a89d19e0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 19:07:54.535: INFO: Waiting for pod pod-projected-configmaps-d2a6a4ae-123b-4eba-b97e-7398a89d19e0 to disappear
Sep 15 19:07:54.542: INFO: Pod pod-projected-configmaps-d2a6a4ae-123b-4eba-b97e-7398a89d19e0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:07:54.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1864" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":4,"skipped":47,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:07:54.548: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1
Sep 15 19:07:54.575: INFO: Pod name my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1: Found 0 pods out of 1
Sep 15 19:07:59.578: INFO: Pod name my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1: Found 1 pods out of 1
Sep 15 19:07:59.578: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1" are running
Sep 15 19:08:01.583: INFO: Pod "my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1-655mq" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-15 19:07:54 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-15 19:07:54 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-15 19:07:54 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-15 19:07:54 +0000 UTC Reason: Message:}])
Sep 15 19:08:01.583: INFO: Trying to dial the pod
Sep 15 19:08:06.591: INFO: Controller my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1: Got expected result from replica 1 [my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1-655mq]: "my-hostname-basic-7de875de-c4d3-424d-859b-6ea7318467d1-655mq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:08:06.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3544" for this suite.

• [SLOW TEST:12.049 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":5,"skipped":100,"failed":0}
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:08:06.597: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-6mgn
STEP: Creating a pod to test atomic-volume-subpath
Sep 15 19:08:06.631: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-6mgn" in namespace "subpath-9137" to be "Succeeded or Failed"
Sep 15 19:08:06.633: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Pending", Reason="", readiness=false. Elapsed: 1.769471ms
Sep 15 19:08:08.635: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004586018s
Sep 15 19:08:10.638: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 4.007347074s
Sep 15 19:08:12.641: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 6.010140723s
Sep 15 19:08:14.644: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 8.012794452s
Sep 15 19:08:16.646: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 10.015700212s
Sep 15 19:08:18.649: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 12.018431211s
Sep 15 19:08:20.652: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 14.020949164s
Sep 15 19:08:22.655: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 16.023789653s
Sep 15 19:08:24.657: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 18.026622122s
Sep 15 19:08:26.660: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 20.029392292s
Sep 15 19:08:28.663: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Running", Reason="", readiness=true. Elapsed: 22.032175914s
Sep 15 19:08:30.666: INFO: Pod "pod-subpath-test-projected-6mgn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.034969143s
STEP: Saw pod success
Sep 15 19:08:30.666: INFO: Pod "pod-subpath-test-projected-6mgn" satisfied condition "Succeeded or Failed"
Sep 15 19:08:30.668: INFO: Trying to get logs from node minion1 pod pod-subpath-test-projected-6mgn container test-container-subpath-projected-6mgn: <nil>
STEP: delete the pod
Sep 15 19:08:30.680: INFO: Waiting for pod pod-subpath-test-projected-6mgn to disappear
Sep 15 19:08:30.687: INFO: Pod pod-subpath-test-projected-6mgn no longer exists
STEP: Deleting pod pod-subpath-test-projected-6mgn
Sep 15 19:08:30.687: INFO: Deleting pod "pod-subpath-test-projected-6mgn" in namespace "subpath-9137"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:08:30.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9137" for this suite.

• [SLOW TEST:24.099 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":277,"completed":6,"skipped":105,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:08:30.696: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:08:36.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3343" for this suite.
STEP: Destroying namespace "nsdeletetest-1926" for this suite.
Sep 15 19:08:36.786: INFO: Namespace nsdeletetest-1926 was already deleted
STEP: Destroying namespace "nsdeletetest-1231" for this suite.

• [SLOW TEST:6.093 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":277,"completed":7,"skipped":120,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:08:36.789: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 15 19:08:36.816: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-a 321ef915-e981-44ef-9446-78282a4a96fa 14229 0 2020-09-15 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-15 19:08:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:08:36.817: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-a 321ef915-e981-44ef-9446-78282a4a96fa 14229 0 2020-09-15 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-15 19:08:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 15 19:08:46.822: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-a 321ef915-e981-44ef-9446-78282a4a96fa 14266 0 2020-09-15 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-15 19:08:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:08:46.822: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-a 321ef915-e981-44ef-9446-78282a4a96fa 14266 0 2020-09-15 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-15 19:08:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 15 19:08:56.827: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-a 321ef915-e981-44ef-9446-78282a4a96fa 14294 0 2020-09-15 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-15 19:08:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:08:56.827: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-a 321ef915-e981-44ef-9446-78282a4a96fa 14294 0 2020-09-15 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-15 19:08:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 15 19:09:06.832: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-a 321ef915-e981-44ef-9446-78282a4a96fa 14322 0 2020-09-15 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-15 19:08:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:09:06.832: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-a 321ef915-e981-44ef-9446-78282a4a96fa 14322 0 2020-09-15 19:08:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-09-15 19:08:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 15 19:09:16.837: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-b 83c5a5d4-6140-4bf2-b7f4-320ad188463a 14350 0 2020-09-15 19:09:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-15 19:09:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:09:16.837: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-b 83c5a5d4-6140-4bf2-b7f4-320ad188463a 14350 0 2020-09-15 19:09:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-15 19:09:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 15 19:09:26.841: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-b 83c5a5d4-6140-4bf2-b7f4-320ad188463a 14378 0 2020-09-15 19:09:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-15 19:09:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:09:26.841: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5241 /api/v1/namespaces/watch-5241/configmaps/e2e-watch-test-configmap-b 83c5a5d4-6140-4bf2-b7f4-320ad188463a 14378 0 2020-09-15 19:09:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-09-15 19:09:16 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:09:36.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5241" for this suite.

• [SLOW TEST:60.059 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":277,"completed":8,"skipped":128,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:09:36.848: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:09:52.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1640" for this suite.

• [SLOW TEST:16.096 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":277,"completed":9,"skipped":141,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:09:52.944: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 15 19:10:00.991: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 15 19:10:00.994: INFO: Pod pod-with-prestop-http-hook still exists
Sep 15 19:10:02.994: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 15 19:10:02.997: INFO: Pod pod-with-prestop-http-hook still exists
Sep 15 19:10:04.994: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 15 19:10:04.996: INFO: Pod pod-with-prestop-http-hook still exists
Sep 15 19:10:06.994: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 15 19:10:06.996: INFO: Pod pod-with-prestop-http-hook still exists
Sep 15 19:10:08.994: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 15 19:10:08.997: INFO: Pod pod-with-prestop-http-hook still exists
Sep 15 19:10:10.994: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 15 19:10:10.997: INFO: Pod pod-with-prestop-http-hook still exists
Sep 15 19:10:12.994: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 15 19:10:12.996: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:13.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1133" for this suite.

• [SLOW TEST:20.072 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":277,"completed":10,"skipped":161,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:13.016: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:10:13.036: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:13.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1541" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":277,"completed":11,"skipped":162,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:13.577: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:10:13.610: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:14.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5107" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":277,"completed":12,"skipped":174,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:14.629: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:10:14.657: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95c6bd5d-8f8d-4751-abe4-0dabdc1b9749" in namespace "projected-1200" to be "Succeeded or Failed"
Sep 15 19:10:14.660: INFO: Pod "downwardapi-volume-95c6bd5d-8f8d-4751-abe4-0dabdc1b9749": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304198ms
Sep 15 19:10:16.662: INFO: Pod "downwardapi-volume-95c6bd5d-8f8d-4751-abe4-0dabdc1b9749": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004586769s
STEP: Saw pod success
Sep 15 19:10:16.662: INFO: Pod "downwardapi-volume-95c6bd5d-8f8d-4751-abe4-0dabdc1b9749" satisfied condition "Succeeded or Failed"
Sep 15 19:10:16.664: INFO: Trying to get logs from node minion1 pod downwardapi-volume-95c6bd5d-8f8d-4751-abe4-0dabdc1b9749 container client-container: <nil>
STEP: delete the pod
Sep 15 19:10:16.673: INFO: Waiting for pod downwardapi-volume-95c6bd5d-8f8d-4751-abe4-0dabdc1b9749 to disappear
Sep 15 19:10:16.675: INFO: Pod downwardapi-volume-95c6bd5d-8f8d-4751-abe4-0dabdc1b9749 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:16.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1200" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":13,"skipped":199,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:16.680: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:10:16.722: INFO: (0) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 11.338193ms)
Sep 15 19:10:16.724: INFO: (1) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.362411ms)
Sep 15 19:10:16.728: INFO: (2) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.50104ms)
Sep 15 19:10:16.730: INFO: (3) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.401195ms)
Sep 15 19:10:16.733: INFO: (4) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.314614ms)
Sep 15 19:10:16.735: INFO: (5) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.277547ms)
Sep 15 19:10:16.737: INFO: (6) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.282763ms)
Sep 15 19:10:16.740: INFO: (7) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.258209ms)
Sep 15 19:10:16.742: INFO: (8) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.321643ms)
Sep 15 19:10:16.744: INFO: (9) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.300973ms)
Sep 15 19:10:16.747: INFO: (10) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.404138ms)
Sep 15 19:10:16.749: INFO: (11) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.53185ms)
Sep 15 19:10:16.755: INFO: (12) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.436237ms)
Sep 15 19:10:16.757: INFO: (13) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.285131ms)
Sep 15 19:10:16.759: INFO: (14) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.195019ms)
Sep 15 19:10:16.762: INFO: (15) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.373967ms)
Sep 15 19:10:16.764: INFO: (16) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.363839ms)
Sep 15 19:10:16.766: INFO: (17) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.18622ms)
Sep 15 19:10:16.769: INFO: (18) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.395436ms)
Sep 15 19:10:16.772: INFO: (19) /api/v1/nodes/minion2/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.885472ms)
[AfterEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:16.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7589" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":277,"completed":14,"skipped":209,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:16.777: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Sep 15 19:10:16.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 cluster-info'
Sep 15 19:10:17.578: INFO: stderr: ""
Sep 15 19:10:17.578: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.241.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:17.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8630" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":277,"completed":15,"skipped":209,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:17.584: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 15 19:10:17.619: INFO: Waiting up to 5m0s for pod "pod-c8d516b4-db4e-47e9-8a96-c1739d58f93b" in namespace "emptydir-9954" to be "Succeeded or Failed"
Sep 15 19:10:17.621: INFO: Pod "pod-c8d516b4-db4e-47e9-8a96-c1739d58f93b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.36815ms
Sep 15 19:10:19.624: INFO: Pod "pod-c8d516b4-db4e-47e9-8a96-c1739d58f93b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004570616s
Sep 15 19:10:21.626: INFO: Pod "pod-c8d516b4-db4e-47e9-8a96-c1739d58f93b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007430861s
STEP: Saw pod success
Sep 15 19:10:21.626: INFO: Pod "pod-c8d516b4-db4e-47e9-8a96-c1739d58f93b" satisfied condition "Succeeded or Failed"
Sep 15 19:10:21.628: INFO: Trying to get logs from node minion1 pod pod-c8d516b4-db4e-47e9-8a96-c1739d58f93b container test-container: <nil>
STEP: delete the pod
Sep 15 19:10:21.641: INFO: Waiting for pod pod-c8d516b4-db4e-47e9-8a96-c1739d58f93b to disappear
Sep 15 19:10:21.648: INFO: Pod pod-c8d516b4-db4e-47e9-8a96-c1739d58f93b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:21.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9954" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":16,"skipped":210,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:21.654: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:10:21.681: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c15cf2f1-95a9-4f86-a279-754796692225" in namespace "projected-1190" to be "Succeeded or Failed"
Sep 15 19:10:21.683: INFO: Pod "downwardapi-volume-c15cf2f1-95a9-4f86-a279-754796692225": Phase="Pending", Reason="", readiness=false. Elapsed: 1.778239ms
Sep 15 19:10:23.686: INFO: Pod "downwardapi-volume-c15cf2f1-95a9-4f86-a279-754796692225": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004561411s
Sep 15 19:10:25.689: INFO: Pod "downwardapi-volume-c15cf2f1-95a9-4f86-a279-754796692225": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007373988s
STEP: Saw pod success
Sep 15 19:10:25.689: INFO: Pod "downwardapi-volume-c15cf2f1-95a9-4f86-a279-754796692225" satisfied condition "Succeeded or Failed"
Sep 15 19:10:25.691: INFO: Trying to get logs from node minion1 pod downwardapi-volume-c15cf2f1-95a9-4f86-a279-754796692225 container client-container: <nil>
STEP: delete the pod
Sep 15 19:10:25.703: INFO: Waiting for pod downwardapi-volume-c15cf2f1-95a9-4f86-a279-754796692225 to disappear
Sep 15 19:10:25.710: INFO: Pod downwardapi-volume-c15cf2f1-95a9-4f86-a279-754796692225 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:25.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1190" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":17,"skipped":240,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:25.715: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:31.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2895" for this suite.

• [SLOW TEST:6.046 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox command in a pod
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:41
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":277,"completed":18,"skipped":261,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:31.762: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 15 19:10:31.792: INFO: Waiting up to 5m0s for pod "pod-de1ed7fd-d63d-4a95-9a18-80ab8e52687a" in namespace "emptydir-7220" to be "Succeeded or Failed"
Sep 15 19:10:31.794: INFO: Pod "pod-de1ed7fd-d63d-4a95-9a18-80ab8e52687a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.197726ms
Sep 15 19:10:33.797: INFO: Pod "pod-de1ed7fd-d63d-4a95-9a18-80ab8e52687a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00482138s
Sep 15 19:10:35.799: INFO: Pod "pod-de1ed7fd-d63d-4a95-9a18-80ab8e52687a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007359521s
STEP: Saw pod success
Sep 15 19:10:35.799: INFO: Pod "pod-de1ed7fd-d63d-4a95-9a18-80ab8e52687a" satisfied condition "Succeeded or Failed"
Sep 15 19:10:35.801: INFO: Trying to get logs from node minion1 pod pod-de1ed7fd-d63d-4a95-9a18-80ab8e52687a container test-container: <nil>
STEP: delete the pod
Sep 15 19:10:35.813: INFO: Waiting for pod pod-de1ed7fd-d63d-4a95-9a18-80ab8e52687a to disappear
Sep 15 19:10:35.819: INFO: Pod pod-de1ed7fd-d63d-4a95-9a18-80ab8e52687a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:35.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7220" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":19,"skipped":274,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:35.825: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 19:10:36.374: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 19:10:38.382: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735793836, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735793836, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735793836, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735793836, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 19:10:41.390: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:41.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-301" for this suite.
STEP: Destroying namespace "webhook-301-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.658 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":277,"completed":20,"skipped":302,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:41.483: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 15 19:10:41.513: INFO: Waiting up to 5m0s for pod "pod-c6165ea0-ac22-4da6-9dde-17982bd50ed8" in namespace "emptydir-2810" to be "Succeeded or Failed"
Sep 15 19:10:41.521: INFO: Pod "pod-c6165ea0-ac22-4da6-9dde-17982bd50ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.72261ms
Sep 15 19:10:43.523: INFO: Pod "pod-c6165ea0-ac22-4da6-9dde-17982bd50ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010431752s
Sep 15 19:10:45.526: INFO: Pod "pod-c6165ea0-ac22-4da6-9dde-17982bd50ed8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013422237s
STEP: Saw pod success
Sep 15 19:10:45.526: INFO: Pod "pod-c6165ea0-ac22-4da6-9dde-17982bd50ed8" satisfied condition "Succeeded or Failed"
Sep 15 19:10:45.528: INFO: Trying to get logs from node minion2 pod pod-c6165ea0-ac22-4da6-9dde-17982bd50ed8 container test-container: <nil>
STEP: delete the pod
Sep 15 19:10:45.541: INFO: Waiting for pod pod-c6165ea0-ac22-4da6-9dde-17982bd50ed8 to disappear
Sep 15 19:10:45.543: INFO: Pod pod-c6165ea0-ac22-4da6-9dde-17982bd50ed8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:45.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2810" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":21,"skipped":304,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:45.549: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-d6c6a8c4-e418-400e-9e3b-deaa8d1d7eab
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:45.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7605" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":277,"completed":22,"skipped":310,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:45.579: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:10:45.597: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Sep 15 19:10:48.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-6475 create -f -'
Sep 15 19:10:49.440: INFO: stderr: ""
Sep 15 19:10:49.440: INFO: stdout: "e2e-test-crd-publish-openapi-1446-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 15 19:10:49.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-6475 delete e2e-test-crd-publish-openapi-1446-crds test-foo'
Sep 15 19:10:49.504: INFO: stderr: ""
Sep 15 19:10:49.504: INFO: stdout: "e2e-test-crd-publish-openapi-1446-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Sep 15 19:10:49.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-6475 apply -f -'
Sep 15 19:10:49.642: INFO: stderr: ""
Sep 15 19:10:49.642: INFO: stdout: "e2e-test-crd-publish-openapi-1446-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 15 19:10:49.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-6475 delete e2e-test-crd-publish-openapi-1446-crds test-foo'
Sep 15 19:10:49.706: INFO: stderr: ""
Sep 15 19:10:49.706: INFO: stdout: "e2e-test-crd-publish-openapi-1446-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Sep 15 19:10:49.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-6475 create -f -'
Sep 15 19:10:49.829: INFO: rc: 1
Sep 15 19:10:49.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-6475 apply -f -'
Sep 15 19:10:49.957: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Sep 15 19:10:49.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-6475 create -f -'
Sep 15 19:10:50.078: INFO: rc: 1
Sep 15 19:10:50.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-6475 apply -f -'
Sep 15 19:10:50.210: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Sep 15 19:10:50.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 explain e2e-test-crd-publish-openapi-1446-crds'
Sep 15 19:10:50.338: INFO: stderr: ""
Sep 15 19:10:50.338: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1446-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Sep 15 19:10:50.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 explain e2e-test-crd-publish-openapi-1446-crds.metadata'
Sep 15 19:10:50.466: INFO: stderr: ""
Sep 15 19:10:50.466: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1446-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Sep 15 19:10:50.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 explain e2e-test-crd-publish-openapi-1446-crds.spec'
Sep 15 19:10:50.600: INFO: stderr: ""
Sep 15 19:10:50.600: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1446-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Sep 15 19:10:50.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 explain e2e-test-crd-publish-openapi-1446-crds.spec.bars'
Sep 15 19:10:50.744: INFO: stderr: ""
Sep 15 19:10:50.744: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1446-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Sep 15 19:10:50.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 explain e2e-test-crd-publish-openapi-1446-crds.spec.bars2'
Sep 15 19:10:50.884: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:52.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6475" for this suite.

• [SLOW TEST:7.151 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":277,"completed":23,"skipped":324,"failed":0}
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:52.730: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:10:52.748: INFO: Creating deployment "test-recreate-deployment"
Sep 15 19:10:52.755: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 15 19:10:52.765: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 15 19:10:54.770: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 15 19:10:54.771: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735793852, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735793852, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735793852, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735793852, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:10:56.774: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 15 19:10:56.779: INFO: Updating deployment test-recreate-deployment
Sep 15 19:10:56.779: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 15 19:10:56.867: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-1262 /apis/apps/v1/namespaces/deployment-1262/deployments/test-recreate-deployment 49206db1-ab56-410d-8706-cd45b8f30a90 15066 2 2020-09-15 19:10:52 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-09-15 19:10:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-15 19:10:56 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00462b7b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-09-15 19:10:56 +0000 UTC,LastTransitionTime:2020-09-15 19:10:56 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-09-15 19:10:56 +0000 UTC,LastTransitionTime:2020-09-15 19:10:52 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Sep 15 19:10:56.869: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-1262 /apis/apps/v1/namespaces/deployment-1262/replicasets/test-recreate-deployment-d5667d9c7 60a98391-01cb-4c82-965f-707b1dd944ad 15064 1 2020-09-15 19:10:56 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 49206db1-ab56-410d-8706-cd45b8f30a90 0xc00462bd40 0xc00462bd41}] []  [{kube-controller-manager Update apps/v1 2020-09-15 19:10:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 57 50 48 54 100 98 49 45 97 98 53 54 45 52 49 48 100 45 56 55 48 54 45 99 100 52 53 98 56 102 51 48 97 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00462bdf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 15 19:10:56.869: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 15 19:10:56.869: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-1262 /apis/apps/v1/namespaces/deployment-1262/replicasets/test-recreate-deployment-74d98b5f7c 724ff853-13df-4e5e-924f-56b1d3d8a868 15054 2 2020-09-15 19:10:52 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 49206db1-ab56-410d-8706-cd45b8f30a90 0xc00462bc47 0xc00462bc48}] []  [{kube-controller-manager Update apps/v1 2020-09-15 19:10:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 57 50 48 54 100 98 49 45 97 98 53 54 45 52 49 48 100 45 56 55 48 54 45 99 100 52 53 98 56 102 51 48 97 57 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00462bcd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 15 19:10:56.871: INFO: Pod "test-recreate-deployment-d5667d9c7-8x67w" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-8x67w test-recreate-deployment-d5667d9c7- deployment-1262 /api/v1/namespaces/deployment-1262/pods/test-recreate-deployment-d5667d9c7-8x67w fd2d2243-411b-48e4-9f73-ac1eddfb7b1d 15065 0 2020-09-15 19:10:56 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 60a98391-01cb-4c82-965f-707b1dd944ad 0xc004688330 0xc004688331}] []  [{kube-controller-manager Update v1 2020-09-15 19:10:56 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 48 97 57 56 51 57 49 45 48 49 99 98 45 52 99 56 50 45 57 54 53 102 45 55 48 55 98 49 100 100 57 52 52 97 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 19:10:56 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-x952v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-x952v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-x952v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:10:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:10:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:10:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:10:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:,StartTime:2020-09-15 19:10:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:10:56.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1262" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":24,"skipped":327,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:10:56.877: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-8017
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8017
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8017
Sep 15 19:10:56.908: INFO: Found 0 stateful pods, waiting for 1
Sep 15 19:11:06.911: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 15 19:11:06.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8017 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 19:11:07.106: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 19:11:07.106: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 19:11:07.106: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 15 19:11:07.109: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 15 19:11:17.112: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 15 19:11:17.112: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 19:11:17.120: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999986s
Sep 15 19:11:18.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998001396s
Sep 15 19:11:19.125: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.995234581s
Sep 15 19:11:20.128: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992326868s
Sep 15 19:11:21.131: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.989528238s
Sep 15 19:11:22.134: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.986681721s
Sep 15 19:11:23.136: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.983891162s
Sep 15 19:11:24.139: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.981428507s
Sep 15 19:11:25.142: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.978427958s
Sep 15 19:11:26.145: INFO: Verifying statefulset ss doesn't scale past 1 for another 975.652649ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8017
Sep 15 19:11:27.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8017 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 15 19:11:27.318: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 15 19:11:27.318: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 15 19:11:27.318: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 15 19:11:27.320: INFO: Found 1 stateful pods, waiting for 3
Sep 15 19:11:37.323: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 19:11:37.323: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 19:11:37.323: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 15 19:11:37.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8017 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 19:11:37.511: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 19:11:37.511: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 19:11:37.511: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 15 19:11:37.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8017 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 19:11:37.708: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 19:11:37.708: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 19:11:37.708: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 15 19:11:37.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8017 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 19:11:37.899: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 19:11:37.899: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 19:11:37.899: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 15 19:11:37.899: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 19:11:37.901: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Sep 15 19:11:47.906: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 15 19:11:47.906: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 15 19:11:47.906: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 15 19:11:47.913: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998514s
Sep 15 19:11:48.916: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997546123s
Sep 15 19:11:49.919: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99474762s
Sep 15 19:11:50.922: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991624158s
Sep 15 19:11:51.925: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988558896s
Sep 15 19:11:52.928: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985489717s
Sep 15 19:11:53.931: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.98243067s
Sep 15 19:11:54.934: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979226476s
Sep 15 19:11:55.938: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976103513s
Sep 15 19:11:56.941: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.926318ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8017
Sep 15 19:11:57.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8017 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 15 19:11:58.113: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 15 19:11:58.113: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 15 19:11:58.113: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 15 19:11:58.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8017 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 15 19:11:58.300: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 15 19:11:58.300: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 15 19:11:58.300: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 15 19:11:58.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8017 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 15 19:11:58.491: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 15 19:11:58.491: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 15 19:11:58.491: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 15 19:11:58.491: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 15 19:12:18.506: INFO: Deleting all statefulset in ns statefulset-8017
Sep 15 19:12:18.510: INFO: Scaling statefulset ss to 0
Sep 15 19:12:18.516: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 19:12:18.517: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:12:18.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8017" for this suite.

• [SLOW TEST:81.654 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":277,"completed":25,"skipped":341,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:12:18.531: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Sep 15 19:12:18.558: INFO: Created pod &Pod{ObjectMeta:{dns-5417  dns-5417 /api/v1/namespaces/dns-5417/pods/dns-5417 0ccda335-7754-4441-a5e2-b354081e5d84 15522 0 2020-09-15 19:12:18 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2020-09-15 19:12:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-68wbg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-68wbg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-68wbg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 19:12:18.561: INFO: The status of Pod dns-5417 is Pending, waiting for it to be Running (with Ready = true)
Sep 15 19:12:20.563: INFO: The status of Pod dns-5417 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Sep 15 19:12:20.563: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5417 PodName:dns-5417 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 19:12:20.563: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Verifying customized DNS server is configured on pod...
Sep 15 19:12:20.687: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5417 PodName:dns-5417 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 19:12:20.687: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 19:12:20.826: INFO: Deleting pod dns-5417...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:12:20.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5417" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":277,"completed":26,"skipped":346,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:12:20.844: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:12:20.861: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:12:21.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5132" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":277,"completed":27,"skipped":350,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:12:21.988: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-e7253878-fe2c-4d06-929d-a303bfaee32c
STEP: Creating a pod to test consume secrets
Sep 15 19:12:22.021: INFO: Waiting up to 5m0s for pod "pod-secrets-92481ec5-3794-420d-aa2a-827a59258550" in namespace "secrets-7361" to be "Succeeded or Failed"
Sep 15 19:12:22.023: INFO: Pod "pod-secrets-92481ec5-3794-420d-aa2a-827a59258550": Phase="Pending", Reason="", readiness=false. Elapsed: 2.175939ms
Sep 15 19:12:24.026: INFO: Pod "pod-secrets-92481ec5-3794-420d-aa2a-827a59258550": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004858344s
Sep 15 19:12:26.029: INFO: Pod "pod-secrets-92481ec5-3794-420d-aa2a-827a59258550": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007642343s
STEP: Saw pod success
Sep 15 19:12:26.029: INFO: Pod "pod-secrets-92481ec5-3794-420d-aa2a-827a59258550" satisfied condition "Succeeded or Failed"
Sep 15 19:12:26.030: INFO: Trying to get logs from node minion1 pod pod-secrets-92481ec5-3794-420d-aa2a-827a59258550 container secret-volume-test: <nil>
STEP: delete the pod
Sep 15 19:12:26.041: INFO: Waiting for pod pod-secrets-92481ec5-3794-420d-aa2a-827a59258550 to disappear
Sep 15 19:12:26.049: INFO: Pod pod-secrets-92481ec5-3794-420d-aa2a-827a59258550 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:12:26.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7361" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":28,"skipped":374,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:12:26.054: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 15 19:12:26.094: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:26.096: INFO: Number of nodes with available pods: 0
Sep 15 19:12:26.096: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:12:27.099: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:27.101: INFO: Number of nodes with available pods: 0
Sep 15 19:12:27.101: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:12:28.100: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:28.102: INFO: Number of nodes with available pods: 1
Sep 15 19:12:28.102: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:12:29.100: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:29.102: INFO: Number of nodes with available pods: 2
Sep 15 19:12:29.102: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 15 19:12:29.110: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:29.112: INFO: Number of nodes with available pods: 1
Sep 15 19:12:29.112: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:30.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:30.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:30.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:31.115: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:31.117: INFO: Number of nodes with available pods: 1
Sep 15 19:12:31.117: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:32.115: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:32.117: INFO: Number of nodes with available pods: 1
Sep 15 19:12:32.117: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:33.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:33.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:33.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:34.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:34.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:34.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:35.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:35.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:35.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:36.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:36.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:36.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:37.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:37.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:37.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:38.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:38.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:38.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:39.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:39.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:39.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:40.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:40.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:40.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:41.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:41.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:41.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:42.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:42.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:42.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:43.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:43.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:43.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:44.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:44.118: INFO: Number of nodes with available pods: 1
Sep 15 19:12:44.118: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:12:45.116: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:12:45.118: INFO: Number of nodes with available pods: 2
Sep 15 19:12:45.118: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-30, will wait for the garbage collector to delete the pods
Sep 15 19:12:45.175: INFO: Deleting DaemonSet.extensions daemon-set took: 3.769329ms
Sep 15 19:12:45.576: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.334751ms
Sep 15 19:12:52.378: INFO: Number of nodes with available pods: 0
Sep 15 19:12:52.378: INFO: Number of running nodes: 0, number of available pods: 0
Sep 15 19:12:52.381: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-30/daemonsets","resourceVersion":"15769"},"items":null}

Sep 15 19:12:52.383: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-30/pods","resourceVersion":"15769"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:12:52.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-30" for this suite.

• [SLOW TEST:26.340 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":277,"completed":29,"skipped":425,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:12:52.394: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:12:52.436: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ffbe6d7d-09bd-45e7-a46d-fe1e28b97cd2" in namespace "projected-4187" to be "Succeeded or Failed"
Sep 15 19:12:52.438: INFO: Pod "downwardapi-volume-ffbe6d7d-09bd-45e7-a46d-fe1e28b97cd2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.630284ms
Sep 15 19:12:54.440: INFO: Pod "downwardapi-volume-ffbe6d7d-09bd-45e7-a46d-fe1e28b97cd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004010531s
STEP: Saw pod success
Sep 15 19:12:54.440: INFO: Pod "downwardapi-volume-ffbe6d7d-09bd-45e7-a46d-fe1e28b97cd2" satisfied condition "Succeeded or Failed"
Sep 15 19:12:54.442: INFO: Trying to get logs from node minion1 pod downwardapi-volume-ffbe6d7d-09bd-45e7-a46d-fe1e28b97cd2 container client-container: <nil>
STEP: delete the pod
Sep 15 19:12:54.454: INFO: Waiting for pod downwardapi-volume-ffbe6d7d-09bd-45e7-a46d-fe1e28b97cd2 to disappear
Sep 15 19:12:54.462: INFO: Pod downwardapi-volume-ffbe6d7d-09bd-45e7-a46d-fe1e28b97cd2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:12:54.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4187" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":277,"completed":30,"skipped":427,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:12:54.467: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:12:54.493: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1fd3f0a1-ad4f-4439-b376-dc3a4875c71b" in namespace "projected-4214" to be "Succeeded or Failed"
Sep 15 19:12:54.495: INFO: Pod "downwardapi-volume-1fd3f0a1-ad4f-4439-b376-dc3a4875c71b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.807122ms
Sep 15 19:12:56.497: INFO: Pod "downwardapi-volume-1fd3f0a1-ad4f-4439-b376-dc3a4875c71b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004323187s
STEP: Saw pod success
Sep 15 19:12:56.497: INFO: Pod "downwardapi-volume-1fd3f0a1-ad4f-4439-b376-dc3a4875c71b" satisfied condition "Succeeded or Failed"
Sep 15 19:12:56.499: INFO: Trying to get logs from node minion1 pod downwardapi-volume-1fd3f0a1-ad4f-4439-b376-dc3a4875c71b container client-container: <nil>
STEP: delete the pod
Sep 15 19:12:56.511: INFO: Waiting for pod downwardapi-volume-1fd3f0a1-ad4f-4439-b376-dc3a4875c71b to disappear
Sep 15 19:12:56.517: INFO: Pod downwardapi-volume-1fd3f0a1-ad4f-4439-b376-dc3a4875c71b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:12:56.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4214" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":31,"skipped":436,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:12:56.522: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Sep 15 19:12:56.541: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Sep 15 19:13:06.685: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 19:13:08.542: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:13:19.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7762" for this suite.

• [SLOW TEST:23.338 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":277,"completed":32,"skipped":443,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:13:19.861: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:13:26.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7916" for this suite.

• [SLOW TEST:7.032 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":277,"completed":33,"skipped":462,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:13:26.893: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 15 19:13:27.789: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Sep 15 19:13:29.796: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794007, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794007, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794007, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794007, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 19:13:32.804: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:13:32.806: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:13:33.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9186" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:7.103 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":277,"completed":34,"skipped":474,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:13:33.997: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Sep 15 19:13:34.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-622'
Sep 15 19:13:34.243: INFO: stderr: ""
Sep 15 19:13:34.243: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 15 19:13:34.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-622'
Sep 15 19:13:34.311: INFO: stderr: ""
Sep 15 19:13:34.311: INFO: stdout: "update-demo-nautilus-9kkgq update-demo-nautilus-zmhnx "
Sep 15 19:13:34.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-9kkgq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-622'
Sep 15 19:13:34.371: INFO: stderr: ""
Sep 15 19:13:34.371: INFO: stdout: ""
Sep 15 19:13:34.371: INFO: update-demo-nautilus-9kkgq is created but not running
Sep 15 19:13:39.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-622'
Sep 15 19:13:39.439: INFO: stderr: ""
Sep 15 19:13:39.439: INFO: stdout: "update-demo-nautilus-9kkgq update-demo-nautilus-zmhnx "
Sep 15 19:13:39.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-9kkgq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-622'
Sep 15 19:13:39.498: INFO: stderr: ""
Sep 15 19:13:39.498: INFO: stdout: "true"
Sep 15 19:13:39.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-9kkgq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-622'
Sep 15 19:13:39.556: INFO: stderr: ""
Sep 15 19:13:39.556: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 15 19:13:39.556: INFO: validating pod update-demo-nautilus-9kkgq
Sep 15 19:13:39.561: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 15 19:13:39.561: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 15 19:13:39.561: INFO: update-demo-nautilus-9kkgq is verified up and running
Sep 15 19:13:39.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-zmhnx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-622'
Sep 15 19:13:39.619: INFO: stderr: ""
Sep 15 19:13:39.619: INFO: stdout: "true"
Sep 15 19:13:39.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-zmhnx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-622'
Sep 15 19:13:39.679: INFO: stderr: ""
Sep 15 19:13:39.679: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 15 19:13:39.679: INFO: validating pod update-demo-nautilus-zmhnx
Sep 15 19:13:39.684: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 15 19:13:39.684: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 15 19:13:39.684: INFO: update-demo-nautilus-zmhnx is verified up and running
STEP: using delete to clean up resources
Sep 15 19:13:39.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete --grace-period=0 --force -f - --namespace=kubectl-622'
Sep 15 19:13:39.747: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 15 19:13:39.747: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 15 19:13:39.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-622'
Sep 15 19:13:39.815: INFO: stderr: "No resources found in kubectl-622 namespace.\n"
Sep 15 19:13:39.815: INFO: stdout: ""
Sep 15 19:13:39.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -l name=update-demo --namespace=kubectl-622 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 15 19:13:39.876: INFO: stderr: ""
Sep 15 19:13:39.876: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:13:39.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-622" for this suite.

• [SLOW TEST:5.885 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":277,"completed":35,"skipped":485,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:13:39.882: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:13:49.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8355" for this suite.

• [SLOW TEST:10.034 seconds]
[sig-apps] Job
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":277,"completed":36,"skipped":511,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:13:49.916: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:13:49.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-785" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":277,"completed":37,"skipped":520,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:13:49.969: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 15 19:13:54.508: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5972 pod-service-account-3cd479ea-d56a-42c9-bfbb-ccbf0b3254f8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 15 19:13:54.677: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5972 pod-service-account-3cd479ea-d56a-42c9-bfbb-ccbf0b3254f8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 15 19:13:54.848: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5972 pod-service-account-3cd479ea-d56a-42c9-bfbb-ccbf0b3254f8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:13:55.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5972" for this suite.

• [SLOW TEST:5.056 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":277,"completed":38,"skipped":536,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:13:55.025: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 15 19:13:55.286: INFO: Pod name wrapped-volume-race-e29e4318-0e46-4792-816b-e3273f00ca5d: Found 0 pods out of 5
Sep 15 19:14:00.291: INFO: Pod name wrapped-volume-race-e29e4318-0e46-4792-816b-e3273f00ca5d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e29e4318-0e46-4792-816b-e3273f00ca5d in namespace emptydir-wrapper-9121, will wait for the garbage collector to delete the pods
Sep 15 19:14:10.380: INFO: Deleting ReplicationController wrapped-volume-race-e29e4318-0e46-4792-816b-e3273f00ca5d took: 4.689512ms
Sep 15 19:14:10.481: INFO: Terminating ReplicationController wrapped-volume-race-e29e4318-0e46-4792-816b-e3273f00ca5d pods took: 100.268087ms
STEP: Creating RC which spawns configmap-volume pods
Sep 15 19:14:15.407: INFO: Pod name wrapped-volume-race-d2204608-47f9-439d-9e2b-fdd26412c15b: Found 0 pods out of 5
Sep 15 19:14:20.412: INFO: Pod name wrapped-volume-race-d2204608-47f9-439d-9e2b-fdd26412c15b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d2204608-47f9-439d-9e2b-fdd26412c15b in namespace emptydir-wrapper-9121, will wait for the garbage collector to delete the pods
Sep 15 19:14:32.493: INFO: Deleting ReplicationController wrapped-volume-race-d2204608-47f9-439d-9e2b-fdd26412c15b took: 4.470805ms
Sep 15 19:14:32.894: INFO: Terminating ReplicationController wrapped-volume-race-d2204608-47f9-439d-9e2b-fdd26412c15b pods took: 401.444761ms
STEP: Creating RC which spawns configmap-volume pods
Sep 15 19:14:42.423: INFO: Pod name wrapped-volume-race-efb2d6fb-d00c-46de-9e08-98eaf374ca8e: Found 0 pods out of 5
Sep 15 19:14:47.434: INFO: Pod name wrapped-volume-race-efb2d6fb-d00c-46de-9e08-98eaf374ca8e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-efb2d6fb-d00c-46de-9e08-98eaf374ca8e in namespace emptydir-wrapper-9121, will wait for the garbage collector to delete the pods
Sep 15 19:14:59.505: INFO: Deleting ReplicationController wrapped-volume-race-efb2d6fb-d00c-46de-9e08-98eaf374ca8e took: 4.711501ms
Sep 15 19:14:59.906: INFO: Terminating ReplicationController wrapped-volume-race-efb2d6fb-d00c-46de-9e08-98eaf374ca8e pods took: 400.337675ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:12.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9121" for this suite.

• [SLOW TEST:77.600 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":277,"completed":39,"skipped":572,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:12.625: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:15:12.659: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1fd23135-e4b2-4fd0-9c31-d3b56c4d39c1" in namespace "projected-4280" to be "Succeeded or Failed"
Sep 15 19:15:12.661: INFO: Pod "downwardapi-volume-1fd23135-e4b2-4fd0-9c31-d3b56c4d39c1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.995752ms
Sep 15 19:15:14.664: INFO: Pod "downwardapi-volume-1fd23135-e4b2-4fd0-9c31-d3b56c4d39c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004814826s
Sep 15 19:15:16.667: INFO: Pod "downwardapi-volume-1fd23135-e4b2-4fd0-9c31-d3b56c4d39c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007578588s
STEP: Saw pod success
Sep 15 19:15:16.667: INFO: Pod "downwardapi-volume-1fd23135-e4b2-4fd0-9c31-d3b56c4d39c1" satisfied condition "Succeeded or Failed"
Sep 15 19:15:16.669: INFO: Trying to get logs from node minion1 pod downwardapi-volume-1fd23135-e4b2-4fd0-9c31-d3b56c4d39c1 container client-container: <nil>
STEP: delete the pod
Sep 15 19:15:16.691: INFO: Waiting for pod downwardapi-volume-1fd23135-e4b2-4fd0-9c31-d3b56c4d39c1 to disappear
Sep 15 19:15:16.696: INFO: Pod downwardapi-volume-1fd23135-e4b2-4fd0-9c31-d3b56c4d39c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:16.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4280" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":40,"skipped":573,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:16.702: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 15 19:15:16.722: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 15 19:15:16.734: INFO: Waiting for terminating namespaces to be deleted...
Sep 15 19:15:16.736: INFO: 
Logging pods the kubelet thinks is on node minion1 before test
Sep 15 19:15:16.742: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-2zszp from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 19:15:16.742: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 15 19:15:16.742: INFO: kube-proxy-z8vzb from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 19:15:16.742: INFO: nodelocaldns-dk627 from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 19:15:16.742: INFO: kubernetes-metrics-scraper-54fbb4d595-8z4nb from kube-system started at 2020-09-15 17:50:15 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Sep 15 19:15:16.742: INFO: weave-scope-cluster-agent-7944c858c9-67nbc from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container scope-cluster-agent ready: true, restart count 0
Sep 15 19:15:16.742: INFO: nginx-proxy-minion1 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container nginx-proxy ready: true, restart count 0
Sep 15 19:15:16.742: INFO: kubernetes-dashboard-667c4c65f8-pvn4d from kube-system started at 2020-09-15 17:50:15 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 15 19:15:16.742: INFO: sonobuoy from sonobuoy started at 2020-09-15 19:07:01 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 15 19:15:16.742: INFO: weave-net-sj6qn from kube-system started at 2020-09-15 17:49:49 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container weave ready: true, restart count 0
Sep 15 19:15:16.742: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 19:15:16.742: INFO: weave-scope-agent-wft6l from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.742: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 19:15:16.742: INFO: 
Logging pods the kubelet thinks is on node minion2 before test
Sep 15 19:15:16.755: INFO: weave-net-9ck4j from kube-system started at 2020-09-15 17:49:48 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:16.755: INFO: 	Container weave ready: true, restart count 0
Sep 15 19:15:16.755: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 19:15:16.755: INFO: weave-scope-app-bc7444d59-mwtxs from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.755: INFO: 	Container app ready: true, restart count 0
Sep 15 19:15:16.755: INFO: nodelocaldns-d2gct from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.755: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 19:15:16.755: INFO: coredns-59dcc4799b-dpc9n from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.755: INFO: 	Container coredns ready: true, restart count 0
Sep 15 19:15:16.755: INFO: weave-scope-agent-wg887 from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.755: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 19:15:16.755: INFO: sonobuoy-e2e-job-874580613c114f91 from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:16.755: INFO: 	Container e2e ready: true, restart count 0
Sep 15 19:15:16.755: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 19:15:16.755: INFO: kube-proxy-5lm96 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.755: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 19:15:16.755: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-kwcxg from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:16.755: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 19:15:16.755: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 15 19:15:16.755: INFO: nginx-proxy-minion2 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:16.755: INFO: 	Container nginx-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0e0396cd-2351-400b-87f4-756eb69d7f77 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-0e0396cd-2351-400b-87f4-756eb69d7f77 off the node minion1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0e0396cd-2351-400b-87f4-756eb69d7f77
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:24.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6709" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:8.117 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":277,"completed":41,"skipped":587,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:24.818: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-dc1da5fa-f601-4509-a048-b985ab04fd00
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:24.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1590" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":277,"completed":42,"skipped":622,"failed":0}

------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:24.848: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:15:24.877: INFO: Waiting up to 5m0s for pod "downwardapi-volume-095233bc-92e6-4d25-a382-4975f274df05" in namespace "projected-3487" to be "Succeeded or Failed"
Sep 15 19:15:24.880: INFO: Pod "downwardapi-volume-095233bc-92e6-4d25-a382-4975f274df05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.730791ms
Sep 15 19:15:26.883: INFO: Pod "downwardapi-volume-095233bc-92e6-4d25-a382-4975f274df05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005433993s
Sep 15 19:15:28.885: INFO: Pod "downwardapi-volume-095233bc-92e6-4d25-a382-4975f274df05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008129235s
STEP: Saw pod success
Sep 15 19:15:28.886: INFO: Pod "downwardapi-volume-095233bc-92e6-4d25-a382-4975f274df05" satisfied condition "Succeeded or Failed"
Sep 15 19:15:28.887: INFO: Trying to get logs from node minion1 pod downwardapi-volume-095233bc-92e6-4d25-a382-4975f274df05 container client-container: <nil>
STEP: delete the pod
Sep 15 19:15:28.901: INFO: Waiting for pod downwardapi-volume-095233bc-92e6-4d25-a382-4975f274df05 to disappear
Sep 15 19:15:28.903: INFO: Pod downwardapi-volume-095233bc-92e6-4d25-a382-4975f274df05 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:28.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3487" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":43,"skipped":622,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:28.910: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 19:15:29.322: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 19:15:31.328: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794129, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794129, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794129, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794129, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 19:15:34.336: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:34.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-258" for this suite.
STEP: Destroying namespace "webhook-258-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.516 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":277,"completed":44,"skipped":636,"failed":0}
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:34.426: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Sep 15 19:15:34.461: INFO: Waiting up to 5m0s for pod "var-expansion-efd3fbb8-94f9-416f-a9a7-0107b4401218" in namespace "var-expansion-5486" to be "Succeeded or Failed"
Sep 15 19:15:34.467: INFO: Pod "var-expansion-efd3fbb8-94f9-416f-a9a7-0107b4401218": Phase="Pending", Reason="", readiness=false. Elapsed: 5.76321ms
Sep 15 19:15:36.469: INFO: Pod "var-expansion-efd3fbb8-94f9-416f-a9a7-0107b4401218": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008533401s
Sep 15 19:15:38.472: INFO: Pod "var-expansion-efd3fbb8-94f9-416f-a9a7-0107b4401218": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011166255s
STEP: Saw pod success
Sep 15 19:15:38.472: INFO: Pod "var-expansion-efd3fbb8-94f9-416f-a9a7-0107b4401218" satisfied condition "Succeeded or Failed"
Sep 15 19:15:38.474: INFO: Trying to get logs from node minion2 pod var-expansion-efd3fbb8-94f9-416f-a9a7-0107b4401218 container dapi-container: <nil>
STEP: delete the pod
Sep 15 19:15:38.487: INFO: Waiting for pod var-expansion-efd3fbb8-94f9-416f-a9a7-0107b4401218 to disappear
Sep 15 19:15:38.495: INFO: Pod var-expansion-efd3fbb8-94f9-416f-a9a7-0107b4401218 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:38.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5486" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":277,"completed":45,"skipped":638,"failed":0}

------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:38.501: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 15 19:15:38.538: INFO: Waiting up to 5m0s for pod "downward-api-0a1956f1-d2ff-4281-b254-e3216329b7b3" in namespace "downward-api-4192" to be "Succeeded or Failed"
Sep 15 19:15:38.540: INFO: Pod "downward-api-0a1956f1-d2ff-4281-b254-e3216329b7b3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.996471ms
Sep 15 19:15:40.543: INFO: Pod "downward-api-0a1956f1-d2ff-4281-b254-e3216329b7b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00476278s
Sep 15 19:15:42.546: INFO: Pod "downward-api-0a1956f1-d2ff-4281-b254-e3216329b7b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00757942s
STEP: Saw pod success
Sep 15 19:15:42.546: INFO: Pod "downward-api-0a1956f1-d2ff-4281-b254-e3216329b7b3" satisfied condition "Succeeded or Failed"
Sep 15 19:15:42.548: INFO: Trying to get logs from node minion1 pod downward-api-0a1956f1-d2ff-4281-b254-e3216329b7b3 container dapi-container: <nil>
STEP: delete the pod
Sep 15 19:15:42.559: INFO: Waiting for pod downward-api-0a1956f1-d2ff-4281-b254-e3216329b7b3 to disappear
Sep 15 19:15:42.566: INFO: Pod downward-api-0a1956f1-d2ff-4281-b254-e3216329b7b3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:42.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4192" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":277,"completed":46,"skipped":638,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:42.572: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-7805
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7805
STEP: Deleting pre-stop pod
Sep 15 19:15:55.638: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:55.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7805" for this suite.

• [SLOW TEST:13.076 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":277,"completed":47,"skipped":662,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:55.648: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 15 19:15:55.687: INFO: Waiting up to 5m0s for pod "downward-api-9177fd8c-a656-42c9-b874-c4bdc2a34149" in namespace "downward-api-4480" to be "Succeeded or Failed"
Sep 15 19:15:55.690: INFO: Pod "downward-api-9177fd8c-a656-42c9-b874-c4bdc2a34149": Phase="Pending", Reason="", readiness=false. Elapsed: 3.120355ms
Sep 15 19:15:57.693: INFO: Pod "downward-api-9177fd8c-a656-42c9-b874-c4bdc2a34149": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006004711s
Sep 15 19:15:59.696: INFO: Pod "downward-api-9177fd8c-a656-42c9-b874-c4bdc2a34149": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008817499s
STEP: Saw pod success
Sep 15 19:15:59.696: INFO: Pod "downward-api-9177fd8c-a656-42c9-b874-c4bdc2a34149" satisfied condition "Succeeded or Failed"
Sep 15 19:15:59.698: INFO: Trying to get logs from node minion2 pod downward-api-9177fd8c-a656-42c9-b874-c4bdc2a34149 container dapi-container: <nil>
STEP: delete the pod
Sep 15 19:15:59.710: INFO: Waiting for pod downward-api-9177fd8c-a656-42c9-b874-c4bdc2a34149 to disappear
Sep 15 19:15:59.712: INFO: Pod downward-api-9177fd8c-a656-42c9-b874-c4bdc2a34149 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:15:59.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4480" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":277,"completed":48,"skipped":673,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:15:59.718: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 15 19:15:59.738: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 15 19:15:59.752: INFO: Waiting for terminating namespaces to be deleted...
Sep 15 19:15:59.754: INFO: 
Logging pods the kubelet thinks is on node minion1 before test
Sep 15 19:15:59.760: INFO: nginx-proxy-minion1 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.760: INFO: 	Container nginx-proxy ready: true, restart count 0
Sep 15 19:15:59.760: INFO: kubernetes-dashboard-667c4c65f8-pvn4d from kube-system started at 2020-09-15 17:50:15 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.760: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 15 19:15:59.760: INFO: kubernetes-metrics-scraper-54fbb4d595-8z4nb from kube-system started at 2020-09-15 17:50:15 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.760: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Sep 15 19:15:59.760: INFO: weave-scope-cluster-agent-7944c858c9-67nbc from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.760: INFO: 	Container scope-cluster-agent ready: true, restart count 0
Sep 15 19:15:59.760: INFO: weave-net-sj6qn from kube-system started at 2020-09-15 17:49:49 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:59.760: INFO: 	Container weave ready: true, restart count 0
Sep 15 19:15:59.760: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 19:15:59.760: INFO: weave-scope-agent-wft6l from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.760: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 19:15:59.760: INFO: sonobuoy from sonobuoy started at 2020-09-15 19:07:01 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.760: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 15 19:15:59.760: INFO: server from prestop-7805 started at 2020-09-15 19:15:42 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.760: INFO: 	Container server ready: false, restart count 0
Sep 15 19:15:59.760: INFO: kube-proxy-z8vzb from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.760: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 19:15:59.761: INFO: nodelocaldns-dk627 from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.761: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 19:15:59.761: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-2zszp from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:59.761: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 19:15:59.761: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 15 19:15:59.761: INFO: tester from prestop-7805 started at 2020-09-15 19:15:46 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.761: INFO: 	Container tester ready: true, restart count 0
Sep 15 19:15:59.761: INFO: 
Logging pods the kubelet thinks is on node minion2 before test
Sep 15 19:15:59.766: INFO: sonobuoy-e2e-job-874580613c114f91 from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:59.766: INFO: 	Container e2e ready: true, restart count 0
Sep 15 19:15:59.766: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 19:15:59.766: INFO: nodelocaldns-d2gct from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.766: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 19:15:59.766: INFO: coredns-59dcc4799b-dpc9n from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.766: INFO: 	Container coredns ready: true, restart count 0
Sep 15 19:15:59.766: INFO: weave-scope-agent-wg887 from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.766: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 19:15:59.766: INFO: kube-proxy-5lm96 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.766: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 19:15:59.766: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-kwcxg from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:59.766: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 19:15:59.766: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 15 19:15:59.766: INFO: nginx-proxy-minion2 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.766: INFO: 	Container nginx-proxy ready: true, restart count 0
Sep 15 19:15:59.766: INFO: weave-net-9ck4j from kube-system started at 2020-09-15 17:49:48 +0000 UTC (2 container statuses recorded)
Sep 15 19:15:59.766: INFO: 	Container weave ready: true, restart count 0
Sep 15 19:15:59.766: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 19:15:59.766: INFO: weave-scope-app-bc7444d59-mwtxs from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:15:59.766: INFO: 	Container app ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-482e50fb-e2a5-4c9e-9e81-df0d6068fd55 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-482e50fb-e2a5-4c9e-9e81-df0d6068fd55 off the node minion2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-482e50fb-e2a5-4c9e-9e81-df0d6068fd55
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:16:09.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2251" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:10.123 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":277,"completed":49,"skipped":691,"failed":0}
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:16:09.841: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Sep 15 19:16:09.871: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Sep 15 19:16:10.180: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep 15 19:16:12.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:16:14.232: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:16:16.232: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:16:18.232: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794170, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:16:20.854: INFO: Waited 618.297468ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:16:21.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-84" for this suite.

• [SLOW TEST:11.601 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":277,"completed":50,"skipped":691,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:16:21.442: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:16:21.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 version'
Sep 15 19:16:21.531: INFO: stderr: ""
Sep 15 19:16:21.531: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.6\", GitCommit:\"dff82dc0de47299ab66c83c626e08b245ab19037\", GitTreeState:\"clean\", BuildDate:\"2020-07-15T16:58:53Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.6\", GitCommit:\"dff82dc0de47299ab66c83c626e08b245ab19037\", GitTreeState:\"clean\", BuildDate:\"2020-07-15T16:51:04Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:16:21.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1813" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":277,"completed":51,"skipped":693,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:16:21.537: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1722
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1722
STEP: creating replication controller externalsvc in namespace services-1722
I0915 19:16:21.600603      23 runners.go:190] Created replication controller with name: externalsvc, namespace: services-1722, replica count: 2
I0915 19:16:24.651018      23 runners.go:190] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0915 19:16:27.651336      23 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Sep 15 19:16:27.675: INFO: Creating new exec pod
Sep 15 19:16:29.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-1722 execpodswfcr -- /bin/sh -x -c nslookup nodeport-service'
Sep 15 19:16:29.886: INFO: stderr: "+ nslookup nodeport-service\n"
Sep 15 19:16:29.886: INFO: stdout: "Server:\t\t169.254.25.10\nAddress:\t169.254.25.10#53\n\nnodeport-service.services-1722.svc.cluster.local\tcanonical name = externalsvc.services-1722.svc.cluster.local.\nName:\texternalsvc.services-1722.svc.cluster.local\nAddress: 10.241.168.154\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1722, will wait for the garbage collector to delete the pods
Sep 15 19:16:29.942: INFO: Deleting ReplicationController externalsvc took: 3.988989ms
Sep 15 19:16:30.042: INFO: Terminating ReplicationController externalsvc pods took: 100.224431ms
Sep 15 19:16:42.356: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:16:42.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1722" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:20.843 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":277,"completed":52,"skipped":696,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:16:42.380: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-d9ef1b28-e1aa-4098-8ab6-7d6d86007b60
STEP: Creating a pod to test consume configMaps
Sep 15 19:16:42.411: INFO: Waiting up to 5m0s for pod "pod-configmaps-bd57407f-91ce-447b-a8eb-cc3792132448" in namespace "configmap-5738" to be "Succeeded or Failed"
Sep 15 19:16:42.414: INFO: Pod "pod-configmaps-bd57407f-91ce-447b-a8eb-cc3792132448": Phase="Pending", Reason="", readiness=false. Elapsed: 2.595515ms
Sep 15 19:16:44.416: INFO: Pod "pod-configmaps-bd57407f-91ce-447b-a8eb-cc3792132448": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005547249s
Sep 15 19:16:46.419: INFO: Pod "pod-configmaps-bd57407f-91ce-447b-a8eb-cc3792132448": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008145048s
STEP: Saw pod success
Sep 15 19:16:46.419: INFO: Pod "pod-configmaps-bd57407f-91ce-447b-a8eb-cc3792132448" satisfied condition "Succeeded or Failed"
Sep 15 19:16:46.421: INFO: Trying to get logs from node minion1 pod pod-configmaps-bd57407f-91ce-447b-a8eb-cc3792132448 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 19:16:46.432: INFO: Waiting for pod pod-configmaps-bd57407f-91ce-447b-a8eb-cc3792132448 to disappear
Sep 15 19:16:46.440: INFO: Pod pod-configmaps-bd57407f-91ce-447b-a8eb-cc3792132448 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:16:46.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5738" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":53,"skipped":717,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:16:46.445: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:16:46.475: INFO: Waiting up to 5m0s for pod "downwardapi-volume-983d2062-4f82-48d7-a44f-ab86cf7d9934" in namespace "downward-api-7470" to be "Succeeded or Failed"
Sep 15 19:16:46.485: INFO: Pod "downwardapi-volume-983d2062-4f82-48d7-a44f-ab86cf7d9934": Phase="Pending", Reason="", readiness=false. Elapsed: 9.511005ms
Sep 15 19:16:48.488: INFO: Pod "downwardapi-volume-983d2062-4f82-48d7-a44f-ab86cf7d9934": Phase="Running", Reason="", readiness=true. Elapsed: 2.012154143s
Sep 15 19:16:50.491: INFO: Pod "downwardapi-volume-983d2062-4f82-48d7-a44f-ab86cf7d9934": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015153964s
STEP: Saw pod success
Sep 15 19:16:50.491: INFO: Pod "downwardapi-volume-983d2062-4f82-48d7-a44f-ab86cf7d9934" satisfied condition "Succeeded or Failed"
Sep 15 19:16:50.492: INFO: Trying to get logs from node minion1 pod downwardapi-volume-983d2062-4f82-48d7-a44f-ab86cf7d9934 container client-container: <nil>
STEP: delete the pod
Sep 15 19:16:50.504: INFO: Waiting for pod downwardapi-volume-983d2062-4f82-48d7-a44f-ab86cf7d9934 to disappear
Sep 15 19:16:50.511: INFO: Pod downwardapi-volume-983d2062-4f82-48d7-a44f-ab86cf7d9934 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:16:50.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7470" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":54,"skipped":724,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:16:50.517: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 15 19:16:50.543: INFO: Waiting up to 5m0s for pod "pod-d0d6a6d7-b803-4825-922a-8b9ff9d499e6" in namespace "emptydir-8033" to be "Succeeded or Failed"
Sep 15 19:16:50.545: INFO: Pod "pod-d0d6a6d7-b803-4825-922a-8b9ff9d499e6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.755807ms
Sep 15 19:16:52.547: INFO: Pod "pod-d0d6a6d7-b803-4825-922a-8b9ff9d499e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00408746s
STEP: Saw pod success
Sep 15 19:16:52.547: INFO: Pod "pod-d0d6a6d7-b803-4825-922a-8b9ff9d499e6" satisfied condition "Succeeded or Failed"
Sep 15 19:16:52.549: INFO: Trying to get logs from node minion1 pod pod-d0d6a6d7-b803-4825-922a-8b9ff9d499e6 container test-container: <nil>
STEP: delete the pod
Sep 15 19:16:52.560: INFO: Waiting for pod pod-d0d6a6d7-b803-4825-922a-8b9ff9d499e6 to disappear
Sep 15 19:16:52.562: INFO: Pod pod-d0d6a6d7-b803-4825-922a-8b9ff9d499e6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:16:52.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8033" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":55,"skipped":729,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:16:52.568: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 15 19:16:55.115: INFO: Successfully updated pod "annotationupdate2b4b63ec-ac82-4c4e-a9dc-4a8ea8711d6b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:16:57.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-287" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":56,"skipped":740,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:16:57.133: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-a247c8ad-af75-4951-b360-01212a176f4c
STEP: Creating a pod to test consume secrets
Sep 15 19:16:57.161: INFO: Waiting up to 5m0s for pod "pod-secrets-db1de1d9-8f77-4b9f-b983-b62f3ca217e8" in namespace "secrets-9220" to be "Succeeded or Failed"
Sep 15 19:16:57.163: INFO: Pod "pod-secrets-db1de1d9-8f77-4b9f-b983-b62f3ca217e8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.559802ms
Sep 15 19:16:59.166: INFO: Pod "pod-secrets-db1de1d9-8f77-4b9f-b983-b62f3ca217e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004253413s
Sep 15 19:17:01.168: INFO: Pod "pod-secrets-db1de1d9-8f77-4b9f-b983-b62f3ca217e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006852104s
STEP: Saw pod success
Sep 15 19:17:01.168: INFO: Pod "pod-secrets-db1de1d9-8f77-4b9f-b983-b62f3ca217e8" satisfied condition "Succeeded or Failed"
Sep 15 19:17:01.171: INFO: Trying to get logs from node minion1 pod pod-secrets-db1de1d9-8f77-4b9f-b983-b62f3ca217e8 container secret-volume-test: <nil>
STEP: delete the pod
Sep 15 19:17:01.183: INFO: Waiting for pod pod-secrets-db1de1d9-8f77-4b9f-b983-b62f3ca217e8 to disappear
Sep 15 19:17:01.190: INFO: Pod pod-secrets-db1de1d9-8f77-4b9f-b983-b62f3ca217e8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:17:01.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9220" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":57,"skipped":860,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:17:01.197: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-1624
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1624 to expose endpoints map[]
Sep 15 19:17:01.235: INFO: Get endpoints failed (9.498899ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep 15 19:17:02.238: INFO: successfully validated that service multi-endpoint-test in namespace services-1624 exposes endpoints map[] (1.012074765s elapsed)
STEP: Creating pod pod1 in namespace services-1624
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1624 to expose endpoints map[pod1:[100]]
Sep 15 19:17:05.275: INFO: successfully validated that service multi-endpoint-test in namespace services-1624 exposes endpoints map[pod1:[100]] (3.027552043s elapsed)
STEP: Creating pod pod2 in namespace services-1624
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1624 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 15 19:17:07.302: INFO: successfully validated that service multi-endpoint-test in namespace services-1624 exposes endpoints map[pod1:[100] pod2:[101]] (2.023251044s elapsed)
STEP: Deleting pod pod1 in namespace services-1624
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1624 to expose endpoints map[pod2:[101]]
Sep 15 19:17:08.319: INFO: successfully validated that service multi-endpoint-test in namespace services-1624 exposes endpoints map[pod2:[101]] (1.014604837s elapsed)
STEP: Deleting pod pod2 in namespace services-1624
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1624 to expose endpoints map[]
Sep 15 19:17:09.328: INFO: successfully validated that service multi-endpoint-test in namespace services-1624 exposes endpoints map[] (1.005551666s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:17:09.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1624" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:8.150 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":277,"completed":58,"skipped":881,"failed":0}
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:17:09.348: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-77262497-8c1c-4304-be13-7cabc86eec39
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-77262497-8c1c-4304-be13-7cabc86eec39
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:17:13.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4172" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":59,"skipped":881,"failed":0}
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:17:13.411: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:17:15.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6652" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":60,"skipped":886,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:17:15.458: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-22ba08ed-20ed-4b8c-a7b7-f0f9ee9f410b
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:17:17.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3396" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":61,"skipped":939,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:17:17.522: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:17:17.565: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 15 19:17:17.569: INFO: Number of nodes with available pods: 0
Sep 15 19:17:17.569: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 15 19:17:17.593: INFO: Number of nodes with available pods: 0
Sep 15 19:17:17.593: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:18.596: INFO: Number of nodes with available pods: 0
Sep 15 19:17:18.596: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:19.596: INFO: Number of nodes with available pods: 0
Sep 15 19:17:19.596: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:20.595: INFO: Number of nodes with available pods: 1
Sep 15 19:17:20.595: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 15 19:17:20.614: INFO: Number of nodes with available pods: 1
Sep 15 19:17:20.614: INFO: Number of running nodes: 0, number of available pods: 1
Sep 15 19:17:21.617: INFO: Number of nodes with available pods: 0
Sep 15 19:17:21.617: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 15 19:17:21.624: INFO: Number of nodes with available pods: 0
Sep 15 19:17:21.624: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:22.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:22.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:23.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:23.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:24.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:24.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:25.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:25.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:26.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:26.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:27.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:27.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:28.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:28.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:29.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:29.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:30.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:30.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:31.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:31.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:32.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:32.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:33.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:33.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:34.627: INFO: Number of nodes with available pods: 0
Sep 15 19:17:34.627: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:35.627: INFO: Number of nodes with available pods: 1
Sep 15 19:17:35.627: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2163, will wait for the garbage collector to delete the pods
Sep 15 19:17:35.687: INFO: Deleting DaemonSet.extensions daemon-set took: 3.932199ms
Sep 15 19:17:36.087: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.219732ms
Sep 15 19:17:38.889: INFO: Number of nodes with available pods: 0
Sep 15 19:17:38.889: INFO: Number of running nodes: 0, number of available pods: 0
Sep 15 19:17:38.891: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2163/daemonsets","resourceVersion":"18671"},"items":null}

Sep 15 19:17:38.892: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2163/pods","resourceVersion":"18671"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:17:38.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2163" for this suite.

• [SLOW TEST:21.386 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":277,"completed":62,"skipped":979,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:17:38.908: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:17:38.934: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 15 19:17:39.954: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:17:40.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5818" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":277,"completed":63,"skipped":1005,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:17:40.965: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 15 19:17:41.014: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:17:41.016: INFO: Number of nodes with available pods: 0
Sep 15 19:17:41.016: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:42.020: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:17:42.022: INFO: Number of nodes with available pods: 0
Sep 15 19:17:42.022: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:43.020: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:17:43.021: INFO: Number of nodes with available pods: 2
Sep 15 19:17:43.021: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 15 19:17:43.030: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:17:43.033: INFO: Number of nodes with available pods: 1
Sep 15 19:17:43.033: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:44.037: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:17:44.040: INFO: Number of nodes with available pods: 1
Sep 15 19:17:44.040: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:45.037: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:17:45.039: INFO: Number of nodes with available pods: 1
Sep 15 19:17:45.039: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:17:46.037: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:17:46.039: INFO: Number of nodes with available pods: 2
Sep 15 19:17:46.039: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4705, will wait for the garbage collector to delete the pods
Sep 15 19:17:46.111: INFO: Deleting DaemonSet.extensions daemon-set took: 14.149098ms
Sep 15 19:17:46.511: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.230856ms
Sep 15 19:17:52.413: INFO: Number of nodes with available pods: 0
Sep 15 19:17:52.413: INFO: Number of running nodes: 0, number of available pods: 0
Sep 15 19:17:52.415: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4705/daemonsets","resourceVersion":"18863"},"items":null}

Sep 15 19:17:52.417: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4705/pods","resourceVersion":"18863"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:17:52.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4705" for this suite.

• [SLOW TEST:11.465 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":277,"completed":64,"skipped":1020,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:17:52.433: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:17:56.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5415" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":277,"completed":65,"skipped":1061,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:17:56.478: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:01.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7431" for this suite.

• [SLOW TEST:5.505 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":277,"completed":66,"skipped":1097,"failed":0}
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:01.983: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 15 19:18:02.002: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:06.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8987" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":277,"completed":67,"skipped":1097,"failed":0}
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:06.068: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 15 19:18:06.093: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 15 19:18:06.107: INFO: Waiting for terminating namespaces to be deleted...
Sep 15 19:18:06.109: INFO: 
Logging pods the kubelet thinks is on node minion1 before test
Sep 15 19:18:06.117: INFO: weave-net-sj6qn from kube-system started at 2020-09-15 17:49:49 +0000 UTC (2 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container weave ready: true, restart count 0
Sep 15 19:18:06.117: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 19:18:06.117: INFO: weave-scope-agent-wft6l from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 19:18:06.117: INFO: sonobuoy from sonobuoy started at 2020-09-15 19:07:01 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 15 19:18:06.117: INFO: kube-proxy-z8vzb from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 19:18:06.117: INFO: nodelocaldns-dk627 from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 19:18:06.117: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-2zszp from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 19:18:06.117: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 15 19:18:06.117: INFO: weave-scope-cluster-agent-7944c858c9-67nbc from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container scope-cluster-agent ready: true, restart count 0
Sep 15 19:18:06.117: INFO: pod-init-41b16bdc-242e-4d3f-8331-8082130a5c4d from init-container-8987 started at 2020-09-15 19:18:02 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container run1 ready: false, restart count 0
Sep 15 19:18:06.117: INFO: nginx-proxy-minion1 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container nginx-proxy ready: true, restart count 0
Sep 15 19:18:06.117: INFO: kubernetes-dashboard-667c4c65f8-pvn4d from kube-system started at 2020-09-15 17:50:15 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 15 19:18:06.117: INFO: kubernetes-metrics-scraper-54fbb4d595-8z4nb from kube-system started at 2020-09-15 17:50:15 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.117: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Sep 15 19:18:06.117: INFO: 
Logging pods the kubelet thinks is on node minion2 before test
Sep 15 19:18:06.123: INFO: nginx-proxy-minion2 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.123: INFO: 	Container nginx-proxy ready: true, restart count 0
Sep 15 19:18:06.123: INFO: weave-net-9ck4j from kube-system started at 2020-09-15 17:49:48 +0000 UTC (2 container statuses recorded)
Sep 15 19:18:06.123: INFO: 	Container weave ready: true, restart count 0
Sep 15 19:18:06.123: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 19:18:06.123: INFO: weave-scope-app-bc7444d59-mwtxs from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.123: INFO: 	Container app ready: true, restart count 0
Sep 15 19:18:06.123: INFO: nodelocaldns-d2gct from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.123: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 19:18:06.123: INFO: coredns-59dcc4799b-dpc9n from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.123: INFO: 	Container coredns ready: true, restart count 0
Sep 15 19:18:06.123: INFO: weave-scope-agent-wg887 from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.123: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 19:18:06.123: INFO: sonobuoy-e2e-job-874580613c114f91 from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 19:18:06.123: INFO: 	Container e2e ready: true, restart count 0
Sep 15 19:18:06.123: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 19:18:06.123: INFO: kube-proxy-5lm96 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 19:18:06.123: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 19:18:06.123: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-kwcxg from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 19:18:06.123: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 19:18:06.123: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16350b22a6dca991], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16350b22a79da5da], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:07.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6861" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":277,"completed":68,"skipped":1103,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:07.146: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Sep 15 19:18:07.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-9879 -- logs-generator --log-lines-total 100 --run-duration 20s'
Sep 15 19:18:07.234: INFO: stderr: ""
Sep 15 19:18:07.234: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Sep 15 19:18:07.234: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Sep 15 19:18:07.234: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-9879" to be "running and ready, or succeeded"
Sep 15 19:18:07.239: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.216337ms
Sep 15 19:18:09.241: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.007751542s
Sep 15 19:18:09.241: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Sep 15 19:18:09.241: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Sep 15 19:18:09.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 logs logs-generator logs-generator --namespace=kubectl-9879'
Sep 15 19:18:09.313: INFO: stderr: ""
Sep 15 19:18:09.313: INFO: stdout: "I0915 19:18:08.618023       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/n6f 550\nI0915 19:18:08.818267       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/dn5w 537\nI0915 19:18:09.018224       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/n8z9 327\nI0915 19:18:09.218239       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/2vs 423\n"
STEP: limiting log lines
Sep 15 19:18:09.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 logs logs-generator logs-generator --namespace=kubectl-9879 --tail=1'
Sep 15 19:18:09.384: INFO: stderr: ""
Sep 15 19:18:09.384: INFO: stdout: "I0915 19:18:09.218239       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/2vs 423\n"
Sep 15 19:18:09.384: INFO: got output "I0915 19:18:09.218239       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/2vs 423\n"
STEP: limiting log bytes
Sep 15 19:18:09.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 logs logs-generator logs-generator --namespace=kubectl-9879 --limit-bytes=1'
Sep 15 19:18:09.456: INFO: stderr: ""
Sep 15 19:18:09.456: INFO: stdout: "I"
Sep 15 19:18:09.456: INFO: got output "I"
STEP: exposing timestamps
Sep 15 19:18:09.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 logs logs-generator logs-generator --namespace=kubectl-9879 --tail=1 --timestamps'
Sep 15 19:18:09.527: INFO: stderr: ""
Sep 15 19:18:09.527: INFO: stdout: "2020-09-15T19:18:09.418395904Z I0915 19:18:09.418223       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/nhj4 467\n"
Sep 15 19:18:09.527: INFO: got output "2020-09-15T19:18:09.418395904Z I0915 19:18:09.418223       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/nhj4 467\n"
STEP: restricting to a time range
Sep 15 19:18:12.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 logs logs-generator logs-generator --namespace=kubectl-9879 --since=1s'
Sep 15 19:18:12.104: INFO: stderr: ""
Sep 15 19:18:12.104: INFO: stdout: "I0915 19:18:11.218172       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/v4k 387\nI0915 19:18:11.418238       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/zdss 594\nI0915 19:18:11.618301       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/n2k 558\nI0915 19:18:11.818197       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/64pr 396\nI0915 19:18:12.018218       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/fnlb 317\n"
Sep 15 19:18:12.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 logs logs-generator logs-generator --namespace=kubectl-9879 --since=24h'
Sep 15 19:18:12.175: INFO: stderr: ""
Sep 15 19:18:12.175: INFO: stdout: "I0915 19:18:08.618023       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/n6f 550\nI0915 19:18:08.818267       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/dn5w 537\nI0915 19:18:09.018224       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/n8z9 327\nI0915 19:18:09.218239       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/2vs 423\nI0915 19:18:09.418223       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/nhj4 467\nI0915 19:18:09.618174       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/ctbk 298\nI0915 19:18:09.818208       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/wkzg 363\nI0915 19:18:10.018208       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/7gt5 386\nI0915 19:18:10.218205       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/mpbx 558\nI0915 19:18:10.418207       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/n5t 499\nI0915 19:18:10.618201       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/xwb8 251\nI0915 19:18:10.818201       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/wpg 369\nI0915 19:18:11.018193       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/n9z 266\nI0915 19:18:11.218172       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/v4k 387\nI0915 19:18:11.418238       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/zdss 594\nI0915 19:18:11.618301       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/n2k 558\nI0915 19:18:11.818197       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/64pr 396\nI0915 19:18:12.018218       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/fnlb 317\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Sep 15 19:18:12.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete pod logs-generator --namespace=kubectl-9879'
Sep 15 19:18:22.331: INFO: stderr: ""
Sep 15 19:18:22.331: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:22.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9879" for this suite.

• [SLOW TEST:15.192 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1284
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":277,"completed":69,"skipped":1117,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:22.338: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-a07c8d76-5cc9-4a06-90ac-4fac3131f1c4
STEP: Creating secret with name s-test-opt-upd-204aef6e-c415-4731-bab1-3265de1b3d35
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a07c8d76-5cc9-4a06-90ac-4fac3131f1c4
STEP: Updating secret s-test-opt-upd-204aef6e-c415-4731-bab1-3265de1b3d35
STEP: Creating secret with name s-test-opt-create-453705d3-cde4-4e91-8bc8-3fea85415711
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:28.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2658" for this suite.

• [SLOW TEST:6.097 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":70,"skipped":1124,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:28.435: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-9d1f7377-7ecb-4c4b-ac98-9cb09ce7cce8
STEP: Creating secret with name s-test-opt-upd-a083d123-165b-49f8-b3bf-08aea4c15bce
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9d1f7377-7ecb-4c4b-ac98-9cb09ce7cce8
STEP: Updating secret s-test-opt-upd-a083d123-165b-49f8-b3bf-08aea4c15bce
STEP: Creating secret with name s-test-opt-create-352a598a-01af-4a26-9dd2-20567f663c98
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:34.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8074" for this suite.

• [SLOW TEST:6.097 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":71,"skipped":1129,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:34.532: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 19:18:34.942: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 19:18:36.949: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794314, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794314, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794314, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735794314, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 19:18:39.966: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:18:39.968: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4338-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:41.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5402" for this suite.
STEP: Destroying namespace "webhook-5402-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.514 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":277,"completed":72,"skipped":1159,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:41.047: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:41.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-599" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":277,"completed":73,"skipped":1184,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:41.097: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:44.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6801" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":277,"completed":74,"skipped":1203,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:44.155: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:18:46.208: INFO: Waiting up to 5m0s for pod "client-envvars-f7fca4c7-95ea-44a2-8e1d-4043f047a5ed" in namespace "pods-8599" to be "Succeeded or Failed"
Sep 15 19:18:46.219: INFO: Pod "client-envvars-f7fca4c7-95ea-44a2-8e1d-4043f047a5ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.408745ms
Sep 15 19:18:48.221: INFO: Pod "client-envvars-f7fca4c7-95ea-44a2-8e1d-4043f047a5ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012626196s
STEP: Saw pod success
Sep 15 19:18:48.221: INFO: Pod "client-envvars-f7fca4c7-95ea-44a2-8e1d-4043f047a5ed" satisfied condition "Succeeded or Failed"
Sep 15 19:18:48.222: INFO: Trying to get logs from node minion1 pod client-envvars-f7fca4c7-95ea-44a2-8e1d-4043f047a5ed container env3cont: <nil>
STEP: delete the pod
Sep 15 19:18:48.233: INFO: Waiting for pod client-envvars-f7fca4c7-95ea-44a2-8e1d-4043f047a5ed to disappear
Sep 15 19:18:48.241: INFO: Pod client-envvars-f7fca4c7-95ea-44a2-8e1d-4043f047a5ed no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:48.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8599" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":277,"completed":75,"skipped":1212,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:48.249: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 15 19:18:53.326: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:54.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8890" for this suite.

• [SLOW TEST:6.117 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":277,"completed":76,"skipped":1258,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:54.367: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:18:58.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3378" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":77,"skipped":1269,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:18:58.411: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:18:58.460: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"089619ed-e618-482d-99e4-2312ed971ce5", Controller:(*bool)(0xc0008a2fd6), BlockOwnerDeletion:(*bool)(0xc0008a2fd7)}}
Sep 15 19:18:58.464: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ed222d90-88b3-4e37-a63b-a942a34eb913", Controller:(*bool)(0xc00246d426), BlockOwnerDeletion:(*bool)(0xc00246d427)}}
Sep 15 19:18:58.473: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"938e12bf-2b39-4620-8099-9b0ce9572fe0", Controller:(*bool)(0xc00246d626), BlockOwnerDeletion:(*bool)(0xc00246d627)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:19:03.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-911" for this suite.

• [SLOW TEST:5.089 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":277,"completed":78,"skipped":1276,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:19:03.501: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Sep 15 19:19:08.050: INFO: Successfully updated pod "adopt-release-csr5f"
STEP: Checking that the Job readopts the Pod
Sep 15 19:19:08.050: INFO: Waiting up to 15m0s for pod "adopt-release-csr5f" in namespace "job-4934" to be "adopted"
Sep 15 19:19:08.054: INFO: Pod "adopt-release-csr5f": Phase="Running", Reason="", readiness=true. Elapsed: 4.073254ms
Sep 15 19:19:10.057: INFO: Pod "adopt-release-csr5f": Phase="Running", Reason="", readiness=true. Elapsed: 2.006824249s
Sep 15 19:19:10.057: INFO: Pod "adopt-release-csr5f" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Sep 15 19:19:10.564: INFO: Successfully updated pod "adopt-release-csr5f"
STEP: Checking that the Job releases the Pod
Sep 15 19:19:10.564: INFO: Waiting up to 15m0s for pod "adopt-release-csr5f" in namespace "job-4934" to be "released"
Sep 15 19:19:10.566: INFO: Pod "adopt-release-csr5f": Phase="Running", Reason="", readiness=true. Elapsed: 1.573866ms
Sep 15 19:19:12.569: INFO: Pod "adopt-release-csr5f": Phase="Running", Reason="", readiness=true. Elapsed: 2.004278568s
Sep 15 19:19:12.569: INFO: Pod "adopt-release-csr5f" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:19:12.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4934" for this suite.

• [SLOW TEST:9.074 seconds]
[sig-apps] Job
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":277,"completed":79,"skipped":1286,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:19:12.575: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-496a5889-8600-4e3d-9f87-d92d40bffbee
STEP: Creating a pod to test consume secrets
Sep 15 19:19:12.607: INFO: Waiting up to 5m0s for pod "pod-secrets-eb788f33-4655-40f0-9499-1aab3d9c48b8" in namespace "secrets-1990" to be "Succeeded or Failed"
Sep 15 19:19:12.609: INFO: Pod "pod-secrets-eb788f33-4655-40f0-9499-1aab3d9c48b8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.609518ms
Sep 15 19:19:14.611: INFO: Pod "pod-secrets-eb788f33-4655-40f0-9499-1aab3d9c48b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003745638s
Sep 15 19:19:16.614: INFO: Pod "pod-secrets-eb788f33-4655-40f0-9499-1aab3d9c48b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006396836s
STEP: Saw pod success
Sep 15 19:19:16.614: INFO: Pod "pod-secrets-eb788f33-4655-40f0-9499-1aab3d9c48b8" satisfied condition "Succeeded or Failed"
Sep 15 19:19:16.615: INFO: Trying to get logs from node minion1 pod pod-secrets-eb788f33-4655-40f0-9499-1aab3d9c48b8 container secret-env-test: <nil>
STEP: delete the pod
Sep 15 19:19:16.627: INFO: Waiting for pod pod-secrets-eb788f33-4655-40f0-9499-1aab3d9c48b8 to disappear
Sep 15 19:19:16.635: INFO: Pod pod-secrets-eb788f33-4655-40f0-9499-1aab3d9c48b8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:19:16.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1990" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":277,"completed":80,"skipped":1290,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:19:16.641: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:19:29.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7538" for this suite.

• [SLOW TEST:13.068 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":277,"completed":81,"skipped":1364,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:19:29.710: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-69955590-c90e-4818-a042-3cf4c132b750
STEP: Creating a pod to test consume secrets
Sep 15 19:19:29.739: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1ec57976-5c52-49f2-a068-948fb81d9d9a" in namespace "projected-3935" to be "Succeeded or Failed"
Sep 15 19:19:29.746: INFO: Pod "pod-projected-secrets-1ec57976-5c52-49f2-a068-948fb81d9d9a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.570978ms
Sep 15 19:19:31.748: INFO: Pod "pod-projected-secrets-1ec57976-5c52-49f2-a068-948fb81d9d9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008987758s
STEP: Saw pod success
Sep 15 19:19:31.748: INFO: Pod "pod-projected-secrets-1ec57976-5c52-49f2-a068-948fb81d9d9a" satisfied condition "Succeeded or Failed"
Sep 15 19:19:31.750: INFO: Trying to get logs from node minion1 pod pod-projected-secrets-1ec57976-5c52-49f2-a068-948fb81d9d9a container secret-volume-test: <nil>
STEP: delete the pod
Sep 15 19:19:31.761: INFO: Waiting for pod pod-projected-secrets-1ec57976-5c52-49f2-a068-948fb81d9d9a to disappear
Sep 15 19:19:31.769: INFO: Pod pod-projected-secrets-1ec57976-5c52-49f2-a068-948fb81d9d9a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:19:31.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3935" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":82,"skipped":1409,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:19:31.775: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 15 19:19:31.825: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1562 /api/v1/namespaces/watch-1562/configmaps/e2e-watch-test-resource-version 34bc955e-2b55-42fc-bd5a-118f4fcc3b3f 19872 0 2020-09-15 19:19:31 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-09-15 19:19:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:19:31.825: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1562 /api/v1/namespaces/watch-1562/configmaps/e2e-watch-test-resource-version 34bc955e-2b55-42fc-bd5a-118f4fcc3b3f 19873 0 2020-09-15 19:19:31 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-09-15 19:19:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:19:31.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1562" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":277,"completed":83,"skipped":1417,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:19:31.831: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Sep 15 19:19:31.857: INFO: Waiting up to 5m0s for pod "client-containers-1432eeb3-e992-47ae-95e4-0b06e26b1b46" in namespace "containers-8658" to be "Succeeded or Failed"
Sep 15 19:19:31.859: INFO: Pod "client-containers-1432eeb3-e992-47ae-95e4-0b06e26b1b46": Phase="Pending", Reason="", readiness=false. Elapsed: 1.63392ms
Sep 15 19:19:33.861: INFO: Pod "client-containers-1432eeb3-e992-47ae-95e4-0b06e26b1b46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004116227s
STEP: Saw pod success
Sep 15 19:19:33.861: INFO: Pod "client-containers-1432eeb3-e992-47ae-95e4-0b06e26b1b46" satisfied condition "Succeeded or Failed"
Sep 15 19:19:33.863: INFO: Trying to get logs from node minion1 pod client-containers-1432eeb3-e992-47ae-95e4-0b06e26b1b46 container test-container: <nil>
STEP: delete the pod
Sep 15 19:19:33.879: INFO: Waiting for pod client-containers-1432eeb3-e992-47ae-95e4-0b06e26b1b46 to disappear
Sep 15 19:19:33.883: INFO: Pod client-containers-1432eeb3-e992-47ae-95e4-0b06e26b1b46 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:19:33.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8658" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":277,"completed":84,"skipped":1499,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:19:33.889: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 15 19:19:35.929: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:19:35.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3479" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":85,"skipped":1515,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:19:35.942: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3027
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3027
I0915 19:19:35.988155      23 runners.go:190] Created replication controller with name: externalname-service, namespace: services-3027, replica count: 2
Sep 15 19:19:39.040: INFO: Creating new exec pod
I0915 19:19:39.040610      23 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 15 19:19:42.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-3027 execpodm5bm2 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 15 19:19:42.231: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 15 19:19:42.231: INFO: stdout: ""
Sep 15 19:19:42.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-3027 execpodm5bm2 -- /bin/sh -x -c nc -zv -t -w 2 10.241.169.87 80'
Sep 15 19:19:42.431: INFO: stderr: "+ nc -zv -t -w 2 10.241.169.87 80\nConnection to 10.241.169.87 80 port [tcp/http] succeeded!\n"
Sep 15 19:19:42.431: INFO: stdout: ""
Sep 15 19:19:42.431: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:19:42.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3027" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:6.510 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":277,"completed":86,"skipped":1518,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:19:42.453: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-29cd404f-af81-481a-9b28-1225a1743d6f in namespace container-probe-7826
Sep 15 19:19:46.486: INFO: Started pod liveness-29cd404f-af81-481a-9b28-1225a1743d6f in namespace container-probe-7826
STEP: checking the pod's current state and verifying that restartCount is present
Sep 15 19:19:46.488: INFO: Initial restart count of pod liveness-29cd404f-af81-481a-9b28-1225a1743d6f is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:23:46.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7826" for this suite.

• [SLOW TEST:244.378 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":277,"completed":87,"skipped":1551,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:23:46.831: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Sep 15 19:23:46.852: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 15 19:24:46.875: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:24:46.877: INFO: Starting informer...
STEP: Starting pod...
Sep 15 19:24:47.085: INFO: Pod is running on minion1. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Sep 15 19:24:47.095: INFO: Pod wasn't evicted. Proceeding
Sep 15 19:24:47.095: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Sep 15 19:26:02.112: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:26:02.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-4716" for this suite.

• [SLOW TEST:135.288 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":277,"completed":88,"skipped":1560,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:26:02.119: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-148ecb80-0f65-408c-9ccc-9c65e5533a3d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-148ecb80-0f65-408c-9ccc-9c65e5533a3d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:27:08.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8120" for this suite.

• [SLOW TEST:66.288 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":89,"skipped":1571,"failed":0}
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:27:08.407: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 15 19:27:08.425: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:27:11.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7837" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":277,"completed":90,"skipped":1573,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:27:11.675: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:27:11.702: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1125f21c-1ac9-45bd-87e7-d7b4a6444500" in namespace "projected-2641" to be "Succeeded or Failed"
Sep 15 19:27:11.704: INFO: Pod "downwardapi-volume-1125f21c-1ac9-45bd-87e7-d7b4a6444500": Phase="Pending", Reason="", readiness=false. Elapsed: 1.991614ms
Sep 15 19:27:13.706: INFO: Pod "downwardapi-volume-1125f21c-1ac9-45bd-87e7-d7b4a6444500": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004802064s
Sep 15 19:27:15.709: INFO: Pod "downwardapi-volume-1125f21c-1ac9-45bd-87e7-d7b4a6444500": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007745617s
STEP: Saw pod success
Sep 15 19:27:15.709: INFO: Pod "downwardapi-volume-1125f21c-1ac9-45bd-87e7-d7b4a6444500" satisfied condition "Succeeded or Failed"
Sep 15 19:27:15.711: INFO: Trying to get logs from node minion1 pod downwardapi-volume-1125f21c-1ac9-45bd-87e7-d7b4a6444500 container client-container: <nil>
STEP: delete the pod
Sep 15 19:27:15.723: INFO: Waiting for pod downwardapi-volume-1125f21c-1ac9-45bd-87e7-d7b4a6444500 to disappear
Sep 15 19:27:15.725: INFO: Pod downwardapi-volume-1125f21c-1ac9-45bd-87e7-d7b4a6444500 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:27:15.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2641" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":91,"skipped":1587,"failed":0}

------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:27:15.730: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-7e244275-a1ac-42b6-920d-d878e94c2b35 in namespace container-probe-7546
Sep 15 19:27:19.762: INFO: Started pod test-webserver-7e244275-a1ac-42b6-920d-d878e94c2b35 in namespace container-probe-7546
STEP: checking the pod's current state and verifying that restartCount is present
Sep 15 19:27:19.764: INFO: Initial restart count of pod test-webserver-7e244275-a1ac-42b6-920d-d878e94c2b35 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:31:20.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7546" for this suite.

• [SLOW TEST:244.373 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":92,"skipped":1587,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:31:20.103: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 15 19:31:20.130: INFO: Waiting up to 5m0s for pod "pod-d12176ae-f5c5-4d35-9980-a9588522d607" in namespace "emptydir-4628" to be "Succeeded or Failed"
Sep 15 19:31:20.133: INFO: Pod "pod-d12176ae-f5c5-4d35-9980-a9588522d607": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021852ms
Sep 15 19:31:22.135: INFO: Pod "pod-d12176ae-f5c5-4d35-9980-a9588522d607": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004752463s
Sep 15 19:31:24.138: INFO: Pod "pod-d12176ae-f5c5-4d35-9980-a9588522d607": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007312981s
STEP: Saw pod success
Sep 15 19:31:24.138: INFO: Pod "pod-d12176ae-f5c5-4d35-9980-a9588522d607" satisfied condition "Succeeded or Failed"
Sep 15 19:31:24.140: INFO: Trying to get logs from node minion1 pod pod-d12176ae-f5c5-4d35-9980-a9588522d607 container test-container: <nil>
STEP: delete the pod
Sep 15 19:31:24.159: INFO: Waiting for pod pod-d12176ae-f5c5-4d35-9980-a9588522d607 to disappear
Sep 15 19:31:24.167: INFO: Pod pod-d12176ae-f5c5-4d35-9980-a9588522d607 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:31:24.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4628" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":93,"skipped":1593,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:31:24.173: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2912.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2912.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2912.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2912.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2912.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2912.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2912.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2912.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2912.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2912.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 15 19:31:32.218: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local from pod dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f: the server could not find the requested resource (get pods dns-test-0a55dc01-ad03-460c-9923-a341521f438f)
Sep 15 19:31:32.220: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local from pod dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f: the server could not find the requested resource (get pods dns-test-0a55dc01-ad03-460c-9923-a341521f438f)
Sep 15 19:31:32.223: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-2912.svc.cluster.local from pod dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f: the server could not find the requested resource (get pods dns-test-0a55dc01-ad03-460c-9923-a341521f438f)
Sep 15 19:31:32.225: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-2912.svc.cluster.local from pod dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f: the server could not find the requested resource (get pods dns-test-0a55dc01-ad03-460c-9923-a341521f438f)
Sep 15 19:31:32.232: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local from pod dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f: the server could not find the requested resource (get pods dns-test-0a55dc01-ad03-460c-9923-a341521f438f)
Sep 15 19:31:32.235: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local from pod dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f: the server could not find the requested resource (get pods dns-test-0a55dc01-ad03-460c-9923-a341521f438f)
Sep 15 19:31:32.237: INFO: Unable to read jessie_udp@dns-test-service-2.dns-2912.svc.cluster.local from pod dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f: the server could not find the requested resource (get pods dns-test-0a55dc01-ad03-460c-9923-a341521f438f)
Sep 15 19:31:32.239: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-2912.svc.cluster.local from pod dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f: the server could not find the requested resource (get pods dns-test-0a55dc01-ad03-460c-9923-a341521f438f)
Sep 15 19:31:32.244: INFO: Lookups using dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local wheezy_udp@dns-test-service-2.dns-2912.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-2912.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2912.svc.cluster.local jessie_udp@dns-test-service-2.dns-2912.svc.cluster.local jessie_tcp@dns-test-service-2.dns-2912.svc.cluster.local]

Sep 15 19:31:37.272: INFO: DNS probes using dns-2912/dns-test-0a55dc01-ad03-460c-9923-a341521f438f succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:31:37.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2912" for this suite.

• [SLOW TEST:13.136 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":277,"completed":94,"skipped":1621,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:31:37.309: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:31:37.343: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19ae5c61-e55d-4d40-9000-0556d2726199" in namespace "downward-api-6461" to be "Succeeded or Failed"
Sep 15 19:31:37.345: INFO: Pod "downwardapi-volume-19ae5c61-e55d-4d40-9000-0556d2726199": Phase="Pending", Reason="", readiness=false. Elapsed: 1.575296ms
Sep 15 19:31:39.348: INFO: Pod "downwardapi-volume-19ae5c61-e55d-4d40-9000-0556d2726199": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004430608s
Sep 15 19:31:41.351: INFO: Pod "downwardapi-volume-19ae5c61-e55d-4d40-9000-0556d2726199": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007149313s
STEP: Saw pod success
Sep 15 19:31:41.351: INFO: Pod "downwardapi-volume-19ae5c61-e55d-4d40-9000-0556d2726199" satisfied condition "Succeeded or Failed"
Sep 15 19:31:41.353: INFO: Trying to get logs from node minion1 pod downwardapi-volume-19ae5c61-e55d-4d40-9000-0556d2726199 container client-container: <nil>
STEP: delete the pod
Sep 15 19:31:41.367: INFO: Waiting for pod downwardapi-volume-19ae5c61-e55d-4d40-9000-0556d2726199 to disappear
Sep 15 19:31:41.371: INFO: Pod downwardapi-volume-19ae5c61-e55d-4d40-9000-0556d2726199 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:31:41.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6461" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":95,"skipped":1622,"failed":0}
SSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:31:41.382: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:31:41.410: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-f41412b7-e305-43e6-9de2-37e594a3e568" in namespace "security-context-test-5954" to be "Succeeded or Failed"
Sep 15 19:31:41.411: INFO: Pod "busybox-readonly-false-f41412b7-e305-43e6-9de2-37e594a3e568": Phase="Pending", Reason="", readiness=false. Elapsed: 1.49726ms
Sep 15 19:31:43.414: INFO: Pod "busybox-readonly-false-f41412b7-e305-43e6-9de2-37e594a3e568": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004098114s
Sep 15 19:31:45.417: INFO: Pod "busybox-readonly-false-f41412b7-e305-43e6-9de2-37e594a3e568": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00696857s
Sep 15 19:31:45.417: INFO: Pod "busybox-readonly-false-f41412b7-e305-43e6-9de2-37e594a3e568" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:31:45.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5954" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":277,"completed":96,"skipped":1628,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:31:45.423: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 15 19:31:45.452: INFO: Waiting up to 5m0s for pod "pod-650cb7f4-149f-4f3d-a878-2395b896b358" in namespace "emptydir-3395" to be "Succeeded or Failed"
Sep 15 19:31:45.454: INFO: Pod "pod-650cb7f4-149f-4f3d-a878-2395b896b358": Phase="Pending", Reason="", readiness=false. Elapsed: 1.597496ms
Sep 15 19:31:47.456: INFO: Pod "pod-650cb7f4-149f-4f3d-a878-2395b896b358": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00438985s
Sep 15 19:31:49.459: INFO: Pod "pod-650cb7f4-149f-4f3d-a878-2395b896b358": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007232094s
STEP: Saw pod success
Sep 15 19:31:49.459: INFO: Pod "pod-650cb7f4-149f-4f3d-a878-2395b896b358" satisfied condition "Succeeded or Failed"
Sep 15 19:31:49.461: INFO: Trying to get logs from node minion1 pod pod-650cb7f4-149f-4f3d-a878-2395b896b358 container test-container: <nil>
STEP: delete the pod
Sep 15 19:31:49.472: INFO: Waiting for pod pod-650cb7f4-149f-4f3d-a878-2395b896b358 to disappear
Sep 15 19:31:49.480: INFO: Pod pod-650cb7f4-149f-4f3d-a878-2395b896b358 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:31:49.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3395" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":97,"skipped":1631,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:31:49.485: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1967
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Sep 15 19:31:49.519: INFO: Found 0 stateful pods, waiting for 3
Sep 15 19:31:59.523: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 19:31:59.523: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 19:31:59.523: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 15 19:31:59.543: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 15 19:32:09.568: INFO: Updating stateful set ss2
Sep 15 19:32:09.571: INFO: Waiting for Pod statefulset-1967/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 15 19:32:19.576: INFO: Waiting for Pod statefulset-1967/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Sep 15 19:32:29.620: INFO: Found 2 stateful pods, waiting for 3
Sep 15 19:32:39.623: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 19:32:39.623: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 19:32:39.623: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 15 19:32:39.642: INFO: Updating stateful set ss2
Sep 15 19:32:39.654: INFO: Waiting for Pod statefulset-1967/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 15 19:32:49.659: INFO: Waiting for Pod statefulset-1967/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 15 19:32:59.675: INFO: Updating stateful set ss2
Sep 15 19:32:59.678: INFO: Waiting for StatefulSet statefulset-1967/ss2 to complete update
Sep 15 19:32:59.678: INFO: Waiting for Pod statefulset-1967/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 15 19:33:09.683: INFO: Waiting for StatefulSet statefulset-1967/ss2 to complete update
Sep 15 19:33:09.683: INFO: Waiting for Pod statefulset-1967/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 15 19:33:19.683: INFO: Deleting all statefulset in ns statefulset-1967
Sep 15 19:33:19.685: INFO: Scaling statefulset ss2 to 0
Sep 15 19:33:39.694: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 19:33:39.696: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:33:39.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1967" for this suite.

• [SLOW TEST:110.224 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":277,"completed":98,"skipped":1647,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:33:39.710: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 15 19:33:41.747: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:33:41.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2126" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":277,"completed":99,"skipped":1656,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:33:41.766: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Sep 15 19:35:23.827: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:35:23.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8168" for this suite.

• [SLOW TEST:102.067 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":277,"completed":100,"skipped":1662,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:35:23.833: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-wl98
STEP: Creating a pod to test atomic-volume-subpath
Sep 15 19:35:23.870: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-wl98" in namespace "subpath-7723" to be "Succeeded or Failed"
Sep 15 19:35:23.872: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Pending", Reason="", readiness=false. Elapsed: 1.925499ms
Sep 15 19:35:25.875: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004901579s
Sep 15 19:35:27.878: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Running", Reason="", readiness=true. Elapsed: 4.007663901s
Sep 15 19:35:29.884: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Running", Reason="", readiness=true. Elapsed: 6.013586362s
Sep 15 19:35:31.886: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Running", Reason="", readiness=true. Elapsed: 8.01636431s
Sep 15 19:35:33.889: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Running", Reason="", readiness=true. Elapsed: 10.019137258s
Sep 15 19:35:35.892: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Running", Reason="", readiness=true. Elapsed: 12.021663475s
Sep 15 19:35:37.894: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Running", Reason="", readiness=true. Elapsed: 14.02436965s
Sep 15 19:35:39.897: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Running", Reason="", readiness=true. Elapsed: 16.027008395s
Sep 15 19:35:41.900: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Running", Reason="", readiness=true. Elapsed: 18.029779095s
Sep 15 19:35:43.902: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Running", Reason="", readiness=true. Elapsed: 20.032506015s
Sep 15 19:35:45.905: INFO: Pod "pod-subpath-test-downwardapi-wl98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.035229175s
STEP: Saw pod success
Sep 15 19:35:45.905: INFO: Pod "pod-subpath-test-downwardapi-wl98" satisfied condition "Succeeded or Failed"
Sep 15 19:35:45.907: INFO: Trying to get logs from node minion1 pod pod-subpath-test-downwardapi-wl98 container test-container-subpath-downwardapi-wl98: <nil>
STEP: delete the pod
Sep 15 19:35:45.931: INFO: Waiting for pod pod-subpath-test-downwardapi-wl98 to disappear
Sep 15 19:35:45.938: INFO: Pod pod-subpath-test-downwardapi-wl98 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-wl98
Sep 15 19:35:45.938: INFO: Deleting pod "pod-subpath-test-downwardapi-wl98" in namespace "subpath-7723"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:35:45.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7723" for this suite.

• [SLOW TEST:22.112 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":277,"completed":101,"skipped":1699,"failed":0}
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:35:45.946: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-6bnvp in namespace proxy-5750
I0915 19:35:45.987170      23 runners.go:190] Created replication controller with name: proxy-service-6bnvp, namespace: proxy-5750, replica count: 1
I0915 19:35:47.037627      23 runners.go:190] proxy-service-6bnvp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0915 19:35:48.037903      23 runners.go:190] proxy-service-6bnvp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0915 19:35:49.038188      23 runners.go:190] proxy-service-6bnvp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0915 19:35:50.038400      23 runners.go:190] proxy-service-6bnvp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 15 19:35:50.040: INFO: setup took 4.074634945s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 15 19:35:50.048: INFO: (0) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 6.766668ms)
Sep 15 19:35:50.048: INFO: (0) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 7.390443ms)
Sep 15 19:35:50.048: INFO: (0) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 7.956152ms)
Sep 15 19:35:50.048: INFO: (0) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 7.800785ms)
Sep 15 19:35:50.049: INFO: (0) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 8.758428ms)
Sep 15 19:35:50.050: INFO: (0) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 9.257084ms)
Sep 15 19:35:50.050: INFO: (0) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 8.94134ms)
Sep 15 19:35:50.050: INFO: (0) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 8.582882ms)
Sep 15 19:35:50.052: INFO: (0) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 10.733588ms)
Sep 15 19:35:50.052: INFO: (0) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 10.65719ms)
Sep 15 19:35:50.054: INFO: (0) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 12.699138ms)
Sep 15 19:35:50.054: INFO: (0) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 13.468154ms)
Sep 15 19:35:50.054: INFO: (0) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 13.028591ms)
Sep 15 19:35:50.055: INFO: (0) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 13.585467ms)
Sep 15 19:35:50.055: INFO: (0) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 14.072704ms)
Sep 15 19:35:50.056: INFO: (0) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 14.493328ms)
Sep 15 19:35:50.058: INFO: (1) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 2.646389ms)
Sep 15 19:35:50.059: INFO: (1) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 3.046423ms)
Sep 15 19:35:50.062: INFO: (1) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 6.109839ms)
Sep 15 19:35:50.062: INFO: (1) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 6.243896ms)
Sep 15 19:35:50.062: INFO: (1) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.391655ms)
Sep 15 19:35:50.063: INFO: (1) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 6.588925ms)
Sep 15 19:35:50.063: INFO: (1) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 7.02221ms)
Sep 15 19:35:50.063: INFO: (1) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 7.025192ms)
Sep 15 19:35:50.063: INFO: (1) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.899783ms)
Sep 15 19:35:50.063: INFO: (1) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 6.975526ms)
Sep 15 19:35:50.063: INFO: (1) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 7.03031ms)
Sep 15 19:35:50.063: INFO: (1) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 7.040058ms)
Sep 15 19:35:50.063: INFO: (1) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 7.192258ms)
Sep 15 19:35:50.064: INFO: (1) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 8.266541ms)
Sep 15 19:35:50.064: INFO: (1) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 8.42826ms)
Sep 15 19:35:50.064: INFO: (1) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 8.418277ms)
Sep 15 19:35:50.069: INFO: (2) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 4.653689ms)
Sep 15 19:35:50.070: INFO: (2) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 4.91042ms)
Sep 15 19:35:50.070: INFO: (2) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 5.183904ms)
Sep 15 19:35:50.070: INFO: (2) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 5.364806ms)
Sep 15 19:35:50.070: INFO: (2) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 5.572366ms)
Sep 15 19:35:50.070: INFO: (2) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 4.969478ms)
Sep 15 19:35:50.070: INFO: (2) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 5.675437ms)
Sep 15 19:35:50.070: INFO: (2) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 5.89908ms)
Sep 15 19:35:50.070: INFO: (2) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 5.863077ms)
Sep 15 19:35:50.070: INFO: (2) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 5.625273ms)
Sep 15 19:35:50.071: INFO: (2) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 6.170898ms)
Sep 15 19:35:50.071: INFO: (2) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 6.38579ms)
Sep 15 19:35:50.072: INFO: (2) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 7.703631ms)
Sep 15 19:35:50.072: INFO: (2) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 7.984884ms)
Sep 15 19:35:50.072: INFO: (2) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 7.922935ms)
Sep 15 19:35:50.073: INFO: (2) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 8.41936ms)
Sep 15 19:35:50.076: INFO: (3) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 2.854111ms)
Sep 15 19:35:50.076: INFO: (3) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 3.152982ms)
Sep 15 19:35:50.077: INFO: (3) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 3.191516ms)
Sep 15 19:35:50.080: INFO: (3) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 6.656218ms)
Sep 15 19:35:50.080: INFO: (3) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 7.389782ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 7.132596ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 7.547656ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 6.690327ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 6.665095ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 6.950751ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 7.559484ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 8.071998ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 7.801915ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 7.131687ms)
Sep 15 19:35:50.081: INFO: (3) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 7.302843ms)
Sep 15 19:35:50.082: INFO: (3) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 8.468185ms)
Sep 15 19:35:50.087: INFO: (4) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 4.657342ms)
Sep 15 19:35:50.087: INFO: (4) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 4.621005ms)
Sep 15 19:35:50.087: INFO: (4) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 4.674854ms)
Sep 15 19:35:50.087: INFO: (4) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 4.586888ms)
Sep 15 19:35:50.087: INFO: (4) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 4.761516ms)
Sep 15 19:35:50.087: INFO: (4) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 4.595489ms)
Sep 15 19:35:50.087: INFO: (4) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 4.691648ms)
Sep 15 19:35:50.088: INFO: (4) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 5.609187ms)
Sep 15 19:35:50.088: INFO: (4) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 5.909344ms)
Sep 15 19:35:50.088: INFO: (4) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 5.742529ms)
Sep 15 19:35:50.089: INFO: (4) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 7.257103ms)
Sep 15 19:35:50.090: INFO: (4) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 7.558812ms)
Sep 15 19:35:50.090: INFO: (4) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 7.731274ms)
Sep 15 19:35:50.090: INFO: (4) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 7.720929ms)
Sep 15 19:35:50.090: INFO: (4) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 7.697484ms)
Sep 15 19:35:50.090: INFO: (4) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 7.836765ms)
Sep 15 19:35:50.094: INFO: (5) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 3.197095ms)
Sep 15 19:35:50.094: INFO: (5) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 3.404584ms)
Sep 15 19:35:50.094: INFO: (5) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 3.483552ms)
Sep 15 19:35:50.098: INFO: (5) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 7.885975ms)
Sep 15 19:35:50.098: INFO: (5) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 7.652324ms)
Sep 15 19:35:50.099: INFO: (5) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 8.020882ms)
Sep 15 19:35:50.099: INFO: (5) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 8.218596ms)
Sep 15 19:35:50.099: INFO: (5) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 7.980777ms)
Sep 15 19:35:50.099: INFO: (5) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 8.04285ms)
Sep 15 19:35:50.099: INFO: (5) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 8.538574ms)
Sep 15 19:35:50.099: INFO: (5) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 8.711583ms)
Sep 15 19:35:50.100: INFO: (5) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 9.005867ms)
Sep 15 19:35:50.100: INFO: (5) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 9.06323ms)
Sep 15 19:35:50.100: INFO: (5) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 9.180791ms)
Sep 15 19:35:50.100: INFO: (5) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 9.604357ms)
Sep 15 19:35:50.100: INFO: (5) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 9.375073ms)
Sep 15 19:35:50.106: INFO: (6) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 4.970368ms)
Sep 15 19:35:50.106: INFO: (6) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 5.565509ms)
Sep 15 19:35:50.106: INFO: (6) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 6.126979ms)
Sep 15 19:35:50.106: INFO: (6) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 5.885759ms)
Sep 15 19:35:50.106: INFO: (6) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 5.919301ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 6.081475ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 6.068438ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.213247ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 6.500597ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 6.131686ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.185626ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 6.352656ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 6.774563ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 7.015867ms)
Sep 15 19:35:50.107: INFO: (6) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 7.016655ms)
Sep 15 19:35:50.108: INFO: (6) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 7.153682ms)
Sep 15 19:35:50.119: INFO: (7) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 11.129606ms)
Sep 15 19:35:50.119: INFO: (7) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 10.179435ms)
Sep 15 19:35:50.119: INFO: (7) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 11.268821ms)
Sep 15 19:35:50.119: INFO: (7) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 10.846605ms)
Sep 15 19:35:50.119: INFO: (7) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 10.781033ms)
Sep 15 19:35:50.119: INFO: (7) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 10.971396ms)
Sep 15 19:35:50.119: INFO: (7) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 11.156886ms)
Sep 15 19:35:50.119: INFO: (7) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 10.488688ms)
Sep 15 19:35:50.120: INFO: (7) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 10.882856ms)
Sep 15 19:35:50.120: INFO: (7) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 11.899629ms)
Sep 15 19:35:50.120: INFO: (7) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 10.984203ms)
Sep 15 19:35:50.122: INFO: (7) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 13.340066ms)
Sep 15 19:35:50.122: INFO: (7) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 13.957843ms)
Sep 15 19:35:50.122: INFO: (7) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 13.97553ms)
Sep 15 19:35:50.122: INFO: (7) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 13.15196ms)
Sep 15 19:35:50.122: INFO: (7) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 13.257551ms)
Sep 15 19:35:50.126: INFO: (8) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 3.674389ms)
Sep 15 19:35:50.126: INFO: (8) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 3.777096ms)
Sep 15 19:35:50.126: INFO: (8) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 3.648411ms)
Sep 15 19:35:50.126: INFO: (8) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 4.25213ms)
Sep 15 19:35:50.129: INFO: (8) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 6.996593ms)
Sep 15 19:35:50.129: INFO: (8) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 6.525813ms)
Sep 15 19:35:50.129: INFO: (8) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 6.950367ms)
Sep 15 19:35:50.130: INFO: (8) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 7.406779ms)
Sep 15 19:35:50.130: INFO: (8) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 6.574502ms)
Sep 15 19:35:50.130: INFO: (8) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 6.840695ms)
Sep 15 19:35:50.130: INFO: (8) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 7.034226ms)
Sep 15 19:35:50.130: INFO: (8) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 7.747331ms)
Sep 15 19:35:50.130: INFO: (8) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 6.435939ms)
Sep 15 19:35:50.131: INFO: (8) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 8.01019ms)
Sep 15 19:35:50.131: INFO: (8) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 7.725697ms)
Sep 15 19:35:50.131: INFO: (8) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 7.902726ms)
Sep 15 19:35:50.138: INFO: (9) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 7.262139ms)
Sep 15 19:35:50.139: INFO: (9) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 7.293118ms)
Sep 15 19:35:50.139: INFO: (9) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 7.289324ms)
Sep 15 19:35:50.139: INFO: (9) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 7.324915ms)
Sep 15 19:35:50.139: INFO: (9) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 7.742376ms)
Sep 15 19:35:50.139: INFO: (9) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 7.694031ms)
Sep 15 19:35:50.139: INFO: (9) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 7.961801ms)
Sep 15 19:35:50.139: INFO: (9) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 7.941776ms)
Sep 15 19:35:50.140: INFO: (9) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 9.13266ms)
Sep 15 19:35:50.140: INFO: (9) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 9.259901ms)
Sep 15 19:35:50.140: INFO: (9) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 9.121937ms)
Sep 15 19:35:50.140: INFO: (9) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 9.174945ms)
Sep 15 19:35:50.140: INFO: (9) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 9.271493ms)
Sep 15 19:35:50.140: INFO: (9) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 9.252027ms)
Sep 15 19:35:50.141: INFO: (9) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 9.215212ms)
Sep 15 19:35:50.141: INFO: (9) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 9.280324ms)
Sep 15 19:35:50.148: INFO: (10) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 7.125809ms)
Sep 15 19:35:50.149: INFO: (10) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 7.705217ms)
Sep 15 19:35:50.149: INFO: (10) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 7.603351ms)
Sep 15 19:35:50.149: INFO: (10) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 7.903835ms)
Sep 15 19:35:50.149: INFO: (10) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 7.748482ms)
Sep 15 19:35:50.149: INFO: (10) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 7.906607ms)
Sep 15 19:35:50.149: INFO: (10) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 7.706676ms)
Sep 15 19:35:50.149: INFO: (10) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 7.677082ms)
Sep 15 19:35:50.152: INFO: (10) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 10.809225ms)
Sep 15 19:35:50.152: INFO: (10) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 11.038274ms)
Sep 15 19:35:50.152: INFO: (10) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 10.757797ms)
Sep 15 19:35:50.152: INFO: (10) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 10.737097ms)
Sep 15 19:35:50.152: INFO: (10) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 10.741258ms)
Sep 15 19:35:50.152: INFO: (10) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 10.803565ms)
Sep 15 19:35:50.152: INFO: (10) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 10.918706ms)
Sep 15 19:35:50.152: INFO: (10) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 10.72679ms)
Sep 15 19:35:50.156: INFO: (11) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 3.091023ms)
Sep 15 19:35:50.156: INFO: (11) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 3.238073ms)
Sep 15 19:35:50.159: INFO: (11) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.066778ms)
Sep 15 19:35:50.159: INFO: (11) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 6.211965ms)
Sep 15 19:35:50.159: INFO: (11) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 6.420434ms)
Sep 15 19:35:50.159: INFO: (11) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 6.465881ms)
Sep 15 19:35:50.159: INFO: (11) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 6.412222ms)
Sep 15 19:35:50.159: INFO: (11) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 6.420773ms)
Sep 15 19:35:50.160: INFO: (11) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.547871ms)
Sep 15 19:35:50.160: INFO: (11) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 6.70016ms)
Sep 15 19:35:50.160: INFO: (11) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 6.768713ms)
Sep 15 19:35:50.160: INFO: (11) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 6.735964ms)
Sep 15 19:35:50.161: INFO: (11) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 8.545361ms)
Sep 15 19:35:50.162: INFO: (11) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 9.303521ms)
Sep 15 19:35:50.162: INFO: (11) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 9.477249ms)
Sep 15 19:35:50.162: INFO: (11) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 9.385002ms)
Sep 15 19:35:50.166: INFO: (12) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 3.906658ms)
Sep 15 19:35:50.167: INFO: (12) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 4.229837ms)
Sep 15 19:35:50.167: INFO: (12) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 4.111074ms)
Sep 15 19:35:50.167: INFO: (12) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 4.940642ms)
Sep 15 19:35:50.168: INFO: (12) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 5.08781ms)
Sep 15 19:35:50.168: INFO: (12) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 4.619136ms)
Sep 15 19:35:50.168: INFO: (12) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 5.031409ms)
Sep 15 19:35:50.168: INFO: (12) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 5.009452ms)
Sep 15 19:35:50.170: INFO: (12) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 6.449366ms)
Sep 15 19:35:50.170: INFO: (12) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 7.001018ms)
Sep 15 19:35:50.170: INFO: (12) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 7.440822ms)
Sep 15 19:35:50.170: INFO: (12) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 7.381076ms)
Sep 15 19:35:50.170: INFO: (12) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 7.298117ms)
Sep 15 19:35:50.170: INFO: (12) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 7.798964ms)
Sep 15 19:35:50.170: INFO: (12) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 6.638846ms)
Sep 15 19:35:50.170: INFO: (12) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 8.121942ms)
Sep 15 19:35:50.176: INFO: (13) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 5.238478ms)
Sep 15 19:35:50.176: INFO: (13) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 5.256978ms)
Sep 15 19:35:50.177: INFO: (13) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.596148ms)
Sep 15 19:35:50.177: INFO: (13) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 6.554846ms)
Sep 15 19:35:50.177: INFO: (13) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 6.565301ms)
Sep 15 19:35:50.177: INFO: (13) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 6.841775ms)
Sep 15 19:35:50.177: INFO: (13) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 6.850194ms)
Sep 15 19:35:50.178: INFO: (13) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 6.967052ms)
Sep 15 19:35:50.178: INFO: (13) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 7.283625ms)
Sep 15 19:35:50.178: INFO: (13) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 7.513935ms)
Sep 15 19:35:50.178: INFO: (13) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 7.958895ms)
Sep 15 19:35:50.178: INFO: (13) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 7.884706ms)
Sep 15 19:35:50.178: INFO: (13) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 7.861041ms)
Sep 15 19:35:50.179: INFO: (13) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 8.37112ms)
Sep 15 19:35:50.179: INFO: (13) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 8.330831ms)
Sep 15 19:35:50.179: INFO: (13) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 8.750507ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 5.382389ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 5.598107ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 5.342451ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 5.208627ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 5.392628ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 5.544695ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 5.484205ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 5.516979ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 5.236033ms)
Sep 15 19:35:50.185: INFO: (14) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 5.62107ms)
Sep 15 19:35:50.187: INFO: (14) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 6.83416ms)
Sep 15 19:35:50.187: INFO: (14) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 6.768599ms)
Sep 15 19:35:50.187: INFO: (14) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 7.314934ms)
Sep 15 19:35:50.187: INFO: (14) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 7.181701ms)
Sep 15 19:35:50.187: INFO: (14) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 8.053758ms)
Sep 15 19:35:50.187: INFO: (14) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 8.138799ms)
Sep 15 19:35:50.192: INFO: (15) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 4.258645ms)
Sep 15 19:35:50.192: INFO: (15) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 4.411928ms)
Sep 15 19:35:50.192: INFO: (15) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 4.441126ms)
Sep 15 19:35:50.193: INFO: (15) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 5.125956ms)
Sep 15 19:35:50.193: INFO: (15) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 5.869442ms)
Sep 15 19:35:50.194: INFO: (15) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 5.986456ms)
Sep 15 19:35:50.194: INFO: (15) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 6.031917ms)
Sep 15 19:35:50.194: INFO: (15) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 6.222461ms)
Sep 15 19:35:50.194: INFO: (15) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 6.198165ms)
Sep 15 19:35:50.194: INFO: (15) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 6.233283ms)
Sep 15 19:35:50.194: INFO: (15) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 6.147394ms)
Sep 15 19:35:50.194: INFO: (15) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 6.354998ms)
Sep 15 19:35:50.194: INFO: (15) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 6.504188ms)
Sep 15 19:35:50.194: INFO: (15) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 6.594817ms)
Sep 15 19:35:50.195: INFO: (15) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 7.160362ms)
Sep 15 19:35:50.195: INFO: (15) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 7.119622ms)
Sep 15 19:35:50.199: INFO: (16) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 3.923538ms)
Sep 15 19:35:50.199: INFO: (16) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 3.83161ms)
Sep 15 19:35:50.199: INFO: (16) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 3.673967ms)
Sep 15 19:35:50.200: INFO: (16) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 5.144703ms)
Sep 15 19:35:50.200: INFO: (16) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 5.411235ms)
Sep 15 19:35:50.201: INFO: (16) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 5.372472ms)
Sep 15 19:35:50.201: INFO: (16) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 5.704466ms)
Sep 15 19:35:50.201: INFO: (16) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 5.693152ms)
Sep 15 19:35:50.201: INFO: (16) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 5.827882ms)
Sep 15 19:35:50.201: INFO: (16) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 5.880362ms)
Sep 15 19:35:50.203: INFO: (16) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 8.050899ms)
Sep 15 19:35:50.203: INFO: (16) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 8.205951ms)
Sep 15 19:35:50.203: INFO: (16) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 8.065527ms)
Sep 15 19:35:50.203: INFO: (16) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 8.010729ms)
Sep 15 19:35:50.203: INFO: (16) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 8.240764ms)
Sep 15 19:35:50.204: INFO: (16) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 8.686084ms)
Sep 15 19:35:50.208: INFO: (17) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 4.173879ms)
Sep 15 19:35:50.208: INFO: (17) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 4.380137ms)
Sep 15 19:35:50.210: INFO: (17) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 6.064033ms)
Sep 15 19:35:50.210: INFO: (17) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 5.903982ms)
Sep 15 19:35:50.210: INFO: (17) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 6.043354ms)
Sep 15 19:35:50.210: INFO: (17) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.046606ms)
Sep 15 19:35:50.210: INFO: (17) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 6.118313ms)
Sep 15 19:35:50.210: INFO: (17) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 6.194301ms)
Sep 15 19:35:50.210: INFO: (17) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 6.148254ms)
Sep 15 19:35:50.210: INFO: (17) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.214698ms)
Sep 15 19:35:50.210: INFO: (17) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 6.490781ms)
Sep 15 19:35:50.211: INFO: (17) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 7.090167ms)
Sep 15 19:35:50.211: INFO: (17) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 7.19299ms)
Sep 15 19:35:50.211: INFO: (17) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 7.495903ms)
Sep 15 19:35:50.211: INFO: (17) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 7.516788ms)
Sep 15 19:35:50.211: INFO: (17) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 7.353829ms)
Sep 15 19:35:50.215: INFO: (18) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 3.397211ms)
Sep 15 19:35:50.215: INFO: (18) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 3.582489ms)
Sep 15 19:35:50.218: INFO: (18) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 6.286104ms)
Sep 15 19:35:50.218: INFO: (18) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 6.506481ms)
Sep 15 19:35:50.218: INFO: (18) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 6.34533ms)
Sep 15 19:35:50.218: INFO: (18) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 5.835002ms)
Sep 15 19:35:50.219: INFO: (18) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 7.419646ms)
Sep 15 19:35:50.219: INFO: (18) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 7.5286ms)
Sep 15 19:35:50.219: INFO: (18) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 7.69361ms)
Sep 15 19:35:50.219: INFO: (18) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 7.751343ms)
Sep 15 19:35:50.219: INFO: (18) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 7.801387ms)
Sep 15 19:35:50.219: INFO: (18) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 7.911057ms)
Sep 15 19:35:50.219: INFO: (18) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 7.732525ms)
Sep 15 19:35:50.219: INFO: (18) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 7.982725ms)
Sep 15 19:35:50.220: INFO: (18) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 8.406004ms)
Sep 15 19:35:50.220: INFO: (18) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 8.321389ms)
Sep 15 19:35:50.228: INFO: (19) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname2/proxy/: bar (200; 8.062726ms)
Sep 15 19:35:50.228: INFO: (19) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 8.044467ms)
Sep 15 19:35:50.228: INFO: (19) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">... (200; 8.257059ms)
Sep 15 19:35:50.228: INFO: (19) /api/v1/namespaces/proxy-5750/services/proxy-service-6bnvp:portname1/proxy/: foo (200; 8.409024ms)
Sep 15 19:35:50.229: INFO: (19) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:443/proxy/tlsrewritem... (200; 8.62386ms)
Sep 15 19:35:50.229: INFO: (19) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:1080/proxy/rewriteme">test<... (200; 8.650796ms)
Sep 15 19:35:50.229: INFO: (19) /api/v1/namespaces/proxy-5750/pods/http:proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 9.039637ms)
Sep 15 19:35:50.229: INFO: (19) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname1/proxy/: tls baz (200; 9.066198ms)
Sep 15 19:35:50.229: INFO: (19) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/: <a href="/api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4/proxy/rewriteme">test</a> (200; 9.307981ms)
Sep 15 19:35:50.230: INFO: (19) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:160/proxy/: foo (200; 9.386364ms)
Sep 15 19:35:50.230: INFO: (19) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname2/proxy/: bar (200; 9.632998ms)
Sep 15 19:35:50.230: INFO: (19) /api/v1/namespaces/proxy-5750/services/http:proxy-service-6bnvp:portname1/proxy/: foo (200; 9.619719ms)
Sep 15 19:35:50.230: INFO: (19) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:462/proxy/: tls qux (200; 9.773234ms)
Sep 15 19:35:50.230: INFO: (19) /api/v1/namespaces/proxy-5750/pods/https:proxy-service-6bnvp-slgp4:460/proxy/: tls baz (200; 9.857113ms)
Sep 15 19:35:50.230: INFO: (19) /api/v1/namespaces/proxy-5750/services/https:proxy-service-6bnvp:tlsportname2/proxy/: tls qux (200; 9.767215ms)
Sep 15 19:35:50.231: INFO: (19) /api/v1/namespaces/proxy-5750/pods/proxy-service-6bnvp-slgp4:162/proxy/: bar (200; 10.619952ms)
STEP: deleting ReplicationController proxy-service-6bnvp in namespace proxy-5750, will wait for the garbage collector to delete the pods
Sep 15 19:35:50.287: INFO: Deleting ReplicationController proxy-service-6bnvp took: 4.024495ms
Sep 15 19:35:50.687: INFO: Terminating ReplicationController proxy-service-6bnvp pods took: 400.304637ms
[AfterEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:35:53.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5750" for this suite.

• [SLOW TEST:7.248 seconds]
[sig-network] Proxy
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":277,"completed":102,"skipped":1702,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:35:53.194: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-6321d6f3-8fd3-47f4-8c8f-f00f85221135
STEP: Creating a pod to test consume configMaps
Sep 15 19:35:53.224: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ce01a8ac-cf45-4fc3-a665-d06fde8f8989" in namespace "projected-2354" to be "Succeeded or Failed"
Sep 15 19:35:53.226: INFO: Pod "pod-projected-configmaps-ce01a8ac-cf45-4fc3-a665-d06fde8f8989": Phase="Pending", Reason="", readiness=false. Elapsed: 2.279219ms
Sep 15 19:35:55.229: INFO: Pod "pod-projected-configmaps-ce01a8ac-cf45-4fc3-a665-d06fde8f8989": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004696905s
STEP: Saw pod success
Sep 15 19:35:55.229: INFO: Pod "pod-projected-configmaps-ce01a8ac-cf45-4fc3-a665-d06fde8f8989" satisfied condition "Succeeded or Failed"
Sep 15 19:35:55.230: INFO: Trying to get logs from node minion1 pod pod-projected-configmaps-ce01a8ac-cf45-4fc3-a665-d06fde8f8989 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 19:35:55.242: INFO: Waiting for pod pod-projected-configmaps-ce01a8ac-cf45-4fc3-a665-d06fde8f8989 to disappear
Sep 15 19:35:55.249: INFO: Pod pod-projected-configmaps-ce01a8ac-cf45-4fc3-a665-d06fde8f8989 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:35:55.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2354" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":103,"skipped":1710,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:35:55.255: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:35:55.276: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9612
I0915 19:35:55.284420      23 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9612, replica count: 1
I0915 19:35:56.334936      23 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0915 19:35:57.335178      23 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 15 19:35:57.441: INFO: Created: latency-svc-nvrgn
Sep 15 19:35:57.450: INFO: Got endpoints: latency-svc-nvrgn [15.355413ms]
Sep 15 19:35:57.461: INFO: Created: latency-svc-dd7h5
Sep 15 19:35:57.470: INFO: Got endpoints: latency-svc-dd7h5 [19.783984ms]
Sep 15 19:35:57.472: INFO: Created: latency-svc-n4qrp
Sep 15 19:35:57.480: INFO: Got endpoints: latency-svc-n4qrp [29.791474ms]
Sep 15 19:35:57.482: INFO: Created: latency-svc-tk6mq
Sep 15 19:35:57.492: INFO: Got endpoints: latency-svc-tk6mq [41.588358ms]
Sep 15 19:35:57.501: INFO: Created: latency-svc-bzggz
Sep 15 19:35:57.511: INFO: Got endpoints: latency-svc-bzggz [60.542352ms]
Sep 15 19:35:57.514: INFO: Created: latency-svc-bxrvd
Sep 15 19:35:57.523: INFO: Got endpoints: latency-svc-bxrvd [72.53763ms]
Sep 15 19:35:57.525: INFO: Created: latency-svc-q7kkj
Sep 15 19:35:57.534: INFO: Got endpoints: latency-svc-q7kkj [82.958897ms]
Sep 15 19:35:57.544: INFO: Created: latency-svc-7j657
Sep 15 19:35:57.553: INFO: Got endpoints: latency-svc-7j657 [101.543655ms]
Sep 15 19:35:57.555: INFO: Created: latency-svc-ndpzm
Sep 15 19:35:57.563: INFO: Got endpoints: latency-svc-ndpzm [112.051823ms]
Sep 15 19:35:57.564: INFO: Created: latency-svc-gc8t5
Sep 15 19:35:57.573: INFO: Got endpoints: latency-svc-gc8t5 [122.650596ms]
Sep 15 19:35:57.577: INFO: Created: latency-svc-s5lpx
Sep 15 19:35:57.584: INFO: Got endpoints: latency-svc-s5lpx [133.201289ms]
Sep 15 19:35:57.586: INFO: Created: latency-svc-mwx2w
Sep 15 19:35:57.594: INFO: Got endpoints: latency-svc-mwx2w [143.264759ms]
Sep 15 19:35:57.596: INFO: Created: latency-svc-xc9k2
Sep 15 19:35:57.605: INFO: Got endpoints: latency-svc-xc9k2 [154.449249ms]
Sep 15 19:35:57.606: INFO: Created: latency-svc-cpzrt
Sep 15 19:35:57.615: INFO: Got endpoints: latency-svc-cpzrt [163.934076ms]
Sep 15 19:35:57.617: INFO: Created: latency-svc-9hdgb
Sep 15 19:35:57.627: INFO: Got endpoints: latency-svc-9hdgb [175.46916ms]
Sep 15 19:35:57.629: INFO: Created: latency-svc-m9zjm
Sep 15 19:35:57.636: INFO: Got endpoints: latency-svc-m9zjm [185.11204ms]
Sep 15 19:35:57.638: INFO: Created: latency-svc-pdbpt
Sep 15 19:35:57.646: INFO: Got endpoints: latency-svc-pdbpt [176.078751ms]
Sep 15 19:35:57.649: INFO: Created: latency-svc-l77sb
Sep 15 19:35:57.658: INFO: Got endpoints: latency-svc-l77sb [177.884796ms]
Sep 15 19:35:57.668: INFO: Created: latency-svc-rmnzx
Sep 15 19:35:57.677: INFO: Got endpoints: latency-svc-rmnzx [184.808674ms]
Sep 15 19:35:57.679: INFO: Created: latency-svc-jlnsd
Sep 15 19:35:57.687: INFO: Got endpoints: latency-svc-jlnsd [175.89036ms]
Sep 15 19:35:57.688: INFO: Created: latency-svc-s9db7
Sep 15 19:35:57.698: INFO: Got endpoints: latency-svc-s9db7 [174.82935ms]
Sep 15 19:35:57.700: INFO: Created: latency-svc-z92dt
Sep 15 19:35:57.709: INFO: Got endpoints: latency-svc-z92dt [175.535844ms]
Sep 15 19:35:57.718: INFO: Created: latency-svc-prnt9
Sep 15 19:35:57.737: INFO: Got endpoints: latency-svc-prnt9 [183.93705ms]
Sep 15 19:35:57.740: INFO: Created: latency-svc-ccdvh
Sep 15 19:35:57.741: INFO: Got endpoints: latency-svc-ccdvh [178.801125ms]
Sep 15 19:35:57.742: INFO: Created: latency-svc-cvjl2
Sep 15 19:35:57.751: INFO: Got endpoints: latency-svc-cvjl2 [178.117562ms]
Sep 15 19:35:57.761: INFO: Created: latency-svc-jtzl5
Sep 15 19:35:57.770: INFO: Got endpoints: latency-svc-jtzl5 [185.909259ms]
Sep 15 19:35:57.772: INFO: Created: latency-svc-4q7cc
Sep 15 19:35:57.781: INFO: Got endpoints: latency-svc-4q7cc [186.739609ms]
Sep 15 19:35:57.790: INFO: Created: latency-svc-2qr24
Sep 15 19:35:57.800: INFO: Got endpoints: latency-svc-2qr24 [194.854738ms]
Sep 15 19:35:57.802: INFO: Created: latency-svc-9h5n6
Sep 15 19:35:57.809: INFO: Got endpoints: latency-svc-9h5n6 [194.439954ms]
Sep 15 19:35:57.812: INFO: Created: latency-svc-cwzsn
Sep 15 19:35:57.821: INFO: Got endpoints: latency-svc-cwzsn [194.023519ms]
Sep 15 19:35:57.822: INFO: Created: latency-svc-wjffg
Sep 15 19:35:57.832: INFO: Got endpoints: latency-svc-wjffg [195.633456ms]
Sep 15 19:35:57.850: INFO: Created: latency-svc-rfnvf
Sep 15 19:35:57.857: INFO: Created: latency-svc-wq5x9
Sep 15 19:35:57.858: INFO: Got endpoints: latency-svc-rfnvf [211.282301ms]
Sep 15 19:35:57.862: INFO: Got endpoints: latency-svc-wq5x9 [204.086031ms]
Sep 15 19:35:57.872: INFO: Created: latency-svc-9kzq9
Sep 15 19:35:57.883: INFO: Got endpoints: latency-svc-9kzq9 [205.820061ms]
Sep 15 19:35:57.885: INFO: Created: latency-svc-vxhxl
Sep 15 19:35:57.893: INFO: Got endpoints: latency-svc-vxhxl [205.275905ms]
Sep 15 19:35:57.902: INFO: Created: latency-svc-692m2
Sep 15 19:35:57.911: INFO: Got endpoints: latency-svc-692m2 [213.050423ms]
Sep 15 19:35:57.913: INFO: Created: latency-svc-6lxss
Sep 15 19:35:57.921: INFO: Got endpoints: latency-svc-6lxss [212.298045ms]
Sep 15 19:35:57.924: INFO: Created: latency-svc-rnxkf
Sep 15 19:35:57.932: INFO: Got endpoints: latency-svc-rnxkf [194.77545ms]
Sep 15 19:35:57.935: INFO: Created: latency-svc-gl2bw
Sep 15 19:35:57.943: INFO: Got endpoints: latency-svc-gl2bw [201.837369ms]
Sep 15 19:35:57.946: INFO: Created: latency-svc-8fvf7
Sep 15 19:35:57.964: INFO: Got endpoints: latency-svc-8fvf7 [212.621482ms]
Sep 15 19:35:57.965: INFO: Created: latency-svc-sggr9
Sep 15 19:35:57.977: INFO: Created: latency-svc-zzvkq
Sep 15 19:35:58.000: INFO: Created: latency-svc-4x4b4
Sep 15 19:35:58.001: INFO: Got endpoints: latency-svc-sggr9 [230.939654ms]
Sep 15 19:35:58.011: INFO: Created: latency-svc-s77f4
Sep 15 19:35:58.029: INFO: Created: latency-svc-zb44d
Sep 15 19:35:58.040: INFO: Created: latency-svc-nxmx8
Sep 15 19:35:58.049: INFO: Got endpoints: latency-svc-zzvkq [267.516409ms]
Sep 15 19:35:58.055: INFO: Created: latency-svc-pztfc
Sep 15 19:35:58.060: INFO: Created: latency-svc-tv5lm
Sep 15 19:35:58.071: INFO: Created: latency-svc-hlfvg
Sep 15 19:35:58.082: INFO: Created: latency-svc-nrqd8
Sep 15 19:35:58.102: INFO: Got endpoints: latency-svc-4x4b4 [302.307484ms]
Sep 15 19:35:58.102: INFO: Created: latency-svc-2pq9n
Sep 15 19:35:58.112: INFO: Created: latency-svc-jd4vz
Sep 15 19:35:58.131: INFO: Created: latency-svc-2797m
Sep 15 19:35:58.142: INFO: Created: latency-svc-9wznx
Sep 15 19:35:58.150: INFO: Got endpoints: latency-svc-s77f4 [340.943715ms]
Sep 15 19:35:58.152: INFO: Created: latency-svc-s6ggl
Sep 15 19:35:58.162: INFO: Created: latency-svc-dg676
Sep 15 19:35:58.182: INFO: Created: latency-svc-jnm4p
Sep 15 19:35:58.185: INFO: Created: latency-svc-xvl9d
Sep 15 19:35:58.195: INFO: Got endpoints: latency-svc-zb44d [374.375716ms]
Sep 15 19:35:58.203: INFO: Created: latency-svc-m5s4n
Sep 15 19:35:58.217: INFO: Created: latency-svc-m4sxd
Sep 15 19:35:58.245: INFO: Got endpoints: latency-svc-nxmx8 [413.422911ms]
Sep 15 19:35:58.251: INFO: Created: latency-svc-2djwf
Sep 15 19:35:58.297: INFO: Got endpoints: latency-svc-pztfc [439.536366ms]
Sep 15 19:35:58.303: INFO: Created: latency-svc-wfh2v
Sep 15 19:35:58.345: INFO: Got endpoints: latency-svc-tv5lm [482.934077ms]
Sep 15 19:35:58.360: INFO: Created: latency-svc-gfsxr
Sep 15 19:35:58.395: INFO: Got endpoints: latency-svc-hlfvg [512.136993ms]
Sep 15 19:35:58.412: INFO: Created: latency-svc-m8959
Sep 15 19:35:58.444: INFO: Got endpoints: latency-svc-nrqd8 [551.556202ms]
Sep 15 19:35:58.459: INFO: Created: latency-svc-pld9d
Sep 15 19:35:58.494: INFO: Got endpoints: latency-svc-2pq9n [582.760888ms]
Sep 15 19:35:58.506: INFO: Created: latency-svc-blnfp
Sep 15 19:35:58.544: INFO: Got endpoints: latency-svc-jd4vz [622.457608ms]
Sep 15 19:35:58.566: INFO: Created: latency-svc-9qnjq
Sep 15 19:35:58.595: INFO: Got endpoints: latency-svc-2797m [662.658018ms]
Sep 15 19:35:58.600: INFO: Created: latency-svc-j92lq
Sep 15 19:35:58.646: INFO: Got endpoints: latency-svc-9wznx [702.988278ms]
Sep 15 19:35:58.658: INFO: Created: latency-svc-p75t4
Sep 15 19:35:58.695: INFO: Got endpoints: latency-svc-s6ggl [730.716653ms]
Sep 15 19:35:58.707: INFO: Created: latency-svc-jfgjt
Sep 15 19:35:58.745: INFO: Got endpoints: latency-svc-dg676 [743.834121ms]
Sep 15 19:35:58.750: INFO: Created: latency-svc-c5bwx
Sep 15 19:35:58.795: INFO: Got endpoints: latency-svc-jnm4p [746.22931ms]
Sep 15 19:35:58.801: INFO: Created: latency-svc-dm7zt
Sep 15 19:35:58.844: INFO: Got endpoints: latency-svc-xvl9d [742.165804ms]
Sep 15 19:35:58.858: INFO: Created: latency-svc-9vqm2
Sep 15 19:35:58.894: INFO: Got endpoints: latency-svc-m5s4n [743.884174ms]
Sep 15 19:35:58.907: INFO: Created: latency-svc-hpsdk
Sep 15 19:35:58.945: INFO: Got endpoints: latency-svc-m4sxd [749.906309ms]
Sep 15 19:35:58.957: INFO: Created: latency-svc-p9k2l
Sep 15 19:35:58.994: INFO: Got endpoints: latency-svc-2djwf [748.836373ms]
Sep 15 19:35:59.000: INFO: Created: latency-svc-7jf86
Sep 15 19:35:59.045: INFO: Got endpoints: latency-svc-wfh2v [747.707636ms]
Sep 15 19:35:59.050: INFO: Created: latency-svc-w6vjc
Sep 15 19:35:59.144: INFO: Got endpoints: latency-svc-gfsxr [798.730408ms]
Sep 15 19:35:59.166: INFO: Created: latency-svc-df7b7
Sep 15 19:35:59.196: INFO: Got endpoints: latency-svc-m8959 [800.75349ms]
Sep 15 19:35:59.216: INFO: Created: latency-svc-7vwbt
Sep 15 19:35:59.245: INFO: Got endpoints: latency-svc-pld9d [800.680653ms]
Sep 15 19:35:59.250: INFO: Created: latency-svc-v759j
Sep 15 19:35:59.296: INFO: Got endpoints: latency-svc-blnfp [801.395826ms]
Sep 15 19:35:59.300: INFO: Created: latency-svc-4tsvg
Sep 15 19:35:59.344: INFO: Got endpoints: latency-svc-9qnjq [800.202037ms]
Sep 15 19:35:59.350: INFO: Created: latency-svc-q9w9x
Sep 15 19:35:59.394: INFO: Got endpoints: latency-svc-j92lq [798.841124ms]
Sep 15 19:35:59.408: INFO: Created: latency-svc-q4rpr
Sep 15 19:35:59.445: INFO: Got endpoints: latency-svc-p75t4 [798.552808ms]
Sep 15 19:35:59.461: INFO: Created: latency-svc-58q4l
Sep 15 19:35:59.494: INFO: Got endpoints: latency-svc-jfgjt [799.027004ms]
Sep 15 19:35:59.502: INFO: Created: latency-svc-nglsf
Sep 15 19:35:59.544: INFO: Got endpoints: latency-svc-c5bwx [799.156749ms]
Sep 15 19:35:59.557: INFO: Created: latency-svc-v2sg5
Sep 15 19:35:59.596: INFO: Got endpoints: latency-svc-dm7zt [800.668428ms]
Sep 15 19:35:59.606: INFO: Created: latency-svc-kqvsm
Sep 15 19:35:59.645: INFO: Got endpoints: latency-svc-9vqm2 [800.758697ms]
Sep 15 19:35:59.657: INFO: Created: latency-svc-thg42
Sep 15 19:35:59.696: INFO: Got endpoints: latency-svc-hpsdk [801.259893ms]
Sep 15 19:35:59.700: INFO: Created: latency-svc-lxgcz
Sep 15 19:35:59.745: INFO: Got endpoints: latency-svc-p9k2l [799.961908ms]
Sep 15 19:35:59.750: INFO: Created: latency-svc-vzrgr
Sep 15 19:35:59.796: INFO: Got endpoints: latency-svc-7jf86 [802.062094ms]
Sep 15 19:35:59.808: INFO: Created: latency-svc-thj6f
Sep 15 19:35:59.844: INFO: Got endpoints: latency-svc-w6vjc [799.268829ms]
Sep 15 19:35:59.856: INFO: Created: latency-svc-wd55r
Sep 15 19:35:59.895: INFO: Got endpoints: latency-svc-df7b7 [750.310261ms]
Sep 15 19:35:59.905: INFO: Created: latency-svc-ptdnm
Sep 15 19:35:59.945: INFO: Got endpoints: latency-svc-7vwbt [748.789227ms]
Sep 15 19:35:59.950: INFO: Created: latency-svc-85n52
Sep 15 19:35:59.995: INFO: Got endpoints: latency-svc-v759j [749.942561ms]
Sep 15 19:36:00.004: INFO: Created: latency-svc-2vbwk
Sep 15 19:36:00.046: INFO: Got endpoints: latency-svc-4tsvg [750.604353ms]
Sep 15 19:36:00.058: INFO: Created: latency-svc-kxzzw
Sep 15 19:36:00.095: INFO: Got endpoints: latency-svc-q9w9x [750.634239ms]
Sep 15 19:36:00.107: INFO: Created: latency-svc-zsz84
Sep 15 19:36:00.144: INFO: Got endpoints: latency-svc-q4rpr [750.034633ms]
Sep 15 19:36:00.151: INFO: Created: latency-svc-rp7db
Sep 15 19:36:00.195: INFO: Got endpoints: latency-svc-58q4l [749.604255ms]
Sep 15 19:36:00.200: INFO: Created: latency-svc-8prxl
Sep 15 19:36:00.246: INFO: Got endpoints: latency-svc-nglsf [752.343099ms]
Sep 15 19:36:00.259: INFO: Created: latency-svc-rj8mf
Sep 15 19:36:00.295: INFO: Got endpoints: latency-svc-v2sg5 [750.876282ms]
Sep 15 19:36:00.301: INFO: Created: latency-svc-9q4ng
Sep 15 19:36:00.344: INFO: Got endpoints: latency-svc-kqvsm [748.681502ms]
Sep 15 19:36:00.349: INFO: Created: latency-svc-ld7pk
Sep 15 19:36:00.399: INFO: Got endpoints: latency-svc-thg42 [753.542835ms]
Sep 15 19:36:00.407: INFO: Created: latency-svc-ldw4j
Sep 15 19:36:00.445: INFO: Got endpoints: latency-svc-lxgcz [748.970895ms]
Sep 15 19:36:00.450: INFO: Created: latency-svc-qhkz5
Sep 15 19:36:00.495: INFO: Got endpoints: latency-svc-vzrgr [749.774408ms]
Sep 15 19:36:00.501: INFO: Created: latency-svc-5b9jv
Sep 15 19:36:00.545: INFO: Got endpoints: latency-svc-thj6f [749.042338ms]
Sep 15 19:36:00.551: INFO: Created: latency-svc-t77gs
Sep 15 19:36:00.594: INFO: Got endpoints: latency-svc-wd55r [750.171787ms]
Sep 15 19:36:00.608: INFO: Created: latency-svc-nkhc9
Sep 15 19:36:00.646: INFO: Got endpoints: latency-svc-ptdnm [751.237362ms]
Sep 15 19:36:00.657: INFO: Created: latency-svc-6fqwf
Sep 15 19:36:00.694: INFO: Got endpoints: latency-svc-85n52 [749.899706ms]
Sep 15 19:36:00.699: INFO: Created: latency-svc-x9hdj
Sep 15 19:36:00.746: INFO: Got endpoints: latency-svc-2vbwk [751.434423ms]
Sep 15 19:36:00.752: INFO: Created: latency-svc-kn9lf
Sep 15 19:36:00.796: INFO: Got endpoints: latency-svc-kxzzw [749.412971ms]
Sep 15 19:36:00.807: INFO: Created: latency-svc-8dr2c
Sep 15 19:36:00.855: INFO: Got endpoints: latency-svc-zsz84 [760.163596ms]
Sep 15 19:36:00.860: INFO: Created: latency-svc-d8hmf
Sep 15 19:36:00.895: INFO: Got endpoints: latency-svc-rp7db [750.258979ms]
Sep 15 19:36:00.908: INFO: Created: latency-svc-ktxk8
Sep 15 19:36:00.944: INFO: Got endpoints: latency-svc-8prxl [749.594243ms]
Sep 15 19:36:00.950: INFO: Created: latency-svc-nsb5f
Sep 15 19:36:00.995: INFO: Got endpoints: latency-svc-rj8mf [749.039578ms]
Sep 15 19:36:01.001: INFO: Created: latency-svc-5hxk5
Sep 15 19:36:01.046: INFO: Got endpoints: latency-svc-9q4ng [750.82444ms]
Sep 15 19:36:01.058: INFO: Created: latency-svc-82rtd
Sep 15 19:36:01.095: INFO: Got endpoints: latency-svc-ld7pk [750.813087ms]
Sep 15 19:36:01.107: INFO: Created: latency-svc-kqbc8
Sep 15 19:36:01.145: INFO: Got endpoints: latency-svc-ldw4j [745.877801ms]
Sep 15 19:36:01.157: INFO: Created: latency-svc-prpbb
Sep 15 19:36:01.195: INFO: Got endpoints: latency-svc-qhkz5 [750.239574ms]
Sep 15 19:36:01.200: INFO: Created: latency-svc-ln2h4
Sep 15 19:36:01.245: INFO: Got endpoints: latency-svc-5b9jv [750.562169ms]
Sep 15 19:36:01.251: INFO: Created: latency-svc-4c9h4
Sep 15 19:36:01.294: INFO: Got endpoints: latency-svc-t77gs [748.445242ms]
Sep 15 19:36:01.308: INFO: Created: latency-svc-qvnkh
Sep 15 19:36:01.345: INFO: Got endpoints: latency-svc-nkhc9 [750.913396ms]
Sep 15 19:36:01.356: INFO: Created: latency-svc-29s6m
Sep 15 19:36:01.395: INFO: Got endpoints: latency-svc-6fqwf [749.513542ms]
Sep 15 19:36:01.401: INFO: Created: latency-svc-rljbc
Sep 15 19:36:01.446: INFO: Got endpoints: latency-svc-x9hdj [751.397722ms]
Sep 15 19:36:01.451: INFO: Created: latency-svc-qtkmp
Sep 15 19:36:01.494: INFO: Got endpoints: latency-svc-kn9lf [747.781815ms]
Sep 15 19:36:01.506: INFO: Created: latency-svc-r2w4w
Sep 15 19:36:01.544: INFO: Got endpoints: latency-svc-8dr2c [748.65323ms]
Sep 15 19:36:01.557: INFO: Created: latency-svc-2bcn6
Sep 15 19:36:01.594: INFO: Got endpoints: latency-svc-d8hmf [739.242221ms]
Sep 15 19:36:01.600: INFO: Created: latency-svc-rh847
Sep 15 19:36:01.645: INFO: Got endpoints: latency-svc-ktxk8 [750.172733ms]
Sep 15 19:36:01.650: INFO: Created: latency-svc-hx6td
Sep 15 19:36:01.694: INFO: Got endpoints: latency-svc-nsb5f [749.906447ms]
Sep 15 19:36:01.707: INFO: Created: latency-svc-qkwc4
Sep 15 19:36:01.746: INFO: Got endpoints: latency-svc-5hxk5 [751.036651ms]
Sep 15 19:36:01.758: INFO: Created: latency-svc-pvgm8
Sep 15 19:36:01.795: INFO: Got endpoints: latency-svc-82rtd [749.301992ms]
Sep 15 19:36:01.806: INFO: Created: latency-svc-4xblq
Sep 15 19:36:01.844: INFO: Got endpoints: latency-svc-kqbc8 [749.027545ms]
Sep 15 19:36:01.850: INFO: Created: latency-svc-bzx5b
Sep 15 19:36:01.895: INFO: Got endpoints: latency-svc-prpbb [750.59798ms]
Sep 15 19:36:01.901: INFO: Created: latency-svc-zbnvd
Sep 15 19:36:01.944: INFO: Got endpoints: latency-svc-ln2h4 [749.226257ms]
Sep 15 19:36:01.959: INFO: Created: latency-svc-hjd5v
Sep 15 19:36:01.994: INFO: Got endpoints: latency-svc-4c9h4 [748.825116ms]
Sep 15 19:36:02.008: INFO: Created: latency-svc-lhpkf
Sep 15 19:36:02.044: INFO: Got endpoints: latency-svc-qvnkh [750.147013ms]
Sep 15 19:36:02.052: INFO: Created: latency-svc-vbvqp
Sep 15 19:36:02.095: INFO: Got endpoints: latency-svc-29s6m [749.724878ms]
Sep 15 19:36:02.102: INFO: Created: latency-svc-7njgt
Sep 15 19:36:02.146: INFO: Got endpoints: latency-svc-rljbc [750.422012ms]
Sep 15 19:36:02.157: INFO: Created: latency-svc-7jclb
Sep 15 19:36:02.194: INFO: Got endpoints: latency-svc-qtkmp [748.579461ms]
Sep 15 19:36:02.207: INFO: Created: latency-svc-dflmr
Sep 15 19:36:02.245: INFO: Got endpoints: latency-svc-r2w4w [750.532826ms]
Sep 15 19:36:02.256: INFO: Created: latency-svc-58prd
Sep 15 19:36:02.295: INFO: Got endpoints: latency-svc-2bcn6 [750.748729ms]
Sep 15 19:36:02.301: INFO: Created: latency-svc-7g76p
Sep 15 19:36:02.345: INFO: Got endpoints: latency-svc-rh847 [750.421479ms]
Sep 15 19:36:02.351: INFO: Created: latency-svc-rvt4j
Sep 15 19:36:02.405: INFO: Got endpoints: latency-svc-hx6td [760.193189ms]
Sep 15 19:36:02.411: INFO: Created: latency-svc-s4xl5
Sep 15 19:36:02.447: INFO: Got endpoints: latency-svc-qkwc4 [752.091464ms]
Sep 15 19:36:02.458: INFO: Created: latency-svc-6xgm7
Sep 15 19:36:02.495: INFO: Got endpoints: latency-svc-pvgm8 [748.815432ms]
Sep 15 19:36:02.516: INFO: Created: latency-svc-9xxn5
Sep 15 19:36:02.549: INFO: Got endpoints: latency-svc-4xblq [753.262426ms]
Sep 15 19:36:02.555: INFO: Created: latency-svc-9z8vx
Sep 15 19:36:02.595: INFO: Got endpoints: latency-svc-bzx5b [750.334303ms]
Sep 15 19:36:02.601: INFO: Created: latency-svc-bz742
Sep 15 19:36:02.646: INFO: Got endpoints: latency-svc-zbnvd [751.11033ms]
Sep 15 19:36:02.658: INFO: Created: latency-svc-vl249
Sep 15 19:36:02.697: INFO: Got endpoints: latency-svc-hjd5v [752.503425ms]
Sep 15 19:36:02.709: INFO: Created: latency-svc-8z579
Sep 15 19:36:02.745: INFO: Got endpoints: latency-svc-lhpkf [750.42948ms]
Sep 15 19:36:02.764: INFO: Created: latency-svc-gxgxf
Sep 15 19:36:02.795: INFO: Got endpoints: latency-svc-vbvqp [750.860091ms]
Sep 15 19:36:02.801: INFO: Created: latency-svc-lck6q
Sep 15 19:36:02.851: INFO: Got endpoints: latency-svc-7njgt [754.933343ms]
Sep 15 19:36:02.857: INFO: Created: latency-svc-v6xlb
Sep 15 19:36:02.895: INFO: Got endpoints: latency-svc-7jclb [748.721017ms]
Sep 15 19:36:02.907: INFO: Created: latency-svc-f9xzq
Sep 15 19:36:02.945: INFO: Got endpoints: latency-svc-dflmr [750.949583ms]
Sep 15 19:36:02.958: INFO: Created: latency-svc-hkgvv
Sep 15 19:36:02.995: INFO: Got endpoints: latency-svc-58prd [749.843771ms]
Sep 15 19:36:03.001: INFO: Created: latency-svc-86qsj
Sep 15 19:36:03.045: INFO: Got endpoints: latency-svc-7g76p [750.333333ms]
Sep 15 19:36:03.051: INFO: Created: latency-svc-4sdsb
Sep 15 19:36:03.096: INFO: Got endpoints: latency-svc-rvt4j [750.549067ms]
Sep 15 19:36:03.107: INFO: Created: latency-svc-zjjf6
Sep 15 19:36:03.146: INFO: Got endpoints: latency-svc-s4xl5 [741.249647ms]
Sep 15 19:36:03.158: INFO: Created: latency-svc-jhd2j
Sep 15 19:36:03.196: INFO: Got endpoints: latency-svc-6xgm7 [749.166375ms]
Sep 15 19:36:03.207: INFO: Created: latency-svc-zkdlf
Sep 15 19:36:03.246: INFO: Got endpoints: latency-svc-9xxn5 [750.575166ms]
Sep 15 19:36:03.252: INFO: Created: latency-svc-ndzqq
Sep 15 19:36:03.295: INFO: Got endpoints: latency-svc-9z8vx [746.409819ms]
Sep 15 19:36:03.301: INFO: Created: latency-svc-dcqv4
Sep 15 19:36:03.344: INFO: Got endpoints: latency-svc-bz742 [749.475026ms]
Sep 15 19:36:03.349: INFO: Created: latency-svc-nlmgk
Sep 15 19:36:03.396: INFO: Got endpoints: latency-svc-vl249 [749.396098ms]
Sep 15 19:36:03.407: INFO: Created: latency-svc-bcd4l
Sep 15 19:36:03.446: INFO: Got endpoints: latency-svc-8z579 [749.173128ms]
Sep 15 19:36:03.456: INFO: Created: latency-svc-6pc2q
Sep 15 19:36:03.503: INFO: Got endpoints: latency-svc-gxgxf [757.894118ms]
Sep 15 19:36:03.509: INFO: Created: latency-svc-2mmt5
Sep 15 19:36:03.544: INFO: Got endpoints: latency-svc-lck6q [748.923647ms]
Sep 15 19:36:03.558: INFO: Created: latency-svc-zbtqd
Sep 15 19:36:03.598: INFO: Got endpoints: latency-svc-v6xlb [746.776363ms]
Sep 15 19:36:03.610: INFO: Created: latency-svc-g26vn
Sep 15 19:36:03.646: INFO: Got endpoints: latency-svc-f9xzq [750.898228ms]
Sep 15 19:36:03.657: INFO: Created: latency-svc-chjb6
Sep 15 19:36:03.694: INFO: Got endpoints: latency-svc-hkgvv [748.772818ms]
Sep 15 19:36:03.700: INFO: Created: latency-svc-dmfd8
Sep 15 19:36:03.745: INFO: Got endpoints: latency-svc-86qsj [750.722019ms]
Sep 15 19:36:03.751: INFO: Created: latency-svc-jcdfv
Sep 15 19:36:03.794: INFO: Got endpoints: latency-svc-4sdsb [748.646781ms]
Sep 15 19:36:03.808: INFO: Created: latency-svc-n25v5
Sep 15 19:36:03.847: INFO: Got endpoints: latency-svc-zjjf6 [751.26237ms]
Sep 15 19:36:03.857: INFO: Created: latency-svc-lkxgk
Sep 15 19:36:03.894: INFO: Got endpoints: latency-svc-jhd2j [747.926151ms]
Sep 15 19:36:03.899: INFO: Created: latency-svc-95rf6
Sep 15 19:36:03.945: INFO: Got endpoints: latency-svc-zkdlf [749.128419ms]
Sep 15 19:36:03.951: INFO: Created: latency-svc-xsk95
Sep 15 19:36:03.996: INFO: Got endpoints: latency-svc-ndzqq [750.08916ms]
Sep 15 19:36:04.005: INFO: Created: latency-svc-tlqt4
Sep 15 19:36:04.044: INFO: Got endpoints: latency-svc-dcqv4 [749.182222ms]
Sep 15 19:36:04.057: INFO: Created: latency-svc-lmf4c
Sep 15 19:36:04.096: INFO: Got endpoints: latency-svc-nlmgk [751.485756ms]
Sep 15 19:36:04.107: INFO: Created: latency-svc-4g7hv
Sep 15 19:36:04.146: INFO: Got endpoints: latency-svc-bcd4l [749.958783ms]
Sep 15 19:36:04.158: INFO: Created: latency-svc-jq799
Sep 15 19:36:04.195: INFO: Got endpoints: latency-svc-6pc2q [749.318364ms]
Sep 15 19:36:04.200: INFO: Created: latency-svc-956jv
Sep 15 19:36:04.246: INFO: Got endpoints: latency-svc-2mmt5 [743.332845ms]
Sep 15 19:36:04.251: INFO: Created: latency-svc-df2hj
Sep 15 19:36:04.295: INFO: Got endpoints: latency-svc-zbtqd [750.881552ms]
Sep 15 19:36:04.301: INFO: Created: latency-svc-84h2r
Sep 15 19:36:04.346: INFO: Got endpoints: latency-svc-g26vn [747.55851ms]
Sep 15 19:36:04.352: INFO: Created: latency-svc-xvttg
Sep 15 19:36:04.396: INFO: Got endpoints: latency-svc-chjb6 [750.109919ms]
Sep 15 19:36:04.407: INFO: Created: latency-svc-rwvrx
Sep 15 19:36:04.463: INFO: Got endpoints: latency-svc-dmfd8 [768.311631ms]
Sep 15 19:36:04.469: INFO: Created: latency-svc-dpjbn
Sep 15 19:36:04.494: INFO: Got endpoints: latency-svc-jcdfv [748.970115ms]
Sep 15 19:36:04.500: INFO: Created: latency-svc-gwcgc
Sep 15 19:36:04.544: INFO: Got endpoints: latency-svc-n25v5 [749.87273ms]
Sep 15 19:36:04.549: INFO: Created: latency-svc-kcmlw
Sep 15 19:36:04.595: INFO: Got endpoints: latency-svc-lkxgk [747.644448ms]
Sep 15 19:36:04.600: INFO: Created: latency-svc-25x6j
Sep 15 19:36:04.647: INFO: Got endpoints: latency-svc-95rf6 [752.298103ms]
Sep 15 19:36:04.658: INFO: Created: latency-svc-mrmwd
Sep 15 19:36:04.695: INFO: Got endpoints: latency-svc-xsk95 [750.100523ms]
Sep 15 19:36:04.706: INFO: Created: latency-svc-s9zlt
Sep 15 19:36:04.745: INFO: Got endpoints: latency-svc-tlqt4 [748.723352ms]
Sep 15 19:36:04.750: INFO: Created: latency-svc-t568c
Sep 15 19:36:04.794: INFO: Got endpoints: latency-svc-lmf4c [750.202628ms]
Sep 15 19:36:04.800: INFO: Created: latency-svc-wpnvg
Sep 15 19:36:04.844: INFO: Got endpoints: latency-svc-4g7hv [748.73611ms]
Sep 15 19:36:04.857: INFO: Created: latency-svc-zld7f
Sep 15 19:36:04.894: INFO: Got endpoints: latency-svc-jq799 [748.583772ms]
Sep 15 19:36:04.906: INFO: Created: latency-svc-kd2fr
Sep 15 19:36:04.945: INFO: Got endpoints: latency-svc-956jv [749.468642ms]
Sep 15 19:36:04.956: INFO: Created: latency-svc-4wwpj
Sep 15 19:36:04.994: INFO: Got endpoints: latency-svc-df2hj [747.956297ms]
Sep 15 19:36:05.000: INFO: Created: latency-svc-qrvtq
Sep 15 19:36:05.044: INFO: Got endpoints: latency-svc-84h2r [749.083976ms]
Sep 15 19:36:05.049: INFO: Created: latency-svc-7b96p
Sep 15 19:36:05.095: INFO: Got endpoints: latency-svc-xvttg [749.782881ms]
Sep 15 19:36:05.107: INFO: Created: latency-svc-w47q6
Sep 15 19:36:05.145: INFO: Got endpoints: latency-svc-rwvrx [748.822945ms]
Sep 15 19:36:05.157: INFO: Created: latency-svc-zwgtp
Sep 15 19:36:05.194: INFO: Got endpoints: latency-svc-dpjbn [731.178362ms]
Sep 15 19:36:05.207: INFO: Created: latency-svc-tb9cl
Sep 15 19:36:05.245: INFO: Got endpoints: latency-svc-gwcgc [750.37307ms]
Sep 15 19:36:05.250: INFO: Created: latency-svc-2244v
Sep 15 19:36:05.294: INFO: Got endpoints: latency-svc-kcmlw [749.968038ms]
Sep 15 19:36:05.299: INFO: Created: latency-svc-zvlbk
Sep 15 19:36:05.346: INFO: Got endpoints: latency-svc-25x6j [751.789804ms]
Sep 15 19:36:05.395: INFO: Got endpoints: latency-svc-mrmwd [747.949574ms]
Sep 15 19:36:05.446: INFO: Got endpoints: latency-svc-s9zlt [751.204176ms]
Sep 15 19:36:05.494: INFO: Got endpoints: latency-svc-t568c [749.239588ms]
Sep 15 19:36:05.544: INFO: Got endpoints: latency-svc-wpnvg [749.750094ms]
Sep 15 19:36:05.596: INFO: Got endpoints: latency-svc-zld7f [751.23372ms]
Sep 15 19:36:05.647: INFO: Got endpoints: latency-svc-kd2fr [752.016209ms]
Sep 15 19:36:05.694: INFO: Got endpoints: latency-svc-4wwpj [749.555081ms]
Sep 15 19:36:05.744: INFO: Got endpoints: latency-svc-qrvtq [750.016148ms]
Sep 15 19:36:05.795: INFO: Got endpoints: latency-svc-7b96p [750.157839ms]
Sep 15 19:36:05.845: INFO: Got endpoints: latency-svc-w47q6 [749.508764ms]
Sep 15 19:36:05.894: INFO: Got endpoints: latency-svc-zwgtp [749.336365ms]
Sep 15 19:36:05.944: INFO: Got endpoints: latency-svc-tb9cl [750.362664ms]
Sep 15 19:36:05.996: INFO: Got endpoints: latency-svc-2244v [751.09606ms]
Sep 15 19:36:06.044: INFO: Got endpoints: latency-svc-zvlbk [750.359864ms]
Sep 15 19:36:06.045: INFO: Latencies: [19.783984ms 29.791474ms 41.588358ms 60.542352ms 72.53763ms 82.958897ms 101.543655ms 112.051823ms 122.650596ms 133.201289ms 143.264759ms 154.449249ms 163.934076ms 174.82935ms 175.46916ms 175.535844ms 175.89036ms 176.078751ms 177.884796ms 178.117562ms 178.801125ms 183.93705ms 184.808674ms 185.11204ms 185.909259ms 186.739609ms 194.023519ms 194.439954ms 194.77545ms 194.854738ms 195.633456ms 201.837369ms 204.086031ms 205.275905ms 205.820061ms 211.282301ms 212.298045ms 212.621482ms 213.050423ms 230.939654ms 267.516409ms 302.307484ms 340.943715ms 374.375716ms 413.422911ms 439.536366ms 482.934077ms 512.136993ms 551.556202ms 582.760888ms 622.457608ms 662.658018ms 702.988278ms 730.716653ms 731.178362ms 739.242221ms 741.249647ms 742.165804ms 743.332845ms 743.834121ms 743.884174ms 745.877801ms 746.22931ms 746.409819ms 746.776363ms 747.55851ms 747.644448ms 747.707636ms 747.781815ms 747.926151ms 747.949574ms 747.956297ms 748.445242ms 748.579461ms 748.583772ms 748.646781ms 748.65323ms 748.681502ms 748.721017ms 748.723352ms 748.73611ms 748.772818ms 748.789227ms 748.815432ms 748.822945ms 748.825116ms 748.836373ms 748.923647ms 748.970115ms 748.970895ms 749.027545ms 749.039578ms 749.042338ms 749.083976ms 749.128419ms 749.166375ms 749.173128ms 749.182222ms 749.226257ms 749.239588ms 749.301992ms 749.318364ms 749.336365ms 749.396098ms 749.412971ms 749.468642ms 749.475026ms 749.508764ms 749.513542ms 749.555081ms 749.594243ms 749.604255ms 749.724878ms 749.750094ms 749.774408ms 749.782881ms 749.843771ms 749.87273ms 749.899706ms 749.906309ms 749.906447ms 749.942561ms 749.958783ms 749.968038ms 750.016148ms 750.034633ms 750.08916ms 750.100523ms 750.109919ms 750.147013ms 750.157839ms 750.171787ms 750.172733ms 750.202628ms 750.239574ms 750.258979ms 750.310261ms 750.333333ms 750.334303ms 750.359864ms 750.362664ms 750.37307ms 750.421479ms 750.422012ms 750.42948ms 750.532826ms 750.549067ms 750.562169ms 750.575166ms 750.59798ms 750.604353ms 750.634239ms 750.722019ms 750.748729ms 750.813087ms 750.82444ms 750.860091ms 750.876282ms 750.881552ms 750.898228ms 750.913396ms 750.949583ms 751.036651ms 751.09606ms 751.11033ms 751.204176ms 751.23372ms 751.237362ms 751.26237ms 751.397722ms 751.434423ms 751.485756ms 751.789804ms 752.016209ms 752.091464ms 752.298103ms 752.343099ms 752.503425ms 753.262426ms 753.542835ms 754.933343ms 757.894118ms 760.163596ms 760.193189ms 768.311631ms 798.552808ms 798.730408ms 798.841124ms 799.027004ms 799.156749ms 799.268829ms 799.961908ms 800.202037ms 800.668428ms 800.680653ms 800.75349ms 800.758697ms 801.259893ms 801.395826ms 802.062094ms]
Sep 15 19:36:06.045: INFO: 50 %ile: 749.301992ms
Sep 15 19:36:06.045: INFO: 90 %ile: 754.933343ms
Sep 15 19:36:06.045: INFO: 99 %ile: 801.395826ms
Sep 15 19:36:06.045: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:06.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9612" for this suite.

• [SLOW TEST:10.798 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":277,"completed":104,"skipped":1721,"failed":0}
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:06.053: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:36:06.074: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:10.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5382" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":277,"completed":105,"skipped":1726,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:10.110: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 15 19:36:10.135: INFO: Waiting up to 5m0s for pod "downward-api-039dd8a3-9d23-43cf-9d90-5daf829fa64f" in namespace "downward-api-2824" to be "Succeeded or Failed"
Sep 15 19:36:10.137: INFO: Pod "downward-api-039dd8a3-9d23-43cf-9d90-5daf829fa64f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.540463ms
Sep 15 19:36:12.140: INFO: Pod "downward-api-039dd8a3-9d23-43cf-9d90-5daf829fa64f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004259176s
STEP: Saw pod success
Sep 15 19:36:12.140: INFO: Pod "downward-api-039dd8a3-9d23-43cf-9d90-5daf829fa64f" satisfied condition "Succeeded or Failed"
Sep 15 19:36:12.142: INFO: Trying to get logs from node minion1 pod downward-api-039dd8a3-9d23-43cf-9d90-5daf829fa64f container dapi-container: <nil>
STEP: delete the pod
Sep 15 19:36:12.163: INFO: Waiting for pod downward-api-039dd8a3-9d23-43cf-9d90-5daf829fa64f to disappear
Sep 15 19:36:12.165: INFO: Pod downward-api-039dd8a3-9d23-43cf-9d90-5daf829fa64f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:12.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2824" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":277,"completed":106,"skipped":1846,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:12.172: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Sep 15 19:36:12.216: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-448" to be "Succeeded or Failed"
Sep 15 19:36:12.226: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.443434ms
Sep 15 19:36:14.231: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01504941s
Sep 15 19:36:16.234: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017808066s
STEP: Saw pod success
Sep 15 19:36:16.234: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Sep 15 19:36:16.236: INFO: Trying to get logs from node minion2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 15 19:36:16.255: INFO: Waiting for pod pod-host-path-test to disappear
Sep 15 19:36:16.264: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:16.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-448" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":107,"skipped":1872,"failed":0}

------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:16.270: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-e3ee37f6-eb12-4c04-8408-e1d97878f924
STEP: Creating a pod to test consume secrets
Sep 15 19:36:16.305: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-010f35e0-2c20-4cb8-86c8-e2c9104cc71b" in namespace "projected-1883" to be "Succeeded or Failed"
Sep 15 19:36:16.310: INFO: Pod "pod-projected-secrets-010f35e0-2c20-4cb8-86c8-e2c9104cc71b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.13644ms
Sep 15 19:36:18.312: INFO: Pod "pod-projected-secrets-010f35e0-2c20-4cb8-86c8-e2c9104cc71b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007482762s
STEP: Saw pod success
Sep 15 19:36:18.312: INFO: Pod "pod-projected-secrets-010f35e0-2c20-4cb8-86c8-e2c9104cc71b" satisfied condition "Succeeded or Failed"
Sep 15 19:36:18.314: INFO: Trying to get logs from node minion1 pod pod-projected-secrets-010f35e0-2c20-4cb8-86c8-e2c9104cc71b container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 15 19:36:18.335: INFO: Waiting for pod pod-projected-secrets-010f35e0-2c20-4cb8-86c8-e2c9104cc71b to disappear
Sep 15 19:36:18.337: INFO: Pod pod-projected-secrets-010f35e0-2c20-4cb8-86c8-e2c9104cc71b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:18.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1883" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":108,"skipped":1872,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:18.343: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:36:18.374: INFO: (0) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 4.616895ms)
Sep 15 19:36:18.380: INFO: (1) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.785457ms)
Sep 15 19:36:18.382: INFO: (2) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.733197ms)
Sep 15 19:36:18.385: INFO: (3) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.486452ms)
Sep 15 19:36:18.387: INFO: (4) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.633817ms)
Sep 15 19:36:18.390: INFO: (5) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.521253ms)
Sep 15 19:36:18.392: INFO: (6) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.424131ms)
Sep 15 19:36:18.395: INFO: (7) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.271586ms)
Sep 15 19:36:18.397: INFO: (8) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.230532ms)
Sep 15 19:36:18.400: INFO: (9) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.58426ms)
Sep 15 19:36:18.402: INFO: (10) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.430547ms)
Sep 15 19:36:18.405: INFO: (11) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.622383ms)
Sep 15 19:36:18.407: INFO: (12) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.367125ms)
Sep 15 19:36:18.410: INFO: (13) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.837127ms)
Sep 15 19:36:18.414: INFO: (14) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.430637ms)
Sep 15 19:36:18.416: INFO: (15) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.373777ms)
Sep 15 19:36:18.418: INFO: (16) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.434664ms)
Sep 15 19:36:18.421: INFO: (17) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.360397ms)
Sep 15 19:36:18.423: INFO: (18) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.549498ms)
Sep 15 19:36:18.426: INFO: (19) /api/v1/nodes/minion1:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.570861ms)
[AfterEach] version v1
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:18.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6508" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":277,"completed":109,"skipped":1887,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:18.431: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:18.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4338" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":277,"completed":110,"skipped":1900,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:18.465: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 15 19:36:18.500: INFO: Waiting up to 5m0s for pod "pod-69c02aae-47d9-4442-a645-69b680a34237" in namespace "emptydir-3527" to be "Succeeded or Failed"
Sep 15 19:36:18.502: INFO: Pod "pod-69c02aae-47d9-4442-a645-69b680a34237": Phase="Pending", Reason="", readiness=false. Elapsed: 1.933584ms
Sep 15 19:36:20.505: INFO: Pod "pod-69c02aae-47d9-4442-a645-69b680a34237": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004412105s
Sep 15 19:36:22.507: INFO: Pod "pod-69c02aae-47d9-4442-a645-69b680a34237": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006900402s
STEP: Saw pod success
Sep 15 19:36:22.507: INFO: Pod "pod-69c02aae-47d9-4442-a645-69b680a34237" satisfied condition "Succeeded or Failed"
Sep 15 19:36:22.509: INFO: Trying to get logs from node minion1 pod pod-69c02aae-47d9-4442-a645-69b680a34237 container test-container: <nil>
STEP: delete the pod
Sep 15 19:36:22.520: INFO: Waiting for pod pod-69c02aae-47d9-4442-a645-69b680a34237 to disappear
Sep 15 19:36:22.527: INFO: Pod pod-69c02aae-47d9-4442-a645-69b680a34237 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:22.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3527" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":111,"skipped":1920,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:22.533: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-599944ce-5553-4d98-be9c-0b9e7add2bf8
STEP: Creating configMap with name cm-test-opt-upd-9729e4fa-137b-4766-becf-78ee1ebc7670
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-599944ce-5553-4d98-be9c-0b9e7add2bf8
STEP: Updating configmap cm-test-opt-upd-9729e4fa-137b-4766-becf-78ee1ebc7670
STEP: Creating configMap with name cm-test-opt-create-9466ac54-2fa1-4e81-b7fe-1875278cb3de
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:30.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4340" for this suite.

• [SLOW TEST:8.105 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":112,"skipped":1927,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:30.639: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-8657
STEP: creating replication controller nodeport-test in namespace services-8657
I0915 19:36:30.686847      23 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-8657, replica count: 2
Sep 15 19:36:33.737: INFO: Creating new exec pod
I0915 19:36:33.737288      23 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 15 19:36:36.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-8657 execpodkzwc4 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Sep 15 19:36:37.688: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Sep 15 19:36:37.688: INFO: stdout: ""
Sep 15 19:36:37.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-8657 execpodkzwc4 -- /bin/sh -x -c nc -zv -t -w 2 10.241.154.169 80'
Sep 15 19:36:37.879: INFO: stderr: "+ nc -zv -t -w 2 10.241.154.169 80\nConnection to 10.241.154.169 80 port [tcp/http] succeeded!\n"
Sep 15 19:36:37.879: INFO: stdout: ""
Sep 15 19:36:37.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-8657 execpodkzwc4 -- /bin/sh -x -c nc -zv -t -w 2 172.31.40.94 30826'
Sep 15 19:36:38.071: INFO: stderr: "+ nc -zv -t -w 2 172.31.40.94 30826\nConnection to 172.31.40.94 30826 port [tcp/30826] succeeded!\n"
Sep 15 19:36:38.071: INFO: stdout: ""
Sep 15 19:36:38.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-8657 execpodkzwc4 -- /bin/sh -x -c nc -zv -t -w 2 172.31.33.196 30826'
Sep 15 19:36:38.264: INFO: stderr: "+ nc -zv -t -w 2 172.31.33.196 30826\nConnection to 172.31.33.196 30826 port [tcp/30826] succeeded!\n"
Sep 15 19:36:38.264: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:38.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8657" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:7.631 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":277,"completed":113,"skipped":1942,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:38.270: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Sep 15 19:36:38.301: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 19:36:41.165: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:51.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3029" for this suite.

• [SLOW TEST:13.281 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":277,"completed":114,"skipped":1955,"failed":0}
SSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:51.551: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Sep 15 19:36:51.578: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Sep 15 19:36:51.582: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Sep 15 19:36:51.582: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Sep 15 19:36:51.590: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Sep 15 19:36:51.590: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Sep 15 19:36:51.596: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Sep 15 19:36:51.596: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Sep 15 19:36:58.621: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:36:58.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-1900" for this suite.

• [SLOW TEST:7.089 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":277,"completed":115,"skipped":1963,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:36:58.641: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:36:58.668: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-78239ff0-b7d6-4ded-ae42-157dc5d6fce7" in namespace "security-context-test-9084" to be "Succeeded or Failed"
Sep 15 19:36:58.670: INFO: Pod "alpine-nnp-false-78239ff0-b7d6-4ded-ae42-157dc5d6fce7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.486836ms
Sep 15 19:37:00.673: INFO: Pod "alpine-nnp-false-78239ff0-b7d6-4ded-ae42-157dc5d6fce7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005145985s
Sep 15 19:37:02.676: INFO: Pod "alpine-nnp-false-78239ff0-b7d6-4ded-ae42-157dc5d6fce7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008003007s
Sep 15 19:37:02.676: INFO: Pod "alpine-nnp-false-78239ff0-b7d6-4ded-ae42-157dc5d6fce7" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:37:02.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9084" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":116,"skipped":1978,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:37:02.688: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-a497cc22-0480-4285-97dd-83d8793da234
STEP: Creating a pod to test consume secrets
Sep 15 19:37:02.714: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cfc3842a-fa7b-4071-88dc-44da0e8726bf" in namespace "projected-3273" to be "Succeeded or Failed"
Sep 15 19:37:02.720: INFO: Pod "pod-projected-secrets-cfc3842a-fa7b-4071-88dc-44da0e8726bf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.305044ms
Sep 15 19:37:04.723: INFO: Pod "pod-projected-secrets-cfc3842a-fa7b-4071-88dc-44da0e8726bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00913675s
Sep 15 19:37:06.726: INFO: Pod "pod-projected-secrets-cfc3842a-fa7b-4071-88dc-44da0e8726bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011919329s
STEP: Saw pod success
Sep 15 19:37:06.726: INFO: Pod "pod-projected-secrets-cfc3842a-fa7b-4071-88dc-44da0e8726bf" satisfied condition "Succeeded or Failed"
Sep 15 19:37:06.727: INFO: Trying to get logs from node minion1 pod pod-projected-secrets-cfc3842a-fa7b-4071-88dc-44da0e8726bf container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 15 19:37:06.739: INFO: Waiting for pod pod-projected-secrets-cfc3842a-fa7b-4071-88dc-44da0e8726bf to disappear
Sep 15 19:37:06.746: INFO: Pod pod-projected-secrets-cfc3842a-fa7b-4071-88dc-44da0e8726bf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:37:06.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3273" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":117,"skipped":1986,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:37:06.752: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:37:06.772: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:37:10.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4874" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":277,"completed":118,"skipped":2005,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:37:10.923: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:37:21.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6937" for this suite.

• [SLOW TEST:11.064 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":277,"completed":119,"skipped":2007,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:37:21.988: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1980
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-1980
Sep 15 19:37:22.028: INFO: Found 0 stateful pods, waiting for 1
Sep 15 19:37:32.030: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 15 19:37:32.040: INFO: Deleting all statefulset in ns statefulset-1980
Sep 15 19:37:32.042: INFO: Scaling statefulset ss to 0
Sep 15 19:38:02.084: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 19:38:02.086: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:02.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1980" for this suite.

• [SLOW TEST:40.114 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":277,"completed":120,"skipped":2041,"failed":0}
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:02.101: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:38:02.124: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 15 19:38:02.134: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 15 19:38:07.137: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 15 19:38:07.137: INFO: Creating deployment "test-rolling-update-deployment"
Sep 15 19:38:07.140: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 15 19:38:07.143: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 15 19:38:09.148: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 15 19:38:09.150: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795487, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795487, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795487, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795487, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:38:11.152: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 15 19:38:11.158: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-1911 /apis/apps/v1/namespaces/deployment-1911/deployments/test-rolling-update-deployment bf5029f0-314c-4527-b0f8-279bb80ed0f5 26416 1 2020-09-15 19:38:07 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-09-15 19:38:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-15 19:38:09 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0046d89e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-09-15 19:38:07 +0000 UTC,LastTransitionTime:2020-09-15 19:38:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-09-15 19:38:09 +0000 UTC,LastTransitionTime:2020-09-15 19:38:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 15 19:38:11.161: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-1911 /apis/apps/v1/namespaces/deployment-1911/replicasets/test-rolling-update-deployment-59d5cb45c7 fe035466-02a3-4e7f-a9c0-0af691dbf135 26405 1 2020-09-15 19:38:07 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment bf5029f0-314c-4527-b0f8-279bb80ed0f5 0xc006f58687 0xc006f58688}] []  [{kube-controller-manager Update apps/v1 2020-09-15 19:38:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 102 53 48 50 57 102 48 45 51 49 52 99 45 52 53 50 55 45 98 48 102 56 45 50 55 57 98 98 56 48 101 100 48 102 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006f58718 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 15 19:38:11.161: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 15 19:38:11.161: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-1911 /apis/apps/v1/namespaces/deployment-1911/replicasets/test-rolling-update-controller 55a40e14-df3e-4406-9da1-3622f6ac32f2 26414 2 2020-09-15 19:38:02 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment bf5029f0-314c-4527-b0f8-279bb80ed0f5 0xc006f58567 0xc006f58568}] []  [{e2e.test Update apps/v1 2020-09-15 19:38:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-15 19:38:09 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 102 53 48 50 57 102 48 45 51 49 52 99 45 52 53 50 55 45 98 48 102 56 45 50 55 57 98 98 56 48 101 100 48 102 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc006f58608 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 15 19:38:11.163: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-ptrgs" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-ptrgs test-rolling-update-deployment-59d5cb45c7- deployment-1911 /api/v1/namespaces/deployment-1911/pods/test-rolling-update-deployment-59d5cb45c7-ptrgs 136dec7b-46b8-4ffe-942e-4a141c54e8a3 26404 0 2020-09-15 19:38:07 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 fe035466-02a3-4e7f-a9c0-0af691dbf135 0xc0038005f7 0xc0038005f8}] []  [{kube-controller-manager Update v1 2020-09-15 19:38:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 101 48 51 53 52 54 54 45 48 50 97 51 45 52 101 55 102 45 97 57 99 48 45 48 97 102 54 57 49 100 98 102 49 51 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 19:38:09 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 49 50 56 46 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tt2zf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tt2zf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tt2zf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:10.251.128.5,StartTime:2020-09-15 19:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 19:38:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://f4ee1ef8ef8be20d9aa5a07e8559727f56dfc8ef9a3e2f64b046f36cc5db1593,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.128.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:11.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1911" for this suite.

• [SLOW TEST:9.067 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":121,"skipped":2047,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:11.169: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-6393feb0-1269-4b34-957f-26a3a0cea08e
STEP: Creating a pod to test consume configMaps
Sep 15 19:38:11.199: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b5307e2-6b2f-4bb3-b175-38a85d60a7c2" in namespace "configmap-6435" to be "Succeeded or Failed"
Sep 15 19:38:11.204: INFO: Pod "pod-configmaps-9b5307e2-6b2f-4bb3-b175-38a85d60a7c2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.638006ms
Sep 15 19:38:13.207: INFO: Pod "pod-configmaps-9b5307e2-6b2f-4bb3-b175-38a85d60a7c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007339797s
Sep 15 19:38:15.210: INFO: Pod "pod-configmaps-9b5307e2-6b2f-4bb3-b175-38a85d60a7c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010078475s
STEP: Saw pod success
Sep 15 19:38:15.210: INFO: Pod "pod-configmaps-9b5307e2-6b2f-4bb3-b175-38a85d60a7c2" satisfied condition "Succeeded or Failed"
Sep 15 19:38:15.211: INFO: Trying to get logs from node minion1 pod pod-configmaps-9b5307e2-6b2f-4bb3-b175-38a85d60a7c2 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 19:38:15.228: INFO: Waiting for pod pod-configmaps-9b5307e2-6b2f-4bb3-b175-38a85d60a7c2 to disappear
Sep 15 19:38:15.235: INFO: Pod pod-configmaps-9b5307e2-6b2f-4bb3-b175-38a85d60a7c2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:15.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6435" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":122,"skipped":2087,"failed":0}

------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:15.243: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-26f2ceb6-fb38-4d1d-b7d3-6dc4f0730e4b
STEP: Creating a pod to test consume configMaps
Sep 15 19:38:15.277: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-52d7da34-cd9d-49db-8ad7-cf6893b2baa8" in namespace "projected-6401" to be "Succeeded or Failed"
Sep 15 19:38:15.279: INFO: Pod "pod-projected-configmaps-52d7da34-cd9d-49db-8ad7-cf6893b2baa8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.73847ms
Sep 15 19:38:17.282: INFO: Pod "pod-projected-configmaps-52d7da34-cd9d-49db-8ad7-cf6893b2baa8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004593678s
Sep 15 19:38:19.284: INFO: Pod "pod-projected-configmaps-52d7da34-cd9d-49db-8ad7-cf6893b2baa8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007221388s
STEP: Saw pod success
Sep 15 19:38:19.284: INFO: Pod "pod-projected-configmaps-52d7da34-cd9d-49db-8ad7-cf6893b2baa8" satisfied condition "Succeeded or Failed"
Sep 15 19:38:19.286: INFO: Trying to get logs from node minion1 pod pod-projected-configmaps-52d7da34-cd9d-49db-8ad7-cf6893b2baa8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 19:38:19.305: INFO: Waiting for pod pod-projected-configmaps-52d7da34-cd9d-49db-8ad7-cf6893b2baa8 to disappear
Sep 15 19:38:19.312: INFO: Pod pod-projected-configmaps-52d7da34-cd9d-49db-8ad7-cf6893b2baa8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:19.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6401" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":123,"skipped":2087,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:19.319: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:38:19.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-6105'
Sep 15 19:38:19.526: INFO: stderr: ""
Sep 15 19:38:19.526: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Sep 15 19:38:19.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-6105'
Sep 15 19:38:19.665: INFO: stderr: ""
Sep 15 19:38:19.665: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Sep 15 19:38:20.668: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 19:38:20.668: INFO: Found 0 / 1
Sep 15 19:38:21.668: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 19:38:21.668: INFO: Found 1 / 1
Sep 15 19:38:21.668: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 15 19:38:21.670: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 19:38:21.670: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 15 19:38:21.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 describe pod agnhost-master-52cmf --namespace=kubectl-6105'
Sep 15 19:38:21.742: INFO: stderr: ""
Sep 15 19:38:21.742: INFO: stdout: "Name:         agnhost-master-52cmf\nNamespace:    kubectl-6105\nPriority:     0\nNode:         minion1/172.31.40.94\nStart Time:   Tue, 15 Sep 2020 19:38:19 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.251.128.1\nIPs:\n  IP:           10.251.128.1\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://2db7a024963feb1962e1d64b576b5ccbf33aaa7fe68ffc0ac24c2049ff921836\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 15 Sep 2020 19:38:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-6r742 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-6r742:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-6r742\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From               Message\n  ----    ------     ----       ----               -------\n  Normal  Scheduled  <unknown>  default-scheduler  Successfully assigned kubectl-6105/agnhost-master-52cmf to minion1\n  Normal  Pulled     1s         kubelet, minion1   Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    1s         kubelet, minion1   Created container agnhost-master\n  Normal  Started    1s         kubelet, minion1   Started container agnhost-master\n"
Sep 15 19:38:21.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 describe rc agnhost-master --namespace=kubectl-6105'
Sep 15 19:38:21.819: INFO: stderr: ""
Sep 15 19:38:21.819: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-6105\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-master-52cmf\n"
Sep 15 19:38:21.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 describe service agnhost-master --namespace=kubectl-6105'
Sep 15 19:38:21.889: INFO: stderr: ""
Sep 15 19:38:21.889: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-6105\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.241.62.244\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.251.128.1:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 15 19:38:21.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 describe node master'
Sep 15 19:38:21.976: INFO: stderr: ""
Sep 15 19:38:21.976: INFO: stdout: "Name:               master\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\n                    zone=master\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 15 Sep 2020 17:48:22 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  master\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 15 Sep 2020 19:38:14 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 15 Sep 2020 17:49:51 +0000   Tue, 15 Sep 2020 17:49:51 +0000   WeaveIsUp                    Weave pod has set this\n  MemoryPressure       False   Tue, 15 Sep 2020 19:38:19 +0000   Tue, 15 Sep 2020 17:48:18 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 15 Sep 2020 19:38:19 +0000   Tue, 15 Sep 2020 17:48:18 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 15 Sep 2020 19:38:19 +0000   Tue, 15 Sep 2020 17:48:18 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 15 Sep 2020 19:38:19 +0000   Tue, 15 Sep 2020 17:49:55 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.44.211\n  Hostname:    master\nCapacity:\n  cpu:                4\n  ephemeral-storage:  20263484Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16424480Ki\n  pods:               110\nAllocatable:\n  cpu:                3800m\n  ephemeral-storage:  18674826824\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             15822080Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 af2a2e4b0f1a431ca30d8590b9d358ff\n  System UUID:                EC258C51-1D85-DD29-61D5-2D8289EAFCD2\n  Boot ID:                    a1067280-8d4a-4b11-9404-0c4be3008045\n  Kernel Version:             4.15.0-1044-aws\n  OS Image:                   Ubuntu 18.04.2 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.6.2\n  Kubelet Version:            v1.18.6\n  Kube-Proxy Version:         v1.18.6\nPodCIDR:                      10.251.0.0/24\nPodCIDRs:                     10.251.0.0/24\nNon-terminated Pods:          (11 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-59dcc4799b-pm22w                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     108m\n  kube-system                 dns-autoscaler-757b95599b-zvqkc                            20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         108m\n  kube-system                 kube-apiserver-master                                      250m (6%)     0 (0%)      0 (0%)           0 (0%)         105m\n  kube-system                 kube-controller-manager-master                             200m (5%)     0 (0%)      0 (0%)           0 (0%)         109m\n  kube-system                 kube-proxy-gjkwm                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         109m\n  kube-system                 kube-scheduler-master                                      100m (2%)     0 (0%)      0 (0%)           0 (0%)         109m\n  kube-system                 metrics-server-79d884896f-6j964                            48m (1%)      143m (3%)   105Mi (0%)       355Mi (2%)     107m\n  kube-system                 nodelocaldns-mrtd5                                         100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     108m\n  kube-system                 weave-net-4h49l                                            100m (2%)     0 (0%)      0 (0%)           0 (0%)         108m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-9xg5z    0 (0%)        0 (0%)      0 (0%)           0 (0%)         31m\n  weave                       weave-scope-agent-wm28s                                    100m (2%)     0 (0%)      100Mi (0%)       0 (0%)         107m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1018m (26%)  143m (3%)\n  memory             355Mi (2%)   695Mi (4%)\n  ephemeral-storage  0 (0%)       0 (0%)\n  hugepages-1Gi      0 (0%)       0 (0%)\n  hugepages-2Mi      0 (0%)       0 (0%)\nEvents:              <none>\n"
Sep 15 19:38:21.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 describe namespace kubectl-6105'
Sep 15 19:38:22.044: INFO: stderr: ""
Sep 15 19:38:22.044: INFO: stdout: "Name:         kubectl-6105\nLabels:       e2e-framework=kubectl\n              e2e-run=72576d03-d72c-41ae-bd69-bb914be9f3bf\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:22.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6105" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":277,"completed":124,"skipped":2120,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:22.050: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep 15 19:38:26.087: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3132 PodName:pod-sharedvolume-30def615-7c86-490d-b685-f2bfe8903750 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 19:38:26.087: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 19:38:26.200: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:26.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3132" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":277,"completed":125,"skipped":2128,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:26.207: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Sep 15 19:38:26.226: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:40.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6389" for this suite.

• [SLOW TEST:14.727 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":277,"completed":126,"skipped":2174,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:40.934: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-fb7645c0-1b9f-4a2b-a137-f8334c24ffb6
STEP: Creating a pod to test consume secrets
Sep 15 19:38:40.965: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7fc4d47d-ba27-4867-9a29-5b2bf803653b" in namespace "projected-4475" to be "Succeeded or Failed"
Sep 15 19:38:40.966: INFO: Pod "pod-projected-secrets-7fc4d47d-ba27-4867-9a29-5b2bf803653b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.610677ms
Sep 15 19:38:42.970: INFO: Pod "pod-projected-secrets-7fc4d47d-ba27-4867-9a29-5b2bf803653b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004675462s
Sep 15 19:38:44.972: INFO: Pod "pod-projected-secrets-7fc4d47d-ba27-4867-9a29-5b2bf803653b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00735747s
STEP: Saw pod success
Sep 15 19:38:44.972: INFO: Pod "pod-projected-secrets-7fc4d47d-ba27-4867-9a29-5b2bf803653b" satisfied condition "Succeeded or Failed"
Sep 15 19:38:44.974: INFO: Trying to get logs from node minion1 pod pod-projected-secrets-7fc4d47d-ba27-4867-9a29-5b2bf803653b container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 15 19:38:44.994: INFO: Waiting for pod pod-projected-secrets-7fc4d47d-ba27-4867-9a29-5b2bf803653b to disappear
Sep 15 19:38:45.001: INFO: Pod pod-projected-secrets-7fc4d47d-ba27-4867-9a29-5b2bf803653b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:45.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4475" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":127,"skipped":2186,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:45.006: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 15 19:38:47.551: INFO: Successfully updated pod "labelsupdatece54e8c1-f2c0-4c41-9891-69ae4b00e0b2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:49.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2110" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":128,"skipped":2217,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:49.570: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:38:49.590: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 15 19:38:52.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-1603 create -f -'
Sep 15 19:38:53.390: INFO: stderr: ""
Sep 15 19:38:53.390: INFO: stdout: "e2e-test-crd-publish-openapi-9725-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 15 19:38:53.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-1603 delete e2e-test-crd-publish-openapi-9725-crds test-cr'
Sep 15 19:38:53.455: INFO: stderr: ""
Sep 15 19:38:53.455: INFO: stdout: "e2e-test-crd-publish-openapi-9725-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Sep 15 19:38:53.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-1603 apply -f -'
Sep 15 19:38:53.600: INFO: stderr: ""
Sep 15 19:38:53.600: INFO: stdout: "e2e-test-crd-publish-openapi-9725-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 15 19:38:53.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-1603 delete e2e-test-crd-publish-openapi-9725-crds test-cr'
Sep 15 19:38:53.665: INFO: stderr: ""
Sep 15 19:38:53.665: INFO: stdout: "e2e-test-crd-publish-openapi-9725-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Sep 15 19:38:53.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 explain e2e-test-crd-publish-openapi-9725-crds'
Sep 15 19:38:53.807: INFO: stderr: ""
Sep 15 19:38:53.807: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9725-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:38:55.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1603" for this suite.

• [SLOW TEST:6.089 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":277,"completed":129,"skipped":2225,"failed":0}
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:38:55.659: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-8357
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-8357
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8357
Sep 15 19:38:55.697: INFO: Found 0 stateful pods, waiting for 1
Sep 15 19:39:05.700: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 15 19:39:05.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8357 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 19:39:05.903: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 19:39:05.903: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 19:39:05.903: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 15 19:39:05.905: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 15 19:39:15.908: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 15 19:39:15.908: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 19:39:15.917: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 15 19:39:15.917: INFO: ss-0  minion1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:38:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:38:55 +0000 UTC  }]
Sep 15 19:39:15.917: INFO: 
Sep 15 19:39:15.917: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 15 19:39:16.920: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997965013s
Sep 15 19:39:17.923: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99477803s
Sep 15 19:39:18.926: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992146537s
Sep 15 19:39:19.929: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989059832s
Sep 15 19:39:20.932: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985966052s
Sep 15 19:39:21.935: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982925113s
Sep 15 19:39:22.938: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979806876s
Sep 15 19:39:23.941: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976739057s
Sep 15 19:39:24.944: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.641315ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8357
Sep 15 19:39:25.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8357 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 15 19:39:26.135: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 15 19:39:26.135: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 15 19:39:26.135: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 15 19:39:26.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8357 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 15 19:39:26.309: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 15 19:39:26.309: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 15 19:39:26.309: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 15 19:39:26.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8357 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 15 19:39:26.507: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 15 19:39:26.507: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 15 19:39:26.507: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 15 19:39:26.510: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 15 19:39:36.513: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 19:39:36.513: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 19:39:36.513: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 15 19:39:36.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8357 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 19:39:36.706: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 19:39:36.706: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 19:39:36.706: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 15 19:39:36.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8357 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 19:39:36.885: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 19:39:36.885: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 19:39:36.885: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 15 19:39:36.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-8357 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 19:39:37.081: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 19:39:37.082: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 19:39:37.082: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 15 19:39:37.082: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 19:39:37.083: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Sep 15 19:39:47.088: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 15 19:39:47.088: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 15 19:39:47.088: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 15 19:39:47.095: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 15 19:39:47.095: INFO: ss-0  minion1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:38:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:38:55 +0000 UTC  }]
Sep 15 19:39:47.095: INFO: ss-1  minion2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  }]
Sep 15 19:39:47.095: INFO: ss-2  minion1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  }]
Sep 15 19:39:47.095: INFO: 
Sep 15 19:39:47.095: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 15 19:39:48.099: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 15 19:39:48.099: INFO: ss-0  minion1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:38:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:38:55 +0000 UTC  }]
Sep 15 19:39:48.099: INFO: ss-1  minion2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  }]
Sep 15 19:39:48.099: INFO: ss-2  minion1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  }]
Sep 15 19:39:48.099: INFO: 
Sep 15 19:39:48.099: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 15 19:39:49.102: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 15 19:39:49.102: INFO: ss-0  minion1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:38:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:38:55 +0000 UTC  }]
Sep 15 19:39:49.102: INFO: ss-1  minion2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  }]
Sep 15 19:39:49.102: INFO: ss-2  minion1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  }]
Sep 15 19:39:49.102: INFO: 
Sep 15 19:39:49.102: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 15 19:39:50.105: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 15 19:39:50.105: INFO: ss-1  minion2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  }]
Sep 15 19:39:50.105: INFO: 
Sep 15 19:39:50.105: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 15 19:39:51.108: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 15 19:39:51.108: INFO: ss-1  minion2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  }]
Sep 15 19:39:51.108: INFO: 
Sep 15 19:39:51.108: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 15 19:39:52.111: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Sep 15 19:39:52.111: INFO: ss-1  minion2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-09-15 19:39:15 +0000 UTC  }]
Sep 15 19:39:52.111: INFO: 
Sep 15 19:39:52.111: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 15 19:39:53.113: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.981403477s
Sep 15 19:39:54.116: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.979158003s
Sep 15 19:39:55.119: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.976564923s
Sep 15 19:39:56.121: INFO: Verifying statefulset ss doesn't scale past 0 for another 973.86ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8357
Sep 15 19:39:57.124: INFO: Scaling statefulset ss to 0
Sep 15 19:39:57.130: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 15 19:39:57.131: INFO: Deleting all statefulset in ns statefulset-8357
Sep 15 19:39:57.133: INFO: Scaling statefulset ss to 0
Sep 15 19:39:57.138: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 19:39:57.140: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:39:57.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8357" for this suite.

• [SLOW TEST:61.494 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":277,"completed":130,"skipped":2226,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:39:57.153: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:39:57.178: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Creating first CR 
Sep 15 19:39:57.729: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-15T19:39:57Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-15T19:39:57Z]] name:name1 resourceVersion:27122 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:08ca414d-bfd5-434f-850a-433e70e3fbfb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Sep 15 19:40:07.733: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-15T19:40:07Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-15T19:40:07Z]] name:name2 resourceVersion:27183 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:049dceb8-c4ac-424c-b547-48bfa4f649ca] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Sep 15 19:40:17.737: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-15T19:39:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-15T19:40:17Z]] name:name1 resourceVersion:27211 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:08ca414d-bfd5-434f-850a-433e70e3fbfb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Sep 15 19:40:27.741: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-15T19:40:07Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-15T19:40:27Z]] name:name2 resourceVersion:27239 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:049dceb8-c4ac-424c-b547-48bfa4f649ca] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Sep 15 19:40:37.746: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-15T19:39:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-15T19:40:17Z]] name:name1 resourceVersion:27267 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:08ca414d-bfd5-434f-850a-433e70e3fbfb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Sep 15 19:40:47.751: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-09-15T19:40:07Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-09-15T19:40:27Z]] name:name2 resourceVersion:27295 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:049dceb8-c4ac-424c-b547-48bfa4f649ca] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:40:58.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-5184" for this suite.

• [SLOW TEST:61.111 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":277,"completed":131,"skipped":2237,"failed":0}
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:40:58.265: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 15 19:40:58.288: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:41:02.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1654" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":277,"completed":132,"skipped":2242,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:41:02.624: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Sep 15 19:41:02.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-1989'
Sep 15 19:41:02.824: INFO: stderr: ""
Sep 15 19:41:02.824: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 15 19:41:02.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1989'
Sep 15 19:41:02.889: INFO: stderr: ""
Sep 15 19:41:02.889: INFO: stdout: "update-demo-nautilus-bd8n9 update-demo-nautilus-qbtgd "
Sep 15 19:41:02.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-bd8n9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:02.950: INFO: stderr: ""
Sep 15 19:41:02.950: INFO: stdout: ""
Sep 15 19:41:02.950: INFO: update-demo-nautilus-bd8n9 is created but not running
Sep 15 19:41:07.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1989'
Sep 15 19:41:08.015: INFO: stderr: ""
Sep 15 19:41:08.015: INFO: stdout: "update-demo-nautilus-bd8n9 update-demo-nautilus-qbtgd "
Sep 15 19:41:08.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-bd8n9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:08.074: INFO: stderr: ""
Sep 15 19:41:08.074: INFO: stdout: "true"
Sep 15 19:41:08.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-bd8n9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:08.134: INFO: stderr: ""
Sep 15 19:41:08.134: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 15 19:41:08.134: INFO: validating pod update-demo-nautilus-bd8n9
Sep 15 19:41:08.138: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 15 19:41:08.138: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 15 19:41:08.138: INFO: update-demo-nautilus-bd8n9 is verified up and running
Sep 15 19:41:08.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-qbtgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:08.197: INFO: stderr: ""
Sep 15 19:41:08.197: INFO: stdout: "true"
Sep 15 19:41:08.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-qbtgd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:08.255: INFO: stderr: ""
Sep 15 19:41:08.255: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 15 19:41:08.255: INFO: validating pod update-demo-nautilus-qbtgd
Sep 15 19:41:08.263: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 15 19:41:08.263: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 15 19:41:08.263: INFO: update-demo-nautilus-qbtgd is verified up and running
STEP: scaling down the replication controller
Sep 15 19:41:08.265: INFO: scanned /root for discovery docs: <nil>
Sep 15 19:41:08.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1989'
Sep 15 19:41:09.356: INFO: stderr: ""
Sep 15 19:41:09.356: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 15 19:41:09.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1989'
Sep 15 19:41:09.421: INFO: stderr: ""
Sep 15 19:41:09.421: INFO: stdout: "update-demo-nautilus-bd8n9 update-demo-nautilus-qbtgd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 15 19:41:14.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1989'
Sep 15 19:41:14.483: INFO: stderr: ""
Sep 15 19:41:14.483: INFO: stdout: "update-demo-nautilus-qbtgd "
Sep 15 19:41:14.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-qbtgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:14.542: INFO: stderr: ""
Sep 15 19:41:14.542: INFO: stdout: "true"
Sep 15 19:41:14.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-qbtgd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:14.603: INFO: stderr: ""
Sep 15 19:41:14.603: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 15 19:41:14.603: INFO: validating pod update-demo-nautilus-qbtgd
Sep 15 19:41:14.606: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 15 19:41:14.606: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 15 19:41:14.606: INFO: update-demo-nautilus-qbtgd is verified up and running
STEP: scaling up the replication controller
Sep 15 19:41:14.607: INFO: scanned /root for discovery docs: <nil>
Sep 15 19:41:14.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1989'
Sep 15 19:41:15.689: INFO: stderr: ""
Sep 15 19:41:15.689: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 15 19:41:15.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1989'
Sep 15 19:41:15.752: INFO: stderr: ""
Sep 15 19:41:15.752: INFO: stdout: "update-demo-nautilus-444db update-demo-nautilus-qbtgd "
Sep 15 19:41:15.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-444db -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:15.810: INFO: stderr: ""
Sep 15 19:41:15.810: INFO: stdout: ""
Sep 15 19:41:15.810: INFO: update-demo-nautilus-444db is created but not running
Sep 15 19:41:20.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1989'
Sep 15 19:41:20.875: INFO: stderr: ""
Sep 15 19:41:20.875: INFO: stdout: "update-demo-nautilus-444db update-demo-nautilus-qbtgd "
Sep 15 19:41:20.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-444db -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:20.936: INFO: stderr: ""
Sep 15 19:41:20.936: INFO: stdout: "true"
Sep 15 19:41:20.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-444db -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:20.995: INFO: stderr: ""
Sep 15 19:41:20.995: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 15 19:41:20.995: INFO: validating pod update-demo-nautilus-444db
Sep 15 19:41:21.000: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 15 19:41:21.000: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 15 19:41:21.000: INFO: update-demo-nautilus-444db is verified up and running
Sep 15 19:41:21.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-qbtgd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:21.059: INFO: stderr: ""
Sep 15 19:41:21.059: INFO: stdout: "true"
Sep 15 19:41:21.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods update-demo-nautilus-qbtgd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1989'
Sep 15 19:41:21.118: INFO: stderr: ""
Sep 15 19:41:21.118: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 15 19:41:21.118: INFO: validating pod update-demo-nautilus-qbtgd
Sep 15 19:41:21.121: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 15 19:41:21.121: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 15 19:41:21.121: INFO: update-demo-nautilus-qbtgd is verified up and running
STEP: using delete to clean up resources
Sep 15 19:41:21.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete --grace-period=0 --force -f - --namespace=kubectl-1989'
Sep 15 19:41:21.183: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 15 19:41:21.183: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 15 19:41:21.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1989'
Sep 15 19:41:21.245: INFO: stderr: "No resources found in kubectl-1989 namespace.\n"
Sep 15 19:41:21.245: INFO: stdout: ""
Sep 15 19:41:21.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -l name=update-demo --namespace=kubectl-1989 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 15 19:41:21.313: INFO: stderr: ""
Sep 15 19:41:21.313: INFO: stdout: "update-demo-nautilus-444db\nupdate-demo-nautilus-qbtgd\n"
Sep 15 19:41:21.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1989'
Sep 15 19:41:21.878: INFO: stderr: "No resources found in kubectl-1989 namespace.\n"
Sep 15 19:41:21.878: INFO: stdout: ""
Sep 15 19:41:21.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -l name=update-demo --namespace=kubectl-1989 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 15 19:41:21.943: INFO: stderr: ""
Sep 15 19:41:21.943: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:41:21.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1989" for this suite.

• [SLOW TEST:19.325 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":277,"completed":133,"skipped":2250,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:41:21.949: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Sep 15 19:42:25.005: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:42:25.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9651" for this suite.

• [SLOW TEST:63.062 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":277,"completed":134,"skipped":2266,"failed":0}
SSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:42:25.011: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Sep 15 19:42:25.028: INFO: Waiting up to 1m0s for all nodes to be ready
Sep 15 19:43:25.052: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:43:25.054: INFO: Starting informer...
STEP: Starting pods...
Sep 15 19:43:25.265: INFO: Pod1 is running on minion1. Tainting Node
Sep 15 19:43:27.477: INFO: Pod2 is running on minion1. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Sep 15 19:43:34.421: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Sep 15 19:43:54.562: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:43:54.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9209" for this suite.

• [SLOW TEST:89.565 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":277,"completed":135,"skipped":2272,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:43:54.577: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-241b3b42-c15f-4642-80d8-e1020061e122
STEP: Creating a pod to test consume secrets
Sep 15 19:43:54.606: INFO: Waiting up to 5m0s for pod "pod-secrets-33b3568a-033f-4d2a-bc28-ad46e8e35751" in namespace "secrets-2839" to be "Succeeded or Failed"
Sep 15 19:43:54.617: INFO: Pod "pod-secrets-33b3568a-033f-4d2a-bc28-ad46e8e35751": Phase="Pending", Reason="", readiness=false. Elapsed: 11.232634ms
Sep 15 19:43:56.620: INFO: Pod "pod-secrets-33b3568a-033f-4d2a-bc28-ad46e8e35751": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014181219s
STEP: Saw pod success
Sep 15 19:43:56.620: INFO: Pod "pod-secrets-33b3568a-033f-4d2a-bc28-ad46e8e35751" satisfied condition "Succeeded or Failed"
Sep 15 19:43:56.622: INFO: Trying to get logs from node minion1 pod pod-secrets-33b3568a-033f-4d2a-bc28-ad46e8e35751 container secret-volume-test: <nil>
STEP: delete the pod
Sep 15 19:43:56.643: INFO: Waiting for pod pod-secrets-33b3568a-033f-4d2a-bc28-ad46e8e35751 to disappear
Sep 15 19:43:56.650: INFO: Pod pod-secrets-33b3568a-033f-4d2a-bc28-ad46e8e35751 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:43:56.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2839" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":136,"skipped":2310,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:43:56.656: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3193.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3193.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3193.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3193.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3193.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3193.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 15 19:44:00.713: INFO: DNS probes using dns-3193/dns-test-6fb51825-cc18-4030-9e2a-63da1c23fe32 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:44:00.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3193" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":277,"completed":137,"skipped":2324,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:44:00.732: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:44:00.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-3040" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":277,"completed":138,"skipped":2357,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:44:00.790: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:44:00.818: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 15 19:44:05.820: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 15 19:44:05.820: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 15 19:44:07.823: INFO: Creating deployment "test-rollover-deployment"
Sep 15 19:44:07.827: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 15 19:44:09.832: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 15 19:44:09.835: INFO: Ensure that both replica sets have 1 created replica
Sep 15 19:44:09.839: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 15 19:44:09.844: INFO: Updating deployment test-rollover-deployment
Sep 15 19:44:09.844: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 15 19:44:11.848: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 15 19:44:11.854: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 15 19:44:11.860: INFO: all replica sets need to contain the pod-template-hash label
Sep 15 19:44:11.860: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795849, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:44:13.865: INFO: all replica sets need to contain the pod-template-hash label
Sep 15 19:44:13.865: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795852, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:44:15.865: INFO: all replica sets need to contain the pod-template-hash label
Sep 15 19:44:15.865: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795852, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:44:17.865: INFO: all replica sets need to contain the pod-template-hash label
Sep 15 19:44:17.865: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795852, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:44:19.865: INFO: all replica sets need to contain the pod-template-hash label
Sep 15 19:44:19.865: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795852, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:44:21.865: INFO: all replica sets need to contain the pod-template-hash label
Sep 15 19:44:21.865: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795852, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795847, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 15 19:44:23.865: INFO: 
Sep 15 19:44:23.865: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 15 19:44:23.870: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9116 /apis/apps/v1/namespaces/deployment-9116/deployments/test-rollover-deployment 33690921-a368-4a6b-823c-8ab3792bba79 28323 2 2020-09-15 19:44:07 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-09-15 19:44:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-15 19:44:22 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006f59b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-09-15 19:44:07 +0000 UTC,LastTransitionTime:2020-09-15 19:44:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-09-15 19:44:22 +0000 UTC,LastTransitionTime:2020-09-15 19:44:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 15 19:44:23.872: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-9116 /apis/apps/v1/namespaces/deployment-9116/replicasets/test-rollover-deployment-84f7f6f64b b48f28fb-8af3-4f7b-b176-2578d2b9bbcd 28310 2 2020-09-15 19:44:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 33690921-a368-4a6b-823c-8ab3792bba79 0xc00428a187 0xc00428a188}] []  [{kube-controller-manager Update apps/v1 2020-09-15 19:44:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 54 57 48 57 50 49 45 97 51 54 56 45 52 97 54 98 45 56 50 51 99 45 56 97 98 51 55 57 50 98 98 97 55 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00428a218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 15 19:44:23.872: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 15 19:44:23.872: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9116 /apis/apps/v1/namespaces/deployment-9116/replicasets/test-rollover-controller 87235f82-9b1d-41aa-b6a3-343a4c0ff0dd 28322 2 2020-09-15 19:44:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 33690921-a368-4a6b-823c-8ab3792bba79 0xc006f59f77 0xc006f59f78}] []  [{e2e.test Update apps/v1 2020-09-15 19:44:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-15 19:44:22 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 54 57 48 57 50 49 45 97 51 54 56 45 52 97 54 98 45 56 50 51 99 45 56 97 98 51 55 57 50 98 98 97 55 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00428a018 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 15 19:44:23.873: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-9116 /apis/apps/v1/namespaces/deployment-9116/replicasets/test-rollover-deployment-5686c4cfd5 187aa94c-42fe-47a5-ac5f-2bc3b583808d 28267 2 2020-09-15 19:44:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 33690921-a368-4a6b-823c-8ab3792bba79 0xc00428a087 0xc00428a088}] []  [{kube-controller-manager Update apps/v1 2020-09-15 19:44:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 51 54 57 48 57 50 49 45 97 51 54 56 45 52 97 54 98 45 56 50 51 99 45 56 97 98 51 55 57 50 98 98 97 55 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00428a118 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 15 19:44:23.875: INFO: Pod "test-rollover-deployment-84f7f6f64b-7hndt" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-7hndt test-rollover-deployment-84f7f6f64b- deployment-9116 /api/v1/namespaces/deployment-9116/pods/test-rollover-deployment-84f7f6f64b-7hndt 778d96ed-ac35-4a3a-a5c8-5825a3f3f772 28282 0 2020-09-15 19:44:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b b48f28fb-8af3-4f7b-b176-2578d2b9bbcd 0xc00428a957 0xc00428a958}] []  [{kube-controller-manager Update v1 2020-09-15 19:44:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 52 56 102 50 56 102 98 45 56 97 102 51 45 52 102 55 98 45 98 49 55 54 45 50 53 55 56 100 50 98 57 98 98 99 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 19:44:12 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 49 50 56 46 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qqtph,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qqtph,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qqtph,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:44:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:44:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:44:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 19:44:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:10.251.128.1,StartTime:2020-09-15 19:44:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 19:44:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://aace438112ee4e7406837c3c7b12567b07b00fc81657d46e19d243fc61825f11,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.128.1,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:44:23.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9116" for this suite.

• [SLOW TEST:23.090 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":277,"completed":139,"skipped":2379,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:44:23.881: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 19:44:24.980: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 19:44:26.987: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795864, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795864, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795865, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735795864, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 19:44:30.014: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:44:30.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4755" for this suite.
STEP: Destroying namespace "webhook-4755-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.176 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":277,"completed":140,"skipped":2430,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:44:30.057: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:44:34.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7176" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":277,"completed":141,"skipped":2506,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:44:34.134: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Sep 15 19:44:34.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-4002'
Sep 15 19:44:34.328: INFO: stderr: ""
Sep 15 19:44:34.328: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Sep 15 19:44:35.331: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 19:44:35.331: INFO: Found 0 / 1
Sep 15 19:44:36.337: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 19:44:36.337: INFO: Found 1 / 1
Sep 15 19:44:36.337: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 15 19:44:36.339: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 19:44:36.339: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 15 19:44:36.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 patch pod agnhost-master-6hxr5 --namespace=kubectl-4002 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 15 19:44:36.405: INFO: stderr: ""
Sep 15 19:44:36.405: INFO: stdout: "pod/agnhost-master-6hxr5 patched\n"
STEP: checking annotations
Sep 15 19:44:36.407: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 19:44:36.407: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:44:36.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4002" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":277,"completed":142,"skipped":2509,"failed":0}
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:44:36.413: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Sep 15 19:44:36.958: INFO: created pod pod-service-account-defaultsa
Sep 15 19:44:36.958: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 15 19:44:36.962: INFO: created pod pod-service-account-mountsa
Sep 15 19:44:36.962: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 15 19:44:36.970: INFO: created pod pod-service-account-nomountsa
Sep 15 19:44:36.970: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 15 19:44:36.974: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 15 19:44:36.974: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 15 19:44:36.983: INFO: created pod pod-service-account-mountsa-mountspec
Sep 15 19:44:36.983: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 15 19:44:36.986: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 15 19:44:36.986: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 15 19:44:36.995: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 15 19:44:36.995: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 15 19:44:37.002: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 15 19:44:37.002: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 15 19:44:37.022: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 15 19:44:37.022: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:44:37.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4790" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":277,"completed":143,"skipped":2511,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:44:37.033: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-2c3ac5a8-cf27-434e-b4d7-4e389aa11396 in namespace container-probe-1327
Sep 15 19:44:41.074: INFO: Started pod busybox-2c3ac5a8-cf27-434e-b4d7-4e389aa11396 in namespace container-probe-1327
STEP: checking the pod's current state and verifying that restartCount is present
Sep 15 19:44:41.076: INFO: Initial restart count of pod busybox-2c3ac5a8-cf27-434e-b4d7-4e389aa11396 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:48:41.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1327" for this suite.

• [SLOW TEST:244.390 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":144,"skipped":2512,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:48:41.424: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:48:58.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-878" for this suite.

• [SLOW TEST:17.057 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":277,"completed":145,"skipped":2522,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:48:58.480: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 15 19:49:01.037: INFO: Successfully updated pod "annotationupdate2bc01ed0-128d-483f-8641-df68f41b49af"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:49:03.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-22" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":146,"skipped":2537,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:49:03.056: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 15 19:49:03.085: INFO: Waiting up to 5m0s for pod "pod-d92e8e07-baf9-489d-a036-70c5f7d931e1" in namespace "emptydir-305" to be "Succeeded or Failed"
Sep 15 19:49:03.088: INFO: Pod "pod-d92e8e07-baf9-489d-a036-70c5f7d931e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.853203ms
Sep 15 19:49:05.091: INFO: Pod "pod-d92e8e07-baf9-489d-a036-70c5f7d931e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005571616s
Sep 15 19:49:07.093: INFO: Pod "pod-d92e8e07-baf9-489d-a036-70c5f7d931e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00827023s
STEP: Saw pod success
Sep 15 19:49:07.093: INFO: Pod "pod-d92e8e07-baf9-489d-a036-70c5f7d931e1" satisfied condition "Succeeded or Failed"
Sep 15 19:49:07.095: INFO: Trying to get logs from node minion1 pod pod-d92e8e07-baf9-489d-a036-70c5f7d931e1 container test-container: <nil>
STEP: delete the pod
Sep 15 19:49:07.106: INFO: Waiting for pod pod-d92e8e07-baf9-489d-a036-70c5f7d931e1 to disappear
Sep 15 19:49:07.108: INFO: Pod pod-d92e8e07-baf9-489d-a036-70c5f7d931e1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:49:07.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-305" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":147,"skipped":2564,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:49:07.113: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-63335771-c41d-428f-8caf-5c405e129505
STEP: Creating a pod to test consume configMaps
Sep 15 19:49:07.142: INFO: Waiting up to 5m0s for pod "pod-configmaps-a9e65c0f-2a79-4972-9460-fceb81eb076d" in namespace "configmap-8275" to be "Succeeded or Failed"
Sep 15 19:49:07.148: INFO: Pod "pod-configmaps-a9e65c0f-2a79-4972-9460-fceb81eb076d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.465386ms
Sep 15 19:49:09.151: INFO: Pod "pod-configmaps-a9e65c0f-2a79-4972-9460-fceb81eb076d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009242975s
Sep 15 19:49:11.154: INFO: Pod "pod-configmaps-a9e65c0f-2a79-4972-9460-fceb81eb076d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011906536s
STEP: Saw pod success
Sep 15 19:49:11.154: INFO: Pod "pod-configmaps-a9e65c0f-2a79-4972-9460-fceb81eb076d" satisfied condition "Succeeded or Failed"
Sep 15 19:49:11.155: INFO: Trying to get logs from node minion1 pod pod-configmaps-a9e65c0f-2a79-4972-9460-fceb81eb076d container configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 19:49:11.167: INFO: Waiting for pod pod-configmaps-a9e65c0f-2a79-4972-9460-fceb81eb076d to disappear
Sep 15 19:49:11.174: INFO: Pod pod-configmaps-a9e65c0f-2a79-4972-9460-fceb81eb076d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:49:11.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8275" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":148,"skipped":2615,"failed":0}

------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:49:11.180: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 15 19:49:19.232: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 15 19:49:19.235: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 15 19:49:21.236: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 15 19:49:21.238: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 15 19:49:23.236: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 15 19:49:23.238: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 15 19:49:25.236: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 15 19:49:25.238: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 15 19:49:27.236: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 15 19:49:27.238: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 15 19:49:29.236: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 15 19:49:29.238: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 15 19:49:31.236: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 15 19:49:31.238: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 15 19:49:33.236: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 15 19:49:33.238: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:49:33.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7246" for this suite.

• [SLOW TEST:22.064 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":277,"completed":149,"skipped":2615,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:49:33.245: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Sep 15 19:49:33.269: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-692368794 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:49:33.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7971" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":277,"completed":150,"skipped":2617,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:49:33.328: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Sep 15 19:49:33.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 api-versions'
Sep 15 19:49:33.442: INFO: stderr: ""
Sep 15 19:49:33.442: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:49:33.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7644" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":277,"completed":151,"skipped":2628,"failed":0}
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:49:33.448: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:49:33.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2404" for this suite.
STEP: Destroying namespace "nspatchtest-85201c92-3076-47d8-beea-d902bb64f838-8312" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":277,"completed":152,"skipped":2629,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:49:33.506: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:49:33.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7618" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":277,"completed":153,"skipped":2633,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:49:33.534: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 19:49:34.478: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 19:49:36.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796174, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796174, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796174, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796174, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 19:49:39.492: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:49:49.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6163" for this suite.
STEP: Destroying namespace "webhook-6163-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.120 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":277,"completed":154,"skipped":2639,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:49:49.653: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:49:49.692: INFO: Create a RollingUpdate DaemonSet
Sep 15 19:49:49.695: INFO: Check that daemon pods launch on every node of the cluster
Sep 15 19:49:49.702: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:49:49.705: INFO: Number of nodes with available pods: 0
Sep 15 19:49:49.705: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:49:50.708: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:49:50.710: INFO: Number of nodes with available pods: 0
Sep 15 19:49:50.710: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:49:51.708: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:49:51.710: INFO: Number of nodes with available pods: 1
Sep 15 19:49:51.710: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:49:52.709: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:49:52.710: INFO: Number of nodes with available pods: 2
Sep 15 19:49:52.711: INFO: Number of running nodes: 2, number of available pods: 2
Sep 15 19:49:52.711: INFO: Update the DaemonSet to trigger a rollout
Sep 15 19:49:52.715: INFO: Updating DaemonSet daemon-set
Sep 15 19:50:02.725: INFO: Roll back the DaemonSet before rollout is complete
Sep 15 19:50:02.729: INFO: Updating DaemonSet daemon-set
Sep 15 19:50:02.729: INFO: Make sure DaemonSet rollback is complete
Sep 15 19:50:02.732: INFO: Wrong image for pod: daemon-set-zqsfx. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 15 19:50:02.732: INFO: Pod daemon-set-zqsfx is not available
Sep 15 19:50:02.742: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:50:03.745: INFO: Wrong image for pod: daemon-set-zqsfx. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 15 19:50:03.745: INFO: Pod daemon-set-zqsfx is not available
Sep 15 19:50:03.747: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:50:04.745: INFO: Wrong image for pod: daemon-set-zqsfx. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 15 19:50:04.745: INFO: Pod daemon-set-zqsfx is not available
Sep 15 19:50:04.747: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:50:05.745: INFO: Pod daemon-set-fzddw is not available
Sep 15 19:50:05.748: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5047, will wait for the garbage collector to delete the pods
Sep 15 19:50:05.807: INFO: Deleting DaemonSet.extensions daemon-set took: 3.742415ms
Sep 15 19:50:05.907: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.200863ms
Sep 15 19:50:12.409: INFO: Number of nodes with available pods: 0
Sep 15 19:50:12.409: INFO: Number of running nodes: 0, number of available pods: 0
Sep 15 19:50:12.410: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5047/daemonsets","resourceVersion":"29884"},"items":null}

Sep 15 19:50:12.412: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5047/pods","resourceVersion":"29884"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:50:12.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5047" for this suite.

• [SLOW TEST:22.770 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":277,"completed":155,"skipped":2654,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:50:12.423: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:50:28.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8379" for this suite.

• [SLOW TEST:16.087 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":277,"completed":156,"skipped":2661,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:50:28.511: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 15 19:50:28.539: INFO: Waiting up to 5m0s for pod "pod-0292c349-1bab-4600-8cc6-3e78c9f5427f" in namespace "emptydir-1009" to be "Succeeded or Failed"
Sep 15 19:50:28.542: INFO: Pod "pod-0292c349-1bab-4600-8cc6-3e78c9f5427f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.335172ms
Sep 15 19:50:30.544: INFO: Pod "pod-0292c349-1bab-4600-8cc6-3e78c9f5427f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004421591s
STEP: Saw pod success
Sep 15 19:50:30.544: INFO: Pod "pod-0292c349-1bab-4600-8cc6-3e78c9f5427f" satisfied condition "Succeeded or Failed"
Sep 15 19:50:30.546: INFO: Trying to get logs from node minion1 pod pod-0292c349-1bab-4600-8cc6-3e78c9f5427f container test-container: <nil>
STEP: delete the pod
Sep 15 19:50:30.563: INFO: Waiting for pod pod-0292c349-1bab-4600-8cc6-3e78c9f5427f to disappear
Sep 15 19:50:30.569: INFO: Pod pod-0292c349-1bab-4600-8cc6-3e78c9f5427f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:50:30.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1009" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":157,"skipped":2700,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:50:30.575: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-hwbd
STEP: Creating a pod to test atomic-volume-subpath
Sep 15 19:50:30.607: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-hwbd" in namespace "subpath-4199" to be "Succeeded or Failed"
Sep 15 19:50:30.609: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.372855ms
Sep 15 19:50:32.613: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 2.005513713s
Sep 15 19:50:34.615: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 4.008336624s
Sep 15 19:50:36.618: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 6.011062168s
Sep 15 19:50:38.621: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 8.013591627s
Sep 15 19:50:40.623: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 10.01629603s
Sep 15 19:50:42.626: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 12.019028079s
Sep 15 19:50:44.629: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 14.021836239s
Sep 15 19:50:46.632: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 16.024668392s
Sep 15 19:50:48.634: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 18.027309671s
Sep 15 19:50:50.637: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 20.029881112s
Sep 15 19:50:52.640: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Running", Reason="", readiness=true. Elapsed: 22.032577311s
Sep 15 19:50:54.642: INFO: Pod "pod-subpath-test-secret-hwbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.035142766s
STEP: Saw pod success
Sep 15 19:50:54.642: INFO: Pod "pod-subpath-test-secret-hwbd" satisfied condition "Succeeded or Failed"
Sep 15 19:50:54.644: INFO: Trying to get logs from node minion1 pod pod-subpath-test-secret-hwbd container test-container-subpath-secret-hwbd: <nil>
STEP: delete the pod
Sep 15 19:50:54.664: INFO: Waiting for pod pod-subpath-test-secret-hwbd to disappear
Sep 15 19:50:54.666: INFO: Pod pod-subpath-test-secret-hwbd no longer exists
STEP: Deleting pod pod-subpath-test-secret-hwbd
Sep 15 19:50:54.666: INFO: Deleting pod "pod-subpath-test-secret-hwbd" in namespace "subpath-4199"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:50:54.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4199" for this suite.

• [SLOW TEST:24.098 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":277,"completed":158,"skipped":2703,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:50:54.674: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-5e7fabff-0b7c-4ce8-8d0b-790d5f3eb645
STEP: Creating a pod to test consume secrets
Sep 15 19:50:54.700: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dab63d0d-56fa-4334-8ba2-3cafeca7cb1e" in namespace "projected-2675" to be "Succeeded or Failed"
Sep 15 19:50:54.707: INFO: Pod "pod-projected-secrets-dab63d0d-56fa-4334-8ba2-3cafeca7cb1e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.057747ms
Sep 15 19:50:56.709: INFO: Pod "pod-projected-secrets-dab63d0d-56fa-4334-8ba2-3cafeca7cb1e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009761824s
Sep 15 19:50:58.712: INFO: Pod "pod-projected-secrets-dab63d0d-56fa-4334-8ba2-3cafeca7cb1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012659738s
STEP: Saw pod success
Sep 15 19:50:58.712: INFO: Pod "pod-projected-secrets-dab63d0d-56fa-4334-8ba2-3cafeca7cb1e" satisfied condition "Succeeded or Failed"
Sep 15 19:50:58.714: INFO: Trying to get logs from node minion1 pod pod-projected-secrets-dab63d0d-56fa-4334-8ba2-3cafeca7cb1e container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 15 19:50:58.727: INFO: Waiting for pod pod-projected-secrets-dab63d0d-56fa-4334-8ba2-3cafeca7cb1e to disappear
Sep 15 19:50:58.734: INFO: Pod pod-projected-secrets-dab63d0d-56fa-4334-8ba2-3cafeca7cb1e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:50:58.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2675" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":159,"skipped":2770,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:50:58.739: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-dcbd69b4-58a9-42b4-a861-235ee3ea30d8
STEP: Creating a pod to test consume secrets
Sep 15 19:50:58.768: INFO: Waiting up to 5m0s for pod "pod-secrets-44d84ff8-2739-413a-80c8-2f621df4996d" in namespace "secrets-4556" to be "Succeeded or Failed"
Sep 15 19:50:58.770: INFO: Pod "pod-secrets-44d84ff8-2739-413a-80c8-2f621df4996d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.214193ms
Sep 15 19:51:00.772: INFO: Pod "pod-secrets-44d84ff8-2739-413a-80c8-2f621df4996d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004435723s
STEP: Saw pod success
Sep 15 19:51:00.772: INFO: Pod "pod-secrets-44d84ff8-2739-413a-80c8-2f621df4996d" satisfied condition "Succeeded or Failed"
Sep 15 19:51:00.774: INFO: Trying to get logs from node minion1 pod pod-secrets-44d84ff8-2739-413a-80c8-2f621df4996d container secret-volume-test: <nil>
STEP: delete the pod
Sep 15 19:51:00.786: INFO: Waiting for pod pod-secrets-44d84ff8-2739-413a-80c8-2f621df4996d to disappear
Sep 15 19:51:00.793: INFO: Pod pod-secrets-44d84ff8-2739-413a-80c8-2f621df4996d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:51:00.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4556" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":160,"skipped":2771,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:51:00.799: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 15 19:51:00.830: INFO: Waiting up to 5m0s for pod "pod-3a72d362-d740-4c19-9182-b25e05d25e0e" in namespace "emptydir-1658" to be "Succeeded or Failed"
Sep 15 19:51:00.832: INFO: Pod "pod-3a72d362-d740-4c19-9182-b25e05d25e0e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.554212ms
Sep 15 19:51:02.835: INFO: Pod "pod-3a72d362-d740-4c19-9182-b25e05d25e0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004237965s
STEP: Saw pod success
Sep 15 19:51:02.835: INFO: Pod "pod-3a72d362-d740-4c19-9182-b25e05d25e0e" satisfied condition "Succeeded or Failed"
Sep 15 19:51:02.836: INFO: Trying to get logs from node minion1 pod pod-3a72d362-d740-4c19-9182-b25e05d25e0e container test-container: <nil>
STEP: delete the pod
Sep 15 19:51:02.851: INFO: Waiting for pod pod-3a72d362-d740-4c19-9182-b25e05d25e0e to disappear
Sep 15 19:51:02.859: INFO: Pod pod-3a72d362-d740-4c19-9182-b25e05d25e0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:51:02.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1658" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":161,"skipped":2803,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:51:02.864: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 15 19:51:06.912: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 15 19:51:06.915: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 15 19:51:08.915: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 15 19:51:08.917: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 15 19:51:10.915: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 15 19:51:10.917: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:51:10.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3826" for this suite.

• [SLOW TEST:8.064 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":277,"completed":162,"skipped":2814,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:51:10.930: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:51:10.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3890" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":277,"completed":163,"skipped":2942,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:51:10.962: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1155.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1155.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 15 19:51:15.018: INFO: DNS probes using dns-1155/dns-test-ad9ceaec-009d-4e40-bafe-d17a89460f44 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:51:15.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1155" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":277,"completed":164,"skipped":2967,"failed":0}

------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:51:15.039: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:51:26.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8190" for this suite.

• [SLOW TEST:11.054 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":277,"completed":165,"skipped":2967,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:51:26.093: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 19:51:26.612: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 19:51:28.619: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796286, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796286, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796286, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796286, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 19:51:31.628: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:51:31.631: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4990-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:51:32.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1604" for this suite.
STEP: Destroying namespace "webhook-1604-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.662 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":277,"completed":166,"skipped":3014,"failed":0}
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:51:32.755: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9551, will wait for the garbage collector to delete the pods
Sep 15 19:51:36.840: INFO: Deleting Job.batch foo took: 3.515041ms
Sep 15 19:51:36.940: INFO: Terminating Job.batch foo pods took: 100.218627ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:52:12.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9551" for this suite.

• [SLOW TEST:39.693 seconds]
[sig-apps] Job
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":277,"completed":167,"skipped":3014,"failed":0}
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:52:12.448: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 15 19:53:24.544: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:53:24.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-474" for this suite.

• [SLOW TEST:72.102 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":277,"completed":168,"skipped":3016,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:53:24.550: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:53:24.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1468" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":277,"completed":169,"skipped":3025,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:53:24.578: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 15 19:54:32.630: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:54:32.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2619" for this suite.

• [SLOW TEST:68.057 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":277,"completed":170,"skipped":3030,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:54:32.636: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:54:32.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be7cf4c2-8c61-41c5-b96d-21f73c761518" in namespace "downward-api-1202" to be "Succeeded or Failed"
Sep 15 19:54:32.665: INFO: Pod "downwardapi-volume-be7cf4c2-8c61-41c5-b96d-21f73c761518": Phase="Pending", Reason="", readiness=false. Elapsed: 1.528828ms
Sep 15 19:54:34.668: INFO: Pod "downwardapi-volume-be7cf4c2-8c61-41c5-b96d-21f73c761518": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004321093s
Sep 15 19:54:36.671: INFO: Pod "downwardapi-volume-be7cf4c2-8c61-41c5-b96d-21f73c761518": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007182471s
STEP: Saw pod success
Sep 15 19:54:36.671: INFO: Pod "downwardapi-volume-be7cf4c2-8c61-41c5-b96d-21f73c761518" satisfied condition "Succeeded or Failed"
Sep 15 19:54:36.673: INFO: Trying to get logs from node minion1 pod downwardapi-volume-be7cf4c2-8c61-41c5-b96d-21f73c761518 container client-container: <nil>
STEP: delete the pod
Sep 15 19:54:36.694: INFO: Waiting for pod downwardapi-volume-be7cf4c2-8c61-41c5-b96d-21f73c761518 to disappear
Sep 15 19:54:36.700: INFO: Pod downwardapi-volume-be7cf4c2-8c61-41c5-b96d-21f73c761518 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:54:36.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1202" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":171,"skipped":3032,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:54:36.706: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Sep 15 19:54:36.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-7790'
Sep 15 19:54:37.610: INFO: stderr: ""
Sep 15 19:54:37.610: INFO: stdout: "pod/pause created\n"
Sep 15 19:54:37.610: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 15 19:54:37.610: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7790" to be "running and ready"
Sep 15 19:54:37.612: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.587541ms
Sep 15 19:54:39.615: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005116473s
Sep 15 19:54:41.617: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.007777961s
Sep 15 19:54:41.617: INFO: Pod "pause" satisfied condition "running and ready"
Sep 15 19:54:41.617: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 15 19:54:41.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 label pods pause testing-label=testing-label-value --namespace=kubectl-7790'
Sep 15 19:54:41.688: INFO: stderr: ""
Sep 15 19:54:41.688: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 15 19:54:41.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pod pause -L testing-label --namespace=kubectl-7790'
Sep 15 19:54:41.747: INFO: stderr: ""
Sep 15 19:54:41.747: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 15 19:54:41.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 label pods pause testing-label- --namespace=kubectl-7790'
Sep 15 19:54:41.812: INFO: stderr: ""
Sep 15 19:54:41.812: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 15 19:54:41.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pod pause -L testing-label --namespace=kubectl-7790'
Sep 15 19:54:41.874: INFO: stderr: ""
Sep 15 19:54:41.874: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Sep 15 19:54:41.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete --grace-period=0 --force -f - --namespace=kubectl-7790'
Sep 15 19:54:41.939: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 15 19:54:41.939: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 15 19:54:41.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get rc,svc -l name=pause --no-headers --namespace=kubectl-7790'
Sep 15 19:54:42.005: INFO: stderr: "No resources found in kubectl-7790 namespace.\n"
Sep 15 19:54:42.005: INFO: stdout: ""
Sep 15 19:54:42.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pods -l name=pause --namespace=kubectl-7790 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 15 19:54:42.064: INFO: stderr: ""
Sep 15 19:54:42.064: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:54:42.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7790" for this suite.

• [SLOW TEST:5.364 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1203
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":277,"completed":172,"skipped":3037,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:54:42.070: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Sep 15 19:54:42.088: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 19:54:43.948: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:54:55.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6259" for this suite.

• [SLOW TEST:13.202 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":277,"completed":173,"skipped":3039,"failed":0}
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:54:55.272: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-7467/configmap-test-bea61c07-beff-4381-9718-46e944858c2a
STEP: Creating a pod to test consume configMaps
Sep 15 19:54:55.306: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a97d280-4cc0-4bf6-9cc4-cc624ab34fba" in namespace "configmap-7467" to be "Succeeded or Failed"
Sep 15 19:54:55.308: INFO: Pod "pod-configmaps-1a97d280-4cc0-4bf6-9cc4-cc624ab34fba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.301481ms
Sep 15 19:54:57.311: INFO: Pod "pod-configmaps-1a97d280-4cc0-4bf6-9cc4-cc624ab34fba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004624723s
STEP: Saw pod success
Sep 15 19:54:57.311: INFO: Pod "pod-configmaps-1a97d280-4cc0-4bf6-9cc4-cc624ab34fba" satisfied condition "Succeeded or Failed"
Sep 15 19:54:57.312: INFO: Trying to get logs from node minion1 pod pod-configmaps-1a97d280-4cc0-4bf6-9cc4-cc624ab34fba container env-test: <nil>
STEP: delete the pod
Sep 15 19:54:57.323: INFO: Waiting for pod pod-configmaps-1a97d280-4cc0-4bf6-9cc4-cc624ab34fba to disappear
Sep 15 19:54:57.331: INFO: Pod pod-configmaps-1a97d280-4cc0-4bf6-9cc4-cc624ab34fba no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:54:57.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7467" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":174,"skipped":3041,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:54:57.337: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 19:54:57.941: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 19:54:59.947: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796497, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796497, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796497, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796497, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 19:55:02.956: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:55:02.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8440" for this suite.
STEP: Destroying namespace "webhook-8440-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.689 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":277,"completed":175,"skipped":3059,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:55:03.026: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 15 19:55:03.053: INFO: Waiting up to 5m0s for pod "pod-d2a93a95-d54f-4f19-bb8e-9c68f43e96f1" in namespace "emptydir-3454" to be "Succeeded or Failed"
Sep 15 19:55:03.058: INFO: Pod "pod-d2a93a95-d54f-4f19-bb8e-9c68f43e96f1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.20246ms
Sep 15 19:55:05.061: INFO: Pod "pod-d2a93a95-d54f-4f19-bb8e-9c68f43e96f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00797088s
Sep 15 19:55:07.064: INFO: Pod "pod-d2a93a95-d54f-4f19-bb8e-9c68f43e96f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010704778s
STEP: Saw pod success
Sep 15 19:55:07.064: INFO: Pod "pod-d2a93a95-d54f-4f19-bb8e-9c68f43e96f1" satisfied condition "Succeeded or Failed"
Sep 15 19:55:07.066: INFO: Trying to get logs from node minion1 pod pod-d2a93a95-d54f-4f19-bb8e-9c68f43e96f1 container test-container: <nil>
STEP: delete the pod
Sep 15 19:55:07.077: INFO: Waiting for pod pod-d2a93a95-d54f-4f19-bb8e-9c68f43e96f1 to disappear
Sep 15 19:55:07.079: INFO: Pod pod-d2a93a95-d54f-4f19-bb8e-9c68f43e96f1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:55:07.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3454" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":176,"skipped":3068,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:55:07.084: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:55:07.114: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2849403f-cc2e-4147-8ff4-b690f45f3a22" in namespace "downward-api-7802" to be "Succeeded or Failed"
Sep 15 19:55:07.121: INFO: Pod "downwardapi-volume-2849403f-cc2e-4147-8ff4-b690f45f3a22": Phase="Pending", Reason="", readiness=false. Elapsed: 6.661427ms
Sep 15 19:55:09.123: INFO: Pod "downwardapi-volume-2849403f-cc2e-4147-8ff4-b690f45f3a22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00937375s
Sep 15 19:55:11.126: INFO: Pod "downwardapi-volume-2849403f-cc2e-4147-8ff4-b690f45f3a22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012107587s
STEP: Saw pod success
Sep 15 19:55:11.126: INFO: Pod "downwardapi-volume-2849403f-cc2e-4147-8ff4-b690f45f3a22" satisfied condition "Succeeded or Failed"
Sep 15 19:55:11.128: INFO: Trying to get logs from node minion1 pod downwardapi-volume-2849403f-cc2e-4147-8ff4-b690f45f3a22 container client-container: <nil>
STEP: delete the pod
Sep 15 19:55:11.142: INFO: Waiting for pod downwardapi-volume-2849403f-cc2e-4147-8ff4-b690f45f3a22 to disappear
Sep 15 19:55:11.147: INFO: Pod downwardapi-volume-2849403f-cc2e-4147-8ff4-b690f45f3a22 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:55:11.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7802" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":177,"skipped":3084,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:55:11.152: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:55:11.185: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Pending, waiting for it to be Running (with Ready = true)
Sep 15 19:55:13.188: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Pending, waiting for it to be Running (with Ready = true)
Sep 15 19:55:15.188: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Running (Ready = false)
Sep 15 19:55:17.188: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Running (Ready = false)
Sep 15 19:55:19.188: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Running (Ready = false)
Sep 15 19:55:21.188: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Running (Ready = false)
Sep 15 19:55:23.188: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Running (Ready = false)
Sep 15 19:55:25.188: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Running (Ready = false)
Sep 15 19:55:27.187: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Running (Ready = false)
Sep 15 19:55:29.188: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Running (Ready = false)
Sep 15 19:55:31.188: INFO: The status of Pod test-webserver-8fe4aec7-b65f-4403-97d4-b7311d54ca39 is Running (Ready = true)
Sep 15 19:55:31.189: INFO: Container started at 2020-09-15 19:55:12 +0000 UTC, pod became ready at 2020-09-15 19:55:30 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:55:31.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8993" for this suite.

• [SLOW TEST:20.042 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":277,"completed":178,"skipped":3094,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:55:31.195: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 15 19:55:31.227: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2878 /api/v1/namespaces/watch-2878/configmaps/e2e-watch-test-label-changed b1dcbda4-c834-46f8-8ad6-46ae8238857b 31877 0 2020-09-15 19:55:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-15 19:55:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:55:31.227: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2878 /api/v1/namespaces/watch-2878/configmaps/e2e-watch-test-label-changed b1dcbda4-c834-46f8-8ad6-46ae8238857b 31878 0 2020-09-15 19:55:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-15 19:55:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:55:31.227: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2878 /api/v1/namespaces/watch-2878/configmaps/e2e-watch-test-label-changed b1dcbda4-c834-46f8-8ad6-46ae8238857b 31879 0 2020-09-15 19:55:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-15 19:55:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 15 19:55:41.254: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2878 /api/v1/namespaces/watch-2878/configmaps/e2e-watch-test-label-changed b1dcbda4-c834-46f8-8ad6-46ae8238857b 31917 0 2020-09-15 19:55:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-15 19:55:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:55:41.254: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2878 /api/v1/namespaces/watch-2878/configmaps/e2e-watch-test-label-changed b1dcbda4-c834-46f8-8ad6-46ae8238857b 31918 0 2020-09-15 19:55:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-15 19:55:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 19:55:41.254: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2878 /api/v1/namespaces/watch-2878/configmaps/e2e-watch-test-label-changed b1dcbda4-c834-46f8-8ad6-46ae8238857b 31919 0 2020-09-15 19:55:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-09-15 19:55:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:55:41.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2878" for this suite.

• [SLOW TEST:10.065 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":277,"completed":179,"skipped":3099,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:55:41.260: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:55:41.287: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8dd54645-385c-436a-afe6-57d6ed4d87ba" in namespace "projected-6386" to be "Succeeded or Failed"
Sep 15 19:55:41.289: INFO: Pod "downwardapi-volume-8dd54645-385c-436a-afe6-57d6ed4d87ba": Phase="Pending", Reason="", readiness=false. Elapsed: 1.608096ms
Sep 15 19:55:43.292: INFO: Pod "downwardapi-volume-8dd54645-385c-436a-afe6-57d6ed4d87ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004503943s
Sep 15 19:55:45.295: INFO: Pod "downwardapi-volume-8dd54645-385c-436a-afe6-57d6ed4d87ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007273876s
STEP: Saw pod success
Sep 15 19:55:45.295: INFO: Pod "downwardapi-volume-8dd54645-385c-436a-afe6-57d6ed4d87ba" satisfied condition "Succeeded or Failed"
Sep 15 19:55:45.297: INFO: Trying to get logs from node minion1 pod downwardapi-volume-8dd54645-385c-436a-afe6-57d6ed4d87ba container client-container: <nil>
STEP: delete the pod
Sep 15 19:55:45.307: INFO: Waiting for pod downwardapi-volume-8dd54645-385c-436a-afe6-57d6ed4d87ba to disappear
Sep 15 19:55:45.315: INFO: Pod downwardapi-volume-8dd54645-385c-436a-afe6-57d6ed4d87ba no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:55:45.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6386" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":180,"skipped":3101,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:55:45.320: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 15 19:55:45.348: INFO: Waiting up to 5m0s for pod "pod-fb37b3a8-de7e-4f60-bdb2-36af7d2f235b" in namespace "emptydir-5889" to be "Succeeded or Failed"
Sep 15 19:55:45.351: INFO: Pod "pod-fb37b3a8-de7e-4f60-bdb2-36af7d2f235b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.717653ms
Sep 15 19:55:47.353: INFO: Pod "pod-fb37b3a8-de7e-4f60-bdb2-36af7d2f235b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005333848s
Sep 15 19:55:49.356: INFO: Pod "pod-fb37b3a8-de7e-4f60-bdb2-36af7d2f235b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008229589s
STEP: Saw pod success
Sep 15 19:55:49.356: INFO: Pod "pod-fb37b3a8-de7e-4f60-bdb2-36af7d2f235b" satisfied condition "Succeeded or Failed"
Sep 15 19:55:49.358: INFO: Trying to get logs from node minion1 pod pod-fb37b3a8-de7e-4f60-bdb2-36af7d2f235b container test-container: <nil>
STEP: delete the pod
Sep 15 19:55:49.369: INFO: Waiting for pod pod-fb37b3a8-de7e-4f60-bdb2-36af7d2f235b to disappear
Sep 15 19:55:49.388: INFO: Pod pod-fb37b3a8-de7e-4f60-bdb2-36af7d2f235b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:55:49.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5889" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":181,"skipped":3103,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:55:49.394: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 19:55:49.423: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93797497-9d30-4cbd-a57f-8ca700c49d6e" in namespace "downward-api-6013" to be "Succeeded or Failed"
Sep 15 19:55:49.433: INFO: Pod "downwardapi-volume-93797497-9d30-4cbd-a57f-8ca700c49d6e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.479712ms
Sep 15 19:55:51.436: INFO: Pod "downwardapi-volume-93797497-9d30-4cbd-a57f-8ca700c49d6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012480027s
Sep 15 19:55:53.438: INFO: Pod "downwardapi-volume-93797497-9d30-4cbd-a57f-8ca700c49d6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015222879s
STEP: Saw pod success
Sep 15 19:55:53.438: INFO: Pod "downwardapi-volume-93797497-9d30-4cbd-a57f-8ca700c49d6e" satisfied condition "Succeeded or Failed"
Sep 15 19:55:53.440: INFO: Trying to get logs from node minion1 pod downwardapi-volume-93797497-9d30-4cbd-a57f-8ca700c49d6e container client-container: <nil>
STEP: delete the pod
Sep 15 19:55:53.451: INFO: Waiting for pod downwardapi-volume-93797497-9d30-4cbd-a57f-8ca700c49d6e to disappear
Sep 15 19:55:53.459: INFO: Pod downwardapi-volume-93797497-9d30-4cbd-a57f-8ca700c49d6e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:55:53.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6013" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":182,"skipped":3115,"failed":0}
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:55:53.465: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:56:53.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3466" for this suite.

• [SLOW TEST:60.033 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":277,"completed":183,"skipped":3117,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:56:53.498: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:56:57.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7287" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":277,"completed":184,"skipped":3153,"failed":0}

------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:56:57.541: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Sep 15 19:56:57.562: INFO: PodSpec: initContainers in spec.initContainers
Sep 15 19:57:45.782: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-fc913dde-ae5b-42ff-b005-ae88e0789b94", GenerateName:"", Namespace:"init-container-9374", SelfLink:"/api/v1/namespaces/init-container-9374/pods/pod-init-fc913dde-ae5b-42ff-b005-ae88e0789b94", UID:"7524ac6a-670b-43a5-bf4a-beb01d64bd97", ResourceVersion:"32426", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63735796617, loc:(*time.Location)(0x7b51220)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"562143612"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00406c300), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00406c320)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00406c340), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00406c360)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-wvd84", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0062e03c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wvd84", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wvd84", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wvd84", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc006216488), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"minion1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0007781c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006216510)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006216530)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc006216538), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00621653c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796617, loc:(*time.Location)(0x7b51220)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796617, loc:(*time.Location)(0x7b51220)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796617, loc:(*time.Location)(0x7b51220)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796617, loc:(*time.Location)(0x7b51220)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.40.94", PodIP:"10.251.128.3", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.251.128.3"}}, StartTime:(*v1.Time)(0xc00406c380), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000778310)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0007783f0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://b8936c7af71589b32a978b40c232ef7d54664420fc514ef263ec1283d1e9794d", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00406c3c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00406c3a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc0062165bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:57:45.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9374" for this suite.

• [SLOW TEST:48.247 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":277,"completed":185,"skipped":3153,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:57:45.789: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:57:45.820: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 15 19:57:45.825: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:45.827: INFO: Number of nodes with available pods: 0
Sep 15 19:57:45.827: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:57:46.830: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:46.832: INFO: Number of nodes with available pods: 0
Sep 15 19:57:46.832: INFO: Node minion1 is running more than one daemon pod
Sep 15 19:57:47.834: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:47.836: INFO: Number of nodes with available pods: 2
Sep 15 19:57:47.836: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 15 19:57:47.859: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:47.859: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:47.862: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:48.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:48.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:48.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:49.866: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:49.866: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:49.869: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:50.864: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:50.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:50.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:50.867: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:51.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:51.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:51.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:51.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:52.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:52.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:52.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:52.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:53.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:53.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:53.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:53.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:54.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:54.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:54.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:54.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:55.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:55.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:55.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:55.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:56.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:56.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:56.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:56.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:57.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:57.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:57.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:57.867: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:58.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:58.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:58.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:58.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:57:59.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:59.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:57:59.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:57:59.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:00.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:00.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:58:00.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:00.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:01.865: INFO: Wrong image for pod: daemon-set-7hztw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:01.865: INFO: Pod daemon-set-7hztw is not available
Sep 15 19:58:01.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:01.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:02.865: INFO: Pod daemon-set-cmrgk is not available
Sep 15 19:58:02.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:02.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:03.865: INFO: Pod daemon-set-cmrgk is not available
Sep 15 19:58:03.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:03.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:04.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:04.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:05.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:05.865: INFO: Pod daemon-set-zv4vd is not available
Sep 15 19:58:05.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:06.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:06.865: INFO: Pod daemon-set-zv4vd is not available
Sep 15 19:58:06.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:07.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:07.865: INFO: Pod daemon-set-zv4vd is not available
Sep 15 19:58:07.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:08.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:08.865: INFO: Pod daemon-set-zv4vd is not available
Sep 15 19:58:08.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:09.866: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:09.866: INFO: Pod daemon-set-zv4vd is not available
Sep 15 19:58:09.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:10.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:10.865: INFO: Pod daemon-set-zv4vd is not available
Sep 15 19:58:10.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:11.865: INFO: Wrong image for pod: daemon-set-zv4vd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Sep 15 19:58:11.865: INFO: Pod daemon-set-zv4vd is not available
Sep 15 19:58:11.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:12.865: INFO: Pod daemon-set-vcnsz is not available
Sep 15 19:58:12.868: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 15 19:58:12.870: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:12.872: INFO: Number of nodes with available pods: 1
Sep 15 19:58:12.872: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:58:13.876: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:13.878: INFO: Number of nodes with available pods: 1
Sep 15 19:58:13.878: INFO: Node minion2 is running more than one daemon pod
Sep 15 19:58:14.876: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 15 19:58:14.878: INFO: Number of nodes with available pods: 2
Sep 15 19:58:14.878: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6, will wait for the garbage collector to delete the pods
Sep 15 19:58:14.942: INFO: Deleting DaemonSet.extensions daemon-set took: 4.153343ms
Sep 15 19:58:15.342: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.247564ms
Sep 15 19:58:22.445: INFO: Number of nodes with available pods: 0
Sep 15 19:58:22.445: INFO: Number of running nodes: 0, number of available pods: 0
Sep 15 19:58:22.446: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6/daemonsets","resourceVersion":"32618"},"items":null}

Sep 15 19:58:22.448: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6/pods","resourceVersion":"32618"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:58:22.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6" for this suite.

• [SLOW TEST:36.670 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":277,"completed":186,"skipped":3169,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:58:22.459: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 15 19:58:24.496: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:58:24.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2112" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":187,"skipped":3182,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:58:24.508: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Sep 15 19:58:24.543: INFO: Waiting up to 5m0s for pod "var-expansion-f08475fb-3f78-4dc4-9f92-8b82d3c53e13" in namespace "var-expansion-7848" to be "Succeeded or Failed"
Sep 15 19:58:24.545: INFO: Pod "var-expansion-f08475fb-3f78-4dc4-9f92-8b82d3c53e13": Phase="Pending", Reason="", readiness=false. Elapsed: 1.705303ms
Sep 15 19:58:26.547: INFO: Pod "var-expansion-f08475fb-3f78-4dc4-9f92-8b82d3c53e13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003891525s
STEP: Saw pod success
Sep 15 19:58:26.547: INFO: Pod "var-expansion-f08475fb-3f78-4dc4-9f92-8b82d3c53e13" satisfied condition "Succeeded or Failed"
Sep 15 19:58:26.554: INFO: Trying to get logs from node minion1 pod var-expansion-f08475fb-3f78-4dc4-9f92-8b82d3c53e13 container dapi-container: <nil>
STEP: delete the pod
Sep 15 19:58:26.565: INFO: Waiting for pod var-expansion-f08475fb-3f78-4dc4-9f92-8b82d3c53e13 to disappear
Sep 15 19:58:26.572: INFO: Pod var-expansion-f08475fb-3f78-4dc4-9f92-8b82d3c53e13 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:58:26.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7848" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":277,"completed":188,"skipped":3218,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:58:26.578: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 19:58:26.870: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 19:58:28.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796706, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796706, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796706, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796706, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 19:58:31.886: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 19:58:31.889: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7824-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:58:33.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1905" for this suite.
STEP: Destroying namespace "webhook-1905-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.499 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":277,"completed":189,"skipped":3227,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:58:33.077: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-3619a5ac-aa49-4514-8903-ddae415e4085
STEP: Creating a pod to test consume configMaps
Sep 15 19:58:33.114: INFO: Waiting up to 5m0s for pod "pod-configmaps-39a1ab46-101d-42c9-8678-839bd4aa2216" in namespace "configmap-4755" to be "Succeeded or Failed"
Sep 15 19:58:33.122: INFO: Pod "pod-configmaps-39a1ab46-101d-42c9-8678-839bd4aa2216": Phase="Pending", Reason="", readiness=false. Elapsed: 7.503971ms
Sep 15 19:58:35.125: INFO: Pod "pod-configmaps-39a1ab46-101d-42c9-8678-839bd4aa2216": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010494263s
Sep 15 19:58:37.128: INFO: Pod "pod-configmaps-39a1ab46-101d-42c9-8678-839bd4aa2216": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013334788s
STEP: Saw pod success
Sep 15 19:58:37.128: INFO: Pod "pod-configmaps-39a1ab46-101d-42c9-8678-839bd4aa2216" satisfied condition "Succeeded or Failed"
Sep 15 19:58:37.129: INFO: Trying to get logs from node minion1 pod pod-configmaps-39a1ab46-101d-42c9-8678-839bd4aa2216 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 19:58:37.142: INFO: Waiting for pod pod-configmaps-39a1ab46-101d-42c9-8678-839bd4aa2216 to disappear
Sep 15 19:58:37.149: INFO: Pod pod-configmaps-39a1ab46-101d-42c9-8678-839bd4aa2216 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:58:37.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4755" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":190,"skipped":3245,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:58:37.158: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Sep 15 19:59:39.744: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 19:59:39.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6306" for this suite.

• [SLOW TEST:62.591 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":277,"completed":191,"skipped":3249,"failed":0}
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 19:59:39.750: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-9d3b2487-a0c0-412b-be91-ea1646839325 in namespace container-probe-8408
Sep 15 19:59:43.788: INFO: Started pod busybox-9d3b2487-a0c0-412b-be91-ea1646839325 in namespace container-probe-8408
STEP: checking the pod's current state and verifying that restartCount is present
Sep 15 19:59:43.790: INFO: Initial restart count of pod busybox-9d3b2487-a0c0-412b-be91-ea1646839325 is 0
Sep 15 20:00:31.858: INFO: Restart count of pod container-probe-8408/busybox-9d3b2487-a0c0-412b-be91-ea1646839325 is now 1 (48.068538085s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:00:31.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8408" for this suite.

• [SLOW TEST:52.121 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":192,"skipped":3255,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:00:31.871: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:00:32.739: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 20:00:34.746: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796832, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796832, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796832, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796832, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:00:37.758: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Sep 15 20:00:37.775: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:00:37.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5446" for this suite.
STEP: Destroying namespace "webhook-5446-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.959 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":277,"completed":193,"skipped":3270,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:00:37.831: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:00:38.267: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Sep 15 20:00:40.273: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796838, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796838, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796838, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796838, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:00:43.281: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:00:43.284: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:00:44.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6166" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:6.537 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":277,"completed":194,"skipped":3274,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:00:44.368: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 20:00:44.401: INFO: Waiting up to 5m0s for pod "downwardapi-volume-217fdfbf-d022-41a3-88cf-30aebb2ebd05" in namespace "downward-api-5217" to be "Succeeded or Failed"
Sep 15 20:00:44.410: INFO: Pod "downwardapi-volume-217fdfbf-d022-41a3-88cf-30aebb2ebd05": Phase="Pending", Reason="", readiness=false. Elapsed: 9.027825ms
Sep 15 20:00:46.413: INFO: Pod "downwardapi-volume-217fdfbf-d022-41a3-88cf-30aebb2ebd05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011863307s
Sep 15 20:00:48.416: INFO: Pod "downwardapi-volume-217fdfbf-d022-41a3-88cf-30aebb2ebd05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014600973s
STEP: Saw pod success
Sep 15 20:00:48.416: INFO: Pod "downwardapi-volume-217fdfbf-d022-41a3-88cf-30aebb2ebd05" satisfied condition "Succeeded or Failed"
Sep 15 20:00:48.418: INFO: Trying to get logs from node minion1 pod downwardapi-volume-217fdfbf-d022-41a3-88cf-30aebb2ebd05 container client-container: <nil>
STEP: delete the pod
Sep 15 20:00:48.439: INFO: Waiting for pod downwardapi-volume-217fdfbf-d022-41a3-88cf-30aebb2ebd05 to disappear
Sep 15 20:00:48.445: INFO: Pod downwardapi-volume-217fdfbf-d022-41a3-88cf-30aebb2ebd05 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:00:48.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5217" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":195,"skipped":3279,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:00:48.451: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 15 20:00:48.476: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep 15 20:00:57.503: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:00:57.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4551" for this suite.

• [SLOW TEST:9.059 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":277,"completed":196,"skipped":3316,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:00:57.511: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Sep 15 20:00:57.530: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Sep 15 20:00:57.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-4178'
Sep 15 20:00:57.751: INFO: stderr: ""
Sep 15 20:00:57.751: INFO: stdout: "service/agnhost-slave created\n"
Sep 15 20:00:57.751: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Sep 15 20:00:57.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-4178'
Sep 15 20:00:57.918: INFO: stderr: ""
Sep 15 20:00:57.918: INFO: stdout: "service/agnhost-master created\n"
Sep 15 20:00:57.918: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 15 20:00:57.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-4178'
Sep 15 20:00:58.068: INFO: stderr: ""
Sep 15 20:00:58.068: INFO: stdout: "service/frontend created\n"
Sep 15 20:00:58.068: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Sep 15 20:00:58.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-4178'
Sep 15 20:00:58.208: INFO: stderr: ""
Sep 15 20:00:58.208: INFO: stdout: "deployment.apps/frontend created\n"
Sep 15 20:00:58.208: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 15 20:00:58.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-4178'
Sep 15 20:00:58.369: INFO: stderr: ""
Sep 15 20:00:58.369: INFO: stdout: "deployment.apps/agnhost-master created\n"
Sep 15 20:00:58.369: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 15 20:00:58.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-4178'
Sep 15 20:00:58.520: INFO: stderr: ""
Sep 15 20:00:58.520: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Sep 15 20:00:58.520: INFO: Waiting for all frontend pods to be Running.
Sep 15 20:01:03.571: INFO: Waiting for frontend to serve content.
Sep 15 20:01:03.580: INFO: Trying to add a new entry to the guestbook.
Sep 15 20:01:03.591: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep 15 20:01:03.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete --grace-period=0 --force -f - --namespace=kubectl-4178'
Sep 15 20:01:03.678: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 15 20:01:03.678: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 15 20:01:03.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete --grace-period=0 --force -f - --namespace=kubectl-4178'
Sep 15 20:01:03.761: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 15 20:01:03.761: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 15 20:01:03.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete --grace-period=0 --force -f - --namespace=kubectl-4178'
Sep 15 20:01:03.846: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 15 20:01:03.846: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 15 20:01:03.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete --grace-period=0 --force -f - --namespace=kubectl-4178'
Sep 15 20:01:03.914: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 15 20:01:03.914: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 15 20:01:03.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete --grace-period=0 --force -f - --namespace=kubectl-4178'
Sep 15 20:01:03.989: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 15 20:01:03.989: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 15 20:01:03.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete --grace-period=0 --force -f - --namespace=kubectl-4178'
Sep 15 20:01:04.061: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 15 20:01:04.061: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:01:04.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4178" for this suite.

• [SLOW TEST:6.576 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:310
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":277,"completed":197,"skipped":3356,"failed":0}
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:01:04.087: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Sep 15 20:01:04.125: INFO: Waiting up to 5m0s for pod "var-expansion-0eca684e-dfa2-4364-ad12-a3872711e2c2" in namespace "var-expansion-7603" to be "Succeeded or Failed"
Sep 15 20:01:04.131: INFO: Pod "var-expansion-0eca684e-dfa2-4364-ad12-a3872711e2c2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.583552ms
Sep 15 20:01:06.134: INFO: Pod "var-expansion-0eca684e-dfa2-4364-ad12-a3872711e2c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009287654s
Sep 15 20:01:08.137: INFO: Pod "var-expansion-0eca684e-dfa2-4364-ad12-a3872711e2c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011962221s
STEP: Saw pod success
Sep 15 20:01:08.137: INFO: Pod "var-expansion-0eca684e-dfa2-4364-ad12-a3872711e2c2" satisfied condition "Succeeded or Failed"
Sep 15 20:01:08.139: INFO: Trying to get logs from node minion1 pod var-expansion-0eca684e-dfa2-4364-ad12-a3872711e2c2 container dapi-container: <nil>
STEP: delete the pod
Sep 15 20:01:08.152: INFO: Waiting for pod var-expansion-0eca684e-dfa2-4364-ad12-a3872711e2c2 to disappear
Sep 15 20:01:08.160: INFO: Pod var-expansion-0eca684e-dfa2-4364-ad12-a3872711e2c2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:01:08.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7603" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":277,"completed":198,"skipped":3359,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:01:08.167: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-0bc07fdc-4bec-4f40-ab73-62104e9e7722
STEP: Creating secret with name secret-projected-all-test-volume-e7945f80-398c-4a54-ad0d-2348d0b2424d
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 15 20:01:08.200: INFO: Waiting up to 5m0s for pod "projected-volume-6bf35e72-7164-49f9-a4e2-ca10ec475271" in namespace "projected-4609" to be "Succeeded or Failed"
Sep 15 20:01:08.204: INFO: Pod "projected-volume-6bf35e72-7164-49f9-a4e2-ca10ec475271": Phase="Pending", Reason="", readiness=false. Elapsed: 4.287978ms
Sep 15 20:01:10.207: INFO: Pod "projected-volume-6bf35e72-7164-49f9-a4e2-ca10ec475271": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007064835s
Sep 15 20:01:12.210: INFO: Pod "projected-volume-6bf35e72-7164-49f9-a4e2-ca10ec475271": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009912174s
STEP: Saw pod success
Sep 15 20:01:12.210: INFO: Pod "projected-volume-6bf35e72-7164-49f9-a4e2-ca10ec475271" satisfied condition "Succeeded or Failed"
Sep 15 20:01:12.211: INFO: Trying to get logs from node minion1 pod projected-volume-6bf35e72-7164-49f9-a4e2-ca10ec475271 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 15 20:01:12.226: INFO: Waiting for pod projected-volume-6bf35e72-7164-49f9-a4e2-ca10ec475271 to disappear
Sep 15 20:01:12.234: INFO: Pod projected-volume-6bf35e72-7164-49f9-a4e2-ca10ec475271 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:01:12.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4609" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":277,"completed":199,"skipped":3389,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:01:12.240: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:01:43.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9178" for this suite.
STEP: Destroying namespace "nsdeletetest-4731" for this suite.
Sep 15 20:01:43.343: INFO: Namespace nsdeletetest-4731 was already deleted
STEP: Destroying namespace "nsdeletetest-8333" for this suite.

• [SLOW TEST:31.106 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":277,"completed":200,"skipped":3393,"failed":0}
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:01:43.346: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8360.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8360.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 15 20:01:47.414: INFO: DNS probes using dns-8360/dns-test-f7177673-14f0-456b-9303-fa1eef24bf8f succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:01:47.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8360" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":277,"completed":201,"skipped":3400,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:01:47.464: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:01:48.028: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 20:01:50.034: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796908, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796908, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796908, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796908, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:01:53.043: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:01:53.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9819" for this suite.
STEP: Destroying namespace "webhook-9819-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.801 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":277,"completed":202,"skipped":3402,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:01:53.265: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:01:53.784: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 20:01:55.791: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796913, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796913, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796913, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735796913, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:01:58.800: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:02:10.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1216" for this suite.
STEP: Destroying namespace "webhook-1216-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:17.669 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":277,"completed":203,"skipped":3415,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:02:10.934: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 15 20:02:10.970: INFO: Waiting up to 5m0s for pod "pod-14cc19ad-51dd-4028-99ce-0e89ab39b276" in namespace "emptydir-7621" to be "Succeeded or Failed"
Sep 15 20:02:10.972: INFO: Pod "pod-14cc19ad-51dd-4028-99ce-0e89ab39b276": Phase="Pending", Reason="", readiness=false. Elapsed: 2.11979ms
Sep 15 20:02:12.975: INFO: Pod "pod-14cc19ad-51dd-4028-99ce-0e89ab39b276": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005061s
Sep 15 20:02:14.978: INFO: Pod "pod-14cc19ad-51dd-4028-99ce-0e89ab39b276": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007812832s
STEP: Saw pod success
Sep 15 20:02:14.978: INFO: Pod "pod-14cc19ad-51dd-4028-99ce-0e89ab39b276" satisfied condition "Succeeded or Failed"
Sep 15 20:02:14.980: INFO: Trying to get logs from node minion1 pod pod-14cc19ad-51dd-4028-99ce-0e89ab39b276 container test-container: <nil>
STEP: delete the pod
Sep 15 20:02:14.992: INFO: Waiting for pod pod-14cc19ad-51dd-4028-99ce-0e89ab39b276 to disappear
Sep 15 20:02:14.994: INFO: Pod pod-14cc19ad-51dd-4028-99ce-0e89ab39b276 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:02:14.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7621" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":204,"skipped":3435,"failed":0}
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:02:15.000: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7267.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7267.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7267.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7267.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7267.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7267.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7267.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7267.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7267.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7267.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7267.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 133.28.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.28.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.28.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.28.133_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7267.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7267.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7267.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7267.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7267.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7267.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7267.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7267.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7267.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7267.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7267.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 133.28.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.28.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.28.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.28.133_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 15 20:02:19.287: INFO: Unable to read wheezy_udp@dns-test-service.dns-7267.svc.cluster.local from pod dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf: the server could not find the requested resource (get pods dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf)
Sep 15 20:02:19.290: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7267.svc.cluster.local from pod dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf: the server could not find the requested resource (get pods dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf)
Sep 15 20:02:19.292: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local from pod dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf: the server could not find the requested resource (get pods dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf)
Sep 15 20:02:19.295: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local from pod dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf: the server could not find the requested resource (get pods dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf)
Sep 15 20:02:19.314: INFO: Unable to read jessie_udp@dns-test-service.dns-7267.svc.cluster.local from pod dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf: the server could not find the requested resource (get pods dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf)
Sep 15 20:02:19.316: INFO: Unable to read jessie_tcp@dns-test-service.dns-7267.svc.cluster.local from pod dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf: the server could not find the requested resource (get pods dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf)
Sep 15 20:02:19.319: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local from pod dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf: the server could not find the requested resource (get pods dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf)
Sep 15 20:02:19.321: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local from pod dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf: the server could not find the requested resource (get pods dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf)
Sep 15 20:02:19.339: INFO: Lookups using dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf failed for: [wheezy_udp@dns-test-service.dns-7267.svc.cluster.local wheezy_tcp@dns-test-service.dns-7267.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local jessie_udp@dns-test-service.dns-7267.svc.cluster.local jessie_tcp@dns-test-service.dns-7267.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7267.svc.cluster.local]

Sep 15 20:02:24.388: INFO: DNS probes using dns-7267/dns-test-dfacabbc-0fa6-4ebd-a82b-1cfdad170baf succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:02:24.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7267" for this suite.

• [SLOW TEST:9.473 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":277,"completed":205,"skipped":3443,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:02:24.473: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 15 20:02:26.526: INFO: &Pod{ObjectMeta:{send-events-42cf97eb-3db4-44f6-a9cc-15da890284d0  events-8999 /api/v1/namespaces/events-8999/pods/send-events-42cf97eb-3db4-44f6-a9cc-15da890284d0 70e76c93-5e46-44e8-b13c-417fed1f5d4e 34321 0 2020-09-15 20:02:24 +0000 UTC <nil> <nil> map[name:foo time:509295872] map[] [] []  [{e2e.test Update v1 2020-09-15 20:02:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:02:26 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 49 50 56 46 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bkgmw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bkgmw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bkgmw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:02:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:02:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:02:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:02:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:10.251.128.2,StartTime:2020-09-15 20:02:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:02:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://c752223d9a71c51422e2a84d72c1098d556845db06e12f1d33fc82a2dca4281c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.128.2,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Sep 15 20:02:28.529: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 15 20:02:30.532: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:02:30.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8999" for this suite.

• [SLOW TEST:6.075 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":277,"completed":206,"skipped":3510,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:02:30.549: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-6616
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Sep 15 20:02:30.591: INFO: Found 0 stateful pods, waiting for 3
Sep 15 20:02:40.594: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 20:02:40.594: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 20:02:40.594: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 15 20:02:40.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-6616 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 20:02:40.788: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 20:02:40.788: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 20:02:40.788: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 15 20:02:50.813: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 15 20:03:00.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-6616 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 15 20:03:01.006: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 15 20:03:01.006: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 15 20:03:01.006: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 15 20:03:21.020: INFO: Waiting for StatefulSet statefulset-6616/ss2 to complete update
Sep 15 20:03:21.020: INFO: Waiting for Pod statefulset-6616/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Sep 15 20:03:31.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-6616 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 15 20:03:31.211: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 15 20:03:31.211: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 15 20:03:31.211: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 15 20:03:41.235: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 15 20:03:51.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=statefulset-6616 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 15 20:03:51.429: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 15 20:03:51.429: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 15 20:03:51.429: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 15 20:04:01.442: INFO: Waiting for StatefulSet statefulset-6616/ss2 to complete update
Sep 15 20:04:01.442: INFO: Waiting for Pod statefulset-6616/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Sep 15 20:04:01.442: INFO: Waiting for Pod statefulset-6616/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Sep 15 20:04:01.442: INFO: Waiting for Pod statefulset-6616/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Sep 15 20:04:11.448: INFO: Waiting for StatefulSet statefulset-6616/ss2 to complete update
Sep 15 20:04:11.448: INFO: Waiting for Pod statefulset-6616/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Sep 15 20:04:11.448: INFO: Waiting for Pod statefulset-6616/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Sep 15 20:04:21.447: INFO: Deleting all statefulset in ns statefulset-6616
Sep 15 20:04:21.449: INFO: Scaling statefulset ss2 to 0
Sep 15 20:04:51.459: INFO: Waiting for statefulset status.replicas updated to 0
Sep 15 20:04:51.460: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:04:51.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6616" for this suite.

• [SLOW TEST:140.928 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":277,"completed":207,"skipped":3512,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:04:51.478: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-rzll
STEP: Creating a pod to test atomic-volume-subpath
Sep 15 20:04:51.509: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rzll" in namespace "subpath-8959" to be "Succeeded or Failed"
Sep 15 20:04:51.512: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Pending", Reason="", readiness=false. Elapsed: 2.489599ms
Sep 15 20:04:53.515: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 2.005408035s
Sep 15 20:04:55.517: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 4.008058337s
Sep 15 20:04:57.520: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 6.010844929s
Sep 15 20:04:59.523: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 8.013550066s
Sep 15 20:05:01.525: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 10.01616963s
Sep 15 20:05:03.528: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 12.019032598s
Sep 15 20:05:05.531: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 14.021775561s
Sep 15 20:05:07.534: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 16.024480026s
Sep 15 20:05:09.536: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 18.02720359s
Sep 15 20:05:11.540: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 20.030327948s
Sep 15 20:05:13.542: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Running", Reason="", readiness=true. Elapsed: 22.033005449s
Sep 15 20:05:15.545: INFO: Pod "pod-subpath-test-configmap-rzll": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.035873842s
STEP: Saw pod success
Sep 15 20:05:15.545: INFO: Pod "pod-subpath-test-configmap-rzll" satisfied condition "Succeeded or Failed"
Sep 15 20:05:15.547: INFO: Trying to get logs from node minion1 pod pod-subpath-test-configmap-rzll container test-container-subpath-configmap-rzll: <nil>
STEP: delete the pod
Sep 15 20:05:15.568: INFO: Waiting for pod pod-subpath-test-configmap-rzll to disappear
Sep 15 20:05:15.576: INFO: Pod pod-subpath-test-configmap-rzll no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rzll
Sep 15 20:05:15.576: INFO: Deleting pod "pod-subpath-test-configmap-rzll" in namespace "subpath-8959"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:05:15.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8959" for this suite.

• [SLOW TEST:24.106 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":277,"completed":208,"skipped":3546,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:05:15.584: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-9482
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 15 20:05:15.604: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 15 20:05:15.626: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 15 20:05:17.628: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:05:19.629: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:05:21.629: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:05:23.629: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:05:25.629: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:05:27.629: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:05:29.629: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 15 20:05:29.632: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:05:31.635: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:05:33.636: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:05:35.635: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 15 20:05:39.648: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.251.128.2:8080/dial?request=hostname&protocol=http&host=10.251.128.1&port=8080&tries=1'] Namespace:pod-network-test-9482 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:05:39.648: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:05:39.778: INFO: Waiting for responses: map[]
Sep 15 20:05:39.780: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.251.128.2:8080/dial?request=hostname&protocol=http&host=10.251.32.6&port=8080&tries=1'] Namespace:pod-network-test-9482 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:05:39.780: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:05:39.922: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:05:39.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9482" for this suite.

• [SLOW TEST:24.344 seconds]
[sig-network] Networking
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":277,"completed":209,"skipped":3554,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:05:39.929: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 15 20:05:39.960: INFO: Waiting up to 5m0s for pod "downward-api-2813fb9b-131a-489a-8797-5c7fbd132141" in namespace "downward-api-4524" to be "Succeeded or Failed"
Sep 15 20:05:39.963: INFO: Pod "downward-api-2813fb9b-131a-489a-8797-5c7fbd132141": Phase="Pending", Reason="", readiness=false. Elapsed: 2.479731ms
Sep 15 20:05:41.966: INFO: Pod "downward-api-2813fb9b-131a-489a-8797-5c7fbd132141": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00526443s
Sep 15 20:05:43.968: INFO: Pod "downward-api-2813fb9b-131a-489a-8797-5c7fbd132141": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007899695s
STEP: Saw pod success
Sep 15 20:05:43.968: INFO: Pod "downward-api-2813fb9b-131a-489a-8797-5c7fbd132141" satisfied condition "Succeeded or Failed"
Sep 15 20:05:43.970: INFO: Trying to get logs from node minion1 pod downward-api-2813fb9b-131a-489a-8797-5c7fbd132141 container dapi-container: <nil>
STEP: delete the pod
Sep 15 20:05:43.983: INFO: Waiting for pod downward-api-2813fb9b-131a-489a-8797-5c7fbd132141 to disappear
Sep 15 20:05:43.984: INFO: Pod downward-api-2813fb9b-131a-489a-8797-5c7fbd132141 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:05:43.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4524" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":277,"completed":210,"skipped":3601,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:05:43.992: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Sep 15 20:06:56.041: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:06:56.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7676" for this suite.

• [SLOW TEST:72.055 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":277,"completed":211,"skipped":3663,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:06:56.047: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-c4083609-662e-4c0f-9593-6d58918d51c1 in namespace container-probe-5597
Sep 15 20:07:00.082: INFO: Started pod liveness-c4083609-662e-4c0f-9593-6d58918d51c1 in namespace container-probe-5597
STEP: checking the pod's current state and verifying that restartCount is present
Sep 15 20:07:00.084: INFO: Initial restart count of pod liveness-c4083609-662e-4c0f-9593-6d58918d51c1 is 0
Sep 15 20:07:22.115: INFO: Restart count of pod container-probe-5597/liveness-c4083609-662e-4c0f-9593-6d58918d51c1 is now 1 (22.031654511s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:07:22.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5597" for this suite.

• [SLOW TEST:26.086 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":212,"skipped":3698,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:07:22.134: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:07:22.431: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 20:07:24.437: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797242, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797242, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797242, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797242, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:07:27.445: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Sep 15 20:07:31.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 attach --namespace=webhook-7344 to-be-attached-pod -i -c=container1'
Sep 15 20:07:32.321: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:07:32.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7344" for this suite.
STEP: Destroying namespace "webhook-7344-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:10.230 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":277,"completed":213,"skipped":3727,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:07:32.364: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-5a8d63e3-3358-4f14-bfe2-a561b4e658f5
STEP: Creating a pod to test consume configMaps
Sep 15 20:07:32.397: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b49a38b4-f951-44b6-87ba-f45391e988c1" in namespace "projected-8422" to be "Succeeded or Failed"
Sep 15 20:07:32.401: INFO: Pod "pod-projected-configmaps-b49a38b4-f951-44b6-87ba-f45391e988c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.565362ms
Sep 15 20:07:34.404: INFO: Pod "pod-projected-configmaps-b49a38b4-f951-44b6-87ba-f45391e988c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007315925s
Sep 15 20:07:36.407: INFO: Pod "pod-projected-configmaps-b49a38b4-f951-44b6-87ba-f45391e988c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010054101s
STEP: Saw pod success
Sep 15 20:07:36.407: INFO: Pod "pod-projected-configmaps-b49a38b4-f951-44b6-87ba-f45391e988c1" satisfied condition "Succeeded or Failed"
Sep 15 20:07:36.409: INFO: Trying to get logs from node minion1 pod pod-projected-configmaps-b49a38b4-f951-44b6-87ba-f45391e988c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 20:07:36.421: INFO: Waiting for pod pod-projected-configmaps-b49a38b4-f951-44b6-87ba-f45391e988c1 to disappear
Sep 15 20:07:36.428: INFO: Pod pod-projected-configmaps-b49a38b4-f951-44b6-87ba-f45391e988c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:07:36.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8422" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":214,"skipped":3734,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:07:36.435: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3055
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-3055
I0915 20:07:36.491442      23 runners.go:190] Created replication controller with name: externalname-service, namespace: services-3055, replica count: 2
I0915 20:07:39.541929      23 runners.go:190] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 15 20:07:42.542: INFO: Creating new exec pod
I0915 20:07:42.542137      23 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 15 20:07:45.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-3055 execpodd8pmn -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 15 20:07:45.781: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 15 20:07:45.781: INFO: stdout: ""
Sep 15 20:07:45.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-3055 execpodd8pmn -- /bin/sh -x -c nc -zv -t -w 2 10.241.67.39 80'
Sep 15 20:07:46.013: INFO: stderr: "+ nc -zv -t -w 2 10.241.67.39 80\nConnection to 10.241.67.39 80 port [tcp/http] succeeded!\n"
Sep 15 20:07:46.013: INFO: stdout: ""
Sep 15 20:07:46.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-3055 execpodd8pmn -- /bin/sh -x -c nc -zv -t -w 2 172.31.40.94 31320'
Sep 15 20:07:46.258: INFO: stderr: "+ nc -zv -t -w 2 172.31.40.94 31320\nConnection to 172.31.40.94 31320 port [tcp/31320] succeeded!\n"
Sep 15 20:07:46.258: INFO: stdout: ""
Sep 15 20:07:46.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-3055 execpodd8pmn -- /bin/sh -x -c nc -zv -t -w 2 172.31.33.196 31320'
Sep 15 20:07:46.513: INFO: stderr: "+ nc -zv -t -w 2 172.31.33.196 31320\nConnection to 172.31.33.196 31320 port [tcp/31320] succeeded!\n"
Sep 15 20:07:46.513: INFO: stdout: ""
Sep 15 20:07:46.513: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:07:46.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3055" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:10.103 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":277,"completed":215,"skipped":3762,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:07:46.539: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-00de5584-5dc8-4b1e-8f2e-17546d0b3f6d
STEP: Creating a pod to test consume secrets
Sep 15 20:07:46.601: INFO: Waiting up to 5m0s for pod "pod-secrets-8cb24445-7b7e-41d5-9bf5-50d3c15087b9" in namespace "secrets-6478" to be "Succeeded or Failed"
Sep 15 20:07:46.603: INFO: Pod "pod-secrets-8cb24445-7b7e-41d5-9bf5-50d3c15087b9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.797691ms
Sep 15 20:07:48.605: INFO: Pod "pod-secrets-8cb24445-7b7e-41d5-9bf5-50d3c15087b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004482835s
Sep 15 20:07:50.608: INFO: Pod "pod-secrets-8cb24445-7b7e-41d5-9bf5-50d3c15087b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00724716s
STEP: Saw pod success
Sep 15 20:07:50.608: INFO: Pod "pod-secrets-8cb24445-7b7e-41d5-9bf5-50d3c15087b9" satisfied condition "Succeeded or Failed"
Sep 15 20:07:50.610: INFO: Trying to get logs from node minion1 pod pod-secrets-8cb24445-7b7e-41d5-9bf5-50d3c15087b9 container secret-volume-test: <nil>
STEP: delete the pod
Sep 15 20:07:50.621: INFO: Waiting for pod pod-secrets-8cb24445-7b7e-41d5-9bf5-50d3c15087b9 to disappear
Sep 15 20:07:50.629: INFO: Pod pod-secrets-8cb24445-7b7e-41d5-9bf5-50d3c15087b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:07:50.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6478" for this suite.
STEP: Destroying namespace "secret-namespace-8389" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":277,"completed":216,"skipped":3804,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:07:50.638: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:07:51.260: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 20:07:53.266: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797271, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797271, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797271, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797271, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:07:56.275: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:07:56.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5981" for this suite.
STEP: Destroying namespace "webhook-5981-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.842 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":277,"completed":217,"skipped":3816,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:07:56.480: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Sep 15 20:07:56.518: INFO: Waiting up to 5m0s for pod "client-containers-7c3452c8-20fb-4cf7-b04b-963b43d9f9f9" in namespace "containers-4926" to be "Succeeded or Failed"
Sep 15 20:07:56.519: INFO: Pod "client-containers-7c3452c8-20fb-4cf7-b04b-963b43d9f9f9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.607258ms
Sep 15 20:07:58.522: INFO: Pod "client-containers-7c3452c8-20fb-4cf7-b04b-963b43d9f9f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004350195s
Sep 15 20:08:00.525: INFO: Pod "client-containers-7c3452c8-20fb-4cf7-b04b-963b43d9f9f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007034914s
STEP: Saw pod success
Sep 15 20:08:00.525: INFO: Pod "client-containers-7c3452c8-20fb-4cf7-b04b-963b43d9f9f9" satisfied condition "Succeeded or Failed"
Sep 15 20:08:00.527: INFO: Trying to get logs from node minion1 pod client-containers-7c3452c8-20fb-4cf7-b04b-963b43d9f9f9 container test-container: <nil>
STEP: delete the pod
Sep 15 20:08:00.538: INFO: Waiting for pod client-containers-7c3452c8-20fb-4cf7-b04b-963b43d9f9f9 to disappear
Sep 15 20:08:00.540: INFO: Pod client-containers-7c3452c8-20fb-4cf7-b04b-963b43d9f9f9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:08:00.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4926" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":277,"completed":218,"skipped":3824,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:08:00.545: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-e97ec6ef-e031-4b12-94c2-ae53adc092ff
STEP: Creating a pod to test consume secrets
Sep 15 20:08:00.576: INFO: Waiting up to 5m0s for pod "pod-secrets-a34ee560-cbee-4b93-ae17-8f751e61382b" in namespace "secrets-6910" to be "Succeeded or Failed"
Sep 15 20:08:00.578: INFO: Pod "pod-secrets-a34ee560-cbee-4b93-ae17-8f751e61382b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.501866ms
Sep 15 20:08:02.580: INFO: Pod "pod-secrets-a34ee560-cbee-4b93-ae17-8f751e61382b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003757566s
Sep 15 20:08:04.583: INFO: Pod "pod-secrets-a34ee560-cbee-4b93-ae17-8f751e61382b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006602935s
STEP: Saw pod success
Sep 15 20:08:04.583: INFO: Pod "pod-secrets-a34ee560-cbee-4b93-ae17-8f751e61382b" satisfied condition "Succeeded or Failed"
Sep 15 20:08:04.585: INFO: Trying to get logs from node minion1 pod pod-secrets-a34ee560-cbee-4b93-ae17-8f751e61382b container secret-volume-test: <nil>
STEP: delete the pod
Sep 15 20:08:04.596: INFO: Waiting for pod pod-secrets-a34ee560-cbee-4b93-ae17-8f751e61382b to disappear
Sep 15 20:08:04.604: INFO: Pod pod-secrets-a34ee560-cbee-4b93-ae17-8f751e61382b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:08:04.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6910" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":219,"skipped":3831,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:08:04.610: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:08:05.391: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 20:08:07.398: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797285, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797285, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797285, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797285, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:08:10.406: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:08:10.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9255" for this suite.
STEP: Destroying namespace "webhook-9255-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.903 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":277,"completed":220,"skipped":3837,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:08:10.514: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 20:08:10.549: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d59298b2-0a34-4260-9efd-b86930045d1a" in namespace "downward-api-7772" to be "Succeeded or Failed"
Sep 15 20:08:10.552: INFO: Pod "downwardapi-volume-d59298b2-0a34-4260-9efd-b86930045d1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.504963ms
Sep 15 20:08:12.555: INFO: Pod "downwardapi-volume-d59298b2-0a34-4260-9efd-b86930045d1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005153774s
Sep 15 20:08:14.557: INFO: Pod "downwardapi-volume-d59298b2-0a34-4260-9efd-b86930045d1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00796596s
STEP: Saw pod success
Sep 15 20:08:14.557: INFO: Pod "downwardapi-volume-d59298b2-0a34-4260-9efd-b86930045d1a" satisfied condition "Succeeded or Failed"
Sep 15 20:08:14.559: INFO: Trying to get logs from node minion1 pod downwardapi-volume-d59298b2-0a34-4260-9efd-b86930045d1a container client-container: <nil>
STEP: delete the pod
Sep 15 20:08:14.570: INFO: Waiting for pod downwardapi-volume-d59298b2-0a34-4260-9efd-b86930045d1a to disappear
Sep 15 20:08:14.578: INFO: Pod downwardapi-volume-d59298b2-0a34-4260-9efd-b86930045d1a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:08:14.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7772" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":221,"skipped":3848,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:08:14.584: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-5938/configmap-test-2e992acf-5f30-4420-984a-0f58b9a95304
STEP: Creating a pod to test consume configMaps
Sep 15 20:08:14.624: INFO: Waiting up to 5m0s for pod "pod-configmaps-9def861b-4329-45ce-a44b-7bb728b0ccbc" in namespace "configmap-5938" to be "Succeeded or Failed"
Sep 15 20:08:14.626: INFO: Pod "pod-configmaps-9def861b-4329-45ce-a44b-7bb728b0ccbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.322874ms
Sep 15 20:08:16.629: INFO: Pod "pod-configmaps-9def861b-4329-45ce-a44b-7bb728b0ccbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005209553s
Sep 15 20:08:18.632: INFO: Pod "pod-configmaps-9def861b-4329-45ce-a44b-7bb728b0ccbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007841654s
STEP: Saw pod success
Sep 15 20:08:18.632: INFO: Pod "pod-configmaps-9def861b-4329-45ce-a44b-7bb728b0ccbc" satisfied condition "Succeeded or Failed"
Sep 15 20:08:18.633: INFO: Trying to get logs from node minion1 pod pod-configmaps-9def861b-4329-45ce-a44b-7bb728b0ccbc container env-test: <nil>
STEP: delete the pod
Sep 15 20:08:18.654: INFO: Waiting for pod pod-configmaps-9def861b-4329-45ce-a44b-7bb728b0ccbc to disappear
Sep 15 20:08:18.656: INFO: Pod pod-configmaps-9def861b-4329-45ce-a44b-7bb728b0ccbc no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:08:18.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5938" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":277,"completed":222,"skipped":3875,"failed":0}
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:08:18.662: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-09b89778-74fc-4e31-931f-e782514a79d9
STEP: Creating configMap with name cm-test-opt-upd-2466adc1-f273-4f72-8e0e-a728e0664ed4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-09b89778-74fc-4e31-931f-e782514a79d9
STEP: Updating configmap cm-test-opt-upd-2466adc1-f273-4f72-8e0e-a728e0664ed4
STEP: Creating configMap with name cm-test-opt-create-c7e29846-f1ec-4bf8-bee2-f2f42a9803c5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:08:26.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4773" for this suite.

• [SLOW TEST:8.107 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":223,"skipped":3878,"failed":0}
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:08:26.770: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:08:26.788: INFO: Creating deployment "webserver-deployment"
Sep 15 20:08:26.795: INFO: Waiting for observed generation 1
Sep 15 20:08:28.800: INFO: Waiting for all required pods to come up
Sep 15 20:08:28.803: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 15 20:08:30.811: INFO: Waiting for deployment "webserver-deployment" to complete
Sep 15 20:08:30.815: INFO: Updating deployment "webserver-deployment" with a non-existent image
Sep 15 20:08:30.820: INFO: Updating deployment webserver-deployment
Sep 15 20:08:30.820: INFO: Waiting for observed generation 2
Sep 15 20:08:32.825: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 15 20:08:32.827: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 15 20:08:32.829: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 15 20:08:32.834: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 15 20:08:32.834: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 15 20:08:32.836: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 15 20:08:32.839: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Sep 15 20:08:32.839: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Sep 15 20:08:32.844: INFO: Updating deployment webserver-deployment
Sep 15 20:08:32.844: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Sep 15 20:08:32.849: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 15 20:08:32.859: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 15 20:08:32.893: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2176 /apis/apps/v1/namespaces/deployment-2176/deployments/webserver-deployment e2114b22-4e7c-4285-bb5e-6dcd69190921 36698 3 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001bebb88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-09-15 20:08:30 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-09-15 20:08:32 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Sep 15 20:08:32.929: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-2176 /apis/apps/v1/namespaces/deployment-2176/replicasets/webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 36679 3 2020-09-15 20:08:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment e2114b22-4e7c-4285-bb5e-6dcd69190921 0xc002c66807 0xc002c66808}] []  [{kube-controller-manager Update apps/v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 50 49 49 52 98 50 50 45 52 101 55 99 45 52 50 56 53 45 98 98 53 101 45 54 100 99 100 54 57 49 57 48 57 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002c66898 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 15 20:08:32.929: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Sep 15 20:08:32.929: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-2176 /apis/apps/v1/namespaces/deployment-2176/replicasets/webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 36729 3 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment e2114b22-4e7c-4285-bb5e-6dcd69190921 0xc002c66917 0xc002c66918}] []  [{kube-controller-manager Update apps/v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 50 49 49 52 98 50 50 45 52 101 55 99 45 52 50 56 53 45 98 98 53 101 45 54 100 99 100 54 57 49 57 48 57 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002c66988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Sep 15 20:08:32.944: INFO: Pod "webserver-deployment-6676bcd6d4-2lqm9" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-2lqm9 webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-2lqm9 e07c7bef-b939-40ea-8e02-4d112ab0ff91 36731 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc002c67777 0xc002c67778}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.944: INFO: Pod "webserver-deployment-6676bcd6d4-6sx57" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-6sx57 webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-6sx57 9ddea4bb-6d03-429e-8ee1-a8bd894a3b63 36742 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032da1f0 0xc0032da1f1}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.944: INFO: Pod "webserver-deployment-6676bcd6d4-98vt9" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-98vt9 webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-98vt9 b4d6368c-74f8-4953-a727-15db2ecb278b 36633 0 2020-09-15 20:08:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032da387 0xc0032da388}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:,StartTime:2020-09-15 20:08:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.945: INFO: Pod "webserver-deployment-6676bcd6d4-bgbjd" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-bgbjd webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-bgbjd c212071c-35a6-4f07-a8b3-880d687efc00 36622 0 2020-09-15 20:08:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032da8a7 0xc0032da8a8}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:,StartTime:2020-09-15 20:08:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.945: INFO: Pod "webserver-deployment-6676bcd6d4-bht47" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-bht47 webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-bht47 80a64336-1b75-4eb9-9846-d0d0096d25d6 36707 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032dac17 0xc0032dac18}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.969: INFO: Pod "webserver-deployment-6676bcd6d4-dpb4p" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-dpb4p webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-dpb4p 7caf86b3-c51c-4090-921f-bf69d5a7a3f6 36647 0 2020-09-15 20:08:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032daf10 0xc0032daf11}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:31 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:,StartTime:2020-09-15 20:08:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.969: INFO: Pod "webserver-deployment-6676bcd6d4-dtk4v" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-dtk4v webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-dtk4v 79c53e74-6bbb-414a-ba21-60cdb2aba5d7 36730 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032db2f7 0xc0032db2f8}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.973: INFO: Pod "webserver-deployment-6676bcd6d4-kgvlz" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-kgvlz webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-kgvlz 4976c4a2-4649-458e-86a0-75ab0e0bcbdd 36692 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032db540 0xc0032db541}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.973: INFO: Pod "webserver-deployment-6676bcd6d4-plrhr" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-plrhr webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-plrhr d2394d81-da67-43ce-af90-728b50ddcf97 36623 0 2020-09-15 20:08:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032db890 0xc0032db891}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.33.196,PodIP:,StartTime:2020-09-15 20:08:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.974: INFO: Pod "webserver-deployment-6676bcd6d4-pqtqc" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-pqtqc webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-pqtqc 058f9706-c3b9-4dbe-9381-ca6171ab8ef5 36740 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032dbc47 0xc0032dbc48}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.974: INFO: Pod "webserver-deployment-6676bcd6d4-tlcvp" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-tlcvp webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-tlcvp ab9ee965-e9e6-45d0-9357-be1c603c6ef2 36738 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032dbe60 0xc0032dbe61}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.974: INFO: Pod "webserver-deployment-6676bcd6d4-vpbl4" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-vpbl4 webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-vpbl4 6c4f91cc-b328-4699-9880-32bce0002cec 36710 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0032dbfa0 0xc0032dbfa1}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.974: INFO: Pod "webserver-deployment-6676bcd6d4-xf2h8" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-xf2h8 webserver-deployment-6676bcd6d4- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-6676bcd6d4-xf2h8 d0261bdc-0ae7-440d-8026-f77397d974bc 36649 0 2020-09-15 20:08:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 a8f26578-d15d-4648-8a7d-edb593d5acd0 0xc0004f0b50 0xc0004f0b51}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 102 50 54 53 55 56 45 100 49 53 100 45 52 54 52 56 45 56 97 55 100 45 101 100 98 53 57 51 100 53 97 99 100 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:31 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:,StartTime:2020-09-15 20:08:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.975: INFO: Pod "webserver-deployment-84855cf797-4ssl6" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-4ssl6 webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-4ssl6 81d176c0-9f51-4ae4-832d-4de78a3c39c9 36554 0 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc0004f1bd7 0xc0004f1bd8}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:28 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 49 50 56 46 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:10.251.128.2,StartTime:2020-09-15 20:08:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:08:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://63d10b2659da020906c28c530c381d23f0ec95c834253767eb0d78ebdb0a45ba,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.128.2,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.975: INFO: Pod "webserver-deployment-84855cf797-6bcsw" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6bcsw webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-6bcsw 1284ad69-a4c8-4e10-a573-8af54763c38d 36708 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc0021400e7 0xc0021400e8}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.975: INFO: Pod "webserver-deployment-84855cf797-754v2" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-754v2 webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-754v2 ace5bb4e-7023-486a-b70b-1b443a066d5e 36709 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002140210 0xc002140211}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.975: INFO: Pod "webserver-deployment-84855cf797-7b2g4" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-7b2g4 webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-7b2g4 050a3584-7984-4026-9b42-7c14f28e5044 36723 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002140360 0xc002140361}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.975: INFO: Pod "webserver-deployment-84855cf797-bt7cr" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-bt7cr webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-bt7cr ff208dd9-2c29-4681-b97c-f685ec79a8c1 36718 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002140490 0xc002140491}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.976: INFO: Pod "webserver-deployment-84855cf797-bxjx5" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-bxjx5 webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-bxjx5 985bb5f2-6813-4b62-a7fe-e8be55378c42 36588 0 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc0021405c0 0xc0021405c1}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 49 50 56 46 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:10.251.128.7,StartTime:2020-09-15 20:08:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:08:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://0dffe87066f4f8ad9a81c9718c7144cf0547820ec6f318fa05909c33427e6973,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.128.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.976: INFO: Pod "webserver-deployment-84855cf797-cjn6r" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-cjn6r webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-cjn6r 59331e46-4862-4e8c-8c8c-610fdf72abd9 36702 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002140767 0xc002140768}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.977: INFO: Pod "webserver-deployment-84855cf797-dkxhd" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-dkxhd webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-dkxhd f875a30f-3839-4166-b326-2feb9b09454c 36725 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002140890 0xc002140891}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.977: INFO: Pod "webserver-deployment-84855cf797-m4k69" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-m4k69 webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-m4k69 798ff873-93e4-469c-be1b-6de4ca46b57f 36745 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc0021409c0 0xc0021409c1}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:,StartTime:2020-09-15 20:08:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.977: INFO: Pod "webserver-deployment-84855cf797-nbs5k" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-nbs5k webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-nbs5k fd98ad77-9dc4-4103-8778-2958478a9669 36551 0 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002140b47 0xc002140b48}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:28 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 49 50 56 46 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:10.251.128.3,StartTime:2020-09-15 20:08:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:08:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1bb5ddc0dd669b6b39659b71b358b05ea276f25742f569931501b2d518ad87b4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.128.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.977: INFO: Pod "webserver-deployment-84855cf797-nkk9z" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-nkk9z webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-nkk9z 68f4fcf3-d140-471e-8f0b-011db7b037d9 36719 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002140cf7 0xc002140cf8}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.33.196,PodIP:,StartTime:2020-09-15 20:08:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.978: INFO: Pod "webserver-deployment-84855cf797-p4vwg" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-p4vwg webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-p4vwg fe934281-e29c-41d8-9307-dd2e0365a640 36568 0 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002140e97 0xc002140e98}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:29 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 51 50 46 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.33.196,PodIP:10.251.32.8,StartTime:2020-09-15 20:08:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:08:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://35d92eeca9c7d7d4fbc504bbcad4b2f83a83b2614010ec4f62ea09ff46b46179,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.32.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.978: INFO: Pod "webserver-deployment-84855cf797-q67bh" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-q67bh webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-q67bh 13d4be8d-6019-41d9-8862-312a066bbc76 36724 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002141050 0xc002141051}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.979: INFO: Pod "webserver-deployment-84855cf797-qbndq" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-qbndq webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-qbndq d313edea-b418-43cb-ad1c-3edf15284468 36593 0 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002141180 0xc002141181}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 51 50 46 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.33.196,PodIP:10.251.32.7,StartTime:2020-09-15 20:08:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:08:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5a9dd57ecc97c632b813104a0ed86f945192b7fed2539603b82fd19c2241cbcb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.32.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.979: INFO: Pod "webserver-deployment-84855cf797-rxkwp" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rxkwp webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-rxkwp 6e01cd82-d059-4f96-91f8-d77507f46b92 36558 0 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002141320 0xc002141321}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:28 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 49 50 56 46 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:10.251.128.5,StartTime:2020-09-15 20:08:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:08:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://64d37730db625de0520059187932177dfe1d11080f4d47dfa6eb7d90f9c8cafe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.128.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.980: INFO: Pod "webserver-deployment-84855cf797-s6xpv" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-s6xpv webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-s6xpv a3f209d6-e3ca-43a2-8907-d10a61d7728d 36747 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc0021414c7 0xc0021414c8}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.33.196,PodIP:,StartTime:2020-09-15 20:08:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.980: INFO: Pod "webserver-deployment-84855cf797-vgkm7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-vgkm7 webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-vgkm7 4538f5ad-6e4d-4666-bffc-dd5c3d72e097 36717 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002141657 0xc002141658}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.981: INFO: Pod "webserver-deployment-84855cf797-vl5lk" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-vl5lk webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-vl5lk 80ed8eff-721a-45a9-a804-94846c329dc1 36575 0 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002141780 0xc002141781}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:29 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 51 50 46 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.33.196,PodIP:10.251.32.6,StartTime:2020-09-15 20:08:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:08:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://7121ef76bf719988fe223a38fb0f398bae7a945ba8df809859f6c453b5359769,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.32.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.981: INFO: Pod "webserver-deployment-84855cf797-x5nsw" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-x5nsw webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-x5nsw 56186140-9023-462a-9de8-6ee8cbc23202 36728 0 2020-09-15 20:08:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002141920 0xc002141921}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:08:32.981: INFO: Pod "webserver-deployment-84855cf797-zj5dx" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-zj5dx webserver-deployment-84855cf797- deployment-2176 /api/v1/namespaces/deployment-2176/pods/webserver-deployment-84855cf797-zj5dx 059dc974-71eb-485d-8e80-cb057048f0b9 36572 0 2020-09-15 20:08:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 f2d32e22-b5d2-455a-ae64-b65b4bd61ee4 0xc002141a50 0xc002141a51}] []  [{kube-controller-manager Update v1 2020-09-15 20:08:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 100 51 50 101 50 50 45 98 53 100 50 45 52 53 53 97 45 97 101 54 52 45 98 54 53 98 52 98 100 54 49 101 101 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:08:29 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 51 50 46 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qjfmb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qjfmb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qjfmb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:08:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.33.196,PodIP:10.251.32.9,StartTime:2020-09-15 20:08:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:08:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b9f165742f380d602cbdbbf540ff096995ed7ccc199755c46b89761f7e1399ab,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.32.9,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:08:32.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2176" for this suite.

• [SLOW TEST:6.229 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":277,"completed":224,"skipped":3884,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:08:33.000: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-8687ebdf-5c87-4580-a90b-c5ff3c3fca94
STEP: Creating a pod to test consume secrets
Sep 15 20:08:33.043: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4" in namespace "projected-736" to be "Succeeded or Failed"
Sep 15 20:08:33.050: INFO: Pod "pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.732151ms
Sep 15 20:08:35.052: INFO: Pod "pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009098842s
Sep 15 20:08:37.055: INFO: Pod "pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011521556s
Sep 15 20:08:39.057: INFO: Pod "pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013924491s
Sep 15 20:08:41.060: INFO: Pod "pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.016446835s
STEP: Saw pod success
Sep 15 20:08:41.060: INFO: Pod "pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4" satisfied condition "Succeeded or Failed"
Sep 15 20:08:41.061: INFO: Trying to get logs from node minion1 pod pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 15 20:08:41.074: INFO: Waiting for pod pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4 to disappear
Sep 15 20:08:41.082: INFO: Pod pod-projected-secrets-e642c6a4-918f-4a0c-b21d-5171c05ffee4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:08:41.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-736" for this suite.

• [SLOW TEST:8.087 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":225,"skipped":3916,"failed":0}
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:08:41.088: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:08:41.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5212" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":277,"completed":226,"skipped":3917,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:08:41.144: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-413
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-413
STEP: creating replication controller externalsvc in namespace services-413
I0915 20:08:41.219680      23 runners.go:190] Created replication controller with name: externalsvc, namespace: services-413, replica count: 2
I0915 20:08:44.270176      23 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Sep 15 20:08:44.279: INFO: Creating new exec pod
Sep 15 20:08:48.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 exec --namespace=services-413 execpodpjvm8 -- /bin/sh -x -c nslookup clusterip-service'
Sep 15 20:08:48.492: INFO: stderr: "+ nslookup clusterip-service\n"
Sep 15 20:08:48.492: INFO: stdout: "Server:\t\t169.254.25.10\nAddress:\t169.254.25.10#53\n\nclusterip-service.services-413.svc.cluster.local\tcanonical name = externalsvc.services-413.svc.cluster.local.\nName:\texternalsvc.services-413.svc.cluster.local\nAddress: 10.241.197.75\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-413, will wait for the garbage collector to delete the pods
Sep 15 20:08:48.549: INFO: Deleting ReplicationController externalsvc took: 3.735849ms
Sep 15 20:08:48.949: INFO: Terminating ReplicationController externalsvc pods took: 400.221732ms
Sep 15 20:09:02.361: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:09:02.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-413" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:21.238 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":277,"completed":227,"skipped":3929,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:09:02.383: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:09:02.918: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 20:09:04.925: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797342, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797342, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797343, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735797342, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:09:07.934: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:09:07.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6081" for this suite.
STEP: Destroying namespace "webhook-6081-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.626 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":277,"completed":228,"skipped":3977,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:09:08.010: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 15 20:09:08.045: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 15 20:09:08.059: INFO: Waiting for terminating namespaces to be deleted...
Sep 15 20:09:08.061: INFO: 
Logging pods the kubelet thinks is on node minion1 before test
Sep 15 20:09:08.067: INFO: nginx-proxy-minion1 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.067: INFO: 	Container nginx-proxy ready: true, restart count 0
Sep 15 20:09:08.067: INFO: weave-net-sj6qn from kube-system started at 2020-09-15 17:49:49 +0000 UTC (2 container statuses recorded)
Sep 15 20:09:08.067: INFO: 	Container weave ready: true, restart count 0
Sep 15 20:09:08.067: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 20:09:08.067: INFO: weave-scope-agent-wft6l from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.067: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 20:09:08.067: INFO: sonobuoy from sonobuoy started at 2020-09-15 19:07:01 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.067: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 15 20:09:08.067: INFO: kube-proxy-z8vzb from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.067: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 20:09:08.067: INFO: nodelocaldns-dk627 from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.067: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 20:09:08.067: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-2zszp from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 20:09:08.067: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 15 20:09:08.067: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 15 20:09:08.067: INFO: 
Logging pods the kubelet thinks is on node minion2 before test
Sep 15 20:09:08.088: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-kwcxg from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 15 20:09:08.088: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 15 20:09:08.088: INFO: weave-scope-app-bc7444d59-mwtxs from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container app ready: true, restart count 0
Sep 15 20:09:08.088: INFO: nodelocaldns-d2gct from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 20:09:08.088: INFO: sonobuoy-e2e-job-874580613c114f91 from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container e2e ready: true, restart count 0
Sep 15 20:09:08.088: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 20:09:08.088: INFO: kube-proxy-5lm96 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 20:09:08.088: INFO: kubernetes-dashboard-667c4c65f8-6llcw from kube-system started at 2020-09-15 19:24:47 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 15 20:09:08.088: INFO: weave-scope-cluster-agent-7944c858c9-tsb78 from weave started at 2020-09-15 19:43:27 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container scope-cluster-agent ready: true, restart count 0
Sep 15 20:09:08.088: INFO: nginx-proxy-minion2 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container nginx-proxy ready: true, restart count 0
Sep 15 20:09:08.088: INFO: weave-net-9ck4j from kube-system started at 2020-09-15 17:49:48 +0000 UTC (2 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container weave ready: true, restart count 0
Sep 15 20:09:08.088: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 20:09:08.088: INFO: coredns-59dcc4799b-dpc9n from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container coredns ready: true, restart count 0
Sep 15 20:09:08.088: INFO: weave-scope-agent-wg887 from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 20:09:08.088: INFO: kubernetes-metrics-scraper-54fbb4d595-ncb4z from kube-system started at 2020-09-15 19:43:27 +0000 UTC (1 container statuses recorded)
Sep 15 20:09:08.088: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e59407c9-dec8-4c59-bab7-bd48c5b65ba0 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-e59407c9-dec8-4c59-bab7-bd48c5b65ba0 off the node minion1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e59407c9-dec8-4c59-bab7-bd48c5b65ba0
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:14:16.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6711" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:308.141 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":277,"completed":229,"skipped":4005,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:14:16.151: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Sep 15 20:14:16.174: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:14:30.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8937" for this suite.

• [SLOW TEST:13.918 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":277,"completed":230,"skipped":4009,"failed":0}
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:14:30.069: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 15 20:14:30.100: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 15 20:14:35.103: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:14:36.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8156" for this suite.

• [SLOW TEST:6.049 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":277,"completed":231,"skipped":4009,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:14:36.118: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:14:36.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1753" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":277,"completed":232,"skipped":4025,"failed":0}
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:14:36.168: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 15 20:14:44.215: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:44.215: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:44.324: INFO: Exec stderr: ""
Sep 15 20:14:44.324: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:44.324: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:44.464: INFO: Exec stderr: ""
Sep 15 20:14:44.464: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:44.464: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:44.585: INFO: Exec stderr: ""
Sep 15 20:14:44.585: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:44.585: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:44.709: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 15 20:14:44.709: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:44.709: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:44.820: INFO: Exec stderr: ""
Sep 15 20:14:44.820: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:44.820: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:44.938: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 15 20:14:44.939: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:44.939: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:45.043: INFO: Exec stderr: ""
Sep 15 20:14:45.043: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:45.043: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:45.158: INFO: Exec stderr: ""
Sep 15 20:14:45.158: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:45.158: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:45.283: INFO: Exec stderr: ""
Sep 15 20:14:45.283: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3103 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:14:45.283: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:14:45.401: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:14:45.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3103" for this suite.

• [SLOW TEST:9.238 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":233,"skipped":4030,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:14:45.407: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:14:45.435: INFO: Waiting up to 5m0s for pod "busybox-user-65534-eef3a2cf-d7dd-4ebd-8b37-93449197da3f" in namespace "security-context-test-4911" to be "Succeeded or Failed"
Sep 15 20:14:45.437: INFO: Pod "busybox-user-65534-eef3a2cf-d7dd-4ebd-8b37-93449197da3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.197588ms
Sep 15 20:14:47.440: INFO: Pod "busybox-user-65534-eef3a2cf-d7dd-4ebd-8b37-93449197da3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004852758s
Sep 15 20:14:49.442: INFO: Pod "busybox-user-65534-eef3a2cf-d7dd-4ebd-8b37-93449197da3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007719649s
Sep 15 20:14:49.442: INFO: Pod "busybox-user-65534-eef3a2cf-d7dd-4ebd-8b37-93449197da3f" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:14:49.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4911" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":234,"skipped":4066,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:14:49.450: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-542.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-542.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-542.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-542.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 15 20:14:53.513: INFO: DNS probes using dns-test-260a3b91-1246-49ef-9b03-1f2f00ed8011 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-542.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-542.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-542.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-542.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 15 20:14:57.557: INFO: DNS probes using dns-test-ce5c996f-d8e1-4e7d-ad20-6763995756dd succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-542.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-542.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-542.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-542.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 15 20:15:01.825: INFO: DNS probes using dns-test-d0456c17-873e-4afd-be64-76e09c6c063d succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:15:01.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-542" for this suite.

• [SLOW TEST:12.417 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":277,"completed":235,"skipped":4088,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:15:01.867: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2039 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2039;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2039 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2039;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2039.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2039.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2039.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2039.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2039.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2039.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2039.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2039.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2039.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2039.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2039.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2039.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2039.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 28.130.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.130.28_udp@PTR;check="$$(dig +tcp +noall +answer +search 28.130.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.130.28_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2039 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2039;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2039 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2039;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2039.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2039.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2039.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2039.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2039.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2039.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2039.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2039.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2039.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2039.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2039.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2039.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2039.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 28.130.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.130.28_udp@PTR;check="$$(dig +tcp +noall +answer +search 28.130.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.130.28_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 15 20:15:05.955: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.958: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.961: INFO: Unable to read wheezy_udp@dns-test-service.dns-2039 from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.963: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2039 from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.969: INFO: Unable to read wheezy_udp@dns-test-service.dns-2039.svc from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.971: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2039.svc from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.974: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2039.svc from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.976: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2039.svc from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.994: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.996: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:05.999: INFO: Unable to read jessie_udp@dns-test-service.dns-2039 from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:06.002: INFO: Unable to read jessie_tcp@dns-test-service.dns-2039 from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:06.004: INFO: Unable to read jessie_udp@dns-test-service.dns-2039.svc from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:06.007: INFO: Unable to read jessie_tcp@dns-test-service.dns-2039.svc from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:06.009: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2039.svc from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:06.012: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2039.svc from pod dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea: the server could not find the requested resource (get pods dns-test-add5fc30-fbda-48ae-ad26-098558437eea)
Sep 15 20:15:06.027: INFO: Lookups using dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2039 wheezy_tcp@dns-test-service.dns-2039 wheezy_udp@dns-test-service.dns-2039.svc wheezy_tcp@dns-test-service.dns-2039.svc wheezy_udp@_http._tcp.dns-test-service.dns-2039.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2039.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2039 jessie_tcp@dns-test-service.dns-2039 jessie_udp@dns-test-service.dns-2039.svc jessie_tcp@dns-test-service.dns-2039.svc jessie_udp@_http._tcp.dns-test-service.dns-2039.svc jessie_tcp@_http._tcp.dns-test-service.dns-2039.svc]

Sep 15 20:15:11.100: INFO: DNS probes using dns-2039/dns-test-add5fc30-fbda-48ae-ad26-098558437eea succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:15:11.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2039" for this suite.

• [SLOW TEST:9.312 seconds]
[sig-network] DNS
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":277,"completed":236,"skipped":4107,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:15:11.180: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 15 20:15:15.726: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d3d81f2c-561b-4c80-bb43-1c604d69f0f4"
Sep 15 20:15:15.726: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d3d81f2c-561b-4c80-bb43-1c604d69f0f4" in namespace "pods-5122" to be "terminated due to deadline exceeded"
Sep 15 20:15:15.727: INFO: Pod "pod-update-activedeadlineseconds-d3d81f2c-561b-4c80-bb43-1c604d69f0f4": Phase="Running", Reason="", readiness=true. Elapsed: 1.641064ms
Sep 15 20:15:17.730: INFO: Pod "pod-update-activedeadlineseconds-d3d81f2c-561b-4c80-bb43-1c604d69f0f4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.003910003s
Sep 15 20:15:17.730: INFO: Pod "pod-update-activedeadlineseconds-d3d81f2c-561b-4c80-bb43-1c604d69f0f4" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:15:17.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5122" for this suite.

• [SLOW TEST:6.556 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":277,"completed":237,"skipped":4113,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:15:17.737: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 15 20:15:17.769: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5414 /api/v1/namespaces/watch-5414/configmaps/e2e-watch-test-watch-closed cc2c8459-5f00-470b-9b73-f448e95794cf 38758 0 2020-09-15 20:15:17 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-15 20:15:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 20:15:17.769: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5414 /api/v1/namespaces/watch-5414/configmaps/e2e-watch-test-watch-closed cc2c8459-5f00-470b-9b73-f448e95794cf 38759 0 2020-09-15 20:15:17 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-15 20:15:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 15 20:15:17.777: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5414 /api/v1/namespaces/watch-5414/configmaps/e2e-watch-test-watch-closed cc2c8459-5f00-470b-9b73-f448e95794cf 38760 0 2020-09-15 20:15:17 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-15 20:15:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Sep 15 20:15:17.778: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5414 /api/v1/namespaces/watch-5414/configmaps/e2e-watch-test-watch-closed cc2c8459-5f00-470b-9b73-f448e95794cf 38761 0 2020-09-15 20:15:17 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-09-15 20:15:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:15:17.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5414" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":277,"completed":238,"skipped":4167,"failed":0}
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:15:17.783: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-474
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 15 20:15:17.810: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 15 20:15:17.829: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 15 20:15:19.832: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:15:21.832: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:15:23.831: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:15:25.832: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:15:27.832: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:15:29.832: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:15:31.832: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 15 20:15:31.836: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:15:33.838: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:15:35.838: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:15:37.839: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 15 20:15:41.873: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.251.128.1 8081 | grep -v '^\s*$'] Namespace:pod-network-test-474 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:15:41.873: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:15:42.991: INFO: Found all expected endpoints: [netserver-0]
Sep 15 20:15:42.993: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.251.32.6 8081 | grep -v '^\s*$'] Namespace:pod-network-test-474 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:15:42.993: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:15:44.114: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:15:44.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-474" for this suite.

• [SLOW TEST:26.338 seconds]
[sig-network] Networking
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":239,"skipped":4172,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:15:44.121: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 15 20:15:46.161: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:15:46.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9834" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":240,"skipped":4179,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:15:46.183: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:16:13.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2793" for this suite.

• [SLOW TEST:27.182 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    when starting a container that exits
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":277,"completed":241,"skipped":4197,"failed":0}
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:16:13.365: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:16:13.393: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 15 20:16:18.396: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 15 20:16:18.396: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Sep 15 20:16:18.411: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4381 /apis/apps/v1/namespaces/deployment-4381/deployments/test-cleanup-deployment 807d76cc-d0aa-4c91-b760-27015dfada49 39112 1 2020-09-15 20:16:18 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2020-09-15 20:16:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002c661c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Sep 15 20:16:18.423: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-4381 /apis/apps/v1/namespaces/deployment-4381/replicasets/test-cleanup-deployment-b4867b47f 5373c1de-aa7d-495e-a765-cb1b5852d870 39114 1 2020-09-15 20:16:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 807d76cc-d0aa-4c91-b760-27015dfada49 0xc0032db1c0 0xc0032db1c1}] []  [{kube-controller-manager Update apps/v1 2020-09-15 20:16:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 48 55 100 55 54 99 99 45 100 48 97 97 45 52 99 57 49 45 98 55 54 48 45 50 55 48 49 53 100 102 97 100 97 52 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0032db258 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 15 20:16:18.423: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep 15 20:16:18.423: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-4381 /apis/apps/v1/namespaces/deployment-4381/replicasets/test-cleanup-controller bad5c1ef-6be3-42a0-9950-9b896b9f667b 39113 1 2020-09-15 20:16:13 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 807d76cc-d0aa-4c91-b760-27015dfada49 0xc0032daf07 0xc0032daf08}] []  [{e2e.test Update apps/v1 2020-09-15 20:16:13 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-09-15 20:16:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 48 55 100 55 54 99 99 45 100 48 97 97 45 52 99 57 49 45 98 55 54 48 45 50 55 48 49 53 100 102 97 100 97 52 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0032db028 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 15 20:16:18.433: INFO: Pod "test-cleanup-controller-d5pvq" is available:
&Pod{ObjectMeta:{test-cleanup-controller-d5pvq test-cleanup-controller- deployment-4381 /api/v1/namespaces/deployment-4381/pods/test-cleanup-controller-d5pvq 56a702ad-60af-48d2-8a00-31e6daabfe97 39102 0 2020-09-15 20:16:13 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller bad5c1ef-6be3-42a0-9950-9b896b9f667b 0xc0032dbcb7 0xc0032dbcb8}] []  [{kube-controller-manager Update v1 2020-09-15 20:16:13 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 97 100 53 99 49 101 102 45 54 98 101 51 45 52 50 97 48 45 57 57 53 48 45 57 98 56 57 54 98 57 102 54 54 55 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-09-15 20:16:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 50 53 49 46 49 50 56 46 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-56sg4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-56sg4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-56sg4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:16:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:16:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:16:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:16:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.40.94,PodIP:10.251.128.1,StartTime:2020-09-15 20:16:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-09-15 20:16:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3d406cae442edc1f7b1e74d359a63d2c4d3295a927823d1961d9a78529deeea4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.251.128.1,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 15 20:16:18.433: INFO: Pod "test-cleanup-deployment-b4867b47f-l8xwh" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-l8xwh test-cleanup-deployment-b4867b47f- deployment-4381 /api/v1/namespaces/deployment-4381/pods/test-cleanup-deployment-b4867b47f-l8xwh bb7b4c23-66cd-4171-947b-2c4aef9ee740 39118 0 2020-09-15 20:16:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f 5373c1de-aa7d-495e-a765-cb1b5852d870 0xc0032dbf50 0xc0032dbf51}] []  [{kube-controller-manager Update v1 2020-09-15 20:16:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 51 55 51 99 49 100 101 45 97 97 55 100 45 52 57 53 101 45 97 55 54 53 45 99 98 49 98 53 56 53 50 100 56 55 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-56sg4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-56sg4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-56sg4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-09-15 20:16:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:16:18.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4381" for this suite.

• [SLOW TEST:5.097 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":277,"completed":242,"skipped":4199,"failed":0}
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:16:18.463: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:16:18.492: INFO: Creating ReplicaSet my-hostname-basic-a7ae8a8c-f1da-4a46-a3ce-fd8019d26dd7
Sep 15 20:16:18.501: INFO: Pod name my-hostname-basic-a7ae8a8c-f1da-4a46-a3ce-fd8019d26dd7: Found 0 pods out of 1
Sep 15 20:16:23.504: INFO: Pod name my-hostname-basic-a7ae8a8c-f1da-4a46-a3ce-fd8019d26dd7: Found 1 pods out of 1
Sep 15 20:16:23.504: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-a7ae8a8c-f1da-4a46-a3ce-fd8019d26dd7" is running
Sep 15 20:16:23.506: INFO: Pod "my-hostname-basic-a7ae8a8c-f1da-4a46-a3ce-fd8019d26dd7-zf4vt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-15 20:16:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-15 20:16:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-15 20:16:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-09-15 20:16:18 +0000 UTC Reason: Message:}])
Sep 15 20:16:23.506: INFO: Trying to dial the pod
Sep 15 20:16:28.516: INFO: Controller my-hostname-basic-a7ae8a8c-f1da-4a46-a3ce-fd8019d26dd7: Got expected result from replica 1 [my-hostname-basic-a7ae8a8c-f1da-4a46-a3ce-fd8019d26dd7-zf4vt]: "my-hostname-basic-a7ae8a8c-f1da-4a46-a3ce-fd8019d26dd7-zf4vt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:16:28.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2884" for this suite.

• [SLOW TEST:10.062 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":243,"skipped":4200,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:16:28.526: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-ecb0c84d-95c9-4550-ab68-ce358bb9c9b0
STEP: Creating a pod to test consume configMaps
Sep 15 20:16:28.558: INFO: Waiting up to 5m0s for pod "pod-configmaps-308f5ed4-5191-441c-a6ca-964583cb276f" in namespace "configmap-6578" to be "Succeeded or Failed"
Sep 15 20:16:28.560: INFO: Pod "pod-configmaps-308f5ed4-5191-441c-a6ca-964583cb276f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.596405ms
Sep 15 20:16:30.563: INFO: Pod "pod-configmaps-308f5ed4-5191-441c-a6ca-964583cb276f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0046129s
Sep 15 20:16:32.566: INFO: Pod "pod-configmaps-308f5ed4-5191-441c-a6ca-964583cb276f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00754868s
STEP: Saw pod success
Sep 15 20:16:32.566: INFO: Pod "pod-configmaps-308f5ed4-5191-441c-a6ca-964583cb276f" satisfied condition "Succeeded or Failed"
Sep 15 20:16:32.568: INFO: Trying to get logs from node minion1 pod pod-configmaps-308f5ed4-5191-441c-a6ca-964583cb276f container configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 20:16:32.592: INFO: Waiting for pod pod-configmaps-308f5ed4-5191-441c-a6ca-964583cb276f to disappear
Sep 15 20:16:32.600: INFO: Pod pod-configmaps-308f5ed4-5191-441c-a6ca-964583cb276f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:16:32.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6578" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":244,"skipped":4214,"failed":0}
SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:16:32.606: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Sep 15 20:16:32.631: INFO: Waiting up to 5m0s for pod "downward-api-927ba6f3-fc0b-4672-9cea-c8dc4542f559" in namespace "downward-api-1080" to be "Succeeded or Failed"
Sep 15 20:16:32.633: INFO: Pod "downward-api-927ba6f3-fc0b-4672-9cea-c8dc4542f559": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089524ms
Sep 15 20:16:34.636: INFO: Pod "downward-api-927ba6f3-fc0b-4672-9cea-c8dc4542f559": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004868589s
Sep 15 20:16:36.639: INFO: Pod "downward-api-927ba6f3-fc0b-4672-9cea-c8dc4542f559": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007630789s
STEP: Saw pod success
Sep 15 20:16:36.639: INFO: Pod "downward-api-927ba6f3-fc0b-4672-9cea-c8dc4542f559" satisfied condition "Succeeded or Failed"
Sep 15 20:16:36.640: INFO: Trying to get logs from node minion1 pod downward-api-927ba6f3-fc0b-4672-9cea-c8dc4542f559 container dapi-container: <nil>
STEP: delete the pod
Sep 15 20:16:36.654: INFO: Waiting for pod downward-api-927ba6f3-fc0b-4672-9cea-c8dc4542f559 to disappear
Sep 15 20:16:36.661: INFO: Pod downward-api-927ba6f3-fc0b-4672-9cea-c8dc4542f559 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:16:36.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1080" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":277,"completed":245,"skipped":4218,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:16:36.668: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Sep 15 20:16:41.215: INFO: Successfully updated pod "labelsupdate23f25644-5258-4a08-8809-235a36013c9d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:16:43.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5807" for this suite.

• [SLOW TEST:6.566 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":246,"skipped":4241,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:16:43.233: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 20:16:43.258: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d891a16f-a863-4b2a-9a63-8afc95d6904c" in namespace "downward-api-8632" to be "Succeeded or Failed"
Sep 15 20:16:43.261: INFO: Pod "downwardapi-volume-d891a16f-a863-4b2a-9a63-8afc95d6904c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.133815ms
Sep 15 20:16:45.263: INFO: Pod "downwardapi-volume-d891a16f-a863-4b2a-9a63-8afc95d6904c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004649202s
STEP: Saw pod success
Sep 15 20:16:45.263: INFO: Pod "downwardapi-volume-d891a16f-a863-4b2a-9a63-8afc95d6904c" satisfied condition "Succeeded or Failed"
Sep 15 20:16:45.265: INFO: Trying to get logs from node minion1 pod downwardapi-volume-d891a16f-a863-4b2a-9a63-8afc95d6904c container client-container: <nil>
STEP: delete the pod
Sep 15 20:16:45.277: INFO: Waiting for pod downwardapi-volume-d891a16f-a863-4b2a-9a63-8afc95d6904c to disappear
Sep 15 20:16:45.284: INFO: Pod downwardapi-volume-d891a16f-a863-4b2a-9a63-8afc95d6904c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:16:45.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8632" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":277,"completed":247,"skipped":4242,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:16:45.291: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 15 20:16:47.850: INFO: Successfully updated pod "pod-update-532a6242-22ae-40b5-bfeb-2c945cf89d6a"
STEP: verifying the updated pod is in kubernetes
Sep 15 20:16:47.856: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:16:47.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2443" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":277,"completed":248,"skipped":4294,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:16:47.862: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-3616
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 15 20:16:47.881: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 15 20:16:47.907: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 15 20:16:49.910: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:16:51.910: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:16:53.910: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:16:55.910: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:16:57.910: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:16:59.909: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:17:01.910: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 15 20:17:01.913: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:17:03.916: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:17:05.916: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:17:07.916: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 15 20:17:11.943: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.251.128.1:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3616 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:17:11.943: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:17:12.076: INFO: Found all expected endpoints: [netserver-0]
Sep 15 20:17:12.079: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.251.32.6:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3616 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:17:12.079: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:17:12.409: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:17:12.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3616" for this suite.

• [SLOW TEST:24.557 seconds]
[sig-network] Networking
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":249,"skipped":4326,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:17:12.419: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-43961d79-2d84-46b1-b812-f60bc60b6ea4
STEP: Creating a pod to test consume configMaps
Sep 15 20:17:12.454: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d2cfe63a-488f-4af0-a7bf-66723f7fae3c" in namespace "projected-4502" to be "Succeeded or Failed"
Sep 15 20:17:12.457: INFO: Pod "pod-projected-configmaps-d2cfe63a-488f-4af0-a7bf-66723f7fae3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.204799ms
Sep 15 20:17:14.459: INFO: Pod "pod-projected-configmaps-d2cfe63a-488f-4af0-a7bf-66723f7fae3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004631819s
STEP: Saw pod success
Sep 15 20:17:14.459: INFO: Pod "pod-projected-configmaps-d2cfe63a-488f-4af0-a7bf-66723f7fae3c" satisfied condition "Succeeded or Failed"
Sep 15 20:17:14.461: INFO: Trying to get logs from node minion1 pod pod-projected-configmaps-d2cfe63a-488f-4af0-a7bf-66723f7fae3c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 20:17:14.473: INFO: Waiting for pod pod-projected-configmaps-d2cfe63a-488f-4af0-a7bf-66723f7fae3c to disappear
Sep 15 20:17:14.481: INFO: Pod pod-projected-configmaps-d2cfe63a-488f-4af0-a7bf-66723f7fae3c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:17:14.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4502" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":250,"skipped":4332,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:17:14.487: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 15 20:17:18.540: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 15 20:17:18.544: INFO: Pod pod-with-poststart-http-hook still exists
Sep 15 20:17:20.544: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 15 20:17:20.547: INFO: Pod pod-with-poststart-http-hook still exists
Sep 15 20:17:22.544: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 15 20:17:22.547: INFO: Pod pod-with-poststart-http-hook still exists
Sep 15 20:17:24.544: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 15 20:17:24.547: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:17:24.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9920" for this suite.

• [SLOW TEST:10.066 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":277,"completed":251,"skipped":4340,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:17:24.553: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-4853
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4853 to expose endpoints map[]
Sep 15 20:17:24.591: INFO: Get endpoints failed (7.636162ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep 15 20:17:25.594: INFO: successfully validated that service endpoint-test2 in namespace services-4853 exposes endpoints map[] (1.010342342s elapsed)
STEP: Creating pod pod1 in namespace services-4853
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4853 to expose endpoints map[pod1:[80]]
Sep 15 20:17:28.624: INFO: successfully validated that service endpoint-test2 in namespace services-4853 exposes endpoints map[pod1:[80]] (3.025081219s elapsed)
STEP: Creating pod pod2 in namespace services-4853
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4853 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 15 20:17:30.654: INFO: successfully validated that service endpoint-test2 in namespace services-4853 exposes endpoints map[pod1:[80] pod2:[80]] (2.025928706s elapsed)
STEP: Deleting pod pod1 in namespace services-4853
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4853 to expose endpoints map[pod2:[80]]
Sep 15 20:17:31.668: INFO: successfully validated that service endpoint-test2 in namespace services-4853 exposes endpoints map[pod2:[80]] (1.010894871s elapsed)
STEP: Deleting pod pod2 in namespace services-4853
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4853 to expose endpoints map[]
Sep 15 20:17:32.675: INFO: successfully validated that service endpoint-test2 in namespace services-4853 exposes endpoints map[] (1.004637483s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:17:32.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4853" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:8.143 seconds]
[sig-network] Services
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":277,"completed":252,"skipped":4360,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:17:32.698: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 15 20:17:32.730: INFO: Waiting up to 5m0s for pod "pod-daa13897-dada-45ec-8d0f-e32720d94438" in namespace "emptydir-661" to be "Succeeded or Failed"
Sep 15 20:17:32.733: INFO: Pod "pod-daa13897-dada-45ec-8d0f-e32720d94438": Phase="Pending", Reason="", readiness=false. Elapsed: 2.141427ms
Sep 15 20:17:34.735: INFO: Pod "pod-daa13897-dada-45ec-8d0f-e32720d94438": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004497533s
Sep 15 20:17:36.738: INFO: Pod "pod-daa13897-dada-45ec-8d0f-e32720d94438": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007144053s
STEP: Saw pod success
Sep 15 20:17:36.738: INFO: Pod "pod-daa13897-dada-45ec-8d0f-e32720d94438" satisfied condition "Succeeded or Failed"
Sep 15 20:17:36.740: INFO: Trying to get logs from node minion1 pod pod-daa13897-dada-45ec-8d0f-e32720d94438 container test-container: <nil>
STEP: delete the pod
Sep 15 20:17:36.752: INFO: Waiting for pod pod-daa13897-dada-45ec-8d0f-e32720d94438 to disappear
Sep 15 20:17:36.753: INFO: Pod pod-daa13897-dada-45ec-8d0f-e32720d94438 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:17:36.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-661" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":253,"skipped":4367,"failed":0}
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:17:36.759: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-ps9w
STEP: Creating a pod to test atomic-volume-subpath
Sep 15 20:17:36.799: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ps9w" in namespace "subpath-4594" to be "Succeeded or Failed"
Sep 15 20:17:36.801: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Pending", Reason="", readiness=false. Elapsed: 1.851923ms
Sep 15 20:17:38.804: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004540761s
Sep 15 20:17:40.806: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 4.007109323s
Sep 15 20:17:42.809: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 6.009810799s
Sep 15 20:17:44.812: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 8.012657919s
Sep 15 20:17:46.815: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 10.015460499s
Sep 15 20:17:48.817: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 12.018233752s
Sep 15 20:17:50.820: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 14.020673599s
Sep 15 20:17:52.823: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 16.023375549s
Sep 15 20:17:54.825: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 18.026108359s
Sep 15 20:17:56.828: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 20.02877058s
Sep 15 20:17:58.831: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Running", Reason="", readiness=true. Elapsed: 22.031516892s
Sep 15 20:18:00.833: INFO: Pod "pod-subpath-test-configmap-ps9w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.034231503s
STEP: Saw pod success
Sep 15 20:18:00.833: INFO: Pod "pod-subpath-test-configmap-ps9w" satisfied condition "Succeeded or Failed"
Sep 15 20:18:00.835: INFO: Trying to get logs from node minion1 pod pod-subpath-test-configmap-ps9w container test-container-subpath-configmap-ps9w: <nil>
STEP: delete the pod
Sep 15 20:18:00.847: INFO: Waiting for pod pod-subpath-test-configmap-ps9w to disappear
Sep 15 20:18:00.855: INFO: Pod pod-subpath-test-configmap-ps9w no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ps9w
Sep 15 20:18:00.855: INFO: Deleting pod "pod-subpath-test-configmap-ps9w" in namespace "subpath-4594"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:18:00.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4594" for this suite.

• [SLOW TEST:24.104 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":277,"completed":254,"skipped":4373,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:18:00.863: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Sep 15 20:18:00.887: INFO: namespace kubectl-6142
Sep 15 20:18:00.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 create -f - --namespace=kubectl-6142'
Sep 15 20:18:01.800: INFO: stderr: ""
Sep 15 20:18:01.800: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Sep 15 20:18:02.803: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 20:18:02.803: INFO: Found 0 / 1
Sep 15 20:18:03.803: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 20:18:03.803: INFO: Found 0 / 1
Sep 15 20:18:04.803: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 20:18:04.803: INFO: Found 1 / 1
Sep 15 20:18:04.803: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 15 20:18:04.805: INFO: Selector matched 1 pods for map[app:agnhost]
Sep 15 20:18:04.805: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 15 20:18:04.805: INFO: wait on agnhost-master startup in kubectl-6142 
Sep 15 20:18:04.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 logs agnhost-master-4ckgn agnhost-master --namespace=kubectl-6142'
Sep 15 20:18:04.879: INFO: stderr: ""
Sep 15 20:18:04.879: INFO: stdout: "Paused\n"
STEP: exposing RC
Sep 15 20:18:04.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6142'
Sep 15 20:18:04.953: INFO: stderr: ""
Sep 15 20:18:04.953: INFO: stdout: "service/rm2 exposed\n"
Sep 15 20:18:04.963: INFO: Service rm2 in namespace kubectl-6142 found.
STEP: exposing service
Sep 15 20:18:06.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6142'
Sep 15 20:18:07.037: INFO: stderr: ""
Sep 15 20:18:07.037: INFO: stdout: "service/rm3 exposed\n"
Sep 15 20:18:07.044: INFO: Service rm3 in namespace kubectl-6142 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:18:09.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6142" for this suite.

• [SLOW TEST:8.192 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1119
    should create services for rc  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":277,"completed":255,"skipped":4385,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:18:09.055: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 15 20:18:09.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-8414'
Sep 15 20:18:09.145: INFO: stderr: ""
Sep 15 20:18:09.145: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Sep 15 20:18:09.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete pods e2e-test-httpd-pod --namespace=kubectl-8414'
Sep 15 20:18:12.332: INFO: stderr: ""
Sep 15 20:18:12.333: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:18:12.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8414" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":277,"completed":256,"skipped":4423,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:18:12.342: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-ac713e2f-f4b1-45d3-b2f2-43b24261cb90
STEP: Creating a pod to test consume configMaps
Sep 15 20:18:12.374: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3efec174-1a98-4cd4-818e-0a72af36864f" in namespace "projected-2061" to be "Succeeded or Failed"
Sep 15 20:18:12.376: INFO: Pod "pod-projected-configmaps-3efec174-1a98-4cd4-818e-0a72af36864f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.691711ms
Sep 15 20:18:14.378: INFO: Pod "pod-projected-configmaps-3efec174-1a98-4cd4-818e-0a72af36864f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004130629s
Sep 15 20:18:16.381: INFO: Pod "pod-projected-configmaps-3efec174-1a98-4cd4-818e-0a72af36864f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006819939s
STEP: Saw pod success
Sep 15 20:18:16.381: INFO: Pod "pod-projected-configmaps-3efec174-1a98-4cd4-818e-0a72af36864f" satisfied condition "Succeeded or Failed"
Sep 15 20:18:16.383: INFO: Trying to get logs from node minion1 pod pod-projected-configmaps-3efec174-1a98-4cd4-818e-0a72af36864f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 20:18:16.394: INFO: Waiting for pod pod-projected-configmaps-3efec174-1a98-4cd4-818e-0a72af36864f to disappear
Sep 15 20:18:16.402: INFO: Pod pod-projected-configmaps-3efec174-1a98-4cd4-818e-0a72af36864f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:18:16.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2061" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":257,"skipped":4442,"failed":0}

------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:18:16.409: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Sep 15 20:18:16.427: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 15 20:18:16.440: INFO: Waiting for terminating namespaces to be deleted...
Sep 15 20:18:16.442: INFO: 
Logging pods the kubelet thinks is on node minion1 before test
Sep 15 20:18:16.449: INFO: weave-net-sj6qn from kube-system started at 2020-09-15 17:49:49 +0000 UTC (2 container statuses recorded)
Sep 15 20:18:16.449: INFO: 	Container weave ready: true, restart count 0
Sep 15 20:18:16.449: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 20:18:16.449: INFO: weave-scope-agent-wft6l from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.449: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 20:18:16.449: INFO: sonobuoy from sonobuoy started at 2020-09-15 19:07:01 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.449: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 15 20:18:16.449: INFO: kube-proxy-z8vzb from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.449: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 20:18:16.449: INFO: nodelocaldns-dk627 from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.449: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 20:18:16.449: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-2zszp from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 20:18:16.449: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 15 20:18:16.449: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 15 20:18:16.449: INFO: nginx-proxy-minion1 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.449: INFO: 	Container nginx-proxy ready: true, restart count 0
Sep 15 20:18:16.449: INFO: agnhost-master-4ckgn from kubectl-6142 started at 2020-09-15 20:18:01 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.449: INFO: 	Container agnhost-master ready: false, restart count 0
Sep 15 20:18:16.449: INFO: 
Logging pods the kubelet thinks is on node minion2 before test
Sep 15 20:18:16.465: INFO: weave-scope-app-bc7444d59-mwtxs from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.465: INFO: 	Container app ready: true, restart count 0
Sep 15 20:18:16.465: INFO: nodelocaldns-d2gct from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.465: INFO: 	Container node-cache ready: true, restart count 0
Sep 15 20:18:16.465: INFO: sonobuoy-e2e-job-874580613c114f91 from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 20:18:16.465: INFO: 	Container e2e ready: true, restart count 0
Sep 15 20:18:16.465: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 15 20:18:16.465: INFO: kube-proxy-5lm96 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.465: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 15 20:18:16.465: INFO: kubernetes-dashboard-667c4c65f8-6llcw from kube-system started at 2020-09-15 19:24:47 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.465: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Sep 15 20:18:16.465: INFO: weave-scope-cluster-agent-7944c858c9-tsb78 from weave started at 2020-09-15 19:43:27 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.465: INFO: 	Container scope-cluster-agent ready: true, restart count 0
Sep 15 20:18:16.465: INFO: nginx-proxy-minion2 from kube-system started at 2020-09-15 17:49:22 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.465: INFO: 	Container nginx-proxy ready: true, restart count 0
Sep 15 20:18:16.465: INFO: weave-net-9ck4j from kube-system started at 2020-09-15 17:49:48 +0000 UTC (2 container statuses recorded)
Sep 15 20:18:16.465: INFO: 	Container weave ready: true, restart count 0
Sep 15 20:18:16.466: INFO: 	Container weave-npc ready: true, restart count 0
Sep 15 20:18:16.466: INFO: coredns-59dcc4799b-dpc9n from kube-system started at 2020-09-15 17:50:14 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.466: INFO: 	Container coredns ready: true, restart count 0
Sep 15 20:18:16.466: INFO: weave-scope-agent-wg887 from weave started at 2020-09-15 17:51:06 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.466: INFO: 	Container scope-agent ready: true, restart count 0
Sep 15 20:18:16.466: INFO: kubernetes-metrics-scraper-54fbb4d595-ncb4z from kube-system started at 2020-09-15 19:43:27 +0000 UTC (1 container statuses recorded)
Sep 15 20:18:16.466: INFO: 	Container kubernetes-metrics-scraper ready: true, restart count 0
Sep 15 20:18:16.466: INFO: sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-kwcxg from sonobuoy started at 2020-09-15 19:07:06 +0000 UTC (2 container statuses recorded)
Sep 15 20:18:16.466: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 15 20:18:16.466: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node minion1
STEP: verifying the node has the label node minion2
Sep 15 20:18:16.499: INFO: Pod coredns-59dcc4799b-dpc9n requesting resource cpu=100m on Node minion2
Sep 15 20:18:16.499: INFO: Pod kube-proxy-5lm96 requesting resource cpu=0m on Node minion2
Sep 15 20:18:16.499: INFO: Pod kube-proxy-z8vzb requesting resource cpu=0m on Node minion1
Sep 15 20:18:16.499: INFO: Pod kubernetes-dashboard-667c4c65f8-6llcw requesting resource cpu=50m on Node minion2
Sep 15 20:18:16.499: INFO: Pod kubernetes-metrics-scraper-54fbb4d595-ncb4z requesting resource cpu=0m on Node minion2
Sep 15 20:18:16.499: INFO: Pod nginx-proxy-minion1 requesting resource cpu=25m on Node minion1
Sep 15 20:18:16.499: INFO: Pod nginx-proxy-minion2 requesting resource cpu=25m on Node minion2
Sep 15 20:18:16.499: INFO: Pod nodelocaldns-d2gct requesting resource cpu=100m on Node minion2
Sep 15 20:18:16.499: INFO: Pod nodelocaldns-dk627 requesting resource cpu=100m on Node minion1
Sep 15 20:18:16.499: INFO: Pod weave-net-9ck4j requesting resource cpu=100m on Node minion2
Sep 15 20:18:16.499: INFO: Pod weave-net-sj6qn requesting resource cpu=100m on Node minion1
Sep 15 20:18:16.499: INFO: Pod agnhost-master-4ckgn requesting resource cpu=0m on Node minion1
Sep 15 20:18:16.499: INFO: Pod sonobuoy requesting resource cpu=0m on Node minion1
Sep 15 20:18:16.499: INFO: Pod sonobuoy-e2e-job-874580613c114f91 requesting resource cpu=0m on Node minion2
Sep 15 20:18:16.499: INFO: Pod sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-2zszp requesting resource cpu=0m on Node minion1
Sep 15 20:18:16.499: INFO: Pod sonobuoy-systemd-logs-daemon-set-1589b5733b404ed3-kwcxg requesting resource cpu=0m on Node minion2
Sep 15 20:18:16.499: INFO: Pod weave-scope-agent-wft6l requesting resource cpu=100m on Node minion1
Sep 15 20:18:16.499: INFO: Pod weave-scope-agent-wg887 requesting resource cpu=100m on Node minion2
Sep 15 20:18:16.499: INFO: Pod weave-scope-app-bc7444d59-mwtxs requesting resource cpu=0m on Node minion2
Sep 15 20:18:16.499: INFO: Pod weave-scope-cluster-agent-7944c858c9-tsb78 requesting resource cpu=25m on Node minion2
STEP: Starting Pods to consume most of the cluster CPU.
Sep 15 20:18:16.499: INFO: Creating a pod which consumes cpu=2502m on Node minion1
Sep 15 20:18:16.504: INFO: Creating a pod which consumes cpu=2380m on Node minion2
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-290d96ec-2348-42f9-b8c8-4797d7ffc279.16350e6b47a5e385], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2042/filler-pod-290d96ec-2348-42f9-b8c8-4797d7ffc279 to minion1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-290d96ec-2348-42f9-b8c8-4797d7ffc279.16350e6b89df276b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-290d96ec-2348-42f9-b8c8-4797d7ffc279.16350e6b91020eae], Reason = [Created], Message = [Created container filler-pod-290d96ec-2348-42f9-b8c8-4797d7ffc279]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-290d96ec-2348-42f9-b8c8-4797d7ffc279.16350e6ba0d65388], Reason = [Started], Message = [Started container filler-pod-290d96ec-2348-42f9-b8c8-4797d7ffc279]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-614c52a5-9e96-46b1-aea1-e7e69e69fdd3.16350e6b485940af], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2042/filler-pod-614c52a5-9e96-46b1-aea1-e7e69e69fdd3 to minion2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-614c52a5-9e96-46b1-aea1-e7e69e69fdd3.16350e6b8b853b3c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-614c52a5-9e96-46b1-aea1-e7e69e69fdd3.16350e6b923f36b2], Reason = [Created], Message = [Created container filler-pod-614c52a5-9e96-46b1-aea1-e7e69e69fdd3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-614c52a5-9e96-46b1-aea1-e7e69e69fdd3.16350e6ba2ed4986], Reason = [Started], Message = [Started container filler-pod-614c52a5-9e96-46b1-aea1-e7e69e69fdd3]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16350e6c37a8d9e1], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16350e6c37fe0259], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node minion1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node minion2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:18:21.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2042" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:5.154 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":277,"completed":258,"skipped":4442,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:18:21.563: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:18:21.592: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:18:27.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-536" for this suite.

• [SLOW TEST:6.180 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":277,"completed":259,"skipped":4445,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:18:27.743: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-e850e90f-c510-4a93-8012-860ba0707215 in namespace container-probe-4626
Sep 15 20:18:29.772: INFO: Started pod liveness-e850e90f-c510-4a93-8012-860ba0707215 in namespace container-probe-4626
STEP: checking the pod's current state and verifying that restartCount is present
Sep 15 20:18:29.774: INFO: Initial restart count of pod liveness-e850e90f-c510-4a93-8012-860ba0707215 is 0
Sep 15 20:18:47.802: INFO: Restart count of pod container-probe-4626/liveness-e850e90f-c510-4a93-8012-860ba0707215 is now 1 (18.027549673s elapsed)
Sep 15 20:19:07.829: INFO: Restart count of pod container-probe-4626/liveness-e850e90f-c510-4a93-8012-860ba0707215 is now 2 (38.05465501s elapsed)
Sep 15 20:19:27.857: INFO: Restart count of pod container-probe-4626/liveness-e850e90f-c510-4a93-8012-860ba0707215 is now 3 (58.083182122s elapsed)
Sep 15 20:19:47.888: INFO: Restart count of pod container-probe-4626/liveness-e850e90f-c510-4a93-8012-860ba0707215 is now 4 (1m18.113516185s elapsed)
Sep 15 20:20:55.979: INFO: Restart count of pod container-probe-4626/liveness-e850e90f-c510-4a93-8012-860ba0707215 is now 5 (2m26.204402365s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:20:55.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4626" for this suite.

• [SLOW TEST:148.253 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":277,"completed":260,"skipped":4446,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:20:55.996: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:20:56.021: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-39c1f395-054c-48d9-bbe6-c10f73e00766" in namespace "security-context-test-8158" to be "Succeeded or Failed"
Sep 15 20:20:56.024: INFO: Pod "busybox-privileged-false-39c1f395-054c-48d9-bbe6-c10f73e00766": Phase="Pending", Reason="", readiness=false. Elapsed: 1.926602ms
Sep 15 20:20:58.026: INFO: Pod "busybox-privileged-false-39c1f395-054c-48d9-bbe6-c10f73e00766": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004573158s
Sep 15 20:21:00.029: INFO: Pod "busybox-privileged-false-39c1f395-054c-48d9-bbe6-c10f73e00766": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00733435s
Sep 15 20:21:00.029: INFO: Pod "busybox-privileged-false-39c1f395-054c-48d9-bbe6-c10f73e00766" satisfied condition "Succeeded or Failed"
Sep 15 20:21:00.042: INFO: Got logs for pod "busybox-privileged-false-39c1f395-054c-48d9-bbe6-c10f73e00766": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:00.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8158" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":261,"skipped":4469,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:00.049: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:21:00.070: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 15 20:21:02.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-3746 create -f -'
Sep 15 20:21:03.859: INFO: stderr: ""
Sep 15 20:21:03.859: INFO: stdout: "e2e-test-crd-publish-openapi-9004-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 15 20:21:03.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-3746 delete e2e-test-crd-publish-openapi-9004-crds test-cr'
Sep 15 20:21:03.924: INFO: stderr: ""
Sep 15 20:21:03.924: INFO: stdout: "e2e-test-crd-publish-openapi-9004-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Sep 15 20:21:03.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-3746 apply -f -'
Sep 15 20:21:04.060: INFO: stderr: ""
Sep 15 20:21:04.060: INFO: stdout: "e2e-test-crd-publish-openapi-9004-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 15 20:21:04.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-3746 delete e2e-test-crd-publish-openapi-9004-crds test-cr'
Sep 15 20:21:04.125: INFO: stderr: ""
Sep 15 20:21:04.125: INFO: stdout: "e2e-test-crd-publish-openapi-9004-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 15 20:21:04.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 explain e2e-test-crd-publish-openapi-9004-crds'
Sep 15 20:21:04.255: INFO: stderr: ""
Sep 15 20:21:04.255: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9004-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:07.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3746" for this suite.

• [SLOW TEST:7.063 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":277,"completed":262,"skipped":4485,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:07.112: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:21:07.449: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 20:21:09.456: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735798067, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735798067, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735798067, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735798067, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:21:12.464: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:12.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9331" for this suite.
STEP: Destroying namespace "webhook-9331-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.442 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":277,"completed":263,"skipped":4485,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:12.554: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:28.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3370" for this suite.

• [SLOW TEST:16.067 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":277,"completed":264,"skipped":4495,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:28.622: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-b0418204-d85f-49c1-ab1c-1d40d12b2e5c
STEP: Creating a pod to test consume configMaps
Sep 15 20:21:28.652: INFO: Waiting up to 5m0s for pod "pod-configmaps-7a10f5c5-ac14-456d-9a7a-2d8727b0cfc2" in namespace "configmap-8219" to be "Succeeded or Failed"
Sep 15 20:21:28.654: INFO: Pod "pod-configmaps-7a10f5c5-ac14-456d-9a7a-2d8727b0cfc2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.592268ms
Sep 15 20:21:30.657: INFO: Pod "pod-configmaps-7a10f5c5-ac14-456d-9a7a-2d8727b0cfc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004353859s
STEP: Saw pod success
Sep 15 20:21:30.657: INFO: Pod "pod-configmaps-7a10f5c5-ac14-456d-9a7a-2d8727b0cfc2" satisfied condition "Succeeded or Failed"
Sep 15 20:21:30.658: INFO: Trying to get logs from node minion1 pod pod-configmaps-7a10f5c5-ac14-456d-9a7a-2d8727b0cfc2 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 20:21:30.669: INFO: Waiting for pod pod-configmaps-7a10f5c5-ac14-456d-9a7a-2d8727b0cfc2 to disappear
Sep 15 20:21:30.677: INFO: Pod pod-configmaps-7a10f5c5-ac14-456d-9a7a-2d8727b0cfc2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:30.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8219" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":265,"skipped":4506,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:30.684: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:41.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2160" for this suite.

• [SLOW TEST:11.060 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":277,"completed":266,"skipped":4513,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:41.745: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Sep 15 20:21:41.765: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-692368794 proxy --unix-socket=/tmp/kubectl-proxy-unix047536765/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:41.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-474" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":277,"completed":267,"skipped":4542,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:41.819: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 15 20:21:42.371: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 15 20:21:44.378: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735798102, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735798102, loc:(*time.Location)(0x7b51220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63735798102, loc:(*time.Location)(0x7b51220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63735798102, loc:(*time.Location)(0x7b51220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 15 20:21:47.386: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:21:47.389: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:48.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3616" for this suite.
STEP: Destroying namespace "webhook-3616-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.699 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":277,"completed":268,"skipped":4548,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:48.518: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-f1ade947-2a27-4836-b4b4-0dd6513e4a0a
STEP: Creating a pod to test consume secrets
Sep 15 20:21:48.544: INFO: Waiting up to 5m0s for pod "pod-secrets-26256fa1-7509-4a97-adf9-d62545d5c56d" in namespace "secrets-3969" to be "Succeeded or Failed"
Sep 15 20:21:48.546: INFO: Pod "pod-secrets-26256fa1-7509-4a97-adf9-d62545d5c56d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.962649ms
Sep 15 20:21:50.549: INFO: Pod "pod-secrets-26256fa1-7509-4a97-adf9-d62545d5c56d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00478435s
Sep 15 20:21:52.552: INFO: Pod "pod-secrets-26256fa1-7509-4a97-adf9-d62545d5c56d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007696035s
STEP: Saw pod success
Sep 15 20:21:52.552: INFO: Pod "pod-secrets-26256fa1-7509-4a97-adf9-d62545d5c56d" satisfied condition "Succeeded or Failed"
Sep 15 20:21:52.554: INFO: Trying to get logs from node minion1 pod pod-secrets-26256fa1-7509-4a97-adf9-d62545d5c56d container secret-volume-test: <nil>
STEP: delete the pod
Sep 15 20:21:52.572: INFO: Waiting for pod pod-secrets-26256fa1-7509-4a97-adf9-d62545d5c56d to disappear
Sep 15 20:21:52.575: INFO: Pod pod-secrets-26256fa1-7509-4a97-adf9-d62545d5c56d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:52.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3969" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":269,"skipped":4556,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:52.581: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Sep 15 20:21:54.617: INFO: Pod pod-hostip-25678cee-a3e9-497b-8d74-d8ba3fafbc8e has hostIP: 172.31.40.94
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:54.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3167" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":277,"completed":270,"skipped":4562,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:54.624: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Sep 15 20:21:54.652: INFO: Waiting up to 5m0s for pod "client-containers-cabb20dd-8900-426b-a3ee-fea382033d59" in namespace "containers-5966" to be "Succeeded or Failed"
Sep 15 20:21:54.654: INFO: Pod "client-containers-cabb20dd-8900-426b-a3ee-fea382033d59": Phase="Pending", Reason="", readiness=false. Elapsed: 1.880205ms
Sep 15 20:21:56.656: INFO: Pod "client-containers-cabb20dd-8900-426b-a3ee-fea382033d59": Phase="Running", Reason="", readiness=true. Elapsed: 2.004613339s
Sep 15 20:21:58.659: INFO: Pod "client-containers-cabb20dd-8900-426b-a3ee-fea382033d59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00739497s
STEP: Saw pod success
Sep 15 20:21:58.659: INFO: Pod "client-containers-cabb20dd-8900-426b-a3ee-fea382033d59" satisfied condition "Succeeded or Failed"
Sep 15 20:21:58.661: INFO: Trying to get logs from node minion1 pod client-containers-cabb20dd-8900-426b-a3ee-fea382033d59 container test-container: <nil>
STEP: delete the pod
Sep 15 20:21:58.672: INFO: Waiting for pod client-containers-cabb20dd-8900-426b-a3ee-fea382033d59 to disappear
Sep 15 20:21:58.680: INFO: Pod client-containers-cabb20dd-8900-426b-a3ee-fea382033d59 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:21:58.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5966" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":277,"completed":271,"skipped":4624,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:21:58.686: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 15 20:21:58.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-8906'
Sep 15 20:21:58.774: INFO: stderr: ""
Sep 15 20:21:58.774: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Sep 15 20:22:03.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 get pod e2e-test-httpd-pod --namespace=kubectl-8906 -o json'
Sep 15 20:22:03.887: INFO: stderr: ""
Sep 15 20:22:03.887: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-09-15T20:21:58Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-09-15T20:21:58Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"10.251.128.2\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-09-15T20:22:01Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8906\",\n        \"resourceVersion\": \"41093\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8906/pods/e2e-test-httpd-pod\",\n        \"uid\": \"7a8287c6-bf9a-43cc-8e4d-4fdd612a128d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-8q4tl\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"minion1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-8q4tl\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-8q4tl\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-15T20:21:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-15T20:22:01Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-15T20:22:01Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-09-15T20:21:58Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://07c659cead24d6c0d69a72714ebf12f9f58cb462d88a65290ae83bc3340f6317\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-09-15T20:22:00Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.40.94\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.251.128.2\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.251.128.2\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-09-15T20:21:58Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 15 20:22:03.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 replace -f - --namespace=kubectl-8906'
Sep 15 20:22:04.073: INFO: stderr: ""
Sep 15 20:22:04.073: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Sep 15 20:22:04.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 delete pods e2e-test-httpd-pod --namespace=kubectl-8906'
Sep 15 20:22:06.445: INFO: stderr: ""
Sep 15 20:22:06.445: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:22:06.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8906" for this suite.

• [SLOW TEST:7.770 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1450
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":277,"completed":272,"skipped":4626,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:22:06.456: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Sep 15 20:22:06.486: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e190010-895e-4b1f-8720-85db127cbfff" in namespace "downward-api-7237" to be "Succeeded or Failed"
Sep 15 20:22:06.489: INFO: Pod "downwardapi-volume-5e190010-895e-4b1f-8720-85db127cbfff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.648135ms
Sep 15 20:22:08.492: INFO: Pod "downwardapi-volume-5e190010-895e-4b1f-8720-85db127cbfff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005639189s
Sep 15 20:22:10.494: INFO: Pod "downwardapi-volume-5e190010-895e-4b1f-8720-85db127cbfff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00838341s
STEP: Saw pod success
Sep 15 20:22:10.494: INFO: Pod "downwardapi-volume-5e190010-895e-4b1f-8720-85db127cbfff" satisfied condition "Succeeded or Failed"
Sep 15 20:22:10.496: INFO: Trying to get logs from node minion1 pod downwardapi-volume-5e190010-895e-4b1f-8720-85db127cbfff container client-container: <nil>
STEP: delete the pod
Sep 15 20:22:10.506: INFO: Waiting for pod downwardapi-volume-5e190010-895e-4b1f-8720-85db127cbfff to disappear
Sep 15 20:22:10.508: INFO: Pod downwardapi-volume-5e190010-895e-4b1f-8720-85db127cbfff no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:22:10.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7237" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":273,"skipped":4640,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:22:10.514: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Sep 15 20:22:10.535: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 15 20:22:13.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-9359 create -f -'
Sep 15 20:22:14.343: INFO: stderr: ""
Sep 15 20:22:14.343: INFO: stdout: "e2e-test-crd-publish-openapi-7166-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 15 20:22:14.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-9359 delete e2e-test-crd-publish-openapi-7166-crds test-cr'
Sep 15 20:22:14.409: INFO: stderr: ""
Sep 15 20:22:14.409: INFO: stdout: "e2e-test-crd-publish-openapi-7166-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Sep 15 20:22:14.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-9359 apply -f -'
Sep 15 20:22:14.544: INFO: stderr: ""
Sep 15 20:22:14.544: INFO: stdout: "e2e-test-crd-publish-openapi-7166-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 15 20:22:14.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 --namespace=crd-publish-openapi-9359 delete e2e-test-crd-publish-openapi-7166-crds test-cr'
Sep 15 20:22:14.617: INFO: stderr: ""
Sep 15 20:22:14.617: INFO: stdout: "e2e-test-crd-publish-openapi-7166-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 15 20:22:14.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-692368794 explain e2e-test-crd-publish-openapi-7166-crds'
Sep 15 20:22:14.752: INFO: stderr: ""
Sep 15 20:22:14.752: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7166-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:22:17.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9359" for this suite.

• [SLOW TEST:7.100 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":277,"completed":274,"skipped":4651,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:22:17.614: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-2046/secret-test-1924724c-bce2-4067-a087-f0542fc9be1f
STEP: Creating a pod to test consume secrets
Sep 15 20:22:17.644: INFO: Waiting up to 5m0s for pod "pod-configmaps-706f5464-9a01-4c03-a140-4961357f652d" in namespace "secrets-2046" to be "Succeeded or Failed"
Sep 15 20:22:17.646: INFO: Pod "pod-configmaps-706f5464-9a01-4c03-a140-4961357f652d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.258114ms
Sep 15 20:22:19.649: INFO: Pod "pod-configmaps-706f5464-9a01-4c03-a140-4961357f652d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004863732s
STEP: Saw pod success
Sep 15 20:22:19.649: INFO: Pod "pod-configmaps-706f5464-9a01-4c03-a140-4961357f652d" satisfied condition "Succeeded or Failed"
Sep 15 20:22:19.651: INFO: Trying to get logs from node minion1 pod pod-configmaps-706f5464-9a01-4c03-a140-4961357f652d container env-test: <nil>
STEP: delete the pod
Sep 15 20:22:19.662: INFO: Waiting for pod pod-configmaps-706f5464-9a01-4c03-a140-4961357f652d to disappear
Sep 15 20:22:19.670: INFO: Pod pod-configmaps-706f5464-9a01-4c03-a140-4961357f652d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:22:19.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2046" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":275,"skipped":4671,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:22:19.675: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-f5f128eb-be0c-4aa9-b672-39196d1677f2
STEP: Creating a pod to test consume configMaps
Sep 15 20:22:19.706: INFO: Waiting up to 5m0s for pod "pod-configmaps-7f17f517-e9f2-4ae0-a8f9-9626d7ce620e" in namespace "configmap-8063" to be "Succeeded or Failed"
Sep 15 20:22:19.709: INFO: Pod "pod-configmaps-7f17f517-e9f2-4ae0-a8f9-9626d7ce620e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.288917ms
Sep 15 20:22:21.712: INFO: Pod "pod-configmaps-7f17f517-e9f2-4ae0-a8f9-9626d7ce620e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005968713s
STEP: Saw pod success
Sep 15 20:22:21.712: INFO: Pod "pod-configmaps-7f17f517-e9f2-4ae0-a8f9-9626d7ce620e" satisfied condition "Succeeded or Failed"
Sep 15 20:22:21.713: INFO: Trying to get logs from node minion1 pod pod-configmaps-7f17f517-e9f2-4ae0-a8f9-9626d7ce620e container configmap-volume-test: <nil>
STEP: delete the pod
Sep 15 20:22:21.724: INFO: Waiting for pod pod-configmaps-7f17f517-e9f2-4ae0-a8f9-9626d7ce620e to disappear
Sep 15 20:22:21.732: INFO: Pod pod-configmaps-7f17f517-e9f2-4ae0-a8f9-9626d7ce620e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:22:21.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8063" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":276,"skipped":4688,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Sep 15 20:22:21.738: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-2968
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 15 20:22:21.756: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Sep 15 20:22:21.782: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Sep 15 20:22:23.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:22:25.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:22:27.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:22:29.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:22:31.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:22:33.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:22:35.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:22:37.785: INFO: The status of Pod netserver-0 is Running (Ready = false)
Sep 15 20:22:39.785: INFO: The status of Pod netserver-0 is Running (Ready = true)
Sep 15 20:22:39.789: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:22:41.792: INFO: The status of Pod netserver-1 is Running (Ready = false)
Sep 15 20:22:43.792: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Sep 15 20:22:47.808: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.251.128.2:8080/dial?request=hostname&protocol=udp&host=10.251.128.1&port=8081&tries=1'] Namespace:pod-network-test-2968 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:22:47.808: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:22:47.944: INFO: Waiting for responses: map[]
Sep 15 20:22:47.947: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.251.128.2:8080/dial?request=hostname&protocol=udp&host=10.251.32.6&port=8081&tries=1'] Namespace:pod-network-test-2968 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 15 20:22:47.947: INFO: >>> kubeConfig: /tmp/kubeconfig-692368794
Sep 15 20:22:48.087: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Sep 15 20:22:48.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2968" for this suite.

• [SLOW TEST:26.356 seconds]
[sig-network] Networking
/workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.18.6-rc.0.48+a9f7208b601483/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":277,"completed":277,"skipped":4715,"failed":0}
Sep 15 20:22:48.093: INFO: Running AfterSuite actions on all nodes
Sep 15 20:22:48.093: INFO: Running AfterSuite actions on node 1
Sep 15 20:22:48.093: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":277,"completed":277,"skipped":4715,"failed":0}

Ran 277 of 4992 Specs in 4528.120 seconds
SUCCESS! -- 277 Passed | 0 Failed | 0 Pending | 4715 Skipped
PASS

Ginkgo ran 1 suite in 1h15m29.395883349s
Test Suite Passed
