I0704 15:20:25.115111      22 e2e.go:129] Starting e2e run "8abf3a3c-7e2d-4fd8-94e0-dfeb70891b0d" on Ginkgo node 1
{"msg":"Test Suite starting","total":356,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1656948025 - Will randomize all specs
Will run 356 of 6971 specs

Jul  4 15:20:26.899: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:20:26.900: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jul  4 15:20:26.912: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jul  4 15:20:26.928: INFO: The status of Pod rke-coredns-addon-deploy-job-q97vx is Succeeded, skipping waiting
Jul  4 15:20:26.928: INFO: The status of Pod rke-metrics-addon-deploy-job-v6dww is Succeeded, skipping waiting
Jul  4 15:20:26.928: INFO: The status of Pod rke-network-plugin-deploy-job-vqpwx is Succeeded, skipping waiting
Jul  4 15:20:26.928: INFO: 8 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jul  4 15:20:26.928: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Jul  4 15:20:26.928: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jul  4 15:20:26.931: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Jul  4 15:20:26.931: INFO: e2e test version: v1.24.2
Jul  4 15:20:26.932: INFO: kube-apiserver version: v1.24.2
Jul  4 15:20:26.932: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:20:26.934: INFO: Cluster IP family: ipv4
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:20:26.934: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename dns
Jul  4 15:20:26.950: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
W0704 15:20:26.950100      22 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-214.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-214.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-214.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-214.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  4 15:20:44.985: INFO: DNS probes using dns-test-8cbe9337-0e67-4c41-b971-d2715e426952 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-214.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-214.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-214.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-214.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  4 15:21:01.020: INFO: File jessie_udp@dns-test-service-3.dns-214.svc.cluster.local from pod  dns-214/dns-test-18c82617-b150-4e06-94ec-8e6bd0ce2df4 contains '' instead of 'bar.example.com.'
Jul  4 15:21:01.020: INFO: Lookups using dns-214/dns-test-18c82617-b150-4e06-94ec-8e6bd0ce2df4 failed for: [jessie_udp@dns-test-service-3.dns-214.svc.cluster.local]

Jul  4 15:21:06.027: INFO: DNS probes using dns-test-18c82617-b150-4e06-94ec-8e6bd0ce2df4 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-214.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-214.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-214.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-214.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  4 15:21:08.085: INFO: DNS probes using dns-test-e98c7338-47c2-48bc-87c5-1fc263eec8cd succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  4 15:21:08.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-214" for this suite.

• [SLOW TEST:41.175 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":356,"completed":1,"skipped":5,"failed":0}
SSSSSSS
------------------------------
[sig-node] Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:08.109: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Jul  4 15:21:10.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3920" for this suite.
•{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":356,"completed":2,"skipped":12,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:10.166: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 15:21:10.192: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca714f07-337a-4595-a5c8-1a71a16d8229" in namespace "projected-3458" to be "Succeeded or Failed"
Jul  4 15:21:10.194: INFO: Pod "downwardapi-volume-ca714f07-337a-4595-a5c8-1a71a16d8229": Phase="Pending", Reason="", readiness=false. Elapsed: 2.305372ms
Jul  4 15:21:12.200: INFO: Pod "downwardapi-volume-ca714f07-337a-4595-a5c8-1a71a16d8229": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008126767s
Jul  4 15:21:14.208: INFO: Pod "downwardapi-volume-ca714f07-337a-4595-a5c8-1a71a16d8229": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016164958s
STEP: Saw pod success
Jul  4 15:21:14.208: INFO: Pod "downwardapi-volume-ca714f07-337a-4595-a5c8-1a71a16d8229" satisfied condition "Succeeded or Failed"
Jul  4 15:21:14.210: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-ca714f07-337a-4595-a5c8-1a71a16d8229 container client-container: <nil>
STEP: delete the pod
Jul  4 15:21:14.222: INFO: Waiting for pod downwardapi-volume-ca714f07-337a-4595-a5c8-1a71a16d8229 to disappear
Jul  4 15:21:14.225: INFO: Pod downwardapi-volume-ca714f07-337a-4595-a5c8-1a71a16d8229 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 15:21:14.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3458" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":3,"skipped":75,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:14.230: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 15:21:14.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4556" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":356,"completed":4,"skipped":96,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:14.271: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Jul  4 15:21:18.807: INFO: Successfully updated pod "adopt-release-fpl64"
STEP: Checking that the Job readopts the Pod
Jul  4 15:21:18.807: INFO: Waiting up to 15m0s for pod "adopt-release-fpl64" in namespace "job-7581" to be "adopted"
Jul  4 15:21:18.810: INFO: Pod "adopt-release-fpl64": Phase="Running", Reason="", readiness=true. Elapsed: 2.581754ms
Jul  4 15:21:20.815: INFO: Pod "adopt-release-fpl64": Phase="Running", Reason="", readiness=true. Elapsed: 2.007650943s
Jul  4 15:21:20.815: INFO: Pod "adopt-release-fpl64" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Jul  4 15:21:21.326: INFO: Successfully updated pod "adopt-release-fpl64"
STEP: Checking that the Job releases the Pod
Jul  4 15:21:21.326: INFO: Waiting up to 15m0s for pod "adopt-release-fpl64" in namespace "job-7581" to be "released"
Jul  4 15:21:21.327: INFO: Pod "adopt-release-fpl64": Phase="Running", Reason="", readiness=true. Elapsed: 1.73363ms
Jul  4 15:21:23.335: INFO: Pod "adopt-release-fpl64": Phase="Running", Reason="", readiness=true. Elapsed: 2.009567473s
Jul  4 15:21:23.335: INFO: Pod "adopt-release-fpl64" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  4 15:21:23.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7581" for this suite.

• [SLOW TEST:9.070 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":356,"completed":5,"skipped":106,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:23.342: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-d2226f54-c2c8-4c3b-a42e-e0348e8eee15
STEP: Creating a pod to test consume configMaps
Jul  4 15:21:23.365: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-951af6a1-87ea-4cdb-b368-e8c72a7a628c" in namespace "projected-8130" to be "Succeeded or Failed"
Jul  4 15:21:23.368: INFO: Pod "pod-projected-configmaps-951af6a1-87ea-4cdb-b368-e8c72a7a628c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.478238ms
Jul  4 15:21:25.372: INFO: Pod "pod-projected-configmaps-951af6a1-87ea-4cdb-b368-e8c72a7a628c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006375784s
Jul  4 15:21:27.379: INFO: Pod "pod-projected-configmaps-951af6a1-87ea-4cdb-b368-e8c72a7a628c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013644808s
STEP: Saw pod success
Jul  4 15:21:27.379: INFO: Pod "pod-projected-configmaps-951af6a1-87ea-4cdb-b368-e8c72a7a628c" satisfied condition "Succeeded or Failed"
Jul  4 15:21:27.381: INFO: Trying to get logs from node 18.216.149.32 pod pod-projected-configmaps-951af6a1-87ea-4cdb-b368-e8c72a7a628c container agnhost-container: <nil>
STEP: delete the pod
Jul  4 15:21:27.397: INFO: Waiting for pod pod-projected-configmaps-951af6a1-87ea-4cdb-b368-e8c72a7a628c to disappear
Jul  4 15:21:27.399: INFO: Pod pod-projected-configmaps-951af6a1-87ea-4cdb-b368-e8c72a7a628c no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  4 15:21:27.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8130" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":6,"skipped":122,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:27.405: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 15:21:28.135: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 15:21:31.154: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:21:31.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4883" for this suite.
STEP: Destroying namespace "webhook-4883-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":356,"completed":7,"skipped":125,"failed":0}
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:31.317: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Jul  4 15:21:31.385: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  4 15:21:38.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1931" for this suite.

• [SLOW TEST:6.786 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":356,"completed":8,"skipped":129,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:38.104: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-c7sqq in namespace proxy-8879
I0704 15:21:38.133887      22 runners.go:193] Created replication controller with name: proxy-service-c7sqq, namespace: proxy-8879, replica count: 1
I0704 15:21:39.185442      22 runners.go:193] proxy-service-c7sqq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0704 15:21:40.185551      22 runners.go:193] proxy-service-c7sqq Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 15:21:40.187: INFO: setup took 2.067045046s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jul  4 15:21:40.192: INFO: (0) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 4.508796ms)
Jul  4 15:21:40.193: INFO: (0) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 5.678861ms)
Jul  4 15:21:40.195: INFO: (0) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.935687ms)
Jul  4 15:21:40.195: INFO: (0) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 7.534036ms)
Jul  4 15:21:40.198: INFO: (0) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 10.052706ms)
Jul  4 15:21:40.198: INFO: (0) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 10.148889ms)
Jul  4 15:21:40.198: INFO: (0) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 10.538519ms)
Jul  4 15:21:40.198: INFO: (0) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 10.544222ms)
Jul  4 15:21:40.198: INFO: (0) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 10.727743ms)
Jul  4 15:21:40.199: INFO: (0) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 11.08735ms)
Jul  4 15:21:40.201: INFO: (0) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 13.52427ms)
Jul  4 15:21:40.202: INFO: (0) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 13.982901ms)
Jul  4 15:21:40.202: INFO: (0) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 14.153208ms)
Jul  4 15:21:40.202: INFO: (0) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 14.272634ms)
Jul  4 15:21:40.202: INFO: (0) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 14.699997ms)
Jul  4 15:21:40.202: INFO: (0) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 14.389697ms)
Jul  4 15:21:40.207: INFO: (1) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 3.950884ms)
Jul  4 15:21:40.207: INFO: (1) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 4.591458ms)
Jul  4 15:21:40.207: INFO: (1) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 4.998992ms)
Jul  4 15:21:40.207: INFO: (1) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 4.781214ms)
Jul  4 15:21:40.207: INFO: (1) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 4.625623ms)
Jul  4 15:21:40.208: INFO: (1) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 5.746166ms)
Jul  4 15:21:40.208: INFO: (1) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 5.366259ms)
Jul  4 15:21:40.209: INFO: (1) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 5.532315ms)
Jul  4 15:21:40.210: INFO: (1) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.130109ms)
Jul  4 15:21:40.210: INFO: (1) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 7.531232ms)
Jul  4 15:21:40.210: INFO: (1) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 7.170804ms)
Jul  4 15:21:40.210: INFO: (1) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 7.982994ms)
Jul  4 15:21:40.212: INFO: (1) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 9.017682ms)
Jul  4 15:21:40.212: INFO: (1) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 8.972426ms)
Jul  4 15:21:40.212: INFO: (1) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 8.798534ms)
Jul  4 15:21:40.212: INFO: (1) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 9.335044ms)
Jul  4 15:21:40.215: INFO: (2) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 2.96584ms)
Jul  4 15:21:40.218: INFO: (2) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 5.571093ms)
Jul  4 15:21:40.218: INFO: (2) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 5.538797ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.296304ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 6.398495ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.688712ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 6.400321ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 6.670892ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 6.632937ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 6.394192ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 6.590192ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 6.496841ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 7.053167ms)
Jul  4 15:21:40.219: INFO: (2) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 6.869564ms)
Jul  4 15:21:40.220: INFO: (2) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 7.541313ms)
Jul  4 15:21:40.220: INFO: (2) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 7.602577ms)
Jul  4 15:21:40.223: INFO: (3) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 2.917008ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.313268ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 8.652114ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 8.652728ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 8.810614ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 8.57519ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 8.558056ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 8.507848ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.649301ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 8.751892ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 8.753846ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.801626ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.758013ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 8.70362ms)
Jul  4 15:21:40.229: INFO: (3) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 9.129817ms)
Jul  4 15:21:40.230: INFO: (3) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 9.375541ms)
Jul  4 15:21:40.234: INFO: (4) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 3.978013ms)
Jul  4 15:21:40.236: INFO: (4) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 5.853175ms)
Jul  4 15:21:40.238: INFO: (4) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 7.765707ms)
Jul  4 15:21:40.238: INFO: (4) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 8.538522ms)
Jul  4 15:21:40.238: INFO: (4) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 8.43743ms)
Jul  4 15:21:40.238: INFO: (4) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 8.615915ms)
Jul  4 15:21:40.238: INFO: (4) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.573035ms)
Jul  4 15:21:40.239: INFO: (4) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 8.498129ms)
Jul  4 15:21:40.239: INFO: (4) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 8.540697ms)
Jul  4 15:21:40.239: INFO: (4) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.56064ms)
Jul  4 15:21:40.239: INFO: (4) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 8.611593ms)
Jul  4 15:21:40.239: INFO: (4) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.690275ms)
Jul  4 15:21:40.239: INFO: (4) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.70771ms)
Jul  4 15:21:40.239: INFO: (4) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 8.791384ms)
Jul  4 15:21:40.239: INFO: (4) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 8.607609ms)
Jul  4 15:21:40.239: INFO: (4) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 8.915161ms)
Jul  4 15:21:40.243: INFO: (5) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 3.678059ms)
Jul  4 15:21:40.243: INFO: (5) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 3.966509ms)
Jul  4 15:21:40.243: INFO: (5) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 4.059792ms)
Jul  4 15:21:40.244: INFO: (5) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 4.359946ms)
Jul  4 15:21:40.246: INFO: (5) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.551802ms)
Jul  4 15:21:40.246: INFO: (5) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.572695ms)
Jul  4 15:21:40.246: INFO: (5) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 7.173061ms)
Jul  4 15:21:40.247: INFO: (5) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 7.050649ms)
Jul  4 15:21:40.247: INFO: (5) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 7.076261ms)
Jul  4 15:21:40.247: INFO: (5) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.541999ms)
Jul  4 15:21:40.248: INFO: (5) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 8.71944ms)
Jul  4 15:21:40.248: INFO: (5) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 9.409641ms)
Jul  4 15:21:40.249: INFO: (5) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 9.469941ms)
Jul  4 15:21:40.249: INFO: (5) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 9.73665ms)
Jul  4 15:21:40.249: INFO: (5) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 9.825025ms)
Jul  4 15:21:40.249: INFO: (5) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 9.882774ms)
Jul  4 15:21:40.253: INFO: (6) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 3.772732ms)
Jul  4 15:21:40.254: INFO: (6) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 4.128506ms)
Jul  4 15:21:40.257: INFO: (6) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 7.261995ms)
Jul  4 15:21:40.257: INFO: (6) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 7.329195ms)
Jul  4 15:21:40.257: INFO: (6) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 7.657848ms)
Jul  4 15:21:40.257: INFO: (6) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 7.88368ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.310965ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 8.255382ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 8.465102ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 8.630746ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 8.645729ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.61769ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 8.607618ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 8.769835ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 8.700327ms)
Jul  4 15:21:40.258: INFO: (6) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.908671ms)
Jul  4 15:21:40.265: INFO: (7) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 6.354702ms)
Jul  4 15:21:40.266: INFO: (7) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.142776ms)
Jul  4 15:21:40.266: INFO: (7) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.508575ms)
Jul  4 15:21:40.266: INFO: (7) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 7.012785ms)
Jul  4 15:21:40.266: INFO: (7) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.980022ms)
Jul  4 15:21:40.266: INFO: (7) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.62146ms)
Jul  4 15:21:40.266: INFO: (7) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 7.587753ms)
Jul  4 15:21:40.266: INFO: (7) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 7.679123ms)
Jul  4 15:21:40.267: INFO: (7) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 7.753331ms)
Jul  4 15:21:40.267: INFO: (7) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 7.166893ms)
Jul  4 15:21:40.267: INFO: (7) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 7.806515ms)
Jul  4 15:21:40.267: INFO: (7) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 7.937982ms)
Jul  4 15:21:40.268: INFO: (7) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 9.085596ms)
Jul  4 15:21:40.268: INFO: (7) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 9.324226ms)
Jul  4 15:21:40.268: INFO: (7) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 9.386395ms)
Jul  4 15:21:40.269: INFO: (7) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 9.756336ms)
Jul  4 15:21:40.275: INFO: (8) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 5.20579ms)
Jul  4 15:21:40.275: INFO: (8) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 6.077637ms)
Jul  4 15:21:40.275: INFO: (8) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 6.222152ms)
Jul  4 15:21:40.276: INFO: (8) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 6.59997ms)
Jul  4 15:21:40.276: INFO: (8) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.003713ms)
Jul  4 15:21:40.276: INFO: (8) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 7.031782ms)
Jul  4 15:21:40.276: INFO: (8) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.564906ms)
Jul  4 15:21:40.276: INFO: (8) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 6.934487ms)
Jul  4 15:21:40.276: INFO: (8) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 6.750379ms)
Jul  4 15:21:40.277: INFO: (8) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.139864ms)
Jul  4 15:21:40.277: INFO: (8) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 7.492769ms)
Jul  4 15:21:40.278: INFO: (8) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 9.149449ms)
Jul  4 15:21:40.278: INFO: (8) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 8.38979ms)
Jul  4 15:21:40.278: INFO: (8) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 8.771374ms)
Jul  4 15:21:40.278: INFO: (8) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 8.308036ms)
Jul  4 15:21:40.278: INFO: (8) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 9.216596ms)
Jul  4 15:21:40.281: INFO: (9) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 3.006758ms)
Jul  4 15:21:40.286: INFO: (9) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 7.496987ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 7.957428ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 8.307406ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 8.232854ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 8.422607ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 8.02951ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.180343ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.088064ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 8.314677ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 8.156661ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 8.491476ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 8.290477ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.801743ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 8.53831ms)
Jul  4 15:21:40.287: INFO: (9) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 8.708023ms)
Jul  4 15:21:40.290: INFO: (10) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 2.922337ms)
Jul  4 15:21:40.292: INFO: (10) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 4.641386ms)
Jul  4 15:21:40.293: INFO: (10) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 5.639958ms)
Jul  4 15:21:40.293: INFO: (10) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 5.696695ms)
Jul  4 15:21:40.293: INFO: (10) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 5.934286ms)
Jul  4 15:21:40.295: INFO: (10) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.250274ms)
Jul  4 15:21:40.295: INFO: (10) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 7.357869ms)
Jul  4 15:21:40.295: INFO: (10) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 7.465661ms)
Jul  4 15:21:40.295: INFO: (10) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 7.706323ms)
Jul  4 15:21:40.295: INFO: (10) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 7.628401ms)
Jul  4 15:21:40.295: INFO: (10) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 7.721911ms)
Jul  4 15:21:40.296: INFO: (10) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 8.33921ms)
Jul  4 15:21:40.296: INFO: (10) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 8.40011ms)
Jul  4 15:21:40.296: INFO: (10) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 8.839917ms)
Jul  4 15:21:40.296: INFO: (10) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 8.880053ms)
Jul  4 15:21:40.296: INFO: (10) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 8.910639ms)
Jul  4 15:21:40.303: INFO: (11) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.075306ms)
Jul  4 15:21:40.303: INFO: (11) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 6.826706ms)
Jul  4 15:21:40.303: INFO: (11) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 7.041197ms)
Jul  4 15:21:40.303: INFO: (11) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 6.832957ms)
Jul  4 15:21:40.303: INFO: (11) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 7.016075ms)
Jul  4 15:21:40.304: INFO: (11) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 7.129623ms)
Jul  4 15:21:40.313: INFO: (11) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 16.261839ms)
Jul  4 15:21:40.313: INFO: (11) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 16.316698ms)
Jul  4 15:21:40.313: INFO: (11) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 16.599297ms)
Jul  4 15:21:40.313: INFO: (11) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 16.527244ms)
Jul  4 15:21:40.313: INFO: (11) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 16.63176ms)
Jul  4 15:21:40.313: INFO: (11) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 16.859869ms)
Jul  4 15:21:40.313: INFO: (11) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 16.986175ms)
Jul  4 15:21:40.321: INFO: (11) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 24.065187ms)
Jul  4 15:21:40.321: INFO: (11) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 24.461656ms)
Jul  4 15:21:40.321: INFO: (11) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 24.462534ms)
Jul  4 15:21:40.329: INFO: (12) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 7.437793ms)
Jul  4 15:21:40.329: INFO: (12) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 7.592107ms)
Jul  4 15:21:40.329: INFO: (12) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.113272ms)
Jul  4 15:21:40.330: INFO: (12) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 8.305991ms)
Jul  4 15:21:40.330: INFO: (12) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 8.404582ms)
Jul  4 15:21:40.330: INFO: (12) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.668101ms)
Jul  4 15:21:40.330: INFO: (12) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 8.575265ms)
Jul  4 15:21:40.330: INFO: (12) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 8.80574ms)
Jul  4 15:21:40.330: INFO: (12) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 8.776185ms)
Jul  4 15:21:40.330: INFO: (12) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.745213ms)
Jul  4 15:21:40.331: INFO: (12) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 10.154612ms)
Jul  4 15:21:40.331: INFO: (12) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 10.169658ms)
Jul  4 15:21:40.332: INFO: (12) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 11.040236ms)
Jul  4 15:21:40.332: INFO: (12) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 10.916914ms)
Jul  4 15:21:40.332: INFO: (12) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 10.899632ms)
Jul  4 15:21:40.332: INFO: (12) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 10.966008ms)
Jul  4 15:21:40.336: INFO: (13) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 4.126651ms)
Jul  4 15:21:40.337: INFO: (13) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 4.250314ms)
Jul  4 15:21:40.345: INFO: (13) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 12.207711ms)
Jul  4 15:21:40.345: INFO: (13) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 11.907943ms)
Jul  4 15:21:40.345: INFO: (13) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 12.852803ms)
Jul  4 15:21:40.345: INFO: (13) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 12.809912ms)
Jul  4 15:21:40.345: INFO: (13) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 13.107377ms)
Jul  4 15:21:40.345: INFO: (13) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 12.694811ms)
Jul  4 15:21:40.345: INFO: (13) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 12.742231ms)
Jul  4 15:21:40.349: INFO: (13) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 16.635587ms)
Jul  4 15:21:40.349: INFO: (13) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 16.704299ms)
Jul  4 15:21:40.350: INFO: (13) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 17.082241ms)
Jul  4 15:21:40.350: INFO: (13) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 17.319965ms)
Jul  4 15:21:40.350: INFO: (13) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 17.572473ms)
Jul  4 15:21:40.350: INFO: (13) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 17.686613ms)
Jul  4 15:21:40.351: INFO: (13) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 18.032721ms)
Jul  4 15:21:40.355: INFO: (14) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 3.795901ms)
Jul  4 15:21:40.357: INFO: (14) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 6.18401ms)
Jul  4 15:21:40.357: INFO: (14) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.048862ms)
Jul  4 15:21:40.358: INFO: (14) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 6.509319ms)
Jul  4 15:21:40.358: INFO: (14) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 7.186426ms)
Jul  4 15:21:40.359: INFO: (14) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 8.215311ms)
Jul  4 15:21:40.359: INFO: (14) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 7.887384ms)
Jul  4 15:21:40.359: INFO: (14) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 8.034733ms)
Jul  4 15:21:40.359: INFO: (14) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.217265ms)
Jul  4 15:21:40.359: INFO: (14) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 7.875083ms)
Jul  4 15:21:40.359: INFO: (14) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 8.179983ms)
Jul  4 15:21:40.360: INFO: (14) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 8.437356ms)
Jul  4 15:21:40.360: INFO: (14) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 8.054748ms)
Jul  4 15:21:40.360: INFO: (14) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 8.647401ms)
Jul  4 15:21:40.360: INFO: (14) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 7.896201ms)
Jul  4 15:21:40.360: INFO: (14) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 8.596811ms)
Jul  4 15:21:40.362: INFO: (15) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 2.849184ms)
Jul  4 15:21:40.365: INFO: (15) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 5.374657ms)
Jul  4 15:21:40.366: INFO: (15) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 6.113487ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.170828ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.347903ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 7.366729ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 7.33718ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 7.394568ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 7.747846ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 7.647004ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 7.758903ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 7.785728ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 7.671328ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 7.855648ms)
Jul  4 15:21:40.367: INFO: (15) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 7.60573ms)
Jul  4 15:21:40.368: INFO: (15) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 8.128414ms)
Jul  4 15:21:40.370: INFO: (16) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 2.611406ms)
Jul  4 15:21:40.371: INFO: (16) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 3.113675ms)
Jul  4 15:21:40.372: INFO: (16) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 3.693322ms)
Jul  4 15:21:40.372: INFO: (16) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 3.517625ms)
Jul  4 15:21:40.372: INFO: (16) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 3.792458ms)
Jul  4 15:21:40.374: INFO: (16) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 6.09894ms)
Jul  4 15:21:40.374: INFO: (16) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 5.787478ms)
Jul  4 15:21:40.374: INFO: (16) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 6.003121ms)
Jul  4 15:21:40.377: INFO: (16) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 7.792534ms)
Jul  4 15:21:40.377: INFO: (16) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 8.46358ms)
Jul  4 15:21:40.377: INFO: (16) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 8.625974ms)
Jul  4 15:21:40.377: INFO: (16) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.558411ms)
Jul  4 15:21:40.377: INFO: (16) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 8.609431ms)
Jul  4 15:21:40.377: INFO: (16) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 8.621241ms)
Jul  4 15:21:40.378: INFO: (16) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 9.285724ms)
Jul  4 15:21:40.378: INFO: (16) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 9.284257ms)
Jul  4 15:21:40.385: INFO: (17) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 6.426977ms)
Jul  4 15:21:40.385: INFO: (17) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 6.393946ms)
Jul  4 15:21:40.385: INFO: (17) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 6.55471ms)
Jul  4 15:21:40.385: INFO: (17) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 6.717506ms)
Jul  4 15:21:40.385: INFO: (17) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 6.755154ms)
Jul  4 15:21:40.385: INFO: (17) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 6.858471ms)
Jul  4 15:21:40.385: INFO: (17) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 6.93636ms)
Jul  4 15:21:40.386: INFO: (17) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 7.702127ms)
Jul  4 15:21:40.386: INFO: (17) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 7.759641ms)
Jul  4 15:21:40.386: INFO: (17) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 7.944572ms)
Jul  4 15:21:40.386: INFO: (17) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 8.057295ms)
Jul  4 15:21:40.386: INFO: (17) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 8.095991ms)
Jul  4 15:21:40.386: INFO: (17) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 8.111202ms)
Jul  4 15:21:40.386: INFO: (17) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 8.358606ms)
Jul  4 15:21:40.387: INFO: (17) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 8.489917ms)
Jul  4 15:21:40.387: INFO: (17) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 8.836189ms)
Jul  4 15:21:40.390: INFO: (18) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 3.221871ms)
Jul  4 15:21:40.395: INFO: (18) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 7.797301ms)
Jul  4 15:21:40.395: INFO: (18) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 7.717002ms)
Jul  4 15:21:40.395: INFO: (18) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 8.242695ms)
Jul  4 15:21:40.395: INFO: (18) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 8.388278ms)
Jul  4 15:21:40.396: INFO: (18) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 8.409041ms)
Jul  4 15:21:40.396: INFO: (18) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 8.867376ms)
Jul  4 15:21:40.396: INFO: (18) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 8.938115ms)
Jul  4 15:21:40.396: INFO: (18) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.953071ms)
Jul  4 15:21:40.396: INFO: (18) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 8.990714ms)
Jul  4 15:21:40.396: INFO: (18) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 9.246954ms)
Jul  4 15:21:40.397: INFO: (18) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 9.730595ms)
Jul  4 15:21:40.397: INFO: (18) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 9.735289ms)
Jul  4 15:21:40.397: INFO: (18) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 10.279949ms)
Jul  4 15:21:40.397: INFO: (18) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 10.436466ms)
Jul  4 15:21:40.397: INFO: (18) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 10.533028ms)
Jul  4 15:21:40.402: INFO: (19) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 3.809656ms)
Jul  4 15:21:40.403: INFO: (19) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t/proxy/rewriteme">test</a> (200; 4.992387ms)
Jul  4 15:21:40.403: INFO: (19) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">... (200; 5.363127ms)
Jul  4 15:21:40.403: INFO: (19) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 5.455548ms)
Jul  4 15:21:40.404: INFO: (19) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:462/proxy/: tls qux (200; 5.795663ms)
Jul  4 15:21:40.404: INFO: (19) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:162/proxy/: bar (200; 6.13451ms)
Jul  4 15:21:40.404: INFO: (19) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:443/proxy/tlsrewritem... (200; 6.558358ms)
Jul  4 15:21:40.405: INFO: (19) /api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/: <a href="/api/v1/namespaces/proxy-8879/pods/proxy-service-c7sqq-vmt2t:1080/proxy/rewriteme">test<... (200; 7.344258ms)
Jul  4 15:21:40.405: INFO: (19) /api/v1/namespaces/proxy-8879/pods/https:proxy-service-c7sqq-vmt2t:460/proxy/: tls baz (200; 7.402301ms)
Jul  4 15:21:40.405: INFO: (19) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname2/proxy/: bar (200; 7.937818ms)
Jul  4 15:21:40.406: INFO: (19) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname2/proxy/: tls qux (200; 7.488226ms)
Jul  4 15:21:40.406: INFO: (19) /api/v1/namespaces/proxy-8879/services/https:proxy-service-c7sqq:tlsportname1/proxy/: tls baz (200; 8.152308ms)
Jul  4 15:21:40.406: INFO: (19) /api/v1/namespaces/proxy-8879/pods/http:proxy-service-c7sqq-vmt2t:160/proxy/: foo (200; 8.122156ms)
Jul  4 15:21:40.406: INFO: (19) /api/v1/namespaces/proxy-8879/services/proxy-service-c7sqq:portname1/proxy/: foo (200; 8.124241ms)
Jul  4 15:21:40.406: INFO: (19) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname2/proxy/: bar (200; 8.320788ms)
Jul  4 15:21:40.406: INFO: (19) /api/v1/namespaces/proxy-8879/services/http:proxy-service-c7sqq:portname1/proxy/: foo (200; 8.517862ms)
STEP: deleting ReplicationController proxy-service-c7sqq in namespace proxy-8879, will wait for the garbage collector to delete the pods
Jul  4 15:21:40.464: INFO: Deleting ReplicationController proxy-service-c7sqq took: 4.89355ms
Jul  4 15:21:40.564: INFO: Terminating ReplicationController proxy-service-c7sqq pods took: 100.140405ms
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Jul  4 15:21:42.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8879" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":356,"completed":9,"skipped":146,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:42.974: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 15:21:54.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8845" for this suite.

• [SLOW TEST:11.140 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":356,"completed":10,"skipped":149,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:54.114: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul  4 15:21:54.136: INFO: Waiting up to 5m0s for pod "pod-eec0134a-04cd-4544-adeb-b17bf87ff0d1" in namespace "emptydir-434" to be "Succeeded or Failed"
Jul  4 15:21:54.140: INFO: Pod "pod-eec0134a-04cd-4544-adeb-b17bf87ff0d1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.634807ms
Jul  4 15:21:56.145: INFO: Pod "pod-eec0134a-04cd-4544-adeb-b17bf87ff0d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008441677s
Jul  4 15:21:58.148: INFO: Pod "pod-eec0134a-04cd-4544-adeb-b17bf87ff0d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012295921s
STEP: Saw pod success
Jul  4 15:21:58.148: INFO: Pod "pod-eec0134a-04cd-4544-adeb-b17bf87ff0d1" satisfied condition "Succeeded or Failed"
Jul  4 15:21:58.150: INFO: Trying to get logs from node 18.216.149.32 pod pod-eec0134a-04cd-4544-adeb-b17bf87ff0d1 container test-container: <nil>
STEP: delete the pod
Jul  4 15:21:58.166: INFO: Waiting for pod pod-eec0134a-04cd-4544-adeb-b17bf87ff0d1 to disappear
Jul  4 15:21:58.168: INFO: Pod pod-eec0134a-04cd-4544-adeb-b17bf87ff0d1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 15:21:58.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-434" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":11,"skipped":171,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:58.175: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating api versions
Jul  4 15:21:58.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-9129 api-versions'
Jul  4 15:21:58.248: INFO: stderr: ""
Jul  4 15:21:58.248: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 15:21:58.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9129" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":356,"completed":12,"skipped":171,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:21:58.256: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:21:58.279: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-53f12a96-e390-4f06-b687-1d332284c46b" in namespace "security-context-test-7262" to be "Succeeded or Failed"
Jul  4 15:21:58.283: INFO: Pod "busybox-readonly-false-53f12a96-e390-4f06-b687-1d332284c46b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.493651ms
Jul  4 15:22:00.287: INFO: Pod "busybox-readonly-false-53f12a96-e390-4f06-b687-1d332284c46b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008453163s
Jul  4 15:22:02.291: INFO: Pod "busybox-readonly-false-53f12a96-e390-4f06-b687-1d332284c46b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012288826s
Jul  4 15:22:02.291: INFO: Pod "busybox-readonly-false-53f12a96-e390-4f06-b687-1d332284c46b" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  4 15:22:02.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7262" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":356,"completed":13,"skipped":183,"failed":0}
S
------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:22:02.297: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating pod
Jul  4 15:22:02.376: INFO: The status of Pod pod-hostip-868697b6-42d9-41d1-9504-6a2ca937079c is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:22:04.385: INFO: The status of Pod pod-hostip-868697b6-42d9-41d1-9504-6a2ca937079c is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:22:07.293: INFO: The status of Pod pod-hostip-868697b6-42d9-41d1-9504-6a2ca937079c is Running (Ready = true)
Jul  4 15:22:07.299: INFO: Pod pod-hostip-868697b6-42d9-41d1-9504-6a2ca937079c has hostIP: 172.31.20.100
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  4 15:22:07.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-623" for this suite.

• [SLOW TEST:5.012 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":356,"completed":14,"skipped":184,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:22:07.309: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-313d8c78-8e02-4a4c-9de5-0d73182bbdba
STEP: Creating a pod to test consume configMaps
Jul  4 15:22:07.331: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3dbfadc2-0041-42a8-a4c0-ddb728b3ee24" in namespace "projected-7800" to be "Succeeded or Failed"
Jul  4 15:22:07.334: INFO: Pod "pod-projected-configmaps-3dbfadc2-0041-42a8-a4c0-ddb728b3ee24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.927321ms
Jul  4 15:22:09.340: INFO: Pod "pod-projected-configmaps-3dbfadc2-0041-42a8-a4c0-ddb728b3ee24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009004234s
Jul  4 15:22:14.557: INFO: Pod "pod-projected-configmaps-3dbfadc2-0041-42a8-a4c0-ddb728b3ee24": Phase="Pending", Reason="", readiness=false. Elapsed: 7.226132934s
Jul  4 15:22:16.562: INFO: Pod "pod-projected-configmaps-3dbfadc2-0041-42a8-a4c0-ddb728b3ee24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.230916986s
STEP: Saw pod success
Jul  4 15:22:16.562: INFO: Pod "pod-projected-configmaps-3dbfadc2-0041-42a8-a4c0-ddb728b3ee24" satisfied condition "Succeeded or Failed"
Jul  4 15:22:16.564: INFO: Trying to get logs from node 3.138.203.20 pod pod-projected-configmaps-3dbfadc2-0041-42a8-a4c0-ddb728b3ee24 container agnhost-container: <nil>
STEP: delete the pod
Jul  4 15:22:16.587: INFO: Waiting for pod pod-projected-configmaps-3dbfadc2-0041-42a8-a4c0-ddb728b3ee24 to disappear
Jul  4 15:22:16.589: INFO: Pod pod-projected-configmaps-3dbfadc2-0041-42a8-a4c0-ddb728b3ee24 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  4 15:22:16.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7800" for this suite.

• [SLOW TEST:9.286 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":15,"skipped":185,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:22:16.595: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:79
Jul  4 15:22:16.609: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the sample API server.
Jul  4 15:22:16.862: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jul  4 15:22:18.893: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:22:20.898: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:22:22.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:22:24.900: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:22:26.898: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:22:28.899: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:22:30.898: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 22, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:22:37.515: INFO: Waited 4.612969097s for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
Jul  4 15:22:37.574: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:69
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:188
Jul  4 15:22:38.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6234" for this suite.

• [SLOW TEST:21.559 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":356,"completed":16,"skipped":207,"failed":0}
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:22:38.155: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-43d450eb-43a9-417a-8828-5879fbbf9e4e
STEP: Creating a pod to test consume secrets
Jul  4 15:22:38.179: INFO: Waiting up to 5m0s for pod "pod-secrets-e0e59599-ced7-4c25-9a0c-4df5f64abd7a" in namespace "secrets-4746" to be "Succeeded or Failed"
Jul  4 15:22:38.181: INFO: Pod "pod-secrets-e0e59599-ced7-4c25-9a0c-4df5f64abd7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.550659ms
Jul  4 15:22:40.183: INFO: Pod "pod-secrets-e0e59599-ced7-4c25-9a0c-4df5f64abd7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004716157s
Jul  4 15:22:42.192: INFO: Pod "pod-secrets-e0e59599-ced7-4c25-9a0c-4df5f64abd7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013652486s
STEP: Saw pod success
Jul  4 15:22:42.192: INFO: Pod "pod-secrets-e0e59599-ced7-4c25-9a0c-4df5f64abd7a" satisfied condition "Succeeded or Failed"
Jul  4 15:22:42.194: INFO: Trying to get logs from node 18.216.149.32 pod pod-secrets-e0e59599-ced7-4c25-9a0c-4df5f64abd7a container secret-volume-test: <nil>
STEP: delete the pod
Jul  4 15:22:42.211: INFO: Waiting for pod pod-secrets-e0e59599-ced7-4c25-9a0c-4df5f64abd7a to disappear
Jul  4 15:22:42.213: INFO: Pod pod-secrets-e0e59599-ced7-4c25-9a0c-4df5f64abd7a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  4 15:22:42.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4746" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":17,"skipped":207,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:22:42.219: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Jul  4 15:22:42.239: INFO: Waiting up to 5m0s for pod "security-context-5c55ec34-553a-4f28-946e-2dee71af108e" in namespace "security-context-3510" to be "Succeeded or Failed"
Jul  4 15:22:42.246: INFO: Pod "security-context-5c55ec34-553a-4f28-946e-2dee71af108e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.475118ms
Jul  4 15:22:44.252: INFO: Pod "security-context-5c55ec34-553a-4f28-946e-2dee71af108e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01301734s
Jul  4 15:22:46.259: INFO: Pod "security-context-5c55ec34-553a-4f28-946e-2dee71af108e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019668126s
STEP: Saw pod success
Jul  4 15:22:46.259: INFO: Pod "security-context-5c55ec34-553a-4f28-946e-2dee71af108e" satisfied condition "Succeeded or Failed"
Jul  4 15:22:46.261: INFO: Trying to get logs from node 3.138.203.20 pod security-context-5c55ec34-553a-4f28-946e-2dee71af108e container test-container: <nil>
STEP: delete the pod
Jul  4 15:22:46.273: INFO: Waiting for pod security-context-5c55ec34-553a-4f28-946e-2dee71af108e to disappear
Jul  4 15:22:46.277: INFO: Pod security-context-5c55ec34-553a-4f28-946e-2dee71af108e no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  4 15:22:46.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3510" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":18,"skipped":248,"failed":0}
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:22:46.287: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:22:46.306: INFO: Got root ca configmap in namespace "svcaccounts-2081"
Jul  4 15:22:46.310: INFO: Deleted root ca configmap in namespace "svcaccounts-2081"
STEP: waiting for a new root ca configmap created
Jul  4 15:22:46.814: INFO: Recreated root ca configmap in namespace "svcaccounts-2081"
Jul  4 15:22:46.817: INFO: Updated root ca configmap in namespace "svcaccounts-2081"
STEP: waiting for the root ca configmap reconciled
Jul  4 15:22:47.321: INFO: Reconciled root ca configmap in namespace "svcaccounts-2081"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  4 15:22:47.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2081" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":356,"completed":19,"skipped":258,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:22:47.328: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
Jul  4 15:22:47.346: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul  4 15:22:52.354: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  4 15:22:54.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1376" for this suite.

• [SLOW TEST:7.062 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":356,"completed":20,"skipped":270,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:22:54.390: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1412
STEP: creating an pod
Jul  4 15:22:54.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1581 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.39 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Jul  4 15:22:54.654: INFO: stderr: ""
Jul  4 15:22:54.654: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for log generator to start.
Jul  4 15:22:54.654: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Jul  4 15:22:54.654: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1581" to be "running and ready, or succeeded"
Jul  4 15:22:54.657: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.279056ms
Jul  4 15:22:56.660: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.005508241s
Jul  4 15:22:56.660: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Jul  4 15:22:56.660: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Jul  4 15:22:56.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1581 logs logs-generator logs-generator'
Jul  4 15:22:56.720: INFO: stderr: ""
Jul  4 15:22:56.720: INFO: stdout: "I0704 15:22:55.505164       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/2882 368\nI0704 15:22:55.705681       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/qfm 343\nI0704 15:22:55.906049       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/l5sv 496\nI0704 15:22:56.105390       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/g9v 475\nI0704 15:22:56.305872       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/ckrz 399\nI0704 15:22:56.505193       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/f8x 309\nI0704 15:22:56.705728       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/xjrc 594\n"
Jul  4 15:22:58.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1581 logs logs-generator logs-generator'
Jul  4 15:22:58.787: INFO: stderr: ""
Jul  4 15:22:58.787: INFO: stdout: "I0704 15:22:55.505164       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/2882 368\nI0704 15:22:55.705681       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/qfm 343\nI0704 15:22:55.906049       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/l5sv 496\nI0704 15:22:56.105390       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/g9v 475\nI0704 15:22:56.305872       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/ckrz 399\nI0704 15:22:56.505193       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/f8x 309\nI0704 15:22:56.705728       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/xjrc 594\nI0704 15:22:56.906192       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/wwx 434\nI0704 15:22:57.105553       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/np7z 529\nI0704 15:22:57.306121       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/22gz 338\nI0704 15:22:57.505494       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/mp2v 420\nI0704 15:22:57.706049       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/7pch 382\nI0704 15:22:57.905362       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/xddl 217\nI0704 15:22:58.105850       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/9c5g 422\nI0704 15:22:58.305196       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/ggg 453\nI0704 15:22:58.505699       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/9pk 346\nI0704 15:22:58.706205       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/dpz 335\n"
STEP: limiting log lines
Jul  4 15:22:58.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1581 logs logs-generator logs-generator --tail=1'
Jul  4 15:22:58.848: INFO: stderr: ""
Jul  4 15:22:58.848: INFO: stdout: "I0704 15:22:58.706205       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/dpz 335\n"
Jul  4 15:22:58.849: INFO: got output "I0704 15:22:58.706205       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/dpz 335\n"
STEP: limiting log bytes
Jul  4 15:22:58.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1581 logs logs-generator logs-generator --limit-bytes=1'
Jul  4 15:22:58.908: INFO: stderr: ""
Jul  4 15:22:58.908: INFO: stdout: "I"
Jul  4 15:22:58.908: INFO: got output "I"
STEP: exposing timestamps
Jul  4 15:22:58.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1581 logs logs-generator logs-generator --tail=1 --timestamps'
Jul  4 15:22:58.965: INFO: stderr: ""
Jul  4 15:22:58.965: INFO: stdout: "2022-07-04T15:22:58.905723007Z I0704 15:22:58.905596       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/dxqt 369\n"
Jul  4 15:22:58.965: INFO: got output "2022-07-04T15:22:58.905723007Z I0704 15:22:58.905596       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/dxqt 369\n"
STEP: restricting to a time range
Jul  4 15:23:01.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1581 logs logs-generator logs-generator --since=1s'
Jul  4 15:23:01.532: INFO: stderr: ""
Jul  4 15:23:01.532: INFO: stdout: "I0704 15:23:00.705683       1 logs_generator.go:76] 26 POST /api/v1/namespaces/kube-system/pods/scnh 320\nI0704 15:23:00.906172       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/9jb 523\nI0704 15:23:01.105658       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/default/pods/5crh 206\nI0704 15:23:01.306191       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/ns/pods/m8w 372\nI0704 15:23:01.505680       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/kube-system/pods/8h8w 492\n"
Jul  4 15:23:01.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1581 logs logs-generator logs-generator --since=24h'
Jul  4 15:23:01.593: INFO: stderr: ""
Jul  4 15:23:01.593: INFO: stdout: "I0704 15:22:55.505164       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/2882 368\nI0704 15:22:55.705681       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/qfm 343\nI0704 15:22:55.906049       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/l5sv 496\nI0704 15:22:56.105390       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/g9v 475\nI0704 15:22:56.305872       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/ckrz 399\nI0704 15:22:56.505193       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/f8x 309\nI0704 15:22:56.705728       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/xjrc 594\nI0704 15:22:56.906192       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/wwx 434\nI0704 15:22:57.105553       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/np7z 529\nI0704 15:22:57.306121       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/22gz 338\nI0704 15:22:57.505494       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/mp2v 420\nI0704 15:22:57.706049       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/7pch 382\nI0704 15:22:57.905362       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/xddl 217\nI0704 15:22:58.105850       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/9c5g 422\nI0704 15:22:58.305196       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/ggg 453\nI0704 15:22:58.505699       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/9pk 346\nI0704 15:22:58.706205       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/dpz 335\nI0704 15:22:58.905596       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/dxqt 369\nI0704 15:22:59.106051       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/j779 351\nI0704 15:22:59.305528       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/jrz5 239\nI0704 15:22:59.505694       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/hmh 552\nI0704 15:22:59.706181       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/hdth 510\nI0704 15:22:59.905662       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/jlx 366\nI0704 15:23:00.106183       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/qc7 469\nI0704 15:23:00.305690       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/jj6z 220\nI0704 15:23:00.506197       1 logs_generator.go:76] 25 GET /api/v1/namespaces/default/pods/j2th 482\nI0704 15:23:00.705683       1 logs_generator.go:76] 26 POST /api/v1/namespaces/kube-system/pods/scnh 320\nI0704 15:23:00.906172       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/9jb 523\nI0704 15:23:01.105658       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/default/pods/5crh 206\nI0704 15:23:01.306191       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/ns/pods/m8w 372\nI0704 15:23:01.505680       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/kube-system/pods/8h8w 492\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1417
Jul  4 15:23:01.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1581 delete pod logs-generator'
Jul  4 15:23:02.704: INFO: stderr: ""
Jul  4 15:23:02.704: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 15:23:02.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1581" for this suite.

• [SLOW TEST:8.321 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1409
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":356,"completed":21,"skipped":299,"failed":0}
SSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:23:02.711: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-97fd9f6c-c997-4225-9522-b1503bade9d1 in namespace container-probe-5136
Jul  4 15:23:04.750: INFO: Started pod liveness-97fd9f6c-c997-4225-9522-b1503bade9d1 in namespace container-probe-5136
STEP: checking the pod's current state and verifying that restartCount is present
Jul  4 15:23:04.752: INFO: Initial restart count of pod liveness-97fd9f6c-c997-4225-9522-b1503bade9d1 is 0
Jul  4 15:23:24.819: INFO: Restart count of pod container-probe-5136/liveness-97fd9f6c-c997-4225-9522-b1503bade9d1 is now 1 (20.06683833s elapsed)
Jul  4 15:23:44.883: INFO: Restart count of pod container-probe-5136/liveness-97fd9f6c-c997-4225-9522-b1503bade9d1 is now 2 (40.130403065s elapsed)
Jul  4 15:24:04.951: INFO: Restart count of pod container-probe-5136/liveness-97fd9f6c-c997-4225-9522-b1503bade9d1 is now 3 (1m0.19824999s elapsed)
Jul  4 15:24:25.017: INFO: Restart count of pod container-probe-5136/liveness-97fd9f6c-c997-4225-9522-b1503bade9d1 is now 4 (1m20.264296235s elapsed)
Jul  4 15:25:25.212: INFO: Restart count of pod container-probe-5136/liveness-97fd9f6c-c997-4225-9522-b1503bade9d1 is now 5 (2m20.459886941s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  4 15:25:25.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5136" for this suite.

• [SLOW TEST:142.517 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":356,"completed":22,"skipped":302,"failed":0}
SSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:25:25.228: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override arguments
Jul  4 15:25:25.253: INFO: Waiting up to 5m0s for pod "client-containers-d0c55478-b33f-4b33-a866-763c4f9bc942" in namespace "containers-9887" to be "Succeeded or Failed"
Jul  4 15:25:25.255: INFO: Pod "client-containers-d0c55478-b33f-4b33-a866-763c4f9bc942": Phase="Pending", Reason="", readiness=false. Elapsed: 1.940409ms
Jul  4 15:25:27.263: INFO: Pod "client-containers-d0c55478-b33f-4b33-a866-763c4f9bc942": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00948203s
Jul  4 15:25:29.268: INFO: Pod "client-containers-d0c55478-b33f-4b33-a866-763c4f9bc942": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015157818s
STEP: Saw pod success
Jul  4 15:25:29.269: INFO: Pod "client-containers-d0c55478-b33f-4b33-a866-763c4f9bc942" satisfied condition "Succeeded or Failed"
Jul  4 15:25:29.270: INFO: Trying to get logs from node 3.138.203.20 pod client-containers-d0c55478-b33f-4b33-a866-763c4f9bc942 container agnhost-container: <nil>
STEP: delete the pod
Jul  4 15:25:29.289: INFO: Waiting for pod client-containers-d0c55478-b33f-4b33-a866-763c4f9bc942 to disappear
Jul  4 15:25:29.293: INFO: Pod client-containers-d0c55478-b33f-4b33-a866-763c4f9bc942 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Jul  4 15:25:29.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9887" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","total":356,"completed":23,"skipped":307,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:25:29.300: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-a40ade1b-f1b0-40e2-968d-903f7a0124e8
STEP: Creating a pod to test consume secrets
Jul  4 15:25:29.323: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1a82edf0-f553-4c87-8acf-e5c303fde9d0" in namespace "projected-7963" to be "Succeeded or Failed"
Jul  4 15:25:29.325: INFO: Pod "pod-projected-secrets-1a82edf0-f553-4c87-8acf-e5c303fde9d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.57279ms
Jul  4 15:25:31.333: INFO: Pod "pod-projected-secrets-1a82edf0-f553-4c87-8acf-e5c303fde9d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01004006s
Jul  4 15:25:33.340: INFO: Pod "pod-projected-secrets-1a82edf0-f553-4c87-8acf-e5c303fde9d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017748883s
STEP: Saw pod success
Jul  4 15:25:33.340: INFO: Pod "pod-projected-secrets-1a82edf0-f553-4c87-8acf-e5c303fde9d0" satisfied condition "Succeeded or Failed"
Jul  4 15:25:33.342: INFO: Trying to get logs from node 18.216.149.32 pod pod-projected-secrets-1a82edf0-f553-4c87-8acf-e5c303fde9d0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  4 15:25:33.363: INFO: Waiting for pod pod-projected-secrets-1a82edf0-f553-4c87-8acf-e5c303fde9d0 to disappear
Jul  4 15:25:33.365: INFO: Pod pod-projected-secrets-1a82edf0-f553-4c87-8acf-e5c303fde9d0 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  4 15:25:33.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7963" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":24,"skipped":335,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:25:33.371: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 15:25:33.392: INFO: Waiting up to 5m0s for pod "downwardapi-volume-addc0a83-22e5-4abf-ae6b-14fa0820cec7" in namespace "downward-api-9614" to be "Succeeded or Failed"
Jul  4 15:25:33.398: INFO: Pod "downwardapi-volume-addc0a83-22e5-4abf-ae6b-14fa0820cec7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.537877ms
Jul  4 15:25:35.403: INFO: Pod "downwardapi-volume-addc0a83-22e5-4abf-ae6b-14fa0820cec7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011058965s
Jul  4 15:25:37.407: INFO: Pod "downwardapi-volume-addc0a83-22e5-4abf-ae6b-14fa0820cec7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015667142s
STEP: Saw pod success
Jul  4 15:25:37.407: INFO: Pod "downwardapi-volume-addc0a83-22e5-4abf-ae6b-14fa0820cec7" satisfied condition "Succeeded or Failed"
Jul  4 15:25:37.409: INFO: Trying to get logs from node 3.138.203.20 pod downwardapi-volume-addc0a83-22e5-4abf-ae6b-14fa0820cec7 container client-container: <nil>
STEP: delete the pod
Jul  4 15:25:37.422: INFO: Waiting for pod downwardapi-volume-addc0a83-22e5-4abf-ae6b-14fa0820cec7 to disappear
Jul  4 15:25:37.424: INFO: Pod downwardapi-volume-addc0a83-22e5-4abf-ae6b-14fa0820cec7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 15:25:37.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9614" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":25,"skipped":353,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:25:37.430: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 15:25:48.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3715" for this suite.

• [SLOW TEST:11.064 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":356,"completed":26,"skipped":354,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:25:48.494: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1447
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Jul  4 15:25:48.525: INFO: Found 0 stateful pods, waiting for 3
Jul  4 15:25:58.531: INFO: Found 2 stateful pods, waiting for 3
Jul  4 15:26:08.535: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 15:26:08.535: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 15:26:08.535: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Jul  4 15:26:18.531: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 15:26:18.531: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 15:26:18.531: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Jul  4 15:26:18.554: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jul  4 15:26:28.585: INFO: Updating stateful set ss2
Jul  4 15:26:28.591: INFO: Waiting for Pod statefulset-1447/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Restoring Pods to the correct revision when they are deleted
Jul  4 15:26:38.640: INFO: Found 2 stateful pods, waiting for 3
Jul  4 15:26:48.648: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 15:26:48.649: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 15:26:48.649: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jul  4 15:26:48.672: INFO: Updating stateful set ss2
Jul  4 15:26:48.677: INFO: Waiting for Pod statefulset-1447/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Jul  4 15:26:58.705: INFO: Updating stateful set ss2
Jul  4 15:26:58.709: INFO: Waiting for StatefulSet statefulset-1447/ss2 to complete update
Jul  4 15:26:58.709: INFO: Waiting for Pod statefulset-1447/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Jul  4 15:27:08.718: INFO: Waiting for StatefulSet statefulset-1447/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  4 15:27:18.715: INFO: Deleting all statefulset in ns statefulset-1447
Jul  4 15:27:18.716: INFO: Scaling statefulset ss2 to 0
Jul  4 15:27:28.729: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 15:27:28.731: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  4 15:27:28.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1447" for this suite.

• [SLOW TEST:100.256 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":356,"completed":27,"skipped":388,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:27:28.750: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:27:28.764: INFO: Creating deployment "test-recreate-deployment"
Jul  4 15:27:28.767: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jul  4 15:27:28.772: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jul  4 15:27:30.780: INFO: Waiting deployment "test-recreate-deployment" to complete
Jul  4 15:27:30.782: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jul  4 15:27:30.788: INFO: Updating deployment test-recreate-deployment
Jul  4 15:27:30.788: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  4 15:27:30.841: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4369  7ee5efee-2593-4eeb-ae4f-c5f379ac6e32 3028 2 2022-07-04 15:27:28 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-07-04 15:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00313fd68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-07-04 15:27:30 +0000 UTC,LastTransitionTime:2022-07-04 15:27:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cd8586fc7" is progressing.,LastUpdateTime:2022-07-04 15:27:30 +0000 UTC,LastTransitionTime:2022-07-04 15:27:28 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Jul  4 15:27:30.844: INFO: New ReplicaSet "test-recreate-deployment-cd8586fc7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-cd8586fc7  deployment-4369  4ff9ca36-e35d-40c0-bb7a-ccb9eeb9592e 3025 1 2022-07-04 15:27:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 7ee5efee-2593-4eeb-ae4f-c5f379ac6e32 0xc0035555d0 0xc0035555d1}] []  [{kube-controller-manager Update apps/v1 2022-07-04 15:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7ee5efee-2593-4eeb-ae4f-c5f379ac6e32\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:27:30 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cd8586fc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003555748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  4 15:27:30.844: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jul  4 15:27:30.844: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-845d658455  deployment-4369  1aa96ada-446a-47d8-8db2-e4b47d51354d 3016 2 2022-07-04 15:27:28 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 7ee5efee-2593-4eeb-ae4f-c5f379ac6e32 0xc0035550ff 0xc003555230}] []  [{kube-controller-manager Update apps/v1 2022-07-04 15:27:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7ee5efee-2593-4eeb-ae4f-c5f379ac6e32\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:27:30 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 845d658455,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003555458 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  4 15:27:30.846: INFO: Pod "test-recreate-deployment-cd8586fc7-mkgx9" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-cd8586fc7-mkgx9 test-recreate-deployment-cd8586fc7- deployment-4369  dac2533d-6056-4432-87b7-6ec3350add49 3027 0 2022-07-04 15:27:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-cd8586fc7 4ff9ca36-e35d-40c0-bb7a-ccb9eeb9592e 0xc003555bb0 0xc003555bb1}] []  [{kube-controller-manager Update v1 2022-07-04 15:27:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4ff9ca36-e35d-40c0-bb7a-ccb9eeb9592e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:27:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n9dtk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n9dtk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:27:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:27:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:27:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:27:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:,StartTime:2022-07-04 15:27:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  4 15:27:30.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4369" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":28,"skipped":392,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:27:30.852: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 15:27:31.192: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 15:27:34.210: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:27:34.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6016" for this suite.
STEP: Destroying namespace "webhook-6016-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":356,"completed":29,"skipped":414,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:27:34.271: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-bf0431b0-11f4-4ad1-9fd5-c60f88d01eee
STEP: Creating configMap with name cm-test-opt-upd-f035dcd5-fc4a-45b7-837a-b2551e460070
STEP: Creating the pod
Jul  4 15:27:34.312: INFO: The status of Pod pod-configmaps-97ecdce4-acd0-4751-b528-14a59b5bbf8f is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:27:36.317: INFO: The status of Pod pod-configmaps-97ecdce4-acd0-4751-b528-14a59b5bbf8f is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-bf0431b0-11f4-4ad1-9fd5-c60f88d01eee
STEP: Updating configmap cm-test-opt-upd-f035dcd5-fc4a-45b7-837a-b2551e460070
STEP: Creating configMap with name cm-test-opt-create-e31f6b39-4d14-470b-b303-19c6efe3f8c7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 15:27:40.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4849" for this suite.

• [SLOW TEST:6.119 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":30,"skipped":424,"failed":0}
[sig-api-machinery] server version 
  should find the server version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:27:40.390: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should find the server version [Conformance]
  test/e2e/framework/framework.go:652
STEP: Request ServerVersion
STEP: Confirm major version
Jul  4 15:27:40.407: INFO: Major version: 1
STEP: Confirm minor version
Jul  4 15:27:40.407: INFO: cleanMinorVersion: 24
Jul  4 15:27:40.407: INFO: Minor version: 24
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:188
Jul  4 15:27:40.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-7639" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":356,"completed":31,"skipped":424,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:27:40.412: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:27:40.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-119 create -f -'
Jul  4 15:27:41.399: INFO: stderr: ""
Jul  4 15:27:41.399: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Jul  4 15:27:41.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-119 create -f -'
Jul  4 15:27:41.641: INFO: stderr: ""
Jul  4 15:27:41.641: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Jul  4 15:27:42.647: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 15:27:42.647: INFO: Found 0 / 1
Jul  4 15:27:43.647: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 15:27:43.647: INFO: Found 1 / 1
Jul  4 15:27:43.647: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul  4 15:27:43.649: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 15:27:43.649: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul  4 15:27:43.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-119 describe pod agnhost-primary-58t5q'
Jul  4 15:27:43.711: INFO: stderr: ""
Jul  4 15:27:43.711: INFO: stdout: "Name:         agnhost-primary-58t5q\nNamespace:    kubectl-119\nPriority:     0\nNode:         18.216.149.32/172.31.20.100\nStart Time:   Mon, 04 Jul 2022 15:27:41 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  cni.projectcalico.org/containerID: 79b00d1a37ebb160eb7f36aad7dbfdfbf23990773c3bc646ae8c52bd0b234ad8\n              cni.projectcalico.org/podIP: 10.42.2.19/32\n              cni.projectcalico.org/podIPs: 10.42.2.19/32\nStatus:       Running\nIP:           10.42.2.19\nIPs:\n  IP:           10.42.2.19\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   docker://15a66e94418f78c5eecd679a32da16dbc1a5292d6b7671b8cb0d15f80798073c\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Image ID:       docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 04 Jul 2022 15:27:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-hflw8 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-hflw8:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-119/agnhost-primary-58t5q to 18.216.149.32\n  Normal  Pulled     1s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.39\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Jul  4 15:27:43.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-119 describe rc agnhost-primary'
Jul  4 15:27:43.772: INFO: stderr: ""
Jul  4 15:27:43.772: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-119\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-58t5q\n"
Jul  4 15:27:43.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-119 describe service agnhost-primary'
Jul  4 15:27:43.829: INFO: stderr: ""
Jul  4 15:27:43.829: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-119\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.43.211.71\nIPs:               10.43.211.71\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.42.2.19:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jul  4 15:27:43.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-119 describe node 18.216.149.32'
Jul  4 15:27:43.906: INFO: stderr: ""
Jul  4 15:27:43.906: INFO: stdout: "Name:               18.216.149.32\nRoles:              worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=18.216.149.32\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/worker=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"be:19:a4:48:91:95\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.31.20.100\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 172.31.20.100/20\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.42.2.1\n                    rke.cattle.io/external-ip: 18.216.149.32\n                    rke.cattle.io/internal-ip: 172.31.20.100\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 04 Jul 2022 15:16:54 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  18.216.149.32\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 04 Jul 2022 15:27:37 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 04 Jul 2022 15:17:20 +0000   Mon, 04 Jul 2022 15:17:20 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Mon, 04 Jul 2022 15:27:27 +0000   Mon, 04 Jul 2022 15:16:54 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 04 Jul 2022 15:27:27 +0000   Mon, 04 Jul 2022 15:16:54 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 04 Jul 2022 15:27:27 +0000   Mon, 04 Jul 2022 15:16:54 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 04 Jul 2022 15:27:27 +0000   Mon, 04 Jul 2022 15:17:24 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.20.100\n  Hostname:    18.216.149.32\nCapacity:\n  cpu:                4\n  ephemeral-storage:  121770540Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16384724Ki\n  pods:               110\nAllocatable:\n  cpu:                4\n  ephemeral-storage:  112223729479\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16282324Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 \n  System UUID:                ec25ff96-9659-22fe-20b9-a294c53e50fe\n  Boot ID:                    e97143bc-ba63-4273-9118-cd63d39a7708\n  Kernel Version:             5.13.0-1029-aws\n  OS Image:                   Ubuntu 20.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://20.10.12\n  Kubelet Version:            v1.24.2\n  Kube-Proxy Version:         v1.24.2\nPodCIDR:                      10.42.2.0/24\nPodCIDRs:                     10.42.2.0/24\nNon-terminated Pods:          (5 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 canal-7ftvj                                                250m (6%)     0 (0%)      0 (0%)           0 (0%)         10m\n  kube-system                 coredns-85bfbf8f-9f6vk                                     100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     10m\n  kube-system                 metrics-server-585b7cc746-9jchh                            100m (2%)     0 (0%)      200Mi (1%)       0 (0%)         10m\n  kubectl-119                 agnhost-primary-58t5q                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-vttwd    0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m36s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                450m (11%)  0 (0%)\n  memory             270Mi (1%)  170Mi (1%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From             Message\n  ----     ------                   ----               ----             -------\n  Normal   Starting                 10m                kube-proxy       \n  Normal   Starting                 10m                kubelet          Starting kubelet.\n  Normal   NodeAllocatableEnforced  10m                kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      10m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  10m (x2 over 10m)  kubelet          Node 18.216.149.32 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    10m (x2 over 10m)  kubelet          Node 18.216.149.32 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     10m (x2 over 10m)  kubelet          Node 18.216.149.32 status is now: NodeHasSufficientPID\n  Normal   RegisteredNode           10m                node-controller  Node 18.216.149.32 event: Registered Node 18.216.149.32 in Controller\n  Normal   NodeReady                10m                kubelet          Node 18.216.149.32 status is now: NodeReady\n"
Jul  4 15:27:43.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-119 describe namespace kubectl-119'
Jul  4 15:27:43.964: INFO: stderr: ""
Jul  4 15:27:43.964: INFO: stdout: "Name:         kubectl-119\nLabels:       e2e-framework=kubectl\n              e2e-run=8abf3a3c-7e2d-4fd8-94e0-dfeb70891b0d\n              kubernetes.io/metadata.name=kubectl-119\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 15:27:43.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-119" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":356,"completed":32,"skipped":496,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:27:43.971: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 15:27:44.237: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 15:27:47.269: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:27:47.274: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4446-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:27:50.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7428" for this suite.
STEP: Destroying namespace "webhook-7428-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.484 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":356,"completed":33,"skipped":500,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:27:50.455: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Jul  4 15:28:00.546: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0704 15:28:00.545968      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  4 15:28:00.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9558" for this suite.

• [SLOW TEST:10.096 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":356,"completed":34,"skipped":508,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:28:00.552: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-1206
Jul  4 15:28:00.578: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:28:02.585: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Jul  4 15:28:02.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-1206 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Jul  4 15:28:02.742: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Jul  4 15:28:02.742: INFO: stdout: "iptables"
Jul  4 15:28:02.742: INFO: proxyMode: iptables
Jul  4 15:28:02.750: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Jul  4 15:28:02.752: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-1206
STEP: creating replication controller affinity-clusterip-timeout in namespace services-1206
I0704 15:28:02.762590      22 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-1206, replica count: 3
I0704 15:28:05.813880      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0704 15:28:08.814166      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 15:28:08.820: INFO: Creating new exec pod
Jul  4 15:28:11.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-1206 exec execpod-affinityjf6fr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Jul  4 15:28:11.981: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Jul  4 15:28:11.981: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:28:11.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-1206 exec execpod-affinityjf6fr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.212.35 80'
Jul  4 15:28:12.107: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.212.35 80\nConnection to 10.43.212.35 80 port [tcp/http] succeeded!\n"
Jul  4 15:28:12.107: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:28:12.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-1206 exec execpod-affinityjf6fr -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.212.35:80/ ; done'
Jul  4 15:28:12.295: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n"
Jul  4 15:28:12.295: INFO: stdout: "\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg\naffinity-clusterip-timeout-8b2qg"
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Received response from host: affinity-clusterip-timeout-8b2qg
Jul  4 15:28:12.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-1206 exec execpod-affinityjf6fr -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.43.212.35:80/'
Jul  4 15:28:12.426: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n"
Jul  4 15:28:12.426: INFO: stdout: "affinity-clusterip-timeout-8b2qg"
Jul  4 15:28:32.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-1206 exec execpod-affinityjf6fr -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.43.212.35:80/'
Jul  4 15:28:32.561: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.43.212.35:80/\n"
Jul  4 15:28:32.562: INFO: stdout: "affinity-clusterip-timeout-bhzp5"
Jul  4 15:28:32.562: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-1206, will wait for the garbage collector to delete the pods
Jul  4 15:28:32.626: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 3.607919ms
Jul  4 15:28:32.727: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 101.13413ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:28:35.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1206" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:34.502 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":35,"skipped":545,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:28:35.054: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Pod
STEP: Reading file content from the nginx-container
Jul  4 15:28:37.101: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-2547 PodName:pod-sharedvolume-5c25b03f-dc35-42c8-8b14-3a13e669ced9 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:28:37.101: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:28:37.102: INFO: ExecWithOptions: Clientset creation
Jul  4 15:28:37.102: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/emptydir-2547/pods/pod-sharedvolume-5c25b03f-dc35-42c8-8b14-3a13e669ced9/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Jul  4 15:28:37.177: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 15:28:37.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2547" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":356,"completed":36,"skipped":552,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:28:37.184: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jul  4 15:28:37.548: INFO: Pod name wrapped-volume-race-ad5bc253-68db-44dc-867e-76cddee6751d: Found 3 pods out of 5
Jul  4 15:28:42.556: INFO: Pod name wrapped-volume-race-ad5bc253-68db-44dc-867e-76cddee6751d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ad5bc253-68db-44dc-867e-76cddee6751d in namespace emptydir-wrapper-8093, will wait for the garbage collector to delete the pods
Jul  4 15:28:54.633: INFO: Deleting ReplicationController wrapped-volume-race-ad5bc253-68db-44dc-867e-76cddee6751d took: 4.440576ms
Jul  4 15:28:54.734: INFO: Terminating ReplicationController wrapped-volume-race-ad5bc253-68db-44dc-867e-76cddee6751d pods took: 101.22091ms
STEP: Creating RC which spawns configmap-volume pods
Jul  4 15:28:57.651: INFO: Pod name wrapped-volume-race-b184464b-06fb-4f5d-8128-78ab76a777f7: Found 0 pods out of 5
Jul  4 15:29:02.662: INFO: Pod name wrapped-volume-race-b184464b-06fb-4f5d-8128-78ab76a777f7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b184464b-06fb-4f5d-8128-78ab76a777f7 in namespace emptydir-wrapper-8093, will wait for the garbage collector to delete the pods
Jul  4 15:29:14.741: INFO: Deleting ReplicationController wrapped-volume-race-b184464b-06fb-4f5d-8128-78ab76a777f7 took: 4.531778ms
Jul  4 15:29:14.842: INFO: Terminating ReplicationController wrapped-volume-race-b184464b-06fb-4f5d-8128-78ab76a777f7 pods took: 101.104169ms
STEP: Creating RC which spawns configmap-volume pods
Jul  4 15:29:18.157: INFO: Pod name wrapped-volume-race-7897e62d-34ad-4816-88c1-d7e0fed61a32: Found 0 pods out of 5
Jul  4 15:29:23.166: INFO: Pod name wrapped-volume-race-7897e62d-34ad-4816-88c1-d7e0fed61a32: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7897e62d-34ad-4816-88c1-d7e0fed61a32 in namespace emptydir-wrapper-8093, will wait for the garbage collector to delete the pods
Jul  4 15:29:33.240: INFO: Deleting ReplicationController wrapped-volume-race-7897e62d-34ad-4816-88c1-d7e0fed61a32 took: 3.37663ms
Jul  4 15:29:33.340: INFO: Terminating ReplicationController wrapped-volume-race-7897e62d-34ad-4816-88c1-d7e0fed61a32 pods took: 100.241493ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Jul  4 15:29:37.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8093" for this suite.

• [SLOW TEST:60.342 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":356,"completed":37,"skipped":584,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:29:37.527: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pods
Jul  4 15:29:37.554: INFO: created test-pod-1
Jul  4 15:29:37.558: INFO: created test-pod-2
Jul  4 15:29:37.561: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running
Jul  4 15:29:37.561: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-1715' to be running and ready
Jul  4 15:29:37.576: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul  4 15:29:37.576: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul  4 15:29:37.576: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul  4 15:29:37.576: INFO: 0 / 3 pods in namespace 'pods-1715' are running and ready (0 seconds elapsed)
Jul  4 15:29:37.576: INFO: expected 0 pod replicas in namespace 'pods-1715', 0 are Running and Ready.
Jul  4 15:29:37.576: INFO: POD         NODE           PHASE    GRACE  CONDITIONS
Jul  4 15:29:37.576: INFO: test-pod-1  3.138.203.20   Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 15:29:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 15:29:37 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 15:29:37 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 15:29:37 +0000 UTC  }]
Jul  4 15:29:37.576: INFO: test-pod-2  18.224.151.13  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 15:29:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 15:29:37 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 15:29:37 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 15:29:37 +0000 UTC  }]
Jul  4 15:29:37.576: INFO: test-pod-3  3.138.203.20   Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 15:29:37 +0000 UTC  }]
Jul  4 15:29:37.576: INFO: 
Jul  4 15:29:39.585: INFO: 3 / 3 pods in namespace 'pods-1715' are running and ready (2 seconds elapsed)
Jul  4 15:29:39.585: INFO: expected 0 pod replicas in namespace 'pods-1715', 0 are Running and Ready.
STEP: waiting for all pods to be deleted
Jul  4 15:29:39.600: INFO: Pod quantity 3 is different from expected quantity 0
Jul  4 15:29:40.606: INFO: Pod quantity 3 is different from expected quantity 0
Jul  4 15:29:41.606: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  4 15:29:42.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1715" for this suite.

• [SLOW TEST:5.084 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":356,"completed":38,"skipped":607,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:29:42.611: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:29:42.686: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fa00ac5e-9d59-4eac-ac96-5af449887dd2", Controller:(*bool)(0xc0033382e6), BlockOwnerDeletion:(*bool)(0xc0033382e7)}}
Jul  4 15:29:42.695: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"7a32f877-1e1b-4bba-b3f3-5992a7e13965", Controller:(*bool)(0xc003338526), BlockOwnerDeletion:(*bool)(0xc003338527)}}
Jul  4 15:29:42.698: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b2e601a4-0e43-4f72-ae15-000d730dfe41", Controller:(*bool)(0xc003338766), BlockOwnerDeletion:(*bool)(0xc003338767)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  4 15:29:47.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5566" for this suite.

• [SLOW TEST:5.106 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":356,"completed":39,"skipped":614,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:29:47.717: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul  4 15:29:47.742: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  4 15:30:47.760: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:30:47.762: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Jul  4 15:30:49.799: INFO: found a healthy node: 18.216.149.32
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:30:57.850: INFO: pods created so far: [1 1 1]
Jul  4 15:30:57.850: INFO: length of pods created so far: 3
Jul  4 15:30:59.859: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:188
Jul  4 15:31:06.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-2688" for this suite.
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Jul  4 15:31:06.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6166" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:79.205 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":356,"completed":40,"skipped":631,"failed":0}
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:31:06.922: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-7298/configmap-test-a2e1f6e7-f565-4a94-8e4f-550aa16f60ce
STEP: Creating a pod to test consume configMaps
Jul  4 15:31:06.944: INFO: Waiting up to 5m0s for pod "pod-configmaps-96766cdb-4cd3-468d-b9cb-21cedec40557" in namespace "configmap-7298" to be "Succeeded or Failed"
Jul  4 15:31:06.946: INFO: Pod "pod-configmaps-96766cdb-4cd3-468d-b9cb-21cedec40557": Phase="Pending", Reason="", readiness=false. Elapsed: 1.774259ms
Jul  4 15:31:08.952: INFO: Pod "pod-configmaps-96766cdb-4cd3-468d-b9cb-21cedec40557": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007750263s
Jul  4 15:31:10.956: INFO: Pod "pod-configmaps-96766cdb-4cd3-468d-b9cb-21cedec40557": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012519083s
STEP: Saw pod success
Jul  4 15:31:10.956: INFO: Pod "pod-configmaps-96766cdb-4cd3-468d-b9cb-21cedec40557" satisfied condition "Succeeded or Failed"
Jul  4 15:31:10.958: INFO: Trying to get logs from node 3.138.203.20 pod pod-configmaps-96766cdb-4cd3-468d-b9cb-21cedec40557 container env-test: <nil>
STEP: delete the pod
Jul  4 15:31:10.977: INFO: Waiting for pod pod-configmaps-96766cdb-4cd3-468d-b9cb-21cedec40557 to disappear
Jul  4 15:31:10.979: INFO: Pod pod-configmaps-96766cdb-4cd3-468d-b9cb-21cedec40557 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 15:31:10.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7298" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":356,"completed":41,"skipped":634,"failed":0}
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:31:10.985: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
Jul  4 15:31:11.008: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul  4 15:31:16.013: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
Jul  4 15:31:16.017: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
Jul  4 15:31:16.021: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
Jul  4 15:31:16.023: INFO: Observed &ReplicaSet event: ADDED
Jul  4 15:31:16.023: INFO: Observed &ReplicaSet event: MODIFIED
Jul  4 15:31:16.023: INFO: Observed &ReplicaSet event: MODIFIED
Jul  4 15:31:16.023: INFO: Observed &ReplicaSet event: MODIFIED
Jul  4 15:31:16.023: INFO: Found replicaset test-rs in namespace replicaset-3586 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul  4 15:31:16.023: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
Jul  4 15:31:16.023: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jul  4 15:31:16.027: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
Jul  4 15:31:16.028: INFO: Observed &ReplicaSet event: ADDED
Jul  4 15:31:16.028: INFO: Observed &ReplicaSet event: MODIFIED
Jul  4 15:31:16.028: INFO: Observed &ReplicaSet event: MODIFIED
Jul  4 15:31:16.028: INFO: Observed &ReplicaSet event: MODIFIED
Jul  4 15:31:16.028: INFO: Observed replicaset test-rs in namespace replicaset-3586 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul  4 15:31:16.028: INFO: Observed &ReplicaSet event: MODIFIED
Jul  4 15:31:16.029: INFO: Found replicaset test-rs in namespace replicaset-3586 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Jul  4 15:31:16.029: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  4 15:31:16.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3586" for this suite.

• [SLOW TEST:5.050 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":356,"completed":42,"skipped":639,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:31:16.035: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7566
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-7566
Jul  4 15:31:16.069: INFO: Found 0 stateful pods, waiting for 1
Jul  4 15:31:26.075: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
Jul  4 15:31:26.089: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
Jul  4 15:31:26.095: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
Jul  4 15:31:26.096: INFO: Observed &StatefulSet event: ADDED
Jul  4 15:31:26.096: INFO: Found Statefulset ss in namespace statefulset-7566 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul  4 15:31:26.096: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
Jul  4 15:31:26.096: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jul  4 15:31:26.101: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
Jul  4 15:31:26.102: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  4 15:31:26.102: INFO: Deleting all statefulset in ns statefulset-7566
Jul  4 15:31:26.104: INFO: Scaling statefulset ss to 0
Jul  4 15:31:36.117: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 15:31:36.119: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  4 15:31:36.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7566" for this suite.

• [SLOW TEST:20.104 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":356,"completed":43,"skipped":654,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:31:36.139: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching services
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:31:36.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8075" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":356,"completed":44,"skipped":667,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:31:36.160: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 15:31:37.197: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 15:31:40.296: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:31:40.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8100" for this suite.
STEP: Destroying namespace "webhook-8100-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":356,"completed":45,"skipped":669,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:31:40.394: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Jul  4 15:31:41.012: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 15:31:44.045: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:31:44.050: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:31:47.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4834" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:6.794 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":356,"completed":46,"skipped":701,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:31:47.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Jul  4 15:31:47.208: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Jul  4 15:32:01.073: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:32:03.404: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:32:13.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6335" for this suite.

• [SLOW TEST:26.311 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":356,"completed":47,"skipped":711,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:32:13.499: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:32:13.519: INFO: Endpoints addresses: [172.31.25.73] , ports: [6443]
Jul  4 15:32:13.519: INFO: EndpointSlices addresses: [172.31.25.73] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Jul  4 15:32:13.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9404" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":356,"completed":48,"skipped":749,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:32:13.532: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  4 15:34:01.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7784" for this suite.

• [SLOW TEST:108.092 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":356,"completed":49,"skipped":785,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:34:01.625: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test service account token: 
Jul  4 15:34:01.651: INFO: Waiting up to 5m0s for pod "test-pod-0d22a1ac-a572-44a3-90e2-a8fabaf2f28d" in namespace "svcaccounts-6704" to be "Succeeded or Failed"
Jul  4 15:34:01.654: INFO: Pod "test-pod-0d22a1ac-a572-44a3-90e2-a8fabaf2f28d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.731544ms
Jul  4 15:34:03.660: INFO: Pod "test-pod-0d22a1ac-a572-44a3-90e2-a8fabaf2f28d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009136364s
Jul  4 15:34:05.665: INFO: Pod "test-pod-0d22a1ac-a572-44a3-90e2-a8fabaf2f28d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014155698s
STEP: Saw pod success
Jul  4 15:34:05.665: INFO: Pod "test-pod-0d22a1ac-a572-44a3-90e2-a8fabaf2f28d" satisfied condition "Succeeded or Failed"
Jul  4 15:34:05.667: INFO: Trying to get logs from node 3.138.203.20 pod test-pod-0d22a1ac-a572-44a3-90e2-a8fabaf2f28d container agnhost-container: <nil>
STEP: delete the pod
Jul  4 15:34:05.690: INFO: Waiting for pod test-pod-0d22a1ac-a572-44a3-90e2-a8fabaf2f28d to disappear
Jul  4 15:34:05.691: INFO: Pod test-pod-0d22a1ac-a572-44a3-90e2-a8fabaf2f28d no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  4 15:34:05.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6704" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":356,"completed":50,"skipped":815,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:34:05.698: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with configMap that has name projected-configmap-test-upd-daf95181-a4a1-4db0-8dc5-2797b88b4737
STEP: Creating the pod
Jul  4 15:34:05.722: INFO: The status of Pod pod-projected-configmaps-75875fb5-96ae-4435-8466-da4822f31344 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:34:07.729: INFO: The status of Pod pod-projected-configmaps-75875fb5-96ae-4435-8466-da4822f31344 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-daf95181-a4a1-4db0-8dc5-2797b88b4737
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  4 15:34:09.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4439" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":51,"skipped":854,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:34:09.764: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-1926
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  4 15:34:09.778: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul  4 15:34:09.801: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:34:11.806: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:34:13.813: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:34:15.805: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:34:17.811: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:34:19.809: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:34:21.807: INFO: The status of Pod netserver-0 is Running (Ready = true)
Jul  4 15:34:21.811: INFO: The status of Pod netserver-1 is Running (Ready = true)
Jul  4 15:34:21.814: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Jul  4 15:34:23.853: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul  4 15:34:23.853: INFO: Going to poll 10.42.2.37 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jul  4 15:34:23.856: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.2.37:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1926 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:34:23.856: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:34:23.856: INFO: ExecWithOptions: Clientset creation
Jul  4 15:34:23.856: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1926/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.2.37%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  4 15:34:23.944: INFO: Found all 1 expected endpoints: [netserver-0]
Jul  4 15:34:23.944: INFO: Going to poll 10.42.0.17 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jul  4 15:34:23.947: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.17:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1926 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:34:23.947: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:34:23.948: INFO: ExecWithOptions: Clientset creation
Jul  4 15:34:23.948: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1926/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.0.17%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  4 15:34:24.020: INFO: Found all 1 expected endpoints: [netserver-1]
Jul  4 15:34:24.020: INFO: Going to poll 10.42.1.38 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jul  4 15:34:24.023: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.38:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1926 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:34:24.023: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:34:24.024: INFO: ExecWithOptions: Clientset creation
Jul  4 15:34:24.024: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1926/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.42.1.38%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  4 15:34:24.096: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Jul  4 15:34:24.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1926" for this suite.

• [SLOW TEST:14.338 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":52,"skipped":877,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:34:24.103: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Jul  4 15:34:25.162: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0704 15:34:25.162878      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  4 15:34:25.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-626" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":356,"completed":53,"skipped":919,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:34:25.169: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-50e7df06-016b-49cd-b737-53bdc594f449
STEP: Creating a pod to test consume secrets
Jul  4 15:34:25.201: INFO: Waiting up to 5m0s for pod "pod-secrets-3f1089f1-67e5-4f74-84a6-d91ff8450473" in namespace "secrets-3994" to be "Succeeded or Failed"
Jul  4 15:34:25.205: INFO: Pod "pod-secrets-3f1089f1-67e5-4f74-84a6-d91ff8450473": Phase="Pending", Reason="", readiness=false. Elapsed: 3.744756ms
Jul  4 15:34:27.212: INFO: Pod "pod-secrets-3f1089f1-67e5-4f74-84a6-d91ff8450473": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011420755s
Jul  4 15:34:29.217: INFO: Pod "pod-secrets-3f1089f1-67e5-4f74-84a6-d91ff8450473": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016501621s
STEP: Saw pod success
Jul  4 15:34:29.217: INFO: Pod "pod-secrets-3f1089f1-67e5-4f74-84a6-d91ff8450473" satisfied condition "Succeeded or Failed"
Jul  4 15:34:29.220: INFO: Trying to get logs from node 18.224.151.13 pod pod-secrets-3f1089f1-67e5-4f74-84a6-d91ff8450473 container secret-volume-test: <nil>
STEP: delete the pod
Jul  4 15:34:29.259: INFO: Waiting for pod pod-secrets-3f1089f1-67e5-4f74-84a6-d91ff8450473 to disappear
Jul  4 15:34:29.261: INFO: Pod pod-secrets-3f1089f1-67e5-4f74-84a6-d91ff8450473 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  4 15:34:29.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3994" for this suite.
STEP: Destroying namespace "secret-namespace-2860" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":356,"completed":54,"skipped":932,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:34:29.278: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:34:29.297: INFO: Creating deployment "webserver-deployment"
Jul  4 15:34:29.300: INFO: Waiting for observed generation 1
Jul  4 15:34:31.316: INFO: Waiting for all required pods to come up
Jul  4 15:34:31.330: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Jul  4 15:34:33.343: INFO: Waiting for deployment "webserver-deployment" to complete
Jul  4 15:34:33.347: INFO: Updating deployment "webserver-deployment" with a non-existent image
Jul  4 15:34:33.353: INFO: Updating deployment webserver-deployment
Jul  4 15:34:33.353: INFO: Waiting for observed generation 2
Jul  4 15:34:35.358: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jul  4 15:34:35.360: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jul  4 15:34:35.361: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jul  4 15:34:35.368: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jul  4 15:34:35.368: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jul  4 15:34:35.370: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jul  4 15:34:35.374: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Jul  4 15:34:35.374: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Jul  4 15:34:35.381: INFO: Updating deployment webserver-deployment
Jul  4 15:34:35.381: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Jul  4 15:34:35.388: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jul  4 15:34:35.390: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  4 15:34:37.407: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5298  2afe333c-5ca9-4dc9-ad14-69400f164f4e 6256 3 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:34:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0020a2ec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-07-04 15:34:35 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-57ccb67bb8" is progressing.,LastUpdateTime:2022-07-04 15:34:35 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Jul  4 15:34:37.409: INFO: New ReplicaSet "webserver-deployment-57ccb67bb8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-57ccb67bb8  deployment-5298  9f8833d8-76b7-44e8-939d-047e1906ca93 6238 3 2022-07-04 15:34:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 2afe333c-5ca9-4dc9-ad14-69400f164f4e 0xc0020a33f7 0xc0020a33f8}] []  [{kube-controller-manager Update apps/v1 2022-07-04 15:34:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2afe333c-5ca9-4dc9-ad14-69400f164f4e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:34:33 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 57ccb67bb8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0020a3498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  4 15:34:37.409: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Jul  4 15:34:37.410: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-55df494869  deployment-5298  a7efbd78-0266-4651-a444-f6a4adb2d6c9 6253 3 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 2afe333c-5ca9-4dc9-ad14-69400f164f4e 0xc0020a3307 0xc0020a3308}] []  [{kube-controller-manager Update apps/v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2afe333c-5ca9-4dc9-ad14-69400f164f4e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:34:31 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0020a3398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Jul  4 15:34:37.417: INFO: Pod "webserver-deployment-55df494869-4vwc6" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-4vwc6 webserver-deployment-55df494869- deployment-5298  864765a0-9ddf-4c34-b721-73552bb7d276 6032 0 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:bb1ab885019629a9053de799d18405b339dbbe6f1eb649cbc10f6e40e2fc1098 cni.projectcalico.org/podIP:10.42.0.20/32 cni.projectcalico.org/podIPs:10.42.0.20/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc003086af0 0xc003086af1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sb4mv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sb4mv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:10.42.0.20,StartTime:2022-07-04 15:34:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:34:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://361250dbb1df8b5552f1d6803cb316a27e4df2c2efbe8286e59997fc6150c03f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.417: INFO: Pod "webserver-deployment-55df494869-5kp89" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-5kp89 webserver-deployment-55df494869- deployment-5298  0b2ed23e-2eb7-4c01-adcf-371094ebf4d5 6233 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc003086d20 0xc003086d21}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-67x8l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-67x8l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.417: INFO: Pod "webserver-deployment-55df494869-7gnsx" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-7gnsx webserver-deployment-55df494869- deployment-5298  295ae549-98f1-4238-a710-c62f203fdcde 6299 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:724f07b2dde023562d3e7815b26debc29313cea98f757377bd48267796ef24ea cni.projectcalico.org/podIP:10.42.1.46/32 cni.projectcalico.org/podIPs:10.42.1.46/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc003086ec0 0xc003086ec1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wqjw9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wqjw9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.417: INFO: Pod "webserver-deployment-55df494869-9pnbt" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-9pnbt webserver-deployment-55df494869- deployment-5298  e7dc3da1-c88c-4e33-8874-a7e5ad95f393 6054 0 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:8e6ce42a42b57a13b5c0b1aa59d06e0a50c9770635834bb8137e40ee593606e7 cni.projectcalico.org/podIP:10.42.1.42/32 cni.projectcalico.org/podIPs:10.42.1.42/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc003087070 0xc003087071}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v6jn2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v6jn2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.23.66,PodIP:10.42.1.42,StartTime:2022-07-04 15:34:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:34:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://6bc5ea20e7a9da9edaf52fdca269f9e062756cc0746d58732dc13ed2e5ed9cce,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.418: INFO: Pod "webserver-deployment-55df494869-bmqpt" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-bmqpt webserver-deployment-55df494869- deployment-5298  2a7bb87e-5fd6-4715-b7d2-5c2cc70acb7c 6317 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:d4b044b1bd5cae34cd4bf44c488a017edb0bfe86ecd413832ee8df5cc50f27c8 cni.projectcalico.org/podIP:10.42.2.47/32 cni.projectcalico.org/podIPs:10.42.2.47/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc0030872a0 0xc0030872a1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vggrw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vggrw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.418: INFO: Pod "webserver-deployment-55df494869-bt66s" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-bt66s webserver-deployment-55df494869- deployment-5298  8bda4692-3e0c-412a-b1fb-22d7ded90e3e 6302 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:f4c6e9f8bc363249dc0c7fd80260daad52dab72f0671f1a73f71b2210f175930 cni.projectcalico.org/podIP:10.42.2.45/32 cni.projectcalico.org/podIPs:10.42.2.45/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc003087440 0xc003087441}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-07-04 15:34:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vwv9j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vwv9j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:,StartTime:2022-07-04 15:34:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.418: INFO: Pod "webserver-deployment-55df494869-d4qzm" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-d4qzm webserver-deployment-55df494869- deployment-5298  7ce4260c-ea09-4d4b-aed9-85f934c52478 6044 0 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:3daec9b63755737da1ca880891cec7fa412edd6069f5cab26115b5d3a0c3a06c cni.projectcalico.org/podIP:10.42.0.21/32 cni.projectcalico.org/podIPs:10.42.0.21/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc003087647 0xc003087648}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4p847,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4p847,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:10.42.0.21,StartTime:2022-07-04 15:34:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:34:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://ba9165820dca388039561a56f2f14f854a09c1e539838e089cdcc049ee9d30cb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.419: INFO: Pod "webserver-deployment-55df494869-jn8xc" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-jn8xc webserver-deployment-55df494869- deployment-5298  11f97d0c-0dbd-4822-b9a1-c8568c7f3391 6323 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:c77e90dc1cbbf1c57241bcafc38fd59d8fffa0bc1b05d5245daf00168d291829 cni.projectcalico.org/podIP:10.42.0.26/32 cni.projectcalico.org/podIPs:10.42.0.26/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc003087ce0 0xc003087ce1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d9t9l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d9t9l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.419: INFO: Pod "webserver-deployment-55df494869-jqkf2" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-jqkf2 webserver-deployment-55df494869- deployment-5298  2c95d6cf-3e88-48c8-87bf-192fbee3c55f 6051 0 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:226a897fcb686f2ab921720fb8937aff125f6d78893adcabb7fa7da2d94a58f4 cni.projectcalico.org/podIP:10.42.2.40/32 cni.projectcalico.org/podIPs:10.42.2.40/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc003087e80 0xc003087e81}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jl9jp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jl9jp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:10.42.2.40,StartTime:2022-07-04 15:34:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:34:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://641285b308b8ef51119d545fddcc065ea1bad52b0018aa64c46270ec3c9a066f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.419: INFO: Pod "webserver-deployment-55df494869-k46ks" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-k46ks webserver-deployment-55df494869- deployment-5298  4b6ef1b9-25bd-4302-b1bc-fdd5c6758e2b 6321 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:a6ad565c163c54328ea02f58fbbcb355d8aadf6e959df255387194bd425fc8df cni.projectcalico.org/podIP:10.42.1.48/32 cni.projectcalico.org/podIPs:10.42.1.48/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d56260 0xc002d56261}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mpm56,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mpm56,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.419: INFO: Pod "webserver-deployment-55df494869-kt4pl" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-kt4pl webserver-deployment-55df494869- deployment-5298  439a50c6-20cc-47e9-ae03-b952bc27f5a4 6034 0 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:7e921932f9c964947235f6bee7fa38aea766ca5c4b9e3ae8f6479be7f12f21af cni.projectcalico.org/podIP:10.42.0.19/32 cni.projectcalico.org/podIPs:10.42.0.19/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d564a0 0xc002d564a1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.19\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lr7z2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lr7z2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:10.42.0.19,StartTime:2022-07-04 15:34:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:34:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://2f299cafe2cd1f8d85eb9fee9790644878a11aeef8660a563d7c1ce3bf35aab7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.19,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.420: INFO: Pod "webserver-deployment-55df494869-lsjvv" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-lsjvv webserver-deployment-55df494869- deployment-5298  819e64dc-530f-4801-8a2b-8c83b11634f2 6062 0 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:c143528b4e456f142e3fd021379071ffc50e785363a3c80afacb9450e7b401ad cni.projectcalico.org/podIP:10.42.1.41/32 cni.projectcalico.org/podIPs:10.42.1.41/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d566c0 0xc002d566c1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q2xf6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q2xf6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.23.66,PodIP:10.42.1.41,StartTime:2022-07-04 15:34:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:34:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://49d08f9f69c4ff5e40be23732ceffac6582a9cf79bfbff8084116e73bb5ef887,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.421: INFO: Pod "webserver-deployment-55df494869-mbd4z" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-mbd4z webserver-deployment-55df494869- deployment-5298  73f2e950-a179-4a18-acf3-ad8320f0435a 6301 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:e8fd4ccfd9426de1518e29c58521e1385755a1f0d5cc484f619bbe6759e34ea9 cni.projectcalico.org/podIP:10.42.0.24/32 cni.projectcalico.org/podIPs:10.42.0.24/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d568e0 0xc002d568e1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-07-04 15:34:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5qtrk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5qtrk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:,StartTime:2022-07-04 15:34:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.422: INFO: Pod "webserver-deployment-55df494869-mgrrp" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-mgrrp webserver-deployment-55df494869- deployment-5298  ef8d136b-b9d3-47fe-ac0e-b0a09724aaa9 6210 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d56ac7 0xc002d56ac8}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w8vvf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w8vvf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.422: INFO: Pod "webserver-deployment-55df494869-mzqwr" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-mzqwr webserver-deployment-55df494869- deployment-5298  540600c3-a392-4545-83d1-0124946e935a 6258 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d56c30 0xc002d56c31}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kkbv4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kkbv4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:,StartTime:2022-07-04 15:34:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.422: INFO: Pod "webserver-deployment-55df494869-rpdd9" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-rpdd9 webserver-deployment-55df494869- deployment-5298  811cba69-92c2-4e37-affa-15816076ffec 6318 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:eef6273a1ec6d00984a59b5e3176dc8e79f6850d4f096c2457f21c49d98aea61 cni.projectcalico.org/podIP:10.42.2.44/32 cni.projectcalico.org/podIPs:10.42.2.44/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d56e17 0xc002d56e18}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-stsd8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-stsd8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:,StartTime:2022-07-04 15:34:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.422: INFO: Pod "webserver-deployment-55df494869-t9g96" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-t9g96 webserver-deployment-55df494869- deployment-5298  cf71a642-fda5-4f49-8574-0633fdf43bba 6041 0 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:bfd72303dc17121e2e4f3a559219377c47ae14cb5590e880867c16533888ec4b cni.projectcalico.org/podIP:10.42.2.39/32 cni.projectcalico.org/podIPs:10.42.2.39/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d57687 0xc002d57688}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.39\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fsvn8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fsvn8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:10.42.2.39,StartTime:2022-07-04 15:34:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:34:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://fd6fd7fe8aa3e98ebfc12b94653ed4d4fe7621831e1e8440c973f68e7c682ef2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.422: INFO: Pod "webserver-deployment-55df494869-tt75z" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-tt75z webserver-deployment-55df494869- deployment-5298  fbf14808-6480-490b-bf3e-78ac3dca2da6 6059 0 2022-07-04 15:34:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:71599cae4f0e798bd95940da0878d3b9d5d98eb1885317ecf947b4ab3041e8e3 cni.projectcalico.org/podIP:10.42.2.41/32 cni.projectcalico.org/podIPs:10.42.2.41/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d57a10 0xc002d57a11}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hlv56,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hlv56,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:10.42.2.41,StartTime:2022-07-04 15:34:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:34:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://acb900dd3232841bc51c13984adc8e11cd56b66abfbaf65a3eb6b8c5272e1488,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.423: INFO: Pod "webserver-deployment-55df494869-wd29w" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-wd29w webserver-deployment-55df494869- deployment-5298  118dc239-c194-4fb3-aee1-e1e2b8dbbd8f 6287 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:ab97a6670aa632256ee1ae6772c001dbda224e533215ebfd494e22c5a71084e1 cni.projectcalico.org/podIP:10.42.1.45/32 cni.projectcalico.org/podIPs:10.42.1.45/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d82050 0xc002d82051}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gn4j6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gn4j6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.423: INFO: Pod "webserver-deployment-55df494869-wf9pd" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-wf9pd webserver-deployment-55df494869- deployment-5298  8e9c473a-7880-4486-9ffa-ecf00a5659c8 6240 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 a7efbd78-0266-4651-a444-f6a4adb2d6c9 0xc002d82200 0xc002d82201}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a7efbd78-0266-4651-a444-f6a4adb2d6c9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6xqkm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6xqkm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.423: INFO: Pod "webserver-deployment-57ccb67bb8-45npd" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-45npd webserver-deployment-57ccb67bb8- deployment-5298  5118165c-b910-4837-aa7b-637b3da9cecb 6199 0 2022-07-04 15:34:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:43849b9cd9752f43c376afdc16bd35aaa8c4a178593c7a5653dbe7dcbab7d53c cni.projectcalico.org/podIP:10.42.1.43/32 cni.projectcalico.org/podIPs:10.42.1.43/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002d82390 0xc002d82391}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.43\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sfcss,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sfcss,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.23.66,PodIP:10.42.1.43,StartTime:2022-07-04 15:34:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.423: INFO: Pod "webserver-deployment-57ccb67bb8-5bwfz" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-5bwfz webserver-deployment-57ccb67bb8- deployment-5298  feb91d33-05e5-4a01-ac4e-54cd1ebe088a 6154 0 2022-07-04 15:34:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:2afe8172c397c18e49cee1bf1afde8a0398cfa0602cafd4192001fc0e6070533 cni.projectcalico.org/podIP:10.42.2.43/32 cni.projectcalico.org/podIPs:10.42.2.43/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002d82600 0xc002d82601}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:34:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-07-04 15:34:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-km8qb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-km8qb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:,StartTime:2022-07-04 15:34:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.423: INFO: Pod "webserver-deployment-57ccb67bb8-5rgqs" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-5rgqs webserver-deployment-57ccb67bb8- deployment-5298  beddf2b6-898b-415a-a9f4-58712627e484 6312 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:638c9b88f88367d49b194eac3708fbd3befcc4d59d9a78994e2b5fa2d9a00cab cni.projectcalico.org/podIP:10.42.0.25/32 cni.projectcalico.org/podIPs:10.42.0.25/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002d828f7 0xc002d828f8}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-07-04 15:34:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v5m7f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v5m7f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:,StartTime:2022-07-04 15:34:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.423: INFO: Pod "webserver-deployment-57ccb67bb8-7msmc" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-7msmc webserver-deployment-57ccb67bb8- deployment-5298  89bff048-4eac-4e7b-99ea-3bb3e7df2021 6167 0 2022-07-04 15:34:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:8613bf214b31405ef713733c1c314b6402d309aa2b1b64966655a69219514abd cni.projectcalico.org/podIP:10.42.2.42/32 cni.projectcalico.org/podIPs:10.42.2.42/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002d83247 0xc002d83248}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pzx6m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pzx6m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:10.42.2.42,StartTime:2022-07-04 15:34:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.423: INFO: Pod "webserver-deployment-57ccb67bb8-b5pl4" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-b5pl4 webserver-deployment-57ccb67bb8- deployment-5298  219dcc1d-2300-46ff-9c56-6e73174daa58 6215 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002d83be0 0xc002d83be1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7bn56,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7bn56,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.424: INFO: Pod "webserver-deployment-57ccb67bb8-kfbsr" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-kfbsr webserver-deployment-57ccb67bb8- deployment-5298  2642e622-3f03-4f6c-a116-64b829c855e9 6229 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002eec090 0xc002eec091}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-78s4v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-78s4v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.424: INFO: Pod "webserver-deployment-57ccb67bb8-nhg5s" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-nhg5s webserver-deployment-57ccb67bb8- deployment-5298  961ed35a-065a-4662-9f0f-283785cd4738 6162 0 2022-07-04 15:34:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:c97dfb0b2802077a0a734e836872644d02d1498b32c686d8ea82f417cc19f867 cni.projectcalico.org/podIP:10.42.1.44/32 cni.projectcalico.org/podIPs:10.42.1.44/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002eec6b0 0xc002eec6b1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6rsxm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6rsxm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.23.66,PodIP:,StartTime:2022-07-04 15:34:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.424: INFO: Pod "webserver-deployment-57ccb67bb8-qlwzq" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-qlwzq webserver-deployment-57ccb67bb8- deployment-5298  837a193c-0db7-4918-a918-70d60629162b 6288 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:86bd9aabceb5e47f6f6dcaad0451e755e80571842b62788363d096508aef7a66 cni.projectcalico.org/podIP:10.42.0.23/32 cni.projectcalico.org/podIPs:10.42.0.23/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002eecdb7 0xc002eecdb8}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-07-04 15:34:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9nndv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9nndv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:,StartTime:2022-07-04 15:34:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.425: INFO: Pod "webserver-deployment-57ccb67bb8-rlbbl" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-rlbbl webserver-deployment-57ccb67bb8- deployment-5298  7e987ae4-662f-408b-a761-bbfb565fecc6 6319 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:70c677f10a9368225b714883db614b67d1f17d3ccebaee97e85b9a20d98ce45a cni.projectcalico.org/podIP:10.42.1.47/32 cni.projectcalico.org/podIPs:10.42.1.47/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002eed687 0xc002eed688}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mppcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mppcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.427: INFO: Pod "webserver-deployment-57ccb67bb8-shqsh" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-shqsh webserver-deployment-57ccb67bb8- deployment-5298  12366b5c-2011-4382-8cad-77c39d2ce41c 6236 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002eedcc0 0xc002eedcc1}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gs7s4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gs7s4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.428: INFO: Pod "webserver-deployment-57ccb67bb8-tkkc5" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-tkkc5 webserver-deployment-57ccb67bb8- deployment-5298  0ff4923c-44ea-4c81-999f-bceaa96d63ef 6269 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002ed8b00 0xc002ed8b01}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hpxbp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hpxbp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:,StartTime:2022-07-04 15:34:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.428: INFO: Pod "webserver-deployment-57ccb67bb8-w9j8z" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-w9j8z webserver-deployment-57ccb67bb8- deployment-5298  c0e49728-7694-4879-bc16-56bedabd4b8c 6313 0 2022-07-04 15:34:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:81248837eaf3bcbc4b818303a8fd3365a3cc729b7b960ead6f9d0197d900b771 cni.projectcalico.org/podIP:10.42.2.46/32 cni.projectcalico.org/podIPs:10.42.2.46/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002ed92f7 0xc002ed92f8}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:34:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-07-04 15:34:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pflqx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pflqx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:,StartTime:2022-07-04 15:34:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 15:34:37.429: INFO: Pod "webserver-deployment-57ccb67bb8-z9h29" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-z9h29 webserver-deployment-57ccb67bb8- deployment-5298  e26ed1b8-24e9-4223-87f7-aa7d8e4091b0 6172 0 2022-07-04 15:34:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:87078baff8e0e4448ca562084d267c7c23c9169d8f07dddb27ea60fae9b744d4 cni.projectcalico.org/podIP:10.42.0.22/32 cni.projectcalico.org/podIPs:10.42.0.22/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 9f8833d8-76b7-44e8-939d-047e1906ca93 0xc002ed9a57 0xc002ed9a58}] []  [{kube-controller-manager Update v1 2022-07-04 15:34:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9f8833d8-76b7-44e8-939d-047e1906ca93\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:34:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:34:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.22\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qcqr8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qcqr8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:34:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:10.42.0.22,StartTime:2022-07-04 15:34:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "webserver:404",},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.22,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  4 15:34:37.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5298" for this suite.

• [SLOW TEST:8.172 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":356,"completed":55,"skipped":944,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:34:37.450: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Jul  4 15:34:56.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2885" for this suite.
STEP: Destroying namespace "nsdeletetest-4606" for this suite.
Jul  4 15:34:56.595: INFO: Namespace nsdeletetest-4606 was already deleted
STEP: Destroying namespace "nsdeletetest-729" for this suite.

• [SLOW TEST:19.147 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":356,"completed":56,"skipped":959,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:34:56.598: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-4605
Jul  4 15:34:56.616: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:34:58.621: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Jul  4 15:34:58.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-4605 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Jul  4 15:34:58.752: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Jul  4 15:34:58.752: INFO: stdout: "iptables"
Jul  4 15:34:58.752: INFO: proxyMode: iptables
Jul  4 15:34:58.758: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Jul  4 15:34:58.760: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-4605
STEP: creating replication controller affinity-nodeport-timeout in namespace services-4605
I0704 15:34:58.772408      22 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-4605, replica count: 3
I0704 15:35:01.823289      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 15:35:01.833: INFO: Creating new exec pod
Jul  4 15:35:04.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-4605 exec execpod-affinityqwlwd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Jul  4 15:35:04.988: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Jul  4 15:35:04.988: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:35:04.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-4605 exec execpod-affinityqwlwd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.54.255 80'
Jul  4 15:35:05.110: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.54.255 80\nConnection to 10.43.54.255 80 port [tcp/http] succeeded!\n"
Jul  4 15:35:05.110: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:35:05.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-4605 exec execpod-affinityqwlwd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.20.100 30061'
Jul  4 15:35:05.236: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.20.100 30061\nConnection to 172.31.20.100 30061 port [tcp/*] succeeded!\n"
Jul  4 15:35:05.236: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:35:05.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-4605 exec execpod-affinityqwlwd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.23.66 30061'
Jul  4 15:35:05.362: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.23.66 30061\nConnection to 172.31.23.66 30061 port [tcp/*] succeeded!\n"
Jul  4 15:35:05.362: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:35:05.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-4605 exec execpod-affinityqwlwd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.20.100:30061/ ; done'
Jul  4 15:35:05.559: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n"
Jul  4 15:35:05.559: INFO: stdout: "\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk\naffinity-nodeport-timeout-slldk"
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Received response from host: affinity-nodeport-timeout-slldk
Jul  4 15:35:05.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-4605 exec execpod-affinityqwlwd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.20.100:30061/'
Jul  4 15:35:05.686: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n"
Jul  4 15:35:05.686: INFO: stdout: "affinity-nodeport-timeout-slldk"
Jul  4 15:35:25.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-4605 exec execpod-affinityqwlwd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.20.100:30061/'
Jul  4 15:35:25.815: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.20.100:30061/\n"
Jul  4 15:35:25.815: INFO: stdout: "affinity-nodeport-timeout-tnf4n"
Jul  4 15:35:25.815: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-4605, will wait for the garbage collector to delete the pods
Jul  4 15:35:25.878: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 3.78763ms
Jul  4 15:35:25.979: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.371624ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:35:28.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4605" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:31.603 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":57,"skipped":969,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:35:28.201: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-8524
STEP: creating service affinity-clusterip in namespace services-8524
STEP: creating replication controller affinity-clusterip in namespace services-8524
I0704 15:35:28.229699      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-8524, replica count: 3
I0704 15:35:31.281375      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 15:35:31.287: INFO: Creating new exec pod
Jul  4 15:35:34.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-8524 exec execpod-affinity47vvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Jul  4 15:35:34.430: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Jul  4 15:35:34.430: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:35:34.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-8524 exec execpod-affinity47vvz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.204.179 80'
Jul  4 15:35:34.558: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.204.179 80\nConnection to 10.43.204.179 80 port [tcp/http] succeeded!\n"
Jul  4 15:35:34.559: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:35:34.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-8524 exec execpod-affinity47vvz -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.204.179:80/ ; done'
Jul  4 15:35:34.744: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.204.179:80/\n"
Jul  4 15:35:34.744: INFO: stdout: "\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97\naffinity-clusterip-8bx97"
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Received response from host: affinity-clusterip-8bx97
Jul  4 15:35:34.744: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-8524, will wait for the garbage collector to delete the pods
Jul  4 15:35:34.810: INFO: Deleting ReplicationController affinity-clusterip took: 4.587788ms
Jul  4 15:35:34.911: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.90862ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:35:37.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8524" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:8.927 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":58,"skipped":1008,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:35:37.129: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:35:37.141: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Creating first CR 
Jul  4 15:35:39.694: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-04T15:35:39Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-04T15:35:39Z]] name:name1 resourceVersion:7022 uid:5a9aa483-71c6-4606-a0fc-86270bb9a84b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Jul  4 15:35:49.704: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-04T15:35:49Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-04T15:35:49Z]] name:name2 resourceVersion:7066 uid:1a34fc90-cc04-41ba-9623-6d4e8fa3f530] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Jul  4 15:35:59.716: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-04T15:35:39Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-04T15:35:59Z]] name:name1 resourceVersion:7082 uid:5a9aa483-71c6-4606-a0fc-86270bb9a84b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Jul  4 15:36:09.730: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-04T15:35:49Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-04T15:36:09Z]] name:name2 resourceVersion:7098 uid:1a34fc90-cc04-41ba-9623-6d4e8fa3f530] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Jul  4 15:36:19.741: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-04T15:35:39Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-04T15:35:59Z]] name:name1 resourceVersion:7113 uid:5a9aa483-71c6-4606-a0fc-86270bb9a84b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Jul  4 15:36:29.752: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-04T15:35:49Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-04T15:36:09Z]] name:name2 resourceVersion:7128 uid:1a34fc90-cc04-41ba-9623-6d4e8fa3f530] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:36:40.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4105" for this suite.

• [SLOW TEST:63.145 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":356,"completed":59,"skipped":1009,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:36:40.274: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-bf6f075c-da75-406f-9c9c-d861b3a3e753
STEP: Creating a pod to test consume configMaps
Jul  4 15:36:40.306: INFO: Waiting up to 5m0s for pod "pod-configmaps-f72a2253-d3f9-4df9-8b24-aa8cb00becf3" in namespace "configmap-144" to be "Succeeded or Failed"
Jul  4 15:36:40.309: INFO: Pod "pod-configmaps-f72a2253-d3f9-4df9-8b24-aa8cb00becf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055568ms
Jul  4 15:36:42.315: INFO: Pod "pod-configmaps-f72a2253-d3f9-4df9-8b24-aa8cb00becf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009005891s
Jul  4 15:36:44.321: INFO: Pod "pod-configmaps-f72a2253-d3f9-4df9-8b24-aa8cb00becf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014775571s
STEP: Saw pod success
Jul  4 15:36:44.321: INFO: Pod "pod-configmaps-f72a2253-d3f9-4df9-8b24-aa8cb00becf3" satisfied condition "Succeeded or Failed"
Jul  4 15:36:44.323: INFO: Trying to get logs from node 3.138.203.20 pod pod-configmaps-f72a2253-d3f9-4df9-8b24-aa8cb00becf3 container agnhost-container: <nil>
STEP: delete the pod
Jul  4 15:36:44.345: INFO: Waiting for pod pod-configmaps-f72a2253-d3f9-4df9-8b24-aa8cb00becf3 to disappear
Jul  4 15:36:44.346: INFO: Pod pod-configmaps-f72a2253-d3f9-4df9-8b24-aa8cb00becf3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 15:36:44.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-144" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":60,"skipped":1010,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:36:44.352: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  4 15:41:44.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9666" for this suite.

• [SLOW TEST:300.047 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":356,"completed":61,"skipped":1075,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:41:44.400: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 15:41:45.417: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 15:41:48.436: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:41:48.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1363" for this suite.
STEP: Destroying namespace "webhook-1363-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":356,"completed":62,"skipped":1078,"failed":0}

------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:41:48.515: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  4 15:41:48.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4990" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":356,"completed":63,"skipped":1078,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:41:48.559: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 15:41:48.578: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd1ca391-cf76-458f-bc29-583b688c183d" in namespace "projected-5541" to be "Succeeded or Failed"
Jul  4 15:41:48.580: INFO: Pod "downwardapi-volume-fd1ca391-cf76-458f-bc29-583b688c183d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080696ms
Jul  4 15:41:50.584: INFO: Pod "downwardapi-volume-fd1ca391-cf76-458f-bc29-583b688c183d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006298335s
Jul  4 15:41:52.592: INFO: Pod "downwardapi-volume-fd1ca391-cf76-458f-bc29-583b688c183d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013729537s
STEP: Saw pod success
Jul  4 15:41:52.592: INFO: Pod "downwardapi-volume-fd1ca391-cf76-458f-bc29-583b688c183d" satisfied condition "Succeeded or Failed"
Jul  4 15:41:52.594: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-fd1ca391-cf76-458f-bc29-583b688c183d container client-container: <nil>
STEP: delete the pod
Jul  4 15:41:52.615: INFO: Waiting for pod downwardapi-volume-fd1ca391-cf76-458f-bc29-583b688c183d to disappear
Jul  4 15:41:52.617: INFO: Pod downwardapi-volume-fd1ca391-cf76-458f-bc29-583b688c183d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 15:41:52.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5541" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":64,"skipped":1092,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:41:52.622: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on tmpfs
Jul  4 15:41:52.639: INFO: Waiting up to 5m0s for pod "pod-fb3166fe-0d9b-4406-8e3f-802155762112" in namespace "emptydir-7292" to be "Succeeded or Failed"
Jul  4 15:41:52.641: INFO: Pod "pod-fb3166fe-0d9b-4406-8e3f-802155762112": Phase="Pending", Reason="", readiness=false. Elapsed: 1.798529ms
Jul  4 15:41:54.646: INFO: Pod "pod-fb3166fe-0d9b-4406-8e3f-802155762112": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006618745s
Jul  4 15:41:56.653: INFO: Pod "pod-fb3166fe-0d9b-4406-8e3f-802155762112": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01369603s
STEP: Saw pod success
Jul  4 15:41:56.653: INFO: Pod "pod-fb3166fe-0d9b-4406-8e3f-802155762112" satisfied condition "Succeeded or Failed"
Jul  4 15:41:56.657: INFO: Trying to get logs from node 18.216.149.32 pod pod-fb3166fe-0d9b-4406-8e3f-802155762112 container test-container: <nil>
STEP: delete the pod
Jul  4 15:41:56.668: INFO: Waiting for pod pod-fb3166fe-0d9b-4406-8e3f-802155762112 to disappear
Jul  4 15:41:56.669: INFO: Pod pod-fb3166fe-0d9b-4406-8e3f-802155762112 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 15:41:56.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7292" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":65,"skipped":1115,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:41:56.675: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:41:56.691: INFO: Creating pod...
Jul  4 15:41:58.701: INFO: Creating service...
Jul  4 15:41:58.707: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/pods/agnhost/proxy?method=DELETE
Jul  4 15:41:58.711: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul  4 15:41:58.711: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/pods/agnhost/proxy?method=OPTIONS
Jul  4 15:41:58.715: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul  4 15:41:58.715: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/pods/agnhost/proxy?method=PATCH
Jul  4 15:41:58.717: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul  4 15:41:58.717: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/pods/agnhost/proxy?method=POST
Jul  4 15:41:58.719: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul  4 15:41:58.719: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/pods/agnhost/proxy?method=PUT
Jul  4 15:41:58.721: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jul  4 15:41:58.721: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/services/e2e-proxy-test-service/proxy?method=DELETE
Jul  4 15:41:58.724: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul  4 15:41:58.724: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/services/e2e-proxy-test-service/proxy?method=OPTIONS
Jul  4 15:41:58.727: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul  4 15:41:58.727: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/services/e2e-proxy-test-service/proxy?method=PATCH
Jul  4 15:41:58.730: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul  4 15:41:58.730: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/services/e2e-proxy-test-service/proxy?method=POST
Jul  4 15:41:58.733: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul  4 15:41:58.733: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/services/e2e-proxy-test-service/proxy?method=PUT
Jul  4 15:41:58.736: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jul  4 15:41:58.736: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/pods/agnhost/proxy?method=GET
Jul  4 15:41:58.737: INFO: http.Client request:GET StatusCode:301
Jul  4 15:41:58.737: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/services/e2e-proxy-test-service/proxy?method=GET
Jul  4 15:41:58.740: INFO: http.Client request:GET StatusCode:301
Jul  4 15:41:58.740: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/pods/agnhost/proxy?method=HEAD
Jul  4 15:41:58.741: INFO: http.Client request:HEAD StatusCode:301
Jul  4 15:41:58.741: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-2542/services/e2e-proxy-test-service/proxy?method=HEAD
Jul  4 15:41:58.743: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Jul  4 15:41:58.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2542" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","total":356,"completed":66,"skipped":1123,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:41:58.750: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-7905768e-da19-4dc5-af4e-26f01fc2e930 in namespace container-probe-3873
Jul  4 15:42:00.776: INFO: Started pod liveness-7905768e-da19-4dc5-af4e-26f01fc2e930 in namespace container-probe-3873
STEP: checking the pod's current state and verifying that restartCount is present
Jul  4 15:42:00.779: INFO: Initial restart count of pod liveness-7905768e-da19-4dc5-af4e-26f01fc2e930 is 0
Jul  4 15:42:20.837: INFO: Restart count of pod container-probe-3873/liveness-7905768e-da19-4dc5-af4e-26f01fc2e930 is now 1 (20.058234466s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  4 15:42:20.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3873" for this suite.

• [SLOW TEST:22.099 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":67,"skipped":1138,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:42:20.850: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul  4 15:42:20.868: INFO: Waiting up to 5m0s for pod "pod-8487d6df-7971-4ab1-b37d-42a300fd4848" in namespace "emptydir-9630" to be "Succeeded or Failed"
Jul  4 15:42:20.870: INFO: Pod "pod-8487d6df-7971-4ab1-b37d-42a300fd4848": Phase="Pending", Reason="", readiness=false. Elapsed: 1.962947ms
Jul  4 15:42:22.872: INFO: Pod "pod-8487d6df-7971-4ab1-b37d-42a300fd4848": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004454925s
Jul  4 15:42:24.877: INFO: Pod "pod-8487d6df-7971-4ab1-b37d-42a300fd4848": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009872804s
STEP: Saw pod success
Jul  4 15:42:24.878: INFO: Pod "pod-8487d6df-7971-4ab1-b37d-42a300fd4848" satisfied condition "Succeeded or Failed"
Jul  4 15:42:24.880: INFO: Trying to get logs from node 3.138.203.20 pod pod-8487d6df-7971-4ab1-b37d-42a300fd4848 container test-container: <nil>
STEP: delete the pod
Jul  4 15:42:24.905: INFO: Waiting for pod pod-8487d6df-7971-4ab1-b37d-42a300fd4848 to disappear
Jul  4 15:42:24.907: INFO: Pod pod-8487d6df-7971-4ab1-b37d-42a300fd4848 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 15:42:24.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9630" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":68,"skipped":1165,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:42:24.914: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:42:24.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-9365 version'
Jul  4 15:42:24.986: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Jul  4 15:42:24.986: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.2\", GitCommit:\"f66044f4361b9f1f96f0053dd46cb7dce5e990a8\", GitTreeState:\"clean\", BuildDate:\"2022-06-15T14:22:29Z\", GoVersion:\"go1.18.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.4\nServer Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.2\", GitCommit:\"f66044f4361b9f1f96f0053dd46cb7dce5e990a8\", GitTreeState:\"clean\", BuildDate:\"2022-06-15T14:15:38Z\", GoVersion:\"go1.18.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 15:42:24.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9365" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":356,"completed":69,"skipped":1167,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:42:24.993: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Indexed job
STEP: Ensuring job reaches completions
STEP: Ensuring pods with index for job exist
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  4 15:42:35.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6663" for this suite.

• [SLOW TEST:10.031 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","total":356,"completed":70,"skipped":1183,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:42:35.024: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
Jul  4 15:42:46.456: INFO: 71 pods remaining
Jul  4 15:42:46.456: INFO: 71 pods has nil DeletionTimestamp
Jul  4 15:42:46.456: INFO: 
STEP: Gathering metrics
Jul  4 15:42:51.460: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Jul  4 15:42:51.460: INFO: Deleting pod "simpletest-rc-to-be-deleted-26vrl" in namespace "gc-440"
W0704 15:42:51.460140      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul  4 15:42:51.467: INFO: Deleting pod "simpletest-rc-to-be-deleted-2jlv5" in namespace "gc-440"
Jul  4 15:42:51.479: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ncvc" in namespace "gc-440"
Jul  4 15:42:51.490: INFO: Deleting pod "simpletest-rc-to-be-deleted-2q2fg" in namespace "gc-440"
Jul  4 15:42:51.496: INFO: Deleting pod "simpletest-rc-to-be-deleted-47f4t" in namespace "gc-440"
Jul  4 15:42:51.503: INFO: Deleting pod "simpletest-rc-to-be-deleted-4cd9k" in namespace "gc-440"
Jul  4 15:42:51.509: INFO: Deleting pod "simpletest-rc-to-be-deleted-4gtt9" in namespace "gc-440"
Jul  4 15:42:51.519: INFO: Deleting pod "simpletest-rc-to-be-deleted-4ql2j" in namespace "gc-440"
Jul  4 15:42:51.526: INFO: Deleting pod "simpletest-rc-to-be-deleted-52jlp" in namespace "gc-440"
Jul  4 15:42:51.533: INFO: Deleting pod "simpletest-rc-to-be-deleted-5fjrc" in namespace "gc-440"
Jul  4 15:42:51.541: INFO: Deleting pod "simpletest-rc-to-be-deleted-5hvnb" in namespace "gc-440"
Jul  4 15:42:51.546: INFO: Deleting pod "simpletest-rc-to-be-deleted-5mn5k" in namespace "gc-440"
Jul  4 15:42:51.562: INFO: Deleting pod "simpletest-rc-to-be-deleted-5nkdm" in namespace "gc-440"
Jul  4 15:42:51.575: INFO: Deleting pod "simpletest-rc-to-be-deleted-6894f" in namespace "gc-440"
Jul  4 15:42:51.600: INFO: Deleting pod "simpletest-rc-to-be-deleted-68b29" in namespace "gc-440"
Jul  4 15:42:51.617: INFO: Deleting pod "simpletest-rc-to-be-deleted-6k7hg" in namespace "gc-440"
Jul  4 15:42:51.629: INFO: Deleting pod "simpletest-rc-to-be-deleted-6nnq4" in namespace "gc-440"
Jul  4 15:42:51.648: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qh7j" in namespace "gc-440"
Jul  4 15:42:51.663: INFO: Deleting pod "simpletest-rc-to-be-deleted-74zzh" in namespace "gc-440"
Jul  4 15:42:51.696: INFO: Deleting pod "simpletest-rc-to-be-deleted-779kx" in namespace "gc-440"
Jul  4 15:42:51.719: INFO: Deleting pod "simpletest-rc-to-be-deleted-84sq9" in namespace "gc-440"
Jul  4 15:42:51.745: INFO: Deleting pod "simpletest-rc-to-be-deleted-9lpl8" in namespace "gc-440"
Jul  4 15:42:51.767: INFO: Deleting pod "simpletest-rc-to-be-deleted-9nbr9" in namespace "gc-440"
Jul  4 15:42:51.782: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qqq8" in namespace "gc-440"
Jul  4 15:42:51.833: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zr9w" in namespace "gc-440"
Jul  4 15:42:51.888: INFO: Deleting pod "simpletest-rc-to-be-deleted-b4pbj" in namespace "gc-440"
Jul  4 15:42:51.919: INFO: Deleting pod "simpletest-rc-to-be-deleted-bfwmb" in namespace "gc-440"
Jul  4 15:42:51.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-bgfb5" in namespace "gc-440"
Jul  4 15:42:51.958: INFO: Deleting pod "simpletest-rc-to-be-deleted-bl24b" in namespace "gc-440"
Jul  4 15:42:51.982: INFO: Deleting pod "simpletest-rc-to-be-deleted-blz5h" in namespace "gc-440"
Jul  4 15:42:52.000: INFO: Deleting pod "simpletest-rc-to-be-deleted-cdngc" in namespace "gc-440"
Jul  4 15:42:52.011: INFO: Deleting pod "simpletest-rc-to-be-deleted-cms5t" in namespace "gc-440"
Jul  4 15:42:52.044: INFO: Deleting pod "simpletest-rc-to-be-deleted-cnc48" in namespace "gc-440"
Jul  4 15:42:52.077: INFO: Deleting pod "simpletest-rc-to-be-deleted-dgqwp" in namespace "gc-440"
Jul  4 15:42:52.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-dl4cp" in namespace "gc-440"
Jul  4 15:42:52.118: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvv7d" in namespace "gc-440"
Jul  4 15:42:52.126: INFO: Deleting pod "simpletest-rc-to-be-deleted-f54v7" in namespace "gc-440"
Jul  4 15:42:52.149: INFO: Deleting pod "simpletest-rc-to-be-deleted-fdx2k" in namespace "gc-440"
Jul  4 15:42:52.163: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkg5v" in namespace "gc-440"
Jul  4 15:42:52.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-frpqz" in namespace "gc-440"
Jul  4 15:42:52.203: INFO: Deleting pod "simpletest-rc-to-be-deleted-gg5gw" in namespace "gc-440"
Jul  4 15:42:52.263: INFO: Deleting pod "simpletest-rc-to-be-deleted-gqs6d" in namespace "gc-440"
Jul  4 15:42:52.305: INFO: Deleting pod "simpletest-rc-to-be-deleted-grxzv" in namespace "gc-440"
Jul  4 15:42:52.350: INFO: Deleting pod "simpletest-rc-to-be-deleted-gtb4r" in namespace "gc-440"
Jul  4 15:42:52.362: INFO: Deleting pod "simpletest-rc-to-be-deleted-gtgvx" in namespace "gc-440"
Jul  4 15:42:52.376: INFO: Deleting pod "simpletest-rc-to-be-deleted-gw5kd" in namespace "gc-440"
Jul  4 15:42:52.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-gxrtz" in namespace "gc-440"
Jul  4 15:42:52.411: INFO: Deleting pod "simpletest-rc-to-be-deleted-h8xtq" in namespace "gc-440"
Jul  4 15:42:52.431: INFO: Deleting pod "simpletest-rc-to-be-deleted-h92rn" in namespace "gc-440"
Jul  4 15:42:52.469: INFO: Deleting pod "simpletest-rc-to-be-deleted-hhvz7" in namespace "gc-440"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  4 15:42:52.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-440" for this suite.

• [SLOW TEST:17.491 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":356,"completed":71,"skipped":1240,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:42:52.516: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 15:42:52.580: INFO: Waiting up to 5m0s for pod "downwardapi-volume-58ac207e-ca0c-4f19-a3d2-ddfc358e3e81" in namespace "downward-api-3130" to be "Succeeded or Failed"
Jul  4 15:42:52.584: INFO: Pod "downwardapi-volume-58ac207e-ca0c-4f19-a3d2-ddfc358e3e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.341916ms
Jul  4 15:42:54.589: INFO: Pod "downwardapi-volume-58ac207e-ca0c-4f19-a3d2-ddfc358e3e81": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009344875s
Jul  4 15:42:56.595: INFO: Pod "downwardapi-volume-58ac207e-ca0c-4f19-a3d2-ddfc358e3e81": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015067246s
Jul  4 15:42:58.598: INFO: Pod "downwardapi-volume-58ac207e-ca0c-4f19-a3d2-ddfc358e3e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018182345s
STEP: Saw pod success
Jul  4 15:42:58.598: INFO: Pod "downwardapi-volume-58ac207e-ca0c-4f19-a3d2-ddfc358e3e81" satisfied condition "Succeeded or Failed"
Jul  4 15:42:58.600: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-58ac207e-ca0c-4f19-a3d2-ddfc358e3e81 container client-container: <nil>
STEP: delete the pod
Jul  4 15:42:58.615: INFO: Waiting for pod downwardapi-volume-58ac207e-ca0c-4f19-a3d2-ddfc358e3e81 to disappear
Jul  4 15:42:58.618: INFO: Pod downwardapi-volume-58ac207e-ca0c-4f19-a3d2-ddfc358e3e81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 15:42:58.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3130" for this suite.

• [SLOW TEST:6.120 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":356,"completed":72,"skipped":1256,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:42:58.637: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-31983eab-0659-411b-98ba-c3f736fad168
STEP: Creating a pod to test consume configMaps
Jul  4 15:42:58.666: INFO: Waiting up to 5m0s for pod "pod-configmaps-721a1046-9425-4302-a1f7-400653c6ad3c" in namespace "configmap-8431" to be "Succeeded or Failed"
Jul  4 15:42:58.668: INFO: Pod "pod-configmaps-721a1046-9425-4302-a1f7-400653c6ad3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033295ms
Jul  4 15:43:00.672: INFO: Pod "pod-configmaps-721a1046-9425-4302-a1f7-400653c6ad3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006250552s
Jul  4 15:43:02.677: INFO: Pod "pod-configmaps-721a1046-9425-4302-a1f7-400653c6ad3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011548577s
STEP: Saw pod success
Jul  4 15:43:02.677: INFO: Pod "pod-configmaps-721a1046-9425-4302-a1f7-400653c6ad3c" satisfied condition "Succeeded or Failed"
Jul  4 15:43:02.679: INFO: Trying to get logs from node 3.138.203.20 pod pod-configmaps-721a1046-9425-4302-a1f7-400653c6ad3c container agnhost-container: <nil>
STEP: delete the pod
Jul  4 15:43:02.693: INFO: Waiting for pod pod-configmaps-721a1046-9425-4302-a1f7-400653c6ad3c to disappear
Jul  4 15:43:02.695: INFO: Pod pod-configmaps-721a1046-9425-4302-a1f7-400653c6ad3c no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 15:43:02.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8431" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":73,"skipped":1258,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:43:02.701: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:43:02.725: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-e024c060-f3a9-47a8-9026-62896a1757ce" in namespace "security-context-test-3319" to be "Succeeded or Failed"
Jul  4 15:43:02.727: INFO: Pod "busybox-privileged-false-e024c060-f3a9-47a8-9026-62896a1757ce": Phase="Pending", Reason="", readiness=false. Elapsed: 1.826806ms
Jul  4 15:43:04.734: INFO: Pod "busybox-privileged-false-e024c060-f3a9-47a8-9026-62896a1757ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009196194s
Jul  4 15:43:06.742: INFO: Pod "busybox-privileged-false-e024c060-f3a9-47a8-9026-62896a1757ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016573335s
Jul  4 15:43:06.742: INFO: Pod "busybox-privileged-false-e024c060-f3a9-47a8-9026-62896a1757ce" satisfied condition "Succeeded or Failed"
Jul  4 15:43:06.747: INFO: Got logs for pod "busybox-privileged-false-e024c060-f3a9-47a8-9026-62896a1757ce": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  4 15:43:06.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3319" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":74,"skipped":1268,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:43:06.753: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Starting the proxy
Jul  4 15:43:06.769: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1976 proxy --unix-socket=/tmp/kubectl-proxy-unix3899042639/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 15:43:06.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1976" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":356,"completed":75,"skipped":1274,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:43:06.818: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-7318
STEP: creating service affinity-nodeport-transition in namespace services-7318
STEP: creating replication controller affinity-nodeport-transition in namespace services-7318
I0704 15:43:06.843998      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-7318, replica count: 3
I0704 15:43:09.894725      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 15:43:09.904: INFO: Creating new exec pod
Jul  4 15:43:12.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7318 exec execpod-affinityg2cg4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Jul  4 15:43:13.056: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Jul  4 15:43:13.056: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:43:13.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7318 exec execpod-affinityg2cg4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.9.142 80'
Jul  4 15:43:13.179: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.9.142 80\nConnection to 10.43.9.142 80 port [tcp/http] succeeded!\n"
Jul  4 15:43:13.179: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:43:13.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7318 exec execpod-affinityg2cg4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 32295'
Jul  4 15:43:13.310: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 32295\nConnection to 172.31.25.73 32295 port [tcp/*] succeeded!\n"
Jul  4 15:43:13.310: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:43:13.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7318 exec execpod-affinityg2cg4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.23.66 32295'
Jul  4 15:43:13.438: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.23.66 32295\nConnection to 172.31.23.66 32295 port [tcp/*] succeeded!\n"
Jul  4 15:43:13.438: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 15:43:13.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7318 exec execpod-affinityg2cg4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.20.100:32295/ ; done'
Jul  4 15:43:13.641: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n"
Jul  4 15:43:13.641: INFO: stdout: "\naffinity-nodeport-transition-z6jdm\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-z6jdm\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-fwhwp\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-z6jdm\naffinity-nodeport-transition-fwhwp\naffinity-nodeport-transition-fwhwp\naffinity-nodeport-transition-fwhwp\naffinity-nodeport-transition-fwhwp\naffinity-nodeport-transition-z6jdm\naffinity-nodeport-transition-fwhwp\naffinity-nodeport-transition-fwhwp\naffinity-nodeport-transition-z6jdm"
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-z6jdm
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-z6jdm
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-fwhwp
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-z6jdm
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-fwhwp
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-fwhwp
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-fwhwp
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-fwhwp
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-z6jdm
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-fwhwp
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-fwhwp
Jul  4 15:43:13.641: INFO: Received response from host: affinity-nodeport-transition-z6jdm
Jul  4 15:43:13.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7318 exec execpod-affinityg2cg4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.20.100:32295/ ; done'
Jul  4 15:43:13.850: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:32295/\n"
Jul  4 15:43:13.850: INFO: stdout: "\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9\naffinity-nodeport-transition-h9zl9"
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Received response from host: affinity-nodeport-transition-h9zl9
Jul  4 15:43:13.850: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-7318, will wait for the garbage collector to delete the pods
Jul  4 15:43:13.914: INFO: Deleting ReplicationController affinity-nodeport-transition took: 3.06579ms
Jul  4 15:43:14.015: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.448797ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:43:16.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7318" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.420 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":76,"skipped":1279,"failed":0}
SSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:43:16.238: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  4 15:43:42.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8871" for this suite.

• [SLOW TEST:26.262 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":356,"completed":77,"skipped":1283,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:43:42.501: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-934
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-934
STEP: creating replication controller externalsvc in namespace services-934
I0704 15:43:42.601846      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-934, replica count: 2
I0704 15:43:45.653945      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Jul  4 15:43:45.666: INFO: Creating new exec pod
Jul  4 15:43:47.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-934 exec execpod5sgsr -- /bin/sh -x -c nslookup clusterip-service.services-934.svc.cluster.local'
Jul  4 15:43:47.827: INFO: stderr: "+ nslookup clusterip-service.services-934.svc.cluster.local\n"
Jul  4 15:43:47.827: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nclusterip-service.services-934.svc.cluster.local\tcanonical name = externalsvc.services-934.svc.cluster.local.\nName:\texternalsvc.services-934.svc.cluster.local\nAddress: 10.43.116.34\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-934, will wait for the garbage collector to delete the pods
Jul  4 15:43:47.885: INFO: Deleting ReplicationController externalsvc took: 4.150244ms
Jul  4 15:43:47.986: INFO: Terminating ReplicationController externalsvc pods took: 100.656931ms
Jul  4 15:43:49.699: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:43:49.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-934" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:7.211 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":356,"completed":78,"skipped":1286,"failed":0}
SSSSSS
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:43:49.712: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating server pod server in namespace prestop-5746
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5746
STEP: Deleting pre-stop pod
Jul  4 15:43:58.756: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:188
Jul  4 15:43:58.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5746" for this suite.

• [SLOW TEST:9.065 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":356,"completed":79,"skipped":1292,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:43:58.777: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:43:58.802: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul  4 15:44:03.807: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
Jul  4 15:44:03.812: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
Jul  4 15:44:03.820: INFO: observed ReplicaSet test-rs in namespace replicaset-7557 with ReadyReplicas 1, AvailableReplicas 1
Jul  4 15:44:03.827: INFO: observed ReplicaSet test-rs in namespace replicaset-7557 with ReadyReplicas 1, AvailableReplicas 1
Jul  4 15:44:03.841: INFO: observed ReplicaSet test-rs in namespace replicaset-7557 with ReadyReplicas 1, AvailableReplicas 1
Jul  4 15:44:03.849: INFO: observed ReplicaSet test-rs in namespace replicaset-7557 with ReadyReplicas 1, AvailableReplicas 1
Jul  4 15:44:04.785: INFO: observed ReplicaSet test-rs in namespace replicaset-7557 with ReadyReplicas 2, AvailableReplicas 2
Jul  4 15:44:05.451: INFO: observed Replicaset test-rs in namespace replicaset-7557 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  4 15:44:05.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7557" for this suite.

• [SLOW TEST:6.681 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":356,"completed":80,"skipped":1342,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:44:05.458: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Jul  4 15:44:05.478: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:44:07.821: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:44:19.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-688" for this suite.

• [SLOW TEST:14.014 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":356,"completed":81,"skipped":1350,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:44:19.473: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 15:44:19.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8634acd0-bca9-436c-9717-9198854f430f" in namespace "downward-api-2274" to be "Succeeded or Failed"
Jul  4 15:44:19.547: INFO: Pod "downwardapi-volume-8634acd0-bca9-436c-9717-9198854f430f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.308198ms
Jul  4 15:44:21.553: INFO: Pod "downwardapi-volume-8634acd0-bca9-436c-9717-9198854f430f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008512924s
Jul  4 15:44:23.559: INFO: Pod "downwardapi-volume-8634acd0-bca9-436c-9717-9198854f430f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014680723s
STEP: Saw pod success
Jul  4 15:44:23.560: INFO: Pod "downwardapi-volume-8634acd0-bca9-436c-9717-9198854f430f" satisfied condition "Succeeded or Failed"
Jul  4 15:44:23.561: INFO: Trying to get logs from node 3.138.203.20 pod downwardapi-volume-8634acd0-bca9-436c-9717-9198854f430f container client-container: <nil>
STEP: delete the pod
Jul  4 15:44:23.577: INFO: Waiting for pod downwardapi-volume-8634acd0-bca9-436c-9717-9198854f430f to disappear
Jul  4 15:44:23.578: INFO: Pod downwardapi-volume-8634acd0-bca9-436c-9717-9198854f430f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 15:44:23.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2274" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":82,"skipped":1364,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:44:23.586: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 15:44:24.091: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 15:44:27.159: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:44:27.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2356" for this suite.
STEP: Destroying namespace "webhook-2356-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":356,"completed":83,"skipped":1376,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:44:27.242: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in volume subpath
Jul  4 15:44:27.270: INFO: Waiting up to 5m0s for pod "var-expansion-fa57e54c-a427-49c5-ae91-a8e0626d776f" in namespace "var-expansion-6078" to be "Succeeded or Failed"
Jul  4 15:44:27.272: INFO: Pod "var-expansion-fa57e54c-a427-49c5-ae91-a8e0626d776f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154973ms
Jul  4 15:44:29.278: INFO: Pod "var-expansion-fa57e54c-a427-49c5-ae91-a8e0626d776f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008054105s
Jul  4 15:44:31.285: INFO: Pod "var-expansion-fa57e54c-a427-49c5-ae91-a8e0626d776f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01515548s
STEP: Saw pod success
Jul  4 15:44:31.285: INFO: Pod "var-expansion-fa57e54c-a427-49c5-ae91-a8e0626d776f" satisfied condition "Succeeded or Failed"
Jul  4 15:44:31.287: INFO: Trying to get logs from node 3.138.203.20 pod var-expansion-fa57e54c-a427-49c5-ae91-a8e0626d776f container dapi-container: <nil>
STEP: delete the pod
Jul  4 15:44:31.302: INFO: Waiting for pod var-expansion-fa57e54c-a427-49c5-ae91-a8e0626d776f to disappear
Jul  4 15:44:31.304: INFO: Pod var-expansion-fa57e54c-a427-49c5-ae91-a8e0626d776f no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  4 15:44:31.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6078" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":356,"completed":84,"skipped":1410,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:44:31.319: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-93f449d5-3711-447a-bd9f-ff7824e97d86
STEP: Creating secret with name s-test-opt-upd-79bc30de-b7f6-443a-b1a7-8a1ccbd5c128
STEP: Creating the pod
Jul  4 15:44:31.352: INFO: The status of Pod pod-secrets-f3bcf698-d595-4ba5-9432-d42f9b4d102e is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:44:33.359: INFO: The status of Pod pod-secrets-f3bcf698-d595-4ba5-9432-d42f9b4d102e is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-93f449d5-3711-447a-bd9f-ff7824e97d86
STEP: Updating secret s-test-opt-upd-79bc30de-b7f6-443a-b1a7-8a1ccbd5c128
STEP: Creating secret with name s-test-opt-create-259552b4-0571-4b0c-9a79-dc04cfe30abd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  4 15:44:37.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5807" for this suite.

• [SLOW TEST:6.120 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":85,"skipped":1445,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:44:37.440: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 15:44:37.461: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3ad57f85-cecc-4d46-9071-95b41ecd32de" in namespace "projected-9832" to be "Succeeded or Failed"
Jul  4 15:44:37.464: INFO: Pod "downwardapi-volume-3ad57f85-cecc-4d46-9071-95b41ecd32de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298564ms
Jul  4 15:44:39.471: INFO: Pod "downwardapi-volume-3ad57f85-cecc-4d46-9071-95b41ecd32de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009808232s
Jul  4 15:44:41.476: INFO: Pod "downwardapi-volume-3ad57f85-cecc-4d46-9071-95b41ecd32de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014838194s
STEP: Saw pod success
Jul  4 15:44:41.476: INFO: Pod "downwardapi-volume-3ad57f85-cecc-4d46-9071-95b41ecd32de" satisfied condition "Succeeded or Failed"
Jul  4 15:44:41.478: INFO: Trying to get logs from node 3.138.203.20 pod downwardapi-volume-3ad57f85-cecc-4d46-9071-95b41ecd32de container client-container: <nil>
STEP: delete the pod
Jul  4 15:44:41.489: INFO: Waiting for pod downwardapi-volume-3ad57f85-cecc-4d46-9071-95b41ecd32de to disappear
Jul  4 15:44:41.491: INFO: Pod downwardapi-volume-3ad57f85-cecc-4d46-9071-95b41ecd32de no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 15:44:41.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9832" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":86,"skipped":1462,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:44:41.497: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 15:45:09.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8160" for this suite.

• [SLOW TEST:28.068 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":356,"completed":87,"skipped":1503,"failed":0}
SSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:09.565: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  4 15:45:11.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3446" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","total":356,"completed":88,"skipped":1511,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:11.609: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  4 15:45:11.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-6629" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":89,"skipped":1529,"failed":0}
SSSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:11.638: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Jul  4 15:45:13.694: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  4 15:45:15.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-980" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":356,"completed":90,"skipped":1534,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:15.707: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jul  4 15:45:15.747: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-372  b8c8f7e3-0926-447d-852c-4701884c3d09 10617 0 2022-07-04 15:45:15 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-07-04 15:45:15 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 15:45:15.747: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-372  b8c8f7e3-0926-447d-852c-4701884c3d09 10618 0 2022-07-04 15:45:15 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-07-04 15:45:15 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  4 15:45:15.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-372" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":356,"completed":91,"skipped":1561,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:15.753: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 15:45:15.771: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d539be39-8145-48c5-82ba-848358e6f443" in namespace "projected-2598" to be "Succeeded or Failed"
Jul  4 15:45:15.773: INFO: Pod "downwardapi-volume-d539be39-8145-48c5-82ba-848358e6f443": Phase="Pending", Reason="", readiness=false. Elapsed: 1.886196ms
Jul  4 15:45:17.780: INFO: Pod "downwardapi-volume-d539be39-8145-48c5-82ba-848358e6f443": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008696212s
Jul  4 15:45:19.785: INFO: Pod "downwardapi-volume-d539be39-8145-48c5-82ba-848358e6f443": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013997904s
STEP: Saw pod success
Jul  4 15:45:19.785: INFO: Pod "downwardapi-volume-d539be39-8145-48c5-82ba-848358e6f443" satisfied condition "Succeeded or Failed"
Jul  4 15:45:19.787: INFO: Trying to get logs from node 3.138.203.20 pod downwardapi-volume-d539be39-8145-48c5-82ba-848358e6f443 container client-container: <nil>
STEP: delete the pod
Jul  4 15:45:19.800: INFO: Waiting for pod downwardapi-volume-d539be39-8145-48c5-82ba-848358e6f443 to disappear
Jul  4 15:45:19.802: INFO: Pod downwardapi-volume-d539be39-8145-48c5-82ba-848358e6f443 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 15:45:19.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2598" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":356,"completed":92,"skipped":1568,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:19.808: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:45:19.822: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Jul  4 15:45:23.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-2201 --namespace=crd-publish-openapi-2201 create -f -'
Jul  4 15:45:24.425: INFO: stderr: ""
Jul  4 15:45:24.425: INFO: stdout: "e2e-test-crd-publish-openapi-3271-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jul  4 15:45:24.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-2201 --namespace=crd-publish-openapi-2201 delete e2e-test-crd-publish-openapi-3271-crds test-cr'
Jul  4 15:45:24.481: INFO: stderr: ""
Jul  4 15:45:24.481: INFO: stdout: "e2e-test-crd-publish-openapi-3271-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Jul  4 15:45:24.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-2201 --namespace=crd-publish-openapi-2201 apply -f -'
Jul  4 15:45:24.646: INFO: stderr: ""
Jul  4 15:45:24.646: INFO: stdout: "e2e-test-crd-publish-openapi-3271-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jul  4 15:45:24.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-2201 --namespace=crd-publish-openapi-2201 delete e2e-test-crd-publish-openapi-3271-crds test-cr'
Jul  4 15:45:24.702: INFO: stderr: ""
Jul  4 15:45:24.702: INFO: stdout: "e2e-test-crd-publish-openapi-3271-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Jul  4 15:45:24.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-2201 explain e2e-test-crd-publish-openapi-3271-crds'
Jul  4 15:45:24.913: INFO: stderr: ""
Jul  4 15:45:24.913: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3271-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:45:28.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2201" for this suite.

• [SLOW TEST:8.934 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":356,"completed":93,"skipped":1571,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:28.742: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-9sbz
STEP: Creating a pod to test atomic-volume-subpath
Jul  4 15:45:28.768: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9sbz" in namespace "subpath-5768" to be "Succeeded or Failed"
Jul  4 15:45:28.774: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.955459ms
Jul  4 15:45:30.780: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 2.011057312s
Jul  4 15:45:32.787: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 4.018055104s
Jul  4 15:45:34.794: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 6.025054348s
Jul  4 15:45:36.802: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 8.033115398s
Jul  4 15:45:38.806: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 10.037894849s
Jul  4 15:45:40.811: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 12.042405624s
Jul  4 15:45:42.818: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 14.049818589s
Jul  4 15:45:44.824: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 16.055801747s
Jul  4 15:45:46.834: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 18.065548621s
Jul  4 15:45:48.839: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=true. Elapsed: 20.071008916s
Jul  4 15:45:50.844: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Running", Reason="", readiness=false. Elapsed: 22.076030717s
Jul  4 15:45:52.853: INFO: Pod "pod-subpath-test-configmap-9sbz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.084365574s
STEP: Saw pod success
Jul  4 15:45:52.853: INFO: Pod "pod-subpath-test-configmap-9sbz" satisfied condition "Succeeded or Failed"
Jul  4 15:45:52.855: INFO: Trying to get logs from node 3.138.203.20 pod pod-subpath-test-configmap-9sbz container test-container-subpath-configmap-9sbz: <nil>
STEP: delete the pod
Jul  4 15:45:52.868: INFO: Waiting for pod pod-subpath-test-configmap-9sbz to disappear
Jul  4 15:45:52.870: INFO: Pod pod-subpath-test-configmap-9sbz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9sbz
Jul  4 15:45:52.870: INFO: Deleting pod "pod-subpath-test-configmap-9sbz" in namespace "subpath-5768"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  4 15:45:52.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5768" for this suite.

• [SLOW TEST:24.136 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","total":356,"completed":94,"skipped":1601,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests 
  should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:52.878: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename conformance-tests
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
STEP: Getting node addresses
Jul  4 15:45:52.942: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:188
Jul  4 15:45:52.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-2200" for this suite.
•{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","total":356,"completed":95,"skipped":1643,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:52.953: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  4 15:45:52.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4433" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","total":356,"completed":96,"skipped":1665,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:52.984: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-bc79fa39-2301-49ca-bed6-cb93568e973a
STEP: Creating a pod to test consume secrets
Jul  4 15:45:53.004: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-84244f57-2ef3-42fb-b46a-cced752785b8" in namespace "projected-8474" to be "Succeeded or Failed"
Jul  4 15:45:53.007: INFO: Pod "pod-projected-secrets-84244f57-2ef3-42fb-b46a-cced752785b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.636938ms
Jul  4 15:45:55.013: INFO: Pod "pod-projected-secrets-84244f57-2ef3-42fb-b46a-cced752785b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009331669s
Jul  4 15:45:57.020: INFO: Pod "pod-projected-secrets-84244f57-2ef3-42fb-b46a-cced752785b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016106318s
STEP: Saw pod success
Jul  4 15:45:57.020: INFO: Pod "pod-projected-secrets-84244f57-2ef3-42fb-b46a-cced752785b8" satisfied condition "Succeeded or Failed"
Jul  4 15:45:57.022: INFO: Trying to get logs from node 18.216.149.32 pod pod-projected-secrets-84244f57-2ef3-42fb-b46a-cced752785b8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  4 15:45:57.037: INFO: Waiting for pod pod-projected-secrets-84244f57-2ef3-42fb-b46a-cced752785b8 to disappear
Jul  4 15:45:57.039: INFO: Pod pod-projected-secrets-84244f57-2ef3-42fb-b46a-cced752785b8 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  4 15:45:57.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8474" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":97,"skipped":1681,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:45:57.045: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-8f49831b-8eb7-4d2c-adb7-54bf3083637e
STEP: Creating a pod to test consume configMaps
Jul  4 15:45:57.070: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-034bfc1a-25ca-4d9c-a36e-dede1ced3dc2" in namespace "projected-3919" to be "Succeeded or Failed"
Jul  4 15:45:57.072: INFO: Pod "pod-projected-configmaps-034bfc1a-25ca-4d9c-a36e-dede1ced3dc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.191907ms
Jul  4 15:45:59.077: INFO: Pod "pod-projected-configmaps-034bfc1a-25ca-4d9c-a36e-dede1ced3dc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007211386s
Jul  4 15:46:01.082: INFO: Pod "pod-projected-configmaps-034bfc1a-25ca-4d9c-a36e-dede1ced3dc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012402552s
STEP: Saw pod success
Jul  4 15:46:01.082: INFO: Pod "pod-projected-configmaps-034bfc1a-25ca-4d9c-a36e-dede1ced3dc2" satisfied condition "Succeeded or Failed"
Jul  4 15:46:01.084: INFO: Trying to get logs from node 18.216.149.32 pod pod-projected-configmaps-034bfc1a-25ca-4d9c-a36e-dede1ced3dc2 container agnhost-container: <nil>
STEP: delete the pod
Jul  4 15:46:01.098: INFO: Waiting for pod pod-projected-configmaps-034bfc1a-25ca-4d9c-a36e-dede1ced3dc2 to disappear
Jul  4 15:46:01.100: INFO: Pod pod-projected-configmaps-034bfc1a-25ca-4d9c-a36e-dede1ced3dc2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  4 15:46:01.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3919" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":98,"skipped":1686,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:46:01.106: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  4 15:46:01.126: INFO: Waiting up to 5m0s for pod "downward-api-3fb36e38-867d-4dac-9632-c20f3db347a3" in namespace "downward-api-4580" to be "Succeeded or Failed"
Jul  4 15:46:01.128: INFO: Pod "downward-api-3fb36e38-867d-4dac-9632-c20f3db347a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.485185ms
Jul  4 15:46:03.136: INFO: Pod "downward-api-3fb36e38-867d-4dac-9632-c20f3db347a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009960796s
Jul  4 15:46:05.143: INFO: Pod "downward-api-3fb36e38-867d-4dac-9632-c20f3db347a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016987192s
STEP: Saw pod success
Jul  4 15:46:05.143: INFO: Pod "downward-api-3fb36e38-867d-4dac-9632-c20f3db347a3" satisfied condition "Succeeded or Failed"
Jul  4 15:46:05.145: INFO: Trying to get logs from node 3.138.203.20 pod downward-api-3fb36e38-867d-4dac-9632-c20f3db347a3 container dapi-container: <nil>
STEP: delete the pod
Jul  4 15:46:05.157: INFO: Waiting for pod downward-api-3fb36e38-867d-4dac-9632-c20f3db347a3 to disappear
Jul  4 15:46:05.159: INFO: Pod downward-api-3fb36e38-867d-4dac-9632-c20f3db347a3 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  4 15:46:05.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4580" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":356,"completed":99,"skipped":1712,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:46:05.164: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
Jul  4 15:46:05.194: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:46:07.203: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
Jul  4 15:46:07.212: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:46:09.218: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jul  4 15:46:09.220: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.220: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.220: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.220: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul  4 15:46:09.292: INFO: Exec stderr: ""
Jul  4 15:46:09.292: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.292: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.293: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.293: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul  4 15:46:09.372: INFO: Exec stderr: ""
Jul  4 15:46:09.372: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.372: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.373: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.373: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul  4 15:46:09.452: INFO: Exec stderr: ""
Jul  4 15:46:09.452: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.452: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.453: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.453: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul  4 15:46:09.525: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jul  4 15:46:09.525: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.525: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.525: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.525: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jul  4 15:46:09.592: INFO: Exec stderr: ""
Jul  4 15:46:09.592: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.592: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.592: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.592: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jul  4 15:46:09.668: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jul  4 15:46:09.668: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.668: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.668: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.669: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul  4 15:46:09.733: INFO: Exec stderr: ""
Jul  4 15:46:09.733: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.733: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.733: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.733: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul  4 15:46:09.796: INFO: Exec stderr: ""
Jul  4 15:46:09.796: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.796: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.797: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.797: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul  4 15:46:09.873: INFO: Exec stderr: ""
Jul  4 15:46:09.873: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4415 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:46:09.873: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:46:09.873: INFO: ExecWithOptions: Clientset creation
Jul  4 15:46:09.874: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4415/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul  4 15:46:09.949: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:188
Jul  4 15:46:09.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4415" for this suite.
•{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":100,"skipped":1740,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:46:09.959: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:46:09.980: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jul  4 15:46:14.983: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul  4 15:46:14.983: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jul  4 15:46:16.992: INFO: Creating deployment "test-rollover-deployment"
Jul  4 15:46:16.999: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jul  4 15:46:19.006: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jul  4 15:46:19.010: INFO: Ensure that both replica sets have 1 created replica
Jul  4 15:46:19.013: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jul  4 15:46:19.020: INFO: Updating deployment test-rollover-deployment
Jul  4 15:46:19.020: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jul  4 15:46:21.027: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jul  4 15:46:21.031: INFO: Make sure deployment "test-rollover-deployment" is complete
Jul  4 15:46:21.035: INFO: all replica sets need to contain the pod-template-hash label
Jul  4 15:46:21.035: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:46:23.045: INFO: all replica sets need to contain the pod-template-hash label
Jul  4 15:46:23.045: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:46:25.044: INFO: all replica sets need to contain the pod-template-hash label
Jul  4 15:46:25.044: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:46:27.046: INFO: all replica sets need to contain the pod-template-hash label
Jul  4 15:46:27.046: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:46:29.044: INFO: all replica sets need to contain the pod-template-hash label
Jul  4 15:46:29.044: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 15, 46, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 15, 46, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  4 15:46:31.042: INFO: 
Jul  4 15:46:31.042: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  4 15:46:31.047: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5511  0e7d07a7-d3a1-4e28-af4c-a4f78b117213 11106 2 2022-07-04 15:46:16 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-07-04 15:46:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:46:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00608a088 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-07-04 15:46:17 +0000 UTC,LastTransitionTime:2022-07-04 15:46:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-779c67f4f8" has successfully progressed.,LastUpdateTime:2022-07-04 15:46:30 +0000 UTC,LastTransitionTime:2022-07-04 15:46:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul  4 15:46:31.050: INFO: New ReplicaSet "test-rollover-deployment-779c67f4f8" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-779c67f4f8  deployment-5511  28fde214-41fe-4cc3-babf-d2ec224cddfa 11096 2 2022-07-04 15:46:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 0e7d07a7-d3a1-4e28-af4c-a4f78b117213 0xc006043887 0xc006043888}] []  [{kube-controller-manager Update apps/v1 2022-07-04 15:46:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0e7d07a7-d3a1-4e28-af4c-a4f78b117213\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:46:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 779c67f4f8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006043938 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul  4 15:46:31.050: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jul  4 15:46:31.050: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5511  72fca2fb-5f90-45d2-9ad5-0787106a843f 11104 2 2022-07-04 15:46:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 0e7d07a7-d3a1-4e28-af4c-a4f78b117213 0xc006043757 0xc006043758}] []  [{e2e.test Update apps/v1 2022-07-04 15:46:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:46:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0e7d07a7-d3a1-4e28-af4c-a4f78b117213\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:46:30 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc006043818 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  4 15:46:31.050: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-87f8f6dcf  deployment-5511  c757d252-5bed-4c6f-99dd-2201074dd122 11059 2 2022-07-04 15:46:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 0e7d07a7-d3a1-4e28-af4c-a4f78b117213 0xc0060439a0 0xc0060439a1}] []  [{kube-controller-manager Update apps/v1 2022-07-04 15:46:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0e7d07a7-d3a1-4e28-af4c-a4f78b117213\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:46:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 87f8f6dcf,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006043a48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  4 15:46:31.052: INFO: Pod "test-rollover-deployment-779c67f4f8-cwt75" is available:
&Pod{ObjectMeta:{test-rollover-deployment-779c67f4f8-cwt75 test-rollover-deployment-779c67f4f8- deployment-5511  851305de-eba6-41e9-aecb-4cc0719ca717 11079 0 2022-07-04 15:46:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[cni.projectcalico.org/containerID:bae7d14c96c3d2632bd230ea74dc27eafd8b58f95de4ebb932b02f23d2470975 cni.projectcalico.org/podIP:10.42.1.111/32 cni.projectcalico.org/podIPs:10.42.1.111/32] [{apps/v1 ReplicaSet test-rollover-deployment-779c67f4f8 28fde214-41fe-4cc3-babf-d2ec224cddfa 0xc006043fd7 0xc006043fd8}] []  [{calico Update v1 2022-07-04 15:46:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-07-04 15:46:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"28fde214-41fe-4cc3-babf-d2ec224cddfa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:46:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.111\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hhwjl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hhwjl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:46:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:46:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:46:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:46:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.23.66,PodIP:10.42.1.111,StartTime:2022-07-04 15:46:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:46:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:docker://fb7c2ba25aad369ba432f40e4ec0cb85f1ab50d9abbe32c0efce8e05d975d075,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  4 15:46:31.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5511" for this suite.

• [SLOW TEST:21.100 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":356,"completed":101,"skipped":1782,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:46:31.059: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:46:31.079: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:46:31.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8079" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":356,"completed":102,"skipped":1814,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:46:31.611: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul  4 15:46:31.630: INFO: Waiting up to 5m0s for pod "pod-a523adae-2103-49c7-89f9-cb4db73a2cb6" in namespace "emptydir-1719" to be "Succeeded or Failed"
Jul  4 15:46:31.632: INFO: Pod "pod-a523adae-2103-49c7-89f9-cb4db73a2cb6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.832977ms
Jul  4 15:46:33.641: INFO: Pod "pod-a523adae-2103-49c7-89f9-cb4db73a2cb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010163703s
Jul  4 15:46:35.645: INFO: Pod "pod-a523adae-2103-49c7-89f9-cb4db73a2cb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014892001s
STEP: Saw pod success
Jul  4 15:46:35.645: INFO: Pod "pod-a523adae-2103-49c7-89f9-cb4db73a2cb6" satisfied condition "Succeeded or Failed"
Jul  4 15:46:35.647: INFO: Trying to get logs from node 18.216.149.32 pod pod-a523adae-2103-49c7-89f9-cb4db73a2cb6 container test-container: <nil>
STEP: delete the pod
Jul  4 15:46:35.665: INFO: Waiting for pod pod-a523adae-2103-49c7-89f9-cb4db73a2cb6 to disappear
Jul  4 15:46:35.666: INFO: Pod pod-a523adae-2103-49c7-89f9-cb4db73a2cb6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 15:46:35.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1719" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":103,"skipped":1875,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:46:35.673: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service nodeport-test with type=NodePort in namespace services-3581
STEP: creating replication controller nodeport-test in namespace services-3581
I0704 15:46:35.704861      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-3581, replica count: 2
Jul  4 15:46:38.755: INFO: Creating new exec pod
I0704 15:46:38.755748      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 15:46:41.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jul  4 15:46:41.904: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:41.904: INFO: stdout: ""
Jul  4 15:46:42.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jul  4 15:46:43.036: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:43.036: INFO: stdout: ""
Jul  4 15:46:43.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jul  4 15:46:44.036: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:44.036: INFO: stdout: ""
Jul  4 15:46:44.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jul  4 15:46:45.052: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:45.052: INFO: stdout: "nodeport-test-v9kqg"
Jul  4 15:46:45.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.174.47 80'
Jul  4 15:46:45.184: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.174.47 80\nConnection to 10.43.174.47 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:45.184: INFO: stdout: "nodeport-test-v9kqg"
Jul  4 15:46:45.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 31963'
Jul  4 15:46:45.312: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 31963\nConnection to 172.31.25.73 31963 port [tcp/*] succeeded!\n"
Jul  4 15:46:45.312: INFO: stdout: ""
Jul  4 15:46:46.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 31963'
Jul  4 15:46:46.440: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 31963\nConnection to 172.31.25.73 31963 port [tcp/*] succeeded!\n"
Jul  4 15:46:46.440: INFO: stdout: ""
Jul  4 15:46:47.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 31963'
Jul  4 15:46:47.440: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 31963\nConnection to 172.31.25.73 31963 port [tcp/*] succeeded!\n"
Jul  4 15:46:47.440: INFO: stdout: ""
Jul  4 15:46:48.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 31963'
Jul  4 15:46:48.444: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 31963\nConnection to 172.31.25.73 31963 port [tcp/*] succeeded!\n"
Jul  4 15:46:48.444: INFO: stdout: "nodeport-test-v9kqg"
Jul  4 15:46:48.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.20.100 31963'
Jul  4 15:46:48.572: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.20.100 31963\nConnection to 172.31.20.100 31963 port [tcp/*] succeeded!\n"
Jul  4 15:46:48.572: INFO: stdout: ""
Jul  4 15:46:49.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3581 exec execpodp7xwr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.20.100 31963'
Jul  4 15:46:49.700: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.20.100 31963\nConnection to 172.31.20.100 31963 port [tcp/*] succeeded!\n"
Jul  4 15:46:49.700: INFO: stdout: "nodeport-test-kxr5f"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:46:49.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3581" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:14.034 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":356,"completed":104,"skipped":1908,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:46:49.707: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7636
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-7636
I0704 15:46:49.755248      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7636, replica count: 2
I0704 15:46:52.807334      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 15:46:52.807: INFO: Creating new exec pod
Jul  4 15:46:55.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jul  4 15:46:55.989: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:55.989: INFO: stdout: ""
Jul  4 15:46:56.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jul  4 15:46:57.119: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:57.119: INFO: stdout: "externalname-service-mst5d"
Jul  4 15:46:57.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.155.108 80'
Jul  4 15:46:57.247: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.155.108 80\nConnection to 10.43.155.108 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:57.247: INFO: stdout: ""
Jul  4 15:46:58.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.155.108 80'
Jul  4 15:46:58.375: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.155.108 80\nConnection to 10.43.155.108 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:58.375: INFO: stdout: ""
Jul  4 15:46:59.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.155.108 80'
Jul  4 15:46:59.375: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.155.108 80\nConnection to 10.43.155.108 80 port [tcp/http] succeeded!\n"
Jul  4 15:46:59.375: INFO: stdout: "externalname-service-mst5d"
Jul  4 15:46:59.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 32643'
Jul  4 15:46:59.496: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 32643\nConnection to 172.31.25.73 32643 port [tcp/*] succeeded!\n"
Jul  4 15:46:59.496: INFO: stdout: ""
Jul  4 15:47:00.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 32643'
Jul  4 15:47:00.636: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 32643\nConnection to 172.31.25.73 32643 port [tcp/*] succeeded!\n"
Jul  4 15:47:00.636: INFO: stdout: ""
Jul  4 15:47:01.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 32643'
Jul  4 15:47:01.624: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 32643\nConnection to 172.31.25.73 32643 port [tcp/*] succeeded!\n"
Jul  4 15:47:01.624: INFO: stdout: ""
Jul  4 15:47:02.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 32643'
Jul  4 15:47:02.637: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 32643\nConnection to 172.31.25.73 32643 port [tcp/*] succeeded!\n"
Jul  4 15:47:02.637: INFO: stdout: "externalname-service-n5n26"
Jul  4 15:47:02.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.23.66 32643'
Jul  4 15:47:02.767: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.23.66 32643\nConnection to 172.31.23.66 32643 port [tcp/*] succeeded!\n"
Jul  4 15:47:02.767: INFO: stdout: ""
Jul  4 15:47:03.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.23.66 32643'
Jul  4 15:47:03.895: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.23.66 32643\nConnection to 172.31.23.66 32643 port [tcp/*] succeeded!\n"
Jul  4 15:47:03.895: INFO: stdout: ""
Jul  4 15:47:04.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.23.66 32643'
Jul  4 15:47:04.884: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.23.66 32643\nConnection to 172.31.23.66 32643 port [tcp/*] succeeded!\n"
Jul  4 15:47:04.884: INFO: stdout: ""
Jul  4 15:47:05.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-7636 exec execpodlp9b4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.23.66 32643'
Jul  4 15:47:05.894: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.23.66 32643\nConnection to 172.31.23.66 32643 port [tcp/*] succeeded!\n"
Jul  4 15:47:05.894: INFO: stdout: "externalname-service-n5n26"
Jul  4 15:47:05.894: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:47:05.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7636" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:16.216 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":356,"completed":105,"skipped":1912,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:05.923: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-0fbd6d22-8e50-4a0a-87b3-753ae70015dd
STEP: Creating a pod to test consume secrets
Jul  4 15:47:05.945: INFO: Waiting up to 5m0s for pod "pod-secrets-f8021500-9e20-4680-9ccf-5232ffb05c0e" in namespace "secrets-3230" to be "Succeeded or Failed"
Jul  4 15:47:05.948: INFO: Pod "pod-secrets-f8021500-9e20-4680-9ccf-5232ffb05c0e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.058705ms
Jul  4 15:47:07.953: INFO: Pod "pod-secrets-f8021500-9e20-4680-9ccf-5232ffb05c0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008275502s
Jul  4 15:47:09.961: INFO: Pod "pod-secrets-f8021500-9e20-4680-9ccf-5232ffb05c0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015741484s
STEP: Saw pod success
Jul  4 15:47:09.961: INFO: Pod "pod-secrets-f8021500-9e20-4680-9ccf-5232ffb05c0e" satisfied condition "Succeeded or Failed"
Jul  4 15:47:09.963: INFO: Trying to get logs from node 18.216.149.32 pod pod-secrets-f8021500-9e20-4680-9ccf-5232ffb05c0e container secret-volume-test: <nil>
STEP: delete the pod
Jul  4 15:47:09.979: INFO: Waiting for pod pod-secrets-f8021500-9e20-4680-9ccf-5232ffb05c0e to disappear
Jul  4 15:47:09.981: INFO: Pod pod-secrets-f8021500-9e20-4680-9ccf-5232ffb05c0e no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  4 15:47:09.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3230" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":106,"skipped":1921,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:09.987: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not conflict [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:47:10.015: INFO: The status of Pod pod-secrets-52348f06-4a1d-4071-a05e-c73c134054ae is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:47:12.021: INFO: The status of Pod pod-secrets-52348f06-4a1d-4071-a05e-c73c134054ae is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Jul  4 15:47:12.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-551" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":356,"completed":107,"skipped":2002,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:12.054: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:188
Jul  4 15:47:12.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4238" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":356,"completed":108,"skipped":2034,"failed":0}

------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:12.086: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 77.144.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.144.77_udp@PTR;check="$$(dig +tcp +noall +answer +search 77.144.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.144.77_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2959.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2959.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2959.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2959.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 77.144.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.144.77_udp@PTR;check="$$(dig +tcp +noall +answer +search 77.144.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.144.77_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  4 15:47:14.149: INFO: Unable to read wheezy_udp@dns-test-service.dns-2959.svc.cluster.local from pod dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b: the server could not find the requested resource (get pods dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b)
Jul  4 15:47:14.151: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2959.svc.cluster.local from pod dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b: the server could not find the requested resource (get pods dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b)
Jul  4 15:47:14.153: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local from pod dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b: the server could not find the requested resource (get pods dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b)
Jul  4 15:47:14.156: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local from pod dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b: the server could not find the requested resource (get pods dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b)
Jul  4 15:47:14.167: INFO: Unable to read jessie_udp@dns-test-service.dns-2959.svc.cluster.local from pod dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b: the server could not find the requested resource (get pods dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b)
Jul  4 15:47:14.169: INFO: Unable to read jessie_tcp@dns-test-service.dns-2959.svc.cluster.local from pod dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b: the server could not find the requested resource (get pods dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b)
Jul  4 15:47:14.171: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local from pod dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b: the server could not find the requested resource (get pods dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b)
Jul  4 15:47:14.173: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local from pod dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b: the server could not find the requested resource (get pods dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b)
Jul  4 15:47:14.182: INFO: Lookups using dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b failed for: [wheezy_udp@dns-test-service.dns-2959.svc.cluster.local wheezy_tcp@dns-test-service.dns-2959.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local jessie_udp@dns-test-service.dns-2959.svc.cluster.local jessie_tcp@dns-test-service.dns-2959.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2959.svc.cluster.local]

Jul  4 15:47:19.228: INFO: DNS probes using dns-2959/dns-test-77626b75-196a-41d2-97dd-b1bf2eedeb6b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  4 15:47:19.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2959" for this suite.

• [SLOW TEST:7.203 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":356,"completed":109,"skipped":2034,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:19.289: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-0514efa1-4689-40bc-8c81-e58bf3af2652
STEP: Creating secret with name s-test-opt-upd-d05837c6-0942-4be6-be00-f9ee75dba550
STEP: Creating the pod
Jul  4 15:47:19.321: INFO: The status of Pod pod-projected-secrets-5ce1d0f6-0d1f-4bda-b907-e8b96c113e15 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:47:21.328: INFO: The status of Pod pod-projected-secrets-5ce1d0f6-0d1f-4bda-b907-e8b96c113e15 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-0514efa1-4689-40bc-8c81-e58bf3af2652
STEP: Updating secret s-test-opt-upd-d05837c6-0942-4be6-be00-f9ee75dba550
STEP: Creating secret with name s-test-opt-create-94cf77b6-6239-4023-a84b-ecb710371a05
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  4 15:47:23.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7765" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":110,"skipped":2068,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:23.391: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name secret-emptykey-test-9a415a6e-c97a-4e95-acd6-7cceff35af3b
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Jul  4 15:47:23.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6947" for this suite.
•{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":356,"completed":111,"skipped":2079,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:23.414: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Jul  4 15:47:29.686: INFO: 80 pods remaining
Jul  4 15:47:29.686: INFO: 80 pods has nil DeletionTimestamp
Jul  4 15:47:29.686: INFO: 
Jul  4 15:47:30.605: INFO: 71 pods remaining
Jul  4 15:47:30.605: INFO: 70 pods has nil DeletionTimestamp
Jul  4 15:47:30.605: INFO: 
Jul  4 15:47:31.597: INFO: 60 pods remaining
Jul  4 15:47:31.597: INFO: 60 pods has nil DeletionTimestamp
Jul  4 15:47:31.597: INFO: 
Jul  4 15:47:32.570: INFO: 40 pods remaining
Jul  4 15:47:32.570: INFO: 40 pods has nil DeletionTimestamp
Jul  4 15:47:32.570: INFO: 
Jul  4 15:47:33.560: INFO: 31 pods remaining
Jul  4 15:47:33.560: INFO: 30 pods has nil DeletionTimestamp
Jul  4 15:47:33.560: INFO: 
Jul  4 15:47:34.551: INFO: 20 pods remaining
Jul  4 15:47:34.551: INFO: 20 pods has nil DeletionTimestamp
Jul  4 15:47:34.551: INFO: 
STEP: Gathering metrics
Jul  4 15:47:35.565: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  4 15:47:35.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0704 15:47:35.565087      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
STEP: Destroying namespace "gc-9003" for this suite.

• [SLOW TEST:12.163 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":356,"completed":112,"skipped":2150,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:35.577: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1540
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Jul  4 15:47:35.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-3928 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2'
Jul  4 15:47:35.724: INFO: stderr: ""
Jul  4 15:47:35.724: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1544
Jul  4 15:47:35.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-3928 delete pods e2e-test-httpd-pod'
Jul  4 15:47:44.723: INFO: stderr: ""
Jul  4 15:47:44.724: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 15:47:44.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3928" for this suite.

• [SLOW TEST:9.153 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1537
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":356,"completed":113,"skipped":2156,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:44.730: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  4 15:47:50.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9442" for this suite.

• [SLOW TEST:6.060 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":356,"completed":114,"skipped":2210,"failed":0}
SSSSSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:50.790: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Jul  4 15:47:50.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9278" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":115,"skipped":2216,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:50.831: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3467
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3467
I0704 15:47:50.861439      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3467, replica count: 2
I0704 15:47:53.913022      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 15:47:53.913: INFO: Creating new exec pod
Jul  4 15:47:56.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3467 exec execpodpwl6k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jul  4 15:47:57.063: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jul  4 15:47:57.063: INFO: stdout: "externalname-service-sd26q"
Jul  4 15:47:57.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-3467 exec execpodpwl6k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.123.225 80'
Jul  4 15:47:57.190: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.123.225 80\nConnection to 10.43.123.225 80 port [tcp/http] succeeded!\n"
Jul  4 15:47:57.190: INFO: stdout: "externalname-service-sd26q"
Jul  4 15:47:57.190: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:47:57.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3467" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:6.385 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":356,"completed":116,"skipped":2233,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:47:57.217: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1909
[It] should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-1909
Jul  4 15:47:57.250: INFO: Found 0 stateful pods, waiting for 1
Jul  4 15:48:07.259: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  4 15:48:07.279: INFO: Deleting all statefulset in ns statefulset-1909
Jul  4 15:48:07.281: INFO: Scaling statefulset ss to 0
Jul  4 15:48:17.294: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 15:48:17.296: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  4 15:48:17.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1909" for this suite.

• [SLOW TEST:20.097 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":356,"completed":117,"skipped":2257,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:48:17.314: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Jul  4 15:48:17.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 create -f -'
Jul  4 15:48:18.218: INFO: stderr: ""
Jul  4 15:48:18.218: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul  4 15:48:18.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  4 15:48:18.284: INFO: stderr: ""
Jul  4 15:48:18.285: INFO: stdout: "update-demo-nautilus-5x4tb update-demo-nautilus-n7v9h "
Jul  4 15:48:18.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-5x4tb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 15:48:18.337: INFO: stderr: ""
Jul  4 15:48:18.338: INFO: stdout: ""
Jul  4 15:48:18.338: INFO: update-demo-nautilus-5x4tb is created but not running
Jul  4 15:48:23.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  4 15:48:23.399: INFO: stderr: ""
Jul  4 15:48:23.399: INFO: stdout: "update-demo-nautilus-5x4tb update-demo-nautilus-n7v9h "
Jul  4 15:48:23.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-5x4tb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 15:48:23.452: INFO: stderr: ""
Jul  4 15:48:23.452: INFO: stdout: ""
Jul  4 15:48:23.452: INFO: update-demo-nautilus-5x4tb is created but not running
Jul  4 15:48:28.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  4 15:48:28.517: INFO: stderr: ""
Jul  4 15:48:28.517: INFO: stdout: "update-demo-nautilus-5x4tb update-demo-nautilus-n7v9h "
Jul  4 15:48:28.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-5x4tb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 15:48:28.572: INFO: stderr: ""
Jul  4 15:48:28.572: INFO: stdout: "true"
Jul  4 15:48:28.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-5x4tb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  4 15:48:28.626: INFO: stderr: ""
Jul  4 15:48:28.626: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  4 15:48:28.626: INFO: validating pod update-demo-nautilus-5x4tb
Jul  4 15:48:28.630: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  4 15:48:28.630: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  4 15:48:28.630: INFO: update-demo-nautilus-5x4tb is verified up and running
Jul  4 15:48:28.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-n7v9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 15:48:28.683: INFO: stderr: ""
Jul  4 15:48:28.683: INFO: stdout: "true"
Jul  4 15:48:28.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-n7v9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  4 15:48:28.735: INFO: stderr: ""
Jul  4 15:48:28.735: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  4 15:48:28.735: INFO: validating pod update-demo-nautilus-n7v9h
Jul  4 15:48:28.739: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  4 15:48:28.739: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  4 15:48:28.739: INFO: update-demo-nautilus-n7v9h is verified up and running
STEP: scaling down the replication controller
Jul  4 15:48:28.741: INFO: scanned /root for discovery docs: <nil>
Jul  4 15:48:28.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Jul  4 15:48:29.814: INFO: stderr: ""
Jul  4 15:48:29.814: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul  4 15:48:29.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  4 15:48:29.873: INFO: stderr: ""
Jul  4 15:48:29.873: INFO: stdout: "update-demo-nautilus-n7v9h "
Jul  4 15:48:29.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-n7v9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 15:48:29.926: INFO: stderr: ""
Jul  4 15:48:29.926: INFO: stdout: "true"
Jul  4 15:48:29.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-n7v9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  4 15:48:29.978: INFO: stderr: ""
Jul  4 15:48:29.978: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  4 15:48:29.978: INFO: validating pod update-demo-nautilus-n7v9h
Jul  4 15:48:29.981: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  4 15:48:29.981: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  4 15:48:29.981: INFO: update-demo-nautilus-n7v9h is verified up and running
STEP: scaling up the replication controller
Jul  4 15:48:29.982: INFO: scanned /root for discovery docs: <nil>
Jul  4 15:48:29.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Jul  4 15:48:31.051: INFO: stderr: ""
Jul  4 15:48:31.051: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul  4 15:48:31.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  4 15:48:31.114: INFO: stderr: ""
Jul  4 15:48:31.114: INFO: stdout: "update-demo-nautilus-fljx2 update-demo-nautilus-n7v9h "
Jul  4 15:48:31.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-fljx2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 15:48:31.169: INFO: stderr: ""
Jul  4 15:48:31.169: INFO: stdout: ""
Jul  4 15:48:31.169: INFO: update-demo-nautilus-fljx2 is created but not running
Jul  4 15:48:36.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  4 15:48:36.230: INFO: stderr: ""
Jul  4 15:48:36.230: INFO: stdout: "update-demo-nautilus-fljx2 update-demo-nautilus-n7v9h "
Jul  4 15:48:36.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-fljx2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 15:48:36.286: INFO: stderr: ""
Jul  4 15:48:36.286: INFO: stdout: "true"
Jul  4 15:48:36.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-fljx2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  4 15:48:36.340: INFO: stderr: ""
Jul  4 15:48:36.341: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  4 15:48:36.341: INFO: validating pod update-demo-nautilus-fljx2
Jul  4 15:48:36.344: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  4 15:48:36.344: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  4 15:48:36.344: INFO: update-demo-nautilus-fljx2 is verified up and running
Jul  4 15:48:36.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-n7v9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 15:48:36.401: INFO: stderr: ""
Jul  4 15:48:36.401: INFO: stdout: "true"
Jul  4 15:48:36.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods update-demo-nautilus-n7v9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  4 15:48:36.456: INFO: stderr: ""
Jul  4 15:48:36.456: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  4 15:48:36.456: INFO: validating pod update-demo-nautilus-n7v9h
Jul  4 15:48:36.459: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  4 15:48:36.459: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  4 15:48:36.459: INFO: update-demo-nautilus-n7v9h is verified up and running
STEP: using delete to clean up resources
Jul  4 15:48:36.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 delete --grace-period=0 --force -f -'
Jul  4 15:48:36.517: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  4 15:48:36.517: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul  4 15:48:36.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get rc,svc -l name=update-demo --no-headers'
Jul  4 15:48:36.579: INFO: stderr: "No resources found in kubectl-2590 namespace.\n"
Jul  4 15:48:36.579: INFO: stdout: ""
Jul  4 15:48:36.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2590 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul  4 15:48:36.638: INFO: stderr: ""
Jul  4 15:48:36.639: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 15:48:36.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2590" for this suite.

• [SLOW TEST:19.334 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should scale a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":356,"completed":118,"skipped":2258,"failed":0}
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:48:36.648: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  4 15:48:36.673: INFO: Waiting up to 5m0s for pod "downward-api-a2cdb92a-b401-4f20-bad2-b627461aec48" in namespace "downward-api-9483" to be "Succeeded or Failed"
Jul  4 15:48:36.675: INFO: Pod "downward-api-a2cdb92a-b401-4f20-bad2-b627461aec48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113461ms
Jul  4 15:48:38.679: INFO: Pod "downward-api-a2cdb92a-b401-4f20-bad2-b627461aec48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006559817s
Jul  4 15:48:40.684: INFO: Pod "downward-api-a2cdb92a-b401-4f20-bad2-b627461aec48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011491038s
STEP: Saw pod success
Jul  4 15:48:40.684: INFO: Pod "downward-api-a2cdb92a-b401-4f20-bad2-b627461aec48" satisfied condition "Succeeded or Failed"
Jul  4 15:48:40.686: INFO: Trying to get logs from node 18.224.151.13 pod downward-api-a2cdb92a-b401-4f20-bad2-b627461aec48 container dapi-container: <nil>
STEP: delete the pod
Jul  4 15:48:40.709: INFO: Waiting for pod downward-api-a2cdb92a-b401-4f20-bad2-b627461aec48 to disappear
Jul  4 15:48:40.711: INFO: Pod downward-api-a2cdb92a-b401-4f20-bad2-b627461aec48 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  4 15:48:40.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9483" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":356,"completed":119,"skipped":2259,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:48:40.717: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-ab8b95ff-dcd9-4f97-926f-5804580e31e4
STEP: Creating configMap with name cm-test-opt-upd-337965f2-a7fd-40bf-899e-ae5d64b140d1
STEP: Creating the pod
Jul  4 15:48:40.747: INFO: The status of Pod pod-projected-configmaps-d27c915f-afff-4b44-a207-701bd0047d3a is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:48:42.755: INFO: The status of Pod pod-projected-configmaps-d27c915f-afff-4b44-a207-701bd0047d3a is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-ab8b95ff-dcd9-4f97-926f-5804580e31e4
STEP: Updating configmap cm-test-opt-upd-337965f2-a7fd-40bf-899e-ae5d64b140d1
STEP: Creating configMap with name cm-test-opt-create-72852955-1f4c-4158-b0a7-428cd4bdcb23
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  4 15:48:46.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7633" for this suite.

• [SLOW TEST:6.112 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":120,"skipped":2313,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:48:46.829: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:48:46.843: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-9071
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:188
Jul  4 15:48:52.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-1099" for this suite.
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  4 15:48:52.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9071" for this suite.

• [SLOW TEST:6.089 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":356,"completed":121,"skipped":2335,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:48:52.919: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
STEP: mirroring a new custom Endpoint
Jul  4 15:48:52.945: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
Jul  4 15:48:54.954: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint
Jul  4 15:48:56.971: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:188
Jul  4 15:48:58.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-7254" for this suite.

• [SLOW TEST:6.065 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":356,"completed":122,"skipped":2356,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:48:58.984: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:48:59.572: INFO: Checking APIGroup: apiregistration.k8s.io
Jul  4 15:48:59.573: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Jul  4 15:48:59.573: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Jul  4 15:48:59.573: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Jul  4 15:48:59.573: INFO: Checking APIGroup: apps
Jul  4 15:48:59.574: INFO: PreferredVersion.GroupVersion: apps/v1
Jul  4 15:48:59.574: INFO: Versions found [{apps/v1 v1}]
Jul  4 15:48:59.574: INFO: apps/v1 matches apps/v1
Jul  4 15:48:59.574: INFO: Checking APIGroup: events.k8s.io
Jul  4 15:48:59.575: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Jul  4 15:48:59.575: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Jul  4 15:48:59.575: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Jul  4 15:48:59.575: INFO: Checking APIGroup: authentication.k8s.io
Jul  4 15:48:59.576: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Jul  4 15:48:59.576: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Jul  4 15:48:59.576: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Jul  4 15:48:59.576: INFO: Checking APIGroup: authorization.k8s.io
Jul  4 15:48:59.577: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Jul  4 15:48:59.577: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Jul  4 15:48:59.577: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Jul  4 15:48:59.577: INFO: Checking APIGroup: autoscaling
Jul  4 15:48:59.577: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Jul  4 15:48:59.577: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Jul  4 15:48:59.577: INFO: autoscaling/v2 matches autoscaling/v2
Jul  4 15:48:59.577: INFO: Checking APIGroup: batch
Jul  4 15:48:59.578: INFO: PreferredVersion.GroupVersion: batch/v1
Jul  4 15:48:59.578: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Jul  4 15:48:59.578: INFO: batch/v1 matches batch/v1
Jul  4 15:48:59.578: INFO: Checking APIGroup: certificates.k8s.io
Jul  4 15:48:59.579: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Jul  4 15:48:59.579: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Jul  4 15:48:59.579: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Jul  4 15:48:59.579: INFO: Checking APIGroup: networking.k8s.io
Jul  4 15:48:59.580: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Jul  4 15:48:59.580: INFO: Versions found [{networking.k8s.io/v1 v1}]
Jul  4 15:48:59.580: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Jul  4 15:48:59.580: INFO: Checking APIGroup: policy
Jul  4 15:48:59.580: INFO: PreferredVersion.GroupVersion: policy/v1
Jul  4 15:48:59.580: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
Jul  4 15:48:59.580: INFO: policy/v1 matches policy/v1
Jul  4 15:48:59.580: INFO: Checking APIGroup: rbac.authorization.k8s.io
Jul  4 15:48:59.581: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Jul  4 15:48:59.581: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Jul  4 15:48:59.581: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Jul  4 15:48:59.581: INFO: Checking APIGroup: storage.k8s.io
Jul  4 15:48:59.582: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Jul  4 15:48:59.582: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Jul  4 15:48:59.582: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Jul  4 15:48:59.582: INFO: Checking APIGroup: admissionregistration.k8s.io
Jul  4 15:48:59.583: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Jul  4 15:48:59.583: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Jul  4 15:48:59.583: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Jul  4 15:48:59.583: INFO: Checking APIGroup: apiextensions.k8s.io
Jul  4 15:48:59.584: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Jul  4 15:48:59.584: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Jul  4 15:48:59.584: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Jul  4 15:48:59.584: INFO: Checking APIGroup: scheduling.k8s.io
Jul  4 15:48:59.584: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Jul  4 15:48:59.584: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Jul  4 15:48:59.584: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Jul  4 15:48:59.584: INFO: Checking APIGroup: coordination.k8s.io
Jul  4 15:48:59.585: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Jul  4 15:48:59.585: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Jul  4 15:48:59.585: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Jul  4 15:48:59.585: INFO: Checking APIGroup: node.k8s.io
Jul  4 15:48:59.586: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Jul  4 15:48:59.586: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
Jul  4 15:48:59.586: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Jul  4 15:48:59.586: INFO: Checking APIGroup: discovery.k8s.io
Jul  4 15:48:59.587: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Jul  4 15:48:59.587: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
Jul  4 15:48:59.587: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Jul  4 15:48:59.587: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Jul  4 15:48:59.588: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Jul  4 15:48:59.588: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Jul  4 15:48:59.588: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Jul  4 15:48:59.588: INFO: Checking APIGroup: crd.projectcalico.org
Jul  4 15:48:59.588: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Jul  4 15:48:59.588: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Jul  4 15:48:59.588: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Jul  4 15:48:59.588: INFO: Checking APIGroup: metrics.k8s.io
Jul  4 15:48:59.589: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Jul  4 15:48:59.589: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Jul  4 15:48:59.589: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:188
Jul  4 15:48:59.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-4341" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":356,"completed":123,"skipped":2366,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:48:59.596: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Jul  4 15:48:59.618: INFO: The status of Pod annotationupdate887c335f-ec9e-4eae-a233-6ca7e0009e3b is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:49:01.624: INFO: The status of Pod annotationupdate887c335f-ec9e-4eae-a233-6ca7e0009e3b is Running (Ready = true)
Jul  4 15:49:02.154: INFO: Successfully updated pod "annotationupdate887c335f-ec9e-4eae-a233-6ca7e0009e3b"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 15:49:04.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2311" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":124,"skipped":2382,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:49:04.179: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jul  4 15:49:08.218: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  4 15:49:08.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-322" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":125,"skipped":2415,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:49:08.232: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Jul  4 15:49:08.247: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  4 15:49:12.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3777" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":356,"completed":126,"skipped":2425,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:49:12.086: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Jul  4 15:49:52.271: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0704 15:49:52.271671      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul  4 15:49:52.271: INFO: Deleting pod "simpletest.rc-26r86" in namespace "gc-2521"
Jul  4 15:49:52.289: INFO: Deleting pod "simpletest.rc-2bchv" in namespace "gc-2521"
Jul  4 15:49:52.301: INFO: Deleting pod "simpletest.rc-2dbw6" in namespace "gc-2521"
Jul  4 15:49:52.311: INFO: Deleting pod "simpletest.rc-2xzlc" in namespace "gc-2521"
Jul  4 15:49:52.342: INFO: Deleting pod "simpletest.rc-4577v" in namespace "gc-2521"
Jul  4 15:49:52.372: INFO: Deleting pod "simpletest.rc-48xb5" in namespace "gc-2521"
Jul  4 15:49:52.394: INFO: Deleting pod "simpletest.rc-4x2c4" in namespace "gc-2521"
Jul  4 15:49:52.408: INFO: Deleting pod "simpletest.rc-55q9w" in namespace "gc-2521"
Jul  4 15:49:52.426: INFO: Deleting pod "simpletest.rc-5bxsv" in namespace "gc-2521"
Jul  4 15:49:52.440: INFO: Deleting pod "simpletest.rc-68csq" in namespace "gc-2521"
Jul  4 15:49:52.463: INFO: Deleting pod "simpletest.rc-6ch67" in namespace "gc-2521"
Jul  4 15:49:52.492: INFO: Deleting pod "simpletest.rc-6dbcz" in namespace "gc-2521"
Jul  4 15:49:52.536: INFO: Deleting pod "simpletest.rc-6knp7" in namespace "gc-2521"
Jul  4 15:49:52.592: INFO: Deleting pod "simpletest.rc-6x6lt" in namespace "gc-2521"
Jul  4 15:49:52.603: INFO: Deleting pod "simpletest.rc-6xphr" in namespace "gc-2521"
Jul  4 15:49:52.632: INFO: Deleting pod "simpletest.rc-75lrv" in namespace "gc-2521"
Jul  4 15:49:52.653: INFO: Deleting pod "simpletest.rc-79pv5" in namespace "gc-2521"
Jul  4 15:49:52.682: INFO: Deleting pod "simpletest.rc-79qch" in namespace "gc-2521"
Jul  4 15:49:52.708: INFO: Deleting pod "simpletest.rc-7fjb8" in namespace "gc-2521"
Jul  4 15:49:52.728: INFO: Deleting pod "simpletest.rc-7zkmt" in namespace "gc-2521"
Jul  4 15:49:52.743: INFO: Deleting pod "simpletest.rc-8kf69" in namespace "gc-2521"
Jul  4 15:49:52.767: INFO: Deleting pod "simpletest.rc-8kk6h" in namespace "gc-2521"
Jul  4 15:49:52.783: INFO: Deleting pod "simpletest.rc-8r2l6" in namespace "gc-2521"
Jul  4 15:49:52.816: INFO: Deleting pod "simpletest.rc-8v69g" in namespace "gc-2521"
Jul  4 15:49:52.828: INFO: Deleting pod "simpletest.rc-8xt8b" in namespace "gc-2521"
Jul  4 15:49:52.836: INFO: Deleting pod "simpletest.rc-947v7" in namespace "gc-2521"
Jul  4 15:49:52.855: INFO: Deleting pod "simpletest.rc-b4pxb" in namespace "gc-2521"
Jul  4 15:49:52.937: INFO: Deleting pod "simpletest.rc-bb87g" in namespace "gc-2521"
Jul  4 15:49:52.954: INFO: Deleting pod "simpletest.rc-bplvl" in namespace "gc-2521"
Jul  4 15:49:52.973: INFO: Deleting pod "simpletest.rc-bz7kb" in namespace "gc-2521"
Jul  4 15:49:52.989: INFO: Deleting pod "simpletest.rc-ctprc" in namespace "gc-2521"
Jul  4 15:49:53.004: INFO: Deleting pod "simpletest.rc-dtjqm" in namespace "gc-2521"
Jul  4 15:49:53.012: INFO: Deleting pod "simpletest.rc-f6w6h" in namespace "gc-2521"
Jul  4 15:49:53.024: INFO: Deleting pod "simpletest.rc-f7lpn" in namespace "gc-2521"
Jul  4 15:49:53.035: INFO: Deleting pod "simpletest.rc-fmpdd" in namespace "gc-2521"
Jul  4 15:49:53.060: INFO: Deleting pod "simpletest.rc-fwz7h" in namespace "gc-2521"
Jul  4 15:49:53.073: INFO: Deleting pod "simpletest.rc-g6k5c" in namespace "gc-2521"
Jul  4 15:49:53.133: INFO: Deleting pod "simpletest.rc-g74qj" in namespace "gc-2521"
Jul  4 15:49:53.153: INFO: Deleting pod "simpletest.rc-g7k98" in namespace "gc-2521"
Jul  4 15:49:53.167: INFO: Deleting pod "simpletest.rc-g8psk" in namespace "gc-2521"
Jul  4 15:49:53.199: INFO: Deleting pod "simpletest.rc-grmcr" in namespace "gc-2521"
Jul  4 15:49:53.215: INFO: Deleting pod "simpletest.rc-hftct" in namespace "gc-2521"
Jul  4 15:49:53.273: INFO: Deleting pod "simpletest.rc-j52ms" in namespace "gc-2521"
Jul  4 15:49:53.301: INFO: Deleting pod "simpletest.rc-jnmbc" in namespace "gc-2521"
Jul  4 15:49:53.324: INFO: Deleting pod "simpletest.rc-k5nmk" in namespace "gc-2521"
Jul  4 15:49:53.384: INFO: Deleting pod "simpletest.rc-kd8kx" in namespace "gc-2521"
Jul  4 15:49:53.397: INFO: Deleting pod "simpletest.rc-kjhjk" in namespace "gc-2521"
Jul  4 15:49:53.408: INFO: Deleting pod "simpletest.rc-lkccd" in namespace "gc-2521"
Jul  4 15:49:53.419: INFO: Deleting pod "simpletest.rc-lnbwt" in namespace "gc-2521"
Jul  4 15:49:53.468: INFO: Deleting pod "simpletest.rc-lqcmw" in namespace "gc-2521"
Jul  4 15:49:53.508: INFO: Deleting pod "simpletest.rc-lx76v" in namespace "gc-2521"
Jul  4 15:49:53.536: INFO: Deleting pod "simpletest.rc-mbgsd" in namespace "gc-2521"
Jul  4 15:49:53.551: INFO: Deleting pod "simpletest.rc-mlvrt" in namespace "gc-2521"
Jul  4 15:49:53.564: INFO: Deleting pod "simpletest.rc-mmb55" in namespace "gc-2521"
Jul  4 15:49:53.577: INFO: Deleting pod "simpletest.rc-n7jzx" in namespace "gc-2521"
Jul  4 15:49:53.630: INFO: Deleting pod "simpletest.rc-nqrpn" in namespace "gc-2521"
Jul  4 15:49:53.661: INFO: Deleting pod "simpletest.rc-prn42" in namespace "gc-2521"
Jul  4 15:49:53.697: INFO: Deleting pod "simpletest.rc-pv64q" in namespace "gc-2521"
Jul  4 15:49:53.739: INFO: Deleting pod "simpletest.rc-q6nbm" in namespace "gc-2521"
Jul  4 15:49:53.783: INFO: Deleting pod "simpletest.rc-qbpnp" in namespace "gc-2521"
Jul  4 15:49:53.802: INFO: Deleting pod "simpletest.rc-qdpw9" in namespace "gc-2521"
Jul  4 15:49:53.834: INFO: Deleting pod "simpletest.rc-s4fqc" in namespace "gc-2521"
Jul  4 15:49:53.858: INFO: Deleting pod "simpletest.rc-s7qxp" in namespace "gc-2521"
Jul  4 15:49:53.883: INFO: Deleting pod "simpletest.rc-s7z6t" in namespace "gc-2521"
Jul  4 15:49:53.930: INFO: Deleting pod "simpletest.rc-sbm5k" in namespace "gc-2521"
Jul  4 15:49:53.967: INFO: Deleting pod "simpletest.rc-scblp" in namespace "gc-2521"
Jul  4 15:49:54.009: INFO: Deleting pod "simpletest.rc-snnh5" in namespace "gc-2521"
Jul  4 15:49:54.027: INFO: Deleting pod "simpletest.rc-srbtd" in namespace "gc-2521"
Jul  4 15:49:54.070: INFO: Deleting pod "simpletest.rc-srt7z" in namespace "gc-2521"
Jul  4 15:49:54.086: INFO: Deleting pod "simpletest.rc-swz42" in namespace "gc-2521"
Jul  4 15:49:54.159: INFO: Deleting pod "simpletest.rc-t6clh" in namespace "gc-2521"
Jul  4 15:49:54.171: INFO: Deleting pod "simpletest.rc-t9cr6" in namespace "gc-2521"
Jul  4 15:49:54.201: INFO: Deleting pod "simpletest.rc-tflnq" in namespace "gc-2521"
Jul  4 15:49:54.245: INFO: Deleting pod "simpletest.rc-tv7gs" in namespace "gc-2521"
Jul  4 15:49:54.264: INFO: Deleting pod "simpletest.rc-tvw9f" in namespace "gc-2521"
Jul  4 15:49:54.286: INFO: Deleting pod "simpletest.rc-txtxk" in namespace "gc-2521"
Jul  4 15:49:54.321: INFO: Deleting pod "simpletest.rc-vfl2p" in namespace "gc-2521"
Jul  4 15:49:54.342: INFO: Deleting pod "simpletest.rc-vpnxd" in namespace "gc-2521"
Jul  4 15:49:54.353: INFO: Deleting pod "simpletest.rc-vrcwd" in namespace "gc-2521"
Jul  4 15:49:54.375: INFO: Deleting pod "simpletest.rc-vsfq5" in namespace "gc-2521"
Jul  4 15:49:54.401: INFO: Deleting pod "simpletest.rc-vv28x" in namespace "gc-2521"
Jul  4 15:49:54.417: INFO: Deleting pod "simpletest.rc-vwfrs" in namespace "gc-2521"
Jul  4 15:49:54.435: INFO: Deleting pod "simpletest.rc-vxcbt" in namespace "gc-2521"
Jul  4 15:49:54.461: INFO: Deleting pod "simpletest.rc-vxhds" in namespace "gc-2521"
Jul  4 15:49:54.474: INFO: Deleting pod "simpletest.rc-wndm2" in namespace "gc-2521"
Jul  4 15:49:54.489: INFO: Deleting pod "simpletest.rc-wt7gs" in namespace "gc-2521"
Jul  4 15:49:54.520: INFO: Deleting pod "simpletest.rc-wthqq" in namespace "gc-2521"
Jul  4 15:49:54.536: INFO: Deleting pod "simpletest.rc-wx2wq" in namespace "gc-2521"
Jul  4 15:49:54.572: INFO: Deleting pod "simpletest.rc-x6mn8" in namespace "gc-2521"
Jul  4 15:49:54.597: INFO: Deleting pod "simpletest.rc-xcjcc" in namespace "gc-2521"
Jul  4 15:49:54.646: INFO: Deleting pod "simpletest.rc-xjdn8" in namespace "gc-2521"
Jul  4 15:49:54.676: INFO: Deleting pod "simpletest.rc-xlb9t" in namespace "gc-2521"
Jul  4 15:49:54.703: INFO: Deleting pod "simpletest.rc-xs5x9" in namespace "gc-2521"
Jul  4 15:49:54.719: INFO: Deleting pod "simpletest.rc-z2w77" in namespace "gc-2521"
Jul  4 15:49:54.733: INFO: Deleting pod "simpletest.rc-z6xlc" in namespace "gc-2521"
Jul  4 15:49:54.752: INFO: Deleting pod "simpletest.rc-z8bct" in namespace "gc-2521"
Jul  4 15:49:54.764: INFO: Deleting pod "simpletest.rc-zdkcz" in namespace "gc-2521"
Jul  4 15:49:54.793: INFO: Deleting pod "simpletest.rc-zgtzt" in namespace "gc-2521"
Jul  4 15:49:54.832: INFO: Deleting pod "simpletest.rc-zq6c9" in namespace "gc-2521"
Jul  4 15:49:54.868: INFO: Deleting pod "simpletest.rc-ztmx2" in namespace "gc-2521"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  4 15:49:54.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2521" for this suite.

• [SLOW TEST:42.886 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":356,"completed":127,"skipped":2472,"failed":0}
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:49:54.973: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  4 15:49:55.062: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Jul  4 15:49:55.066: INFO: starting watch
STEP: patching
STEP: updating
Jul  4 15:49:55.104: INFO: waiting for watch events with expected annotations
Jul  4 15:49:55.104: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  4 15:49:55.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4586" for this suite.
•{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":356,"completed":128,"skipped":2472,"failed":0}

------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:49:55.162: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  4 15:55:01.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6630" for this suite.

• [SLOW TEST:306.137 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":356,"completed":129,"skipped":2472,"failed":0}
SSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:55:01.299: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Jul  4 15:55:01.314: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  4 15:56:01.341: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:56:01.346: INFO: Starting informer...
STEP: Starting pod...
Jul  4 15:56:01.558: INFO: Pod is running on 18.216.149.32. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Jul  4 15:56:01.571: INFO: Pod wasn't evicted. Proceeding
Jul  4 15:56:01.571: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Jul  4 15:57:16.584: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:188
Jul  4 15:57:16.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-5130" for this suite.

• [SLOW TEST:135.297 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":356,"completed":130,"skipped":2480,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:57:16.596: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 15:57:17.462: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 15:57:20.482: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:57:20.486: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7629-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 15:57:23.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4599" for this suite.
STEP: Destroying namespace "webhook-4599-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:7.093 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":356,"completed":131,"skipped":2497,"failed":0}
SS
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:57:23.689: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
Jul  4 15:57:23.721: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:57:25.725: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.20.100 on the node which pod1 resides and expect scheduled
Jul  4 15:57:25.731: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:57:27.740: INFO: The status of Pod pod2 is Running (Ready = false)
Jul  4 15:57:29.737: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.20.100 but use UDP protocol on the node which pod2 resides
Jul  4 15:57:29.745: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:57:31.753: INFO: The status of Pod pod3 is Running (Ready = true)
Jul  4 15:57:31.761: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:57:33.766: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
Jul  4 15:57:33.768: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.20.100 http://127.0.0.1:54323/hostname] Namespace:hostport-2938 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:57:33.768: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:57:33.768: INFO: ExecWithOptions: Clientset creation
Jul  4 15:57:33.768: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-2938/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.20.100+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.20.100, port: 54323
Jul  4 15:57:33.851: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.20.100:54323/hostname] Namespace:hostport-2938 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:57:33.851: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:57:33.852: INFO: ExecWithOptions: Clientset creation
Jul  4 15:57:33.852: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-2938/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.20.100%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.20.100, port: 54323 UDP
Jul  4 15:57:33.926: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 172.31.20.100 54323] Namespace:hostport-2938 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:57:33.927: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:57:33.927: INFO: ExecWithOptions: Clientset creation
Jul  4 15:57:33.927: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/hostport-2938/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=nc+-vuz+-w+5+172.31.20.100+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:188
Jul  4 15:57:39.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-2938" for this suite.

• [SLOW TEST:15.323 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":356,"completed":132,"skipped":2499,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:57:39.013: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9900.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9900.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  4 15:57:41.053: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local from pod dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488: the server could not find the requested resource (get pods dns-test-726e04d2-f319-420e-9435-914159950488)
Jul  4 15:57:41.056: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local from pod dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488: the server could not find the requested resource (get pods dns-test-726e04d2-f319-420e-9435-914159950488)
Jul  4 15:57:41.058: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9900.svc.cluster.local from pod dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488: the server could not find the requested resource (get pods dns-test-726e04d2-f319-420e-9435-914159950488)
Jul  4 15:57:41.060: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9900.svc.cluster.local from pod dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488: the server could not find the requested resource (get pods dns-test-726e04d2-f319-420e-9435-914159950488)
Jul  4 15:57:41.062: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local from pod dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488: the server could not find the requested resource (get pods dns-test-726e04d2-f319-420e-9435-914159950488)
Jul  4 15:57:41.064: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local from pod dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488: the server could not find the requested resource (get pods dns-test-726e04d2-f319-420e-9435-914159950488)
Jul  4 15:57:41.066: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9900.svc.cluster.local from pod dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488: the server could not find the requested resource (get pods dns-test-726e04d2-f319-420e-9435-914159950488)
Jul  4 15:57:41.068: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9900.svc.cluster.local from pod dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488: the server could not find the requested resource (get pods dns-test-726e04d2-f319-420e-9435-914159950488)
Jul  4 15:57:41.068: INFO: Lookups using dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9900.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9900.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9900.svc.cluster.local jessie_udp@dns-test-service-2.dns-9900.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9900.svc.cluster.local]

Jul  4 15:57:46.088: INFO: DNS probes using dns-9900/dns-test-726e04d2-f319-420e-9435-914159950488 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  4 15:57:46.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9900" for this suite.

• [SLOW TEST:7.105 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":356,"completed":133,"skipped":2594,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:57:46.119: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 15:57:46.140: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2b6fea0-2848-4f0f-9599-c7ea3b2041de" in namespace "projected-7300" to be "Succeeded or Failed"
Jul  4 15:57:46.142: INFO: Pod "downwardapi-volume-f2b6fea0-2848-4f0f-9599-c7ea3b2041de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.524412ms
Jul  4 15:57:48.147: INFO: Pod "downwardapi-volume-f2b6fea0-2848-4f0f-9599-c7ea3b2041de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00707523s
Jul  4 15:57:50.161: INFO: Pod "downwardapi-volume-f2b6fea0-2848-4f0f-9599-c7ea3b2041de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021157109s
STEP: Saw pod success
Jul  4 15:57:50.161: INFO: Pod "downwardapi-volume-f2b6fea0-2848-4f0f-9599-c7ea3b2041de" satisfied condition "Succeeded or Failed"
Jul  4 15:57:50.163: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-f2b6fea0-2848-4f0f-9599-c7ea3b2041de container client-container: <nil>
STEP: delete the pod
Jul  4 15:57:50.191: INFO: Waiting for pod downwardapi-volume-f2b6fea0-2848-4f0f-9599-c7ea3b2041de to disappear
Jul  4 15:57:50.193: INFO: Pod downwardapi-volume-f2b6fea0-2848-4f0f-9599-c7ea3b2041de no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 15:57:50.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7300" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":134,"skipped":2596,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:57:50.201: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service nodeport-service with the type=NodePort in namespace services-5144
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5144
STEP: creating replication controller externalsvc in namespace services-5144
I0704 15:57:50.244817      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5144, replica count: 2
I0704 15:57:53.295640      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Jul  4 15:57:53.317: INFO: Creating new exec pod
Jul  4 15:57:55.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-5144 exec execpodpnh47 -- /bin/sh -x -c nslookup nodeport-service.services-5144.svc.cluster.local'
Jul  4 15:57:55.486: INFO: stderr: "+ nslookup nodeport-service.services-5144.svc.cluster.local\n"
Jul  4 15:57:55.486: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nnodeport-service.services-5144.svc.cluster.local\tcanonical name = externalsvc.services-5144.svc.cluster.local.\nName:\texternalsvc.services-5144.svc.cluster.local\nAddress: 10.43.94.106\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5144, will wait for the garbage collector to delete the pods
Jul  4 15:57:55.544: INFO: Deleting ReplicationController externalsvc took: 3.852474ms
Jul  4 15:57:55.645: INFO: Terminating ReplicationController externalsvc pods took: 100.766749ms
Jul  4 15:57:57.759: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 15:57:57.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5144" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:7.578 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":356,"completed":135,"skipped":2622,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:57:57.779: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
Jul  4 15:57:57.803: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  4 15:57:57.803: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  4 15:57:57.807: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  4 15:57:57.807: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  4 15:57:57.820: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  4 15:57:57.820: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  4 15:57:57.831: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  4 15:57:57.831: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  4 15:57:59.020: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jul  4 15:57:59.020: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jul  4 15:57:59.099: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
Jul  4 15:57:59.109: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
Jul  4 15:57:59.110: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0
Jul  4 15:57:59.110: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0
Jul  4 15:57:59.110: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0
Jul  4 15:57:59.110: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0
Jul  4 15:57:59.110: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0
Jul  4 15:57:59.110: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0
Jul  4 15:57:59.110: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0
Jul  4 15:57:59.110: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 0
Jul  4 15:57:59.111: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:57:59.111: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:57:59.111: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:57:59.111: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:57:59.111: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:57:59.111: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:57:59.116: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:57:59.116: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:57:59.129: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:57:59.129: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:57:59.135: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:57:59.135: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:57:59.145: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:57:59.145: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:58:00.761: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:58:00.761: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:58:00.770: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
STEP: listing Deployments
Jul  4 15:58:00.773: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
Jul  4 15:58:00.783: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
Jul  4 15:58:00.790: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  4 15:58:00.790: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  4 15:58:00.820: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  4 15:58:00.834: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  4 15:58:00.838: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  4 15:58:02.067: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jul  4 15:58:02.169: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Jul  4 15:58:02.180: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jul  4 15:58:02.197: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jul  4 15:58:03.104: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
Jul  4 15:58:03.123: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:58:03.123: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:58:03.123: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:58:03.123: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:58:03.123: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 1
Jul  4 15:58:03.124: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:58:03.124: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 3
Jul  4 15:58:03.124: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:58:03.124: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 2
Jul  4 15:58:03.124: INFO: observed Deployment test-deployment in namespace deployment-235 with ReadyReplicas 3
STEP: deleting the Deployment
Jul  4 15:58:03.129: INFO: observed event type MODIFIED
Jul  4 15:58:03.129: INFO: observed event type MODIFIED
Jul  4 15:58:03.129: INFO: observed event type MODIFIED
Jul  4 15:58:03.129: INFO: observed event type MODIFIED
Jul  4 15:58:03.129: INFO: observed event type MODIFIED
Jul  4 15:58:03.129: INFO: observed event type MODIFIED
Jul  4 15:58:03.129: INFO: observed event type MODIFIED
Jul  4 15:58:03.130: INFO: observed event type MODIFIED
Jul  4 15:58:03.130: INFO: observed event type MODIFIED
Jul  4 15:58:03.130: INFO: observed event type MODIFIED
Jul  4 15:58:03.130: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  4 15:58:03.131: INFO: Log out all the ReplicaSets if there is no deployment created
Jul  4 15:58:03.134: INFO: ReplicaSet "test-deployment-6b48c869b6":
&ReplicaSet{ObjectMeta:{test-deployment-6b48c869b6  deployment-235  bd156679-a5d8-4f8d-8fa2-74e5abca2a35 16578 3 2022-07-04 15:57:57 +0000 UTC <nil> <nil> map[pod-template-hash:6b48c869b6 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 270c656b-d801-472b-a42c-b82dd08320a7 0xc00269ac07 0xc00269ac08}] []  [{kube-controller-manager Update apps/v1 2022-07-04 15:57:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"270c656b-d801-472b-a42c-b82dd08320a7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:58:00 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6b48c869b6,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6b48c869b6 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00269ac90 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Jul  4 15:58:03.144: INFO: ReplicaSet "test-deployment-74c6dd549b":
&ReplicaSet{ObjectMeta:{test-deployment-74c6dd549b  deployment-235  5b25982b-7c08-42e0-b3f2-b281d64b564b 16676 2 2022-07-04 15:58:00 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 270c656b-d801-472b-a42c-b82dd08320a7 0xc00269acf7 0xc00269acf8}] []  [{kube-controller-manager Update apps/v1 2022-07-04 15:58:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"270c656b-d801-472b-a42c-b82dd08320a7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:58:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 74c6dd549b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00269ad80 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Jul  4 15:58:03.148: INFO: pod: "test-deployment-74c6dd549b-jq79j":
&Pod{ObjectMeta:{test-deployment-74c6dd549b-jq79j test-deployment-74c6dd549b- deployment-235  46240188-ab39-4be3-8a6e-ba93c760e005 16675 0 2022-07-04 15:58:02 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[cni.projectcalico.org/containerID:9524ed109a8327d06a0df0592b3d855ff95f9f5473ec052783237ff6169b2184 cni.projectcalico.org/podIP:10.42.2.188/32 cni.projectcalico.org/podIPs:10.42.2.188/32] [{apps/v1 ReplicaSet test-deployment-74c6dd549b 5b25982b-7c08-42e0-b3f2-b281d64b564b 0xc00269b127 0xc00269b128}] []  [{calico Update v1 2022-07-04 15:58:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-07-04 15:58:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5b25982b-7c08-42e0-b3f2-b281d64b564b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:58:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.188\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r569r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r569r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:10.42.2.188,StartTime:2022-07-04 15:58:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:58:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://e889207a82e2a9debc2cd1e2f663b1065bcb5232014f96386cfef27e2b33579d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.188,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul  4 15:58:03.149: INFO: pod: "test-deployment-74c6dd549b-xkn45":
&Pod{ObjectMeta:{test-deployment-74c6dd549b-xkn45 test-deployment-74c6dd549b- deployment-235  78eb0186-f27b-4d83-9873-7beb2f23eb98 16628 0 2022-07-04 15:58:00 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[cni.projectcalico.org/containerID:bc083fac87590538a761a2c9222c94f9a686280db4001bf7c151c2881fc12d27 cni.projectcalico.org/podIP:10.42.0.134/32 cni.projectcalico.org/podIPs:10.42.0.134/32] [{apps/v1 ReplicaSet test-deployment-74c6dd549b 5b25982b-7c08-42e0-b3f2-b281d64b564b 0xc00269b367 0xc00269b368}] []  [{kube-controller-manager Update v1 2022-07-04 15:58:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5b25982b-7c08-42e0-b3f2-b281d64b564b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:58:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:58:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.134\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kq6dk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kq6dk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:10.42.0.134,StartTime:2022-07-04 15:58:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:58:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://f753248e29d41ebe14aaf3d9334a03816252d79ad8ea2e489e38c797395f0dde,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.134,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul  4 15:58:03.149: INFO: ReplicaSet "test-deployment-84b949bdfc":
&ReplicaSet{ObjectMeta:{test-deployment-84b949bdfc  deployment-235  2822e5fe-00dd-4a04-87f8-97cdc56c673a 16684 4 2022-07-04 15:57:59 +0000 UTC <nil> <nil> map[pod-template-hash:84b949bdfc test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 270c656b-d801-472b-a42c-b82dd08320a7 0xc00269ade7 0xc00269ade8}] []  [{kube-controller-manager Update apps/v1 2022-07-04 15:57:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"270c656b-d801-472b-a42c-b82dd08320a7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 15:58:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 84b949bdfc,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:84b949bdfc test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/pause:3.7 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00269ae70 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Jul  4 15:58:03.155: INFO: pod: "test-deployment-84b949bdfc-s4n7d":
&Pod{ObjectMeta:{test-deployment-84b949bdfc-s4n7d test-deployment-84b949bdfc- deployment-235  6996c458-92fb-4186-8cd7-d328dcc01e58 16678 0 2022-07-04 15:57:59 +0000 UTC 2022-07-04 15:58:04 +0000 UTC 0xc0043f87c8 map[pod-template-hash:84b949bdfc test-deployment-static:true] map[cni.projectcalico.org/containerID:012e8ab499bacc96d11da94a60fe4dd1c95d084d2321ec001eedf5beddb4c629 cni.projectcalico.org/podIP:10.42.1.185/32 cni.projectcalico.org/podIPs:10.42.1.185/32] [{apps/v1 ReplicaSet test-deployment-84b949bdfc 2822e5fe-00dd-4a04-87f8-97cdc56c673a 0xc0043f8827 0xc0043f8828}] []  [{calico Update v1 2022-07-04 15:57:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-07-04 15:57:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2822e5fe-00dd-4a04-87f8-97cdc56c673a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-04 15:58:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.185\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qgmq9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.7,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qgmq9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:3.138.203.20,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:57:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:57:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.23.66,PodIP:10.42.1.185,StartTime:2022-07-04 15:57:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:57:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.7,ImageID:docker-pullable://k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c,ContainerID:docker://dc8696540fa6907f9f387013beef6499fe6e23a4642669463dd69ee4af889486,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul  4 15:58:03.155: INFO: pod: "test-deployment-84b949bdfc-vn9xk":
&Pod{ObjectMeta:{test-deployment-84b949bdfc-vn9xk test-deployment-84b949bdfc- deployment-235  f66f188c-a32c-402a-989c-154382a5929e 16632 0 2022-07-04 15:58:00 +0000 UTC 2022-07-04 15:58:03 +0000 UTC 0xc0043f8a10 map[pod-template-hash:84b949bdfc test-deployment-static:true] map[cni.projectcalico.org/containerID:c5e285fb5cfa22964a92819c2afdbe3505483f06173eb15f73145926ce5d7819 cni.projectcalico.org/podIP:10.42.2.187/32 cni.projectcalico.org/podIPs:10.42.2.187/32] [{apps/v1 ReplicaSet test-deployment-84b949bdfc 2822e5fe-00dd-4a04-87f8-97cdc56c673a 0xc0043f8a67 0xc0043f8a68}] []  [{kube-controller-manager Update v1 2022-07-04 15:58:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2822e5fe-00dd-4a04-87f8-97cdc56c673a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 15:58:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 15:58:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.187\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hjv8p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.7,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hjv8p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 15:58:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:10.42.2.187,StartTime:2022-07-04 15:58:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 15:58:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.7,ImageID:docker-pullable://k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c,ContainerID:docker://2eb8bab9f35232dd8b18f969d770d72e30328bf4263ecd6765941f2e82e98c8e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.187,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  4 15:58:03.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-235" for this suite.

• [SLOW TEST:5.382 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":356,"completed":136,"skipped":2626,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:58:03.162: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Jul  4 15:58:03.186: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Jul  4 15:58:03.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3523" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":356,"completed":137,"skipped":2641,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:58:03.202: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  4 15:58:15.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1223" for this suite.

• [SLOW TEST:12.028 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":356,"completed":138,"skipped":2651,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:58:15.230: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul  4 15:58:15.252: INFO: Waiting up to 5m0s for pod "pod-6a17b004-47c1-4601-88aa-428d5d414afe" in namespace "emptydir-1398" to be "Succeeded or Failed"
Jul  4 15:58:15.254: INFO: Pod "pod-6a17b004-47c1-4601-88aa-428d5d414afe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.637538ms
Jul  4 15:58:17.261: INFO: Pod "pod-6a17b004-47c1-4601-88aa-428d5d414afe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008928592s
Jul  4 15:58:19.266: INFO: Pod "pod-6a17b004-47c1-4601-88aa-428d5d414afe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013353243s
STEP: Saw pod success
Jul  4 15:58:19.266: INFO: Pod "pod-6a17b004-47c1-4601-88aa-428d5d414afe" satisfied condition "Succeeded or Failed"
Jul  4 15:58:19.267: INFO: Trying to get logs from node 18.216.149.32 pod pod-6a17b004-47c1-4601-88aa-428d5d414afe container test-container: <nil>
STEP: delete the pod
Jul  4 15:58:19.281: INFO: Waiting for pod pod-6a17b004-47c1-4601-88aa-428d5d414afe to disappear
Jul  4 15:58:19.283: INFO: Pod pod-6a17b004-47c1-4601-88aa-428d5d414afe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 15:58:19.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1398" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":139,"skipped":2662,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:58:19.289: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 15:58:19.311: INFO: The status of Pod busybox-host-aliases6a0b6f71-3134-43ff-8586-560a4bb0bf6e is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:58:21.319: INFO: The status of Pod busybox-host-aliases6a0b6f71-3134-43ff-8586-560a4bb0bf6e is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  4 15:58:21.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9209" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":140,"skipped":2671,"failed":0}

------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:58:21.333: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-1606
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  4 15:58:21.348: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul  4 15:58:21.377: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 15:58:23.384: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:25.381: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:27.385: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:29.381: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:31.382: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:33.385: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:35.381: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:37.386: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:39.381: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:41.384: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 15:58:43.385: INFO: The status of Pod netserver-0 is Running (Ready = true)
Jul  4 15:58:43.389: INFO: The status of Pod netserver-1 is Running (Ready = true)
Jul  4 15:58:43.392: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Jul  4 15:58:45.414: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul  4 15:58:45.414: INFO: Going to poll 10.42.2.192 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jul  4 15:58:45.415: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.2.192 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1606 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:58:45.415: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:58:45.416: INFO: ExecWithOptions: Clientset creation
Jul  4 15:58:45.416: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1606/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.2.192+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  4 15:58:46.495: INFO: Found all 1 expected endpoints: [netserver-0]
Jul  4 15:58:46.495: INFO: Going to poll 10.42.0.136 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jul  4 15:58:46.500: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.0.136 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1606 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:58:46.500: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:58:46.501: INFO: ExecWithOptions: Clientset creation
Jul  4 15:58:46.501: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1606/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.0.136+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  4 15:58:47.577: INFO: Found all 1 expected endpoints: [netserver-1]
Jul  4 15:58:47.577: INFO: Going to poll 10.42.1.188 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jul  4 15:58:47.582: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.1.188 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1606 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 15:58:47.582: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 15:58:47.583: INFO: ExecWithOptions: Clientset creation
Jul  4 15:58:47.583: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-1606/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.42.1.188+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  4 15:58:48.674: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Jul  4 15:58:48.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1606" for this suite.

• [SLOW TEST:27.350 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":141,"skipped":2671,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:58:48.683: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  4 15:58:48.708: INFO: Waiting up to 5m0s for pod "downward-api-71fa134d-e13c-405f-ae4e-44eae38fcd80" in namespace "downward-api-926" to be "Succeeded or Failed"
Jul  4 15:58:48.710: INFO: Pod "downward-api-71fa134d-e13c-405f-ae4e-44eae38fcd80": Phase="Pending", Reason="", readiness=false. Elapsed: 1.798557ms
Jul  4 15:58:50.717: INFO: Pod "downward-api-71fa134d-e13c-405f-ae4e-44eae38fcd80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008645917s
Jul  4 15:58:52.726: INFO: Pod "downward-api-71fa134d-e13c-405f-ae4e-44eae38fcd80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017072547s
STEP: Saw pod success
Jul  4 15:58:52.726: INFO: Pod "downward-api-71fa134d-e13c-405f-ae4e-44eae38fcd80" satisfied condition "Succeeded or Failed"
Jul  4 15:58:52.727: INFO: Trying to get logs from node 3.138.203.20 pod downward-api-71fa134d-e13c-405f-ae4e-44eae38fcd80 container dapi-container: <nil>
STEP: delete the pod
Jul  4 15:58:52.754: INFO: Waiting for pod downward-api-71fa134d-e13c-405f-ae4e-44eae38fcd80 to disappear
Jul  4 15:58:52.756: INFO: Pod downward-api-71fa134d-e13c-405f-ae4e-44eae38fcd80 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  4 15:58:52.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-926" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":356,"completed":142,"skipped":2681,"failed":0}
S
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:58:52.762: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Jul  4 15:58:52.781: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  4 15:58:57.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8904" for this suite.

• [SLOW TEST:5.041 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":356,"completed":143,"skipped":2682,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:58:57.803: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating all guestbook components
Jul  4 15:58:57.816: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Jul  4 15:58:57.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 create -f -'
Jul  4 15:58:58.673: INFO: stderr: ""
Jul  4 15:58:58.673: INFO: stdout: "service/agnhost-replica created\n"
Jul  4 15:58:58.673: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Jul  4 15:58:58.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 create -f -'
Jul  4 15:58:58.847: INFO: stderr: ""
Jul  4 15:58:58.847: INFO: stdout: "service/agnhost-primary created\n"
Jul  4 15:58:58.847: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jul  4 15:58:58.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 create -f -'
Jul  4 15:58:59.023: INFO: stderr: ""
Jul  4 15:58:59.023: INFO: stdout: "service/frontend created\n"
Jul  4 15:58:59.023: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Jul  4 15:58:59.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 create -f -'
Jul  4 15:58:59.215: INFO: stderr: ""
Jul  4 15:58:59.215: INFO: stdout: "deployment.apps/frontend created\n"
Jul  4 15:58:59.215: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul  4 15:58:59.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 create -f -'
Jul  4 15:58:59.406: INFO: stderr: ""
Jul  4 15:58:59.406: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Jul  4 15:58:59.406: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul  4 15:58:59.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 create -f -'
Jul  4 15:58:59.584: INFO: stderr: ""
Jul  4 15:58:59.584: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Jul  4 15:58:59.584: INFO: Waiting for all frontend pods to be Running.
Jul  4 15:59:04.636: INFO: Waiting for frontend to serve content.
Jul  4 15:59:04.644: INFO: Trying to add a new entry to the guestbook.
Jul  4 15:59:04.652: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jul  4 15:59:04.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 delete --grace-period=0 --force -f -'
Jul  4 15:59:04.736: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  4 15:59:04.736: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Jul  4 15:59:04.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 delete --grace-period=0 --force -f -'
Jul  4 15:59:04.813: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  4 15:59:04.813: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Jul  4 15:59:04.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 delete --grace-period=0 --force -f -'
Jul  4 15:59:04.886: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  4 15:59:04.886: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul  4 15:59:04.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 delete --grace-period=0 --force -f -'
Jul  4 15:59:04.944: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  4 15:59:04.944: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul  4 15:59:04.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 delete --grace-period=0 --force -f -'
Jul  4 15:59:05.023: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  4 15:59:05.023: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Jul  4 15:59:05.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-1533 delete --grace-period=0 --force -f -'
Jul  4 15:59:05.087: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  4 15:59:05.087: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 15:59:05.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1533" for this suite.

• [SLOW TEST:7.290 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:340
    should create and stop a working application  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":356,"completed":144,"skipped":2687,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:59:05.093: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-72fc5231-17d6-4853-8120-ef687bc8906f
STEP: Creating a pod to test consume secrets
Jul  4 15:59:05.147: INFO: Waiting up to 5m0s for pod "pod-secrets-7fdac71d-fbb7-44b3-baeb-9ac9e0721319" in namespace "secrets-1806" to be "Succeeded or Failed"
Jul  4 15:59:05.158: INFO: Pod "pod-secrets-7fdac71d-fbb7-44b3-baeb-9ac9e0721319": Phase="Pending", Reason="", readiness=false. Elapsed: 11.415022ms
Jul  4 15:59:07.166: INFO: Pod "pod-secrets-7fdac71d-fbb7-44b3-baeb-9ac9e0721319": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018628258s
Jul  4 15:59:09.169: INFO: Pod "pod-secrets-7fdac71d-fbb7-44b3-baeb-9ac9e0721319": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021985186s
STEP: Saw pod success
Jul  4 15:59:09.169: INFO: Pod "pod-secrets-7fdac71d-fbb7-44b3-baeb-9ac9e0721319" satisfied condition "Succeeded or Failed"
Jul  4 15:59:09.171: INFO: Trying to get logs from node 18.216.149.32 pod pod-secrets-7fdac71d-fbb7-44b3-baeb-9ac9e0721319 container secret-volume-test: <nil>
STEP: delete the pod
Jul  4 15:59:09.184: INFO: Waiting for pod pod-secrets-7fdac71d-fbb7-44b3-baeb-9ac9e0721319 to disappear
Jul  4 15:59:09.186: INFO: Pod pod-secrets-7fdac71d-fbb7-44b3-baeb-9ac9e0721319 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  4 15:59:09.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1806" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":145,"skipped":2702,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 15:59:09.192: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-47723f9a-5c61-4d08-b54b-c326b1125492 in namespace container-probe-1745
Jul  4 15:59:11.218: INFO: Started pod busybox-47723f9a-5c61-4d08-b54b-c326b1125492 in namespace container-probe-1745
STEP: checking the pod's current state and verifying that restartCount is present
Jul  4 15:59:11.220: INFO: Initial restart count of pod busybox-47723f9a-5c61-4d08-b54b-c326b1125492 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  4 16:03:11.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1745" for this suite.

• [SLOW TEST:242.764 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":146,"skipped":2767,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:11.956: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul  4 16:03:11.973: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  4 16:03:11.978: INFO: Waiting for terminating namespaces to be deleted...
Jul  4 16:03:11.980: INFO: 
Logging pods the apiserver thinks is on node 18.216.149.32 before test
Jul  4 16:03:11.983: INFO: canal-7ftvj from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:03:11.983: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:03:11.983: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:03:11.983: INFO: coredns-85bfbf8f-9f6vk from kube-system started at 2022-07-04 15:17:21 +0000 UTC (1 container statuses recorded)
Jul  4 16:03:11.983: INFO: 	Container coredns ready: true, restart count 0
Jul  4 16:03:11.983: INFO: metrics-server-585b7cc746-9jchh from kube-system started at 2022-07-04 15:17:33 +0000 UTC (1 container statuses recorded)
Jul  4 16:03:11.983: INFO: 	Container metrics-server ready: true, restart count 0
Jul  4 16:03:11.983: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-vttwd from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:03:11.983: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:03:11.983: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  4 16:03:11.983: INFO: 
Logging pods the apiserver thinks is on node 18.224.151.13 before test
Jul  4 16:03:11.987: INFO: canal-twgvp from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:03:11.987: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:03:11.987: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:03:11.987: INFO: coredns-autoscaler-67cbd4599c-62tvv from kube-system started at 2022-07-04 15:17:21 +0000 UTC (1 container statuses recorded)
Jul  4 16:03:11.987: INFO: 	Container autoscaler ready: true, restart count 0
Jul  4 16:03:11.987: INFO: rke-coredns-addon-deploy-job-q97vx from kube-system started at 2022-07-04 15:17:20 +0000 UTC (1 container statuses recorded)
Jul  4 16:03:11.987: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Jul  4 16:03:11.987: INFO: rke-metrics-addon-deploy-job-v6dww from kube-system started at 2022-07-04 15:17:32 +0000 UTC (1 container statuses recorded)
Jul  4 16:03:11.987: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Jul  4 16:03:11.987: INFO: rke-network-plugin-deploy-job-vqpwx from kube-system started at 2022-07-04 15:17:12 +0000 UTC (1 container statuses recorded)
Jul  4 16:03:11.987: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Jul  4 16:03:11.987: INFO: sonobuoy from sonobuoy started at 2022-07-04 15:20:04 +0000 UTC (1 container statuses recorded)
Jul  4 16:03:11.987: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  4 16:03:11.987: INFO: sonobuoy-e2e-job-f2b28e16e8b74a5d from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:03:11.987: INFO: 	Container e2e ready: true, restart count 0
Jul  4 16:03:11.987: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:03:11.987: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-6fh2b from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:03:11.987: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:03:11.987: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  4 16:03:11.987: INFO: 
Logging pods the apiserver thinks is on node 3.138.203.20 before test
Jul  4 16:03:11.990: INFO: calico-kube-controllers-74df54cbb7-vdkjz from kube-system started at 2022-07-04 15:17:14 +0000 UTC (1 container statuses recorded)
Jul  4 16:03:11.990: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  4 16:03:11.990: INFO: canal-2hwcq from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:03:11.991: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:03:11.991: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:03:11.991: INFO: coredns-85bfbf8f-zln4g from kube-system started at 2022-07-04 15:17:23 +0000 UTC (1 container statuses recorded)
Jul  4 16:03:11.991: INFO: 	Container coredns ready: true, restart count 0
Jul  4 16:03:11.991: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-jzqpt from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:03:11.991: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:03:11.991: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16feabc8d6c84074], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:03:13.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1351" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":356,"completed":147,"skipped":2780,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:13.015: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 16:03:13.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1628" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":356,"completed":148,"skipped":2794,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:13.038: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:03:13.057: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1bbee0b2-653b-47d5-861b-5f6edfe5234c" in namespace "downward-api-3394" to be "Succeeded or Failed"
Jul  4 16:03:13.059: INFO: Pod "downwardapi-volume-1bbee0b2-653b-47d5-861b-5f6edfe5234c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.830669ms
Jul  4 16:03:15.066: INFO: Pod "downwardapi-volume-1bbee0b2-653b-47d5-861b-5f6edfe5234c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00922671s
Jul  4 16:03:17.073: INFO: Pod "downwardapi-volume-1bbee0b2-653b-47d5-861b-5f6edfe5234c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016332532s
STEP: Saw pod success
Jul  4 16:03:17.073: INFO: Pod "downwardapi-volume-1bbee0b2-653b-47d5-861b-5f6edfe5234c" satisfied condition "Succeeded or Failed"
Jul  4 16:03:17.075: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-1bbee0b2-653b-47d5-861b-5f6edfe5234c container client-container: <nil>
STEP: delete the pod
Jul  4 16:03:17.098: INFO: Waiting for pod downwardapi-volume-1bbee0b2-653b-47d5-861b-5f6edfe5234c to disappear
Jul  4 16:03:17.102: INFO: Pod downwardapi-volume-1bbee0b2-653b-47d5-861b-5f6edfe5234c no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 16:03:17.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3394" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":149,"skipped":2798,"failed":0}
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:17.110: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-74040f82-68ce-4cb9-80f9-3367c300cb76
STEP: Creating a pod to test consume secrets
Jul  4 16:03:17.132: INFO: Waiting up to 5m0s for pod "pod-secrets-06de9d56-d396-4c6b-8540-32c8488943ef" in namespace "secrets-4783" to be "Succeeded or Failed"
Jul  4 16:03:17.135: INFO: Pod "pod-secrets-06de9d56-d396-4c6b-8540-32c8488943ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.531928ms
Jul  4 16:03:19.143: INFO: Pod "pod-secrets-06de9d56-d396-4c6b-8540-32c8488943ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010913662s
Jul  4 16:03:21.149: INFO: Pod "pod-secrets-06de9d56-d396-4c6b-8540-32c8488943ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016625883s
STEP: Saw pod success
Jul  4 16:03:21.149: INFO: Pod "pod-secrets-06de9d56-d396-4c6b-8540-32c8488943ef" satisfied condition "Succeeded or Failed"
Jul  4 16:03:21.151: INFO: Trying to get logs from node 18.216.149.32 pod pod-secrets-06de9d56-d396-4c6b-8540-32c8488943ef container secret-volume-test: <nil>
STEP: delete the pod
Jul  4 16:03:21.165: INFO: Waiting for pod pod-secrets-06de9d56-d396-4c6b-8540-32c8488943ef to disappear
Jul  4 16:03:21.166: INFO: Pod pod-secrets-06de9d56-d396-4c6b-8540-32c8488943ef no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  4 16:03:21.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4783" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":150,"skipped":2804,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:21.172: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:03:21.916: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:03:24.934: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:03:24.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-780" for this suite.
STEP: Destroying namespace "webhook-780-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":356,"completed":151,"skipped":2804,"failed":0}
SSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:24.976: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:188
Jul  4 16:03:25.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8868" for this suite.
•{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":356,"completed":152,"skipped":2809,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:25.015: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Jul  4 16:03:25.040: INFO: The status of Pod labelsupdatea7bdbebf-c472-4210-98e8-09ba6fea8268 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:03:27.047: INFO: The status of Pod labelsupdatea7bdbebf-c472-4210-98e8-09ba6fea8268 is Running (Ready = true)
Jul  4 16:03:27.567: INFO: Successfully updated pod "labelsupdatea7bdbebf-c472-4210-98e8-09ba6fea8268"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 16:03:29.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6356" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":153,"skipped":2836,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:29.591: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-3479/configmap-test-f8a24948-dde2-4580-975b-156aa7379575
STEP: Creating a pod to test consume configMaps
Jul  4 16:03:29.620: INFO: Waiting up to 5m0s for pod "pod-configmaps-faf3515c-d3bd-4fc3-b17e-d2604ac8a023" in namespace "configmap-3479" to be "Succeeded or Failed"
Jul  4 16:03:29.622: INFO: Pod "pod-configmaps-faf3515c-d3bd-4fc3-b17e-d2604ac8a023": Phase="Pending", Reason="", readiness=false. Elapsed: 1.80658ms
Jul  4 16:03:31.628: INFO: Pod "pod-configmaps-faf3515c-d3bd-4fc3-b17e-d2604ac8a023": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008465379s
Jul  4 16:03:33.636: INFO: Pod "pod-configmaps-faf3515c-d3bd-4fc3-b17e-d2604ac8a023": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016604681s
STEP: Saw pod success
Jul  4 16:03:33.636: INFO: Pod "pod-configmaps-faf3515c-d3bd-4fc3-b17e-d2604ac8a023" satisfied condition "Succeeded or Failed"
Jul  4 16:03:33.638: INFO: Trying to get logs from node 18.216.149.32 pod pod-configmaps-faf3515c-d3bd-4fc3-b17e-d2604ac8a023 container env-test: <nil>
STEP: delete the pod
Jul  4 16:03:33.652: INFO: Waiting for pod pod-configmaps-faf3515c-d3bd-4fc3-b17e-d2604ac8a023 to disappear
Jul  4 16:03:33.654: INFO: Pod pod-configmaps-faf3515c-d3bd-4fc3-b17e-d2604ac8a023 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:03:33.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3479" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":154,"skipped":2896,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:33.660: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3109.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3109.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3109.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3109.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  4 16:03:37.707: INFO: DNS probes using dns-3109/dns-test-a8dfbbb4-125b-4bce-9758-2167d63bff2d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  4 16:03:37.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3109" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","total":356,"completed":155,"skipped":2908,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:37.721: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 16:03:53.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2907" for this suite.

• [SLOW TEST:16.137 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":356,"completed":156,"skipped":2973,"failed":0}
SS
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:53.859: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
Jul  4 16:03:53.885: INFO: created test-event-1
Jul  4 16:03:53.887: INFO: created test-event-2
Jul  4 16:03:53.890: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Jul  4 16:03:53.892: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Jul  4 16:03:53.903: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Jul  4 16:03:53.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7701" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":356,"completed":157,"skipped":2975,"failed":0}
SSSSSS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:53.913: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Jul  4 16:03:53.937: INFO: Waiting up to 5m0s for pod "security-context-e0b3c40f-652b-4bfe-88a2-69c712ac93d6" in namespace "security-context-5618" to be "Succeeded or Failed"
Jul  4 16:03:53.939: INFO: Pod "security-context-e0b3c40f-652b-4bfe-88a2-69c712ac93d6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.81846ms
Jul  4 16:03:55.944: INFO: Pod "security-context-e0b3c40f-652b-4bfe-88a2-69c712ac93d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006890914s
Jul  4 16:03:57.952: INFO: Pod "security-context-e0b3c40f-652b-4bfe-88a2-69c712ac93d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014715509s
STEP: Saw pod success
Jul  4 16:03:57.952: INFO: Pod "security-context-e0b3c40f-652b-4bfe-88a2-69c712ac93d6" satisfied condition "Succeeded or Failed"
Jul  4 16:03:57.954: INFO: Trying to get logs from node 18.216.149.32 pod security-context-e0b3c40f-652b-4bfe-88a2-69c712ac93d6 container test-container: <nil>
STEP: delete the pod
Jul  4 16:03:57.967: INFO: Waiting for pod security-context-e0b3c40f-652b-4bfe-88a2-69c712ac93d6 to disappear
Jul  4 16:03:57.969: INFO: Pod security-context-e0b3c40f-652b-4bfe-88a2-69c712ac93d6 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  4 16:03:57.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5618" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":158,"skipped":2981,"failed":0}
SSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:03:57.975: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-8a16b1cb-2db3-4356-8091-82886c73e9f9
STEP: Creating a pod to test consume secrets
Jul  4 16:03:58.050: INFO: Waiting up to 5m0s for pod "pod-secrets-51822a41-beb2-4dcb-a59f-e9f3ceb9b314" in namespace "secrets-1309" to be "Succeeded or Failed"
Jul  4 16:03:58.055: INFO: Pod "pod-secrets-51822a41-beb2-4dcb-a59f-e9f3ceb9b314": Phase="Pending", Reason="", readiness=false. Elapsed: 4.589394ms
Jul  4 16:04:00.060: INFO: Pod "pod-secrets-51822a41-beb2-4dcb-a59f-e9f3ceb9b314": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009614611s
Jul  4 16:04:02.067: INFO: Pod "pod-secrets-51822a41-beb2-4dcb-a59f-e9f3ceb9b314": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016983866s
STEP: Saw pod success
Jul  4 16:04:02.067: INFO: Pod "pod-secrets-51822a41-beb2-4dcb-a59f-e9f3ceb9b314" satisfied condition "Succeeded or Failed"
Jul  4 16:04:02.069: INFO: Trying to get logs from node 18.216.149.32 pod pod-secrets-51822a41-beb2-4dcb-a59f-e9f3ceb9b314 container secret-env-test: <nil>
STEP: delete the pod
Jul  4 16:04:02.083: INFO: Waiting for pod pod-secrets-51822a41-beb2-4dcb-a59f-e9f3ceb9b314 to disappear
Jul  4 16:04:02.085: INFO: Pod pod-secrets-51822a41-beb2-4dcb-a59f-e9f3ceb9b314 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Jul  4 16:04:02.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1309" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":356,"completed":159,"skipped":2984,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:04:02.090: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-d9d52918-2ebe-401a-b5e5-a71e9dd8444c
STEP: Creating a pod to test consume secrets
Jul  4 16:04:02.115: INFO: Waiting up to 5m0s for pod "pod-secrets-f8802202-2553-4c3f-8604-6d6eda77d89b" in namespace "secrets-8699" to be "Succeeded or Failed"
Jul  4 16:04:02.117: INFO: Pod "pod-secrets-f8802202-2553-4c3f-8604-6d6eda77d89b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.262562ms
Jul  4 16:04:04.124: INFO: Pod "pod-secrets-f8802202-2553-4c3f-8604-6d6eda77d89b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008873865s
Jul  4 16:04:06.128: INFO: Pod "pod-secrets-f8802202-2553-4c3f-8604-6d6eda77d89b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012854823s
STEP: Saw pod success
Jul  4 16:04:06.128: INFO: Pod "pod-secrets-f8802202-2553-4c3f-8604-6d6eda77d89b" satisfied condition "Succeeded or Failed"
Jul  4 16:04:06.130: INFO: Trying to get logs from node 18.216.149.32 pod pod-secrets-f8802202-2553-4c3f-8604-6d6eda77d89b container secret-volume-test: <nil>
STEP: delete the pod
Jul  4 16:04:06.141: INFO: Waiting for pod pod-secrets-f8802202-2553-4c3f-8604-6d6eda77d89b to disappear
Jul  4 16:04:06.143: INFO: Pod pod-secrets-f8802202-2553-4c3f-8604-6d6eda77d89b no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  4 16:04:06.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8699" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":160,"skipped":2989,"failed":0}
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:04:06.149: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-secret-z8c2
STEP: Creating a pod to test atomic-volume-subpath
Jul  4 16:04:06.176: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-z8c2" in namespace "subpath-195" to be "Succeeded or Failed"
Jul  4 16:04:06.178: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053369ms
Jul  4 16:04:08.184: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 2.008312223s
Jul  4 16:04:10.186: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 4.010500439s
Jul  4 16:04:12.194: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 6.018713603s
Jul  4 16:04:14.199: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 8.023222424s
Jul  4 16:04:16.205: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 10.029050998s
Jul  4 16:04:18.213: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 12.036877024s
Jul  4 16:04:20.216: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 14.04065968s
Jul  4 16:04:22.224: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 16.047869658s
Jul  4 16:04:24.231: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 18.055435753s
Jul  4 16:04:26.237: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=true. Elapsed: 20.06088055s
Jul  4 16:04:28.244: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Running", Reason="", readiness=false. Elapsed: 22.068087754s
Jul  4 16:04:30.247: INFO: Pod "pod-subpath-test-secret-z8c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.07135626s
STEP: Saw pod success
Jul  4 16:04:30.247: INFO: Pod "pod-subpath-test-secret-z8c2" satisfied condition "Succeeded or Failed"
Jul  4 16:04:30.249: INFO: Trying to get logs from node 18.216.149.32 pod pod-subpath-test-secret-z8c2 container test-container-subpath-secret-z8c2: <nil>
STEP: delete the pod
Jul  4 16:04:30.262: INFO: Waiting for pod pod-subpath-test-secret-z8c2 to disappear
Jul  4 16:04:30.264: INFO: Pod pod-subpath-test-secret-z8c2 no longer exists
STEP: Deleting pod pod-subpath-test-secret-z8c2
Jul  4 16:04:30.264: INFO: Deleting pod "pod-subpath-test-secret-z8c2" in namespace "subpath-195"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  4 16:04:30.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-195" for this suite.

• [SLOW TEST:24.122 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","total":356,"completed":161,"skipped":2991,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:04:30.271: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:04:30.619: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:04:33.637: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:04:43.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6449" for this suite.
STEP: Destroying namespace "webhook-6449-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:13.501 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":356,"completed":162,"skipped":2994,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:04:43.772: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  4 16:04:46.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3445" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":356,"completed":163,"skipped":2999,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:04:46.678: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:04:46.709: INFO: Create a RollingUpdate DaemonSet
Jul  4 16:04:46.711: INFO: Check that daemon pods launch on every node of the cluster
Jul  4 16:04:46.715: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:04:46.716: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:04:47.723: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul  4 16:04:47.723: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:04:48.723: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  4 16:04:48.723: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Jul  4 16:04:48.723: INFO: Update the DaemonSet to trigger a rollout
Jul  4 16:04:48.736: INFO: Updating DaemonSet daemon-set
Jul  4 16:04:51.749: INFO: Roll back the DaemonSet before rollout is complete
Jul  4 16:04:51.759: INFO: Updating DaemonSet daemon-set
Jul  4 16:04:51.759: INFO: Make sure DaemonSet rollback is complete
Jul  4 16:04:51.769: INFO: Wrong image for pod: daemon-set-94xt9. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Jul  4 16:04:51.769: INFO: Pod daemon-set-94xt9 is not available
Jul  4 16:04:53.780: INFO: Pod daemon-set-c8lhw is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9985, will wait for the garbage collector to delete the pods
Jul  4 16:04:53.843: INFO: Deleting DaemonSet.extensions daemon-set took: 4.312667ms
Jul  4 16:04:53.944: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.531122ms
Jul  4 16:04:55.547: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:04:55.547: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  4 16:04:55.549: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18649"},"items":null}

Jul  4 16:04:55.551: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18649"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:04:55.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9985" for this suite.

• [SLOW TEST:8.887 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":356,"completed":164,"skipped":3002,"failed":0}
SS
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:04:55.565: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
Jul  4 16:04:57.594: INFO: pods: 0 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  4 16:05:03.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7055" for this suite.

• [SLOW TEST:8.125 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":356,"completed":165,"skipped":3004,"failed":0}
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:05:03.691: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  4 16:05:07.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4120" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":356,"completed":166,"skipped":3005,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:05:07.735: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Jul  4 16:05:07.756: INFO: namespace kubectl-2452
Jul  4 16:05:07.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2452 create -f -'
Jul  4 16:05:07.969: INFO: stderr: ""
Jul  4 16:05:07.969: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Jul  4 16:05:08.974: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 16:05:08.974: INFO: Found 0 / 1
Jul  4 16:05:09.974: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 16:05:09.974: INFO: Found 1 / 1
Jul  4 16:05:09.974: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul  4 16:05:09.976: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 16:05:09.976: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul  4 16:05:09.976: INFO: wait on agnhost-primary startup in kubectl-2452 
Jul  4 16:05:09.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2452 logs agnhost-primary-67vxm agnhost-primary'
Jul  4 16:05:10.048: INFO: stderr: ""
Jul  4 16:05:10.048: INFO: stdout: "Paused\n"
STEP: exposing RC
Jul  4 16:05:10.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2452 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Jul  4 16:05:10.118: INFO: stderr: ""
Jul  4 16:05:10.118: INFO: stdout: "service/rm2 exposed\n"
Jul  4 16:05:10.120: INFO: Service rm2 in namespace kubectl-2452 found.
STEP: exposing service
Jul  4 16:05:12.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-2452 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Jul  4 16:05:12.189: INFO: stderr: ""
Jul  4 16:05:12.189: INFO: stdout: "service/rm3 exposed\n"
Jul  4 16:05:12.191: INFO: Service rm3 in namespace kubectl-2452 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 16:05:14.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2452" for this suite.

• [SLOW TEST:6.472 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1249
    should create services for rc  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":356,"completed":167,"skipped":3014,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:05:14.207: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 16:05:14.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6297" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":356,"completed":168,"skipped":3021,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:05:14.253: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Jul  4 16:05:14.271: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Jul  4 16:05:14.279: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jul  4 16:05:14.279: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Jul  4 16:05:14.284: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jul  4 16:05:14.284: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Jul  4 16:05:14.291: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Jul  4 16:05:14.291: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Jul  4 16:05:21.320: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:188
Jul  4 16:05:21.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-6874" for this suite.

• [SLOW TEST:7.082 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":356,"completed":169,"skipped":3032,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:05:21.335: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:05:21.354: INFO: Waiting up to 5m0s for pod "downwardapi-volume-810e5ceb-9c70-43f1-8483-9e32e550b5d1" in namespace "downward-api-9435" to be "Succeeded or Failed"
Jul  4 16:05:21.358: INFO: Pod "downwardapi-volume-810e5ceb-9c70-43f1-8483-9e32e550b5d1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.854727ms
Jul  4 16:05:23.366: INFO: Pod "downwardapi-volume-810e5ceb-9c70-43f1-8483-9e32e550b5d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011961572s
Jul  4 16:05:25.371: INFO: Pod "downwardapi-volume-810e5ceb-9c70-43f1-8483-9e32e550b5d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016261846s
STEP: Saw pod success
Jul  4 16:05:25.371: INFO: Pod "downwardapi-volume-810e5ceb-9c70-43f1-8483-9e32e550b5d1" satisfied condition "Succeeded or Failed"
Jul  4 16:05:25.373: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-810e5ceb-9c70-43f1-8483-9e32e550b5d1 container client-container: <nil>
STEP: delete the pod
Jul  4 16:05:25.386: INFO: Waiting for pod downwardapi-volume-810e5ceb-9c70-43f1-8483-9e32e550b5d1 to disappear
Jul  4 16:05:25.389: INFO: Pod downwardapi-volume-810e5ceb-9c70-43f1-8483-9e32e550b5d1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 16:05:25.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9435" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":170,"skipped":3037,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:05:25.396: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  4 16:06:25.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3430" for this suite.

• [SLOW TEST:60.031 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":356,"completed":171,"skipped":3055,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:06:25.427: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:06:25.440: INFO: Creating ReplicaSet my-hostname-basic-b9268e47-db8a-4ee1-9780-26da2fff0c39
Jul  4 16:06:25.446: INFO: Pod name my-hostname-basic-b9268e47-db8a-4ee1-9780-26da2fff0c39: Found 0 pods out of 1
Jul  4 16:06:30.450: INFO: Pod name my-hostname-basic-b9268e47-db8a-4ee1-9780-26da2fff0c39: Found 1 pods out of 1
Jul  4 16:06:30.450: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-b9268e47-db8a-4ee1-9780-26da2fff0c39" is running
Jul  4 16:06:30.452: INFO: Pod "my-hostname-basic-b9268e47-db8a-4ee1-9780-26da2fff0c39-ng4xv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-04 16:06:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-04 16:06:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-04 16:06:26 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-04 16:06:25 +0000 UTC Reason: Message:}])
Jul  4 16:06:30.452: INFO: Trying to dial the pod
Jul  4 16:06:35.462: INFO: Controller my-hostname-basic-b9268e47-db8a-4ee1-9780-26da2fff0c39: Got expected result from replica 1 [my-hostname-basic-b9268e47-db8a-4ee1-9780-26da2fff0c39-ng4xv]: "my-hostname-basic-b9268e47-db8a-4ee1-9780-26da2fff0c39-ng4xv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  4 16:06:35.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8427" for this suite.

• [SLOW TEST:10.044 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":172,"skipped":3081,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:06:35.471: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jul  4 16:06:35.493: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6487  027d3476-7f49-4af8-a936-21a63fdf3571 19182 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:06:35.494: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6487  027d3476-7f49-4af8-a936-21a63fdf3571 19182 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jul  4 16:06:35.497: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6487  027d3476-7f49-4af8-a936-21a63fdf3571 19183 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:06:35.497: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6487  027d3476-7f49-4af8-a936-21a63fdf3571 19183 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jul  4 16:06:35.502: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6487  027d3476-7f49-4af8-a936-21a63fdf3571 19184 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:06:35.502: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6487  027d3476-7f49-4af8-a936-21a63fdf3571 19184 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jul  4 16:06:35.504: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6487  027d3476-7f49-4af8-a936-21a63fdf3571 19185 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:06:35.504: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6487  027d3476-7f49-4af8-a936-21a63fdf3571 19185 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jul  4 16:06:35.507: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6487  78546e65-acc5-4c6c-92f7-b606403fde47 19186 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:06:35.507: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6487  78546e65-acc5-4c6c-92f7-b606403fde47 19186 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jul  4 16:06:45.514: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6487  78546e65-acc5-4c6c-92f7-b606403fde47 19217 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:06:45.514: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6487  78546e65-acc5-4c6c-92f7-b606403fde47 19217 0 2022-07-04 16:06:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-07-04 16:06:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  4 16:06:55.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6487" for this suite.

• [SLOW TEST:20.052 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":356,"completed":173,"skipped":3121,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:06:55.524: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  4 16:06:55.556: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Jul  4 16:06:55.559: INFO: starting watch
STEP: patching
STEP: updating
Jul  4 16:06:55.567: INFO: waiting for watch events with expected annotations
Jul  4 16:06:55.567: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:188
Jul  4 16:06:55.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-4120" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":356,"completed":174,"skipped":3158,"failed":0}
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:06:55.599: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  4 16:06:55.630: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:06:55.630: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:06:56.637: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:06:56.637: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:06:57.639: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  4 16:06:57.639: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jul  4 16:06:57.675: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  4 16:06:57.675: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:06:58.684: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  4 16:06:58.684: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:06:59.681: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  4 16:06:59.681: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1840, will wait for the garbage collector to delete the pods
Jul  4 16:06:59.744: INFO: Deleting DaemonSet.extensions daemon-set took: 3.362485ms
Jul  4 16:06:59.844: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.663782ms
Jul  4 16:07:02.051: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:02.051: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  4 16:07:02.053: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19341"},"items":null}

Jul  4 16:07:02.054: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19341"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:07:02.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1840" for this suite.

• [SLOW TEST:6.472 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":356,"completed":175,"skipped":3159,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:02.070: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul  4 16:07:02.091: INFO: Waiting up to 5m0s for pod "pod-a49397d4-2813-4d71-a425-a45e2846fe4f" in namespace "emptydir-5852" to be "Succeeded or Failed"
Jul  4 16:07:02.094: INFO: Pod "pod-a49397d4-2813-4d71-a425-a45e2846fe4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.985072ms
Jul  4 16:07:04.102: INFO: Pod "pod-a49397d4-2813-4d71-a425-a45e2846fe4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010878014s
Jul  4 16:07:06.109: INFO: Pod "pod-a49397d4-2813-4d71-a425-a45e2846fe4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017827325s
STEP: Saw pod success
Jul  4 16:07:06.109: INFO: Pod "pod-a49397d4-2813-4d71-a425-a45e2846fe4f" satisfied condition "Succeeded or Failed"
Jul  4 16:07:06.111: INFO: Trying to get logs from node 3.138.203.20 pod pod-a49397d4-2813-4d71-a425-a45e2846fe4f container test-container: <nil>
STEP: delete the pod
Jul  4 16:07:06.133: INFO: Waiting for pod pod-a49397d4-2813-4d71-a425-a45e2846fe4f to disappear
Jul  4 16:07:06.135: INFO: Pod pod-a49397d4-2813-4d71-a425-a45e2846fe4f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 16:07:06.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5852" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":176,"skipped":3160,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:06.142: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:07:06.432: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:07:09.450: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:07:09.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4666" for this suite.
STEP: Destroying namespace "webhook-4666-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":356,"completed":177,"skipped":3183,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:09.600: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating cluster-info
Jul  4 16:07:09.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-5592 cluster-info'
Jul  4 16:07:09.674: INFO: stderr: ""
Jul  4 16:07:09.674: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 16:07:09.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5592" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":356,"completed":178,"skipped":3212,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:09.681: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:07:09.707: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jul  4 16:07:09.711: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:09.711: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched.
Jul  4 16:07:09.726: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:09.726: INFO: Node 18.224.151.13 is running 0 daemon pod, expected 1
Jul  4 16:07:10.730: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul  4 16:07:10.730: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jul  4 16:07:10.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul  4 16:07:10.745: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Jul  4 16:07:11.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:11.751: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jul  4 16:07:11.760: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:11.760: INFO: Node 18.224.151.13 is running 0 daemon pod, expected 1
Jul  4 16:07:12.766: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:12.766: INFO: Node 18.224.151.13 is running 0 daemon pod, expected 1
Jul  4 16:07:13.765: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:13.765: INFO: Node 18.224.151.13 is running 0 daemon pod, expected 1
Jul  4 16:07:14.767: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul  4 16:07:14.767: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6460, will wait for the garbage collector to delete the pods
Jul  4 16:07:14.829: INFO: Deleting DaemonSet.extensions daemon-set took: 3.11452ms
Jul  4 16:07:14.936: INFO: Terminating DaemonSet.extensions daemon-set pods took: 106.900478ms
Jul  4 16:07:17.840: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:17.840: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  4 16:07:17.842: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19568"},"items":null}

Jul  4 16:07:17.843: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19568"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:07:17.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6460" for this suite.

• [SLOW TEST:8.184 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":356,"completed":179,"skipped":3232,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:17.864: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: reading a file in the container
Jul  4 16:07:19.899: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4202 pod-service-account-c313d754-b275-411a-9746-30c2e6101ac5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jul  4 16:07:20.031: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4202 pod-service-account-c313d754-b275-411a-9746-30c2e6101ac5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jul  4 16:07:20.158: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4202 pod-service-account-c313d754-b275-411a-9746-30c2e6101ac5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Jul  4 16:07:20.289: INFO: Got root ca configmap in namespace "svcaccounts-4202"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  4 16:07:20.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4202" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":356,"completed":180,"skipped":3262,"failed":0}
SSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:20.297: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:07:20.314: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Jul  4 16:07:22.339: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  4 16:07:23.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-282" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":356,"completed":181,"skipped":3265,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:23.352: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:07:23.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8158" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":356,"completed":182,"skipped":3281,"failed":0}
SSSSSSS
------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:23.374: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
Jul  4 16:07:23.399: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
Jul  4 16:07:23.411: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  4 16:07:23.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2312" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":356,"completed":183,"skipped":3288,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:23.429: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on node default medium
Jul  4 16:07:23.447: INFO: Waiting up to 5m0s for pod "pod-15722611-6352-42e3-8a5e-e77e9b02fb86" in namespace "emptydir-5850" to be "Succeeded or Failed"
Jul  4 16:07:23.449: INFO: Pod "pod-15722611-6352-42e3-8a5e-e77e9b02fb86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038158ms
Jul  4 16:07:25.452: INFO: Pod "pod-15722611-6352-42e3-8a5e-e77e9b02fb86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005119268s
Jul  4 16:07:27.459: INFO: Pod "pod-15722611-6352-42e3-8a5e-e77e9b02fb86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012585701s
STEP: Saw pod success
Jul  4 16:07:27.459: INFO: Pod "pod-15722611-6352-42e3-8a5e-e77e9b02fb86" satisfied condition "Succeeded or Failed"
Jul  4 16:07:27.461: INFO: Trying to get logs from node 3.138.203.20 pod pod-15722611-6352-42e3-8a5e-e77e9b02fb86 container test-container: <nil>
STEP: delete the pod
Jul  4 16:07:27.473: INFO: Waiting for pod pod-15722611-6352-42e3-8a5e-e77e9b02fb86 to disappear
Jul  4 16:07:27.476: INFO: Pod pod-15722611-6352-42e3-8a5e-e77e9b02fb86 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 16:07:27.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5850" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":184,"skipped":3364,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:27.482: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating secret secrets-2268/secret-test-84a022b1-3040-4fe1-8f03-55e66d934187
STEP: Creating a pod to test consume secrets
Jul  4 16:07:27.502: INFO: Waiting up to 5m0s for pod "pod-configmaps-1d1602d8-f4c4-4379-b22b-748655a5be01" in namespace "secrets-2268" to be "Succeeded or Failed"
Jul  4 16:07:27.504: INFO: Pod "pod-configmaps-1d1602d8-f4c4-4379-b22b-748655a5be01": Phase="Pending", Reason="", readiness=false. Elapsed: 1.895004ms
Jul  4 16:07:29.512: INFO: Pod "pod-configmaps-1d1602d8-f4c4-4379-b22b-748655a5be01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009643076s
Jul  4 16:07:31.517: INFO: Pod "pod-configmaps-1d1602d8-f4c4-4379-b22b-748655a5be01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014963683s
STEP: Saw pod success
Jul  4 16:07:31.517: INFO: Pod "pod-configmaps-1d1602d8-f4c4-4379-b22b-748655a5be01" satisfied condition "Succeeded or Failed"
Jul  4 16:07:31.519: INFO: Trying to get logs from node 3.138.203.20 pod pod-configmaps-1d1602d8-f4c4-4379-b22b-748655a5be01 container env-test: <nil>
STEP: delete the pod
Jul  4 16:07:31.531: INFO: Waiting for pod pod-configmaps-1d1602d8-f4c4-4379-b22b-748655a5be01 to disappear
Jul  4 16:07:31.533: INFO: Pod pod-configmaps-1d1602d8-f4c4-4379-b22b-748655a5be01 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Jul  4 16:07:31.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2268" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":185,"skipped":3373,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:31.539: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:07:31.557: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91df67ee-1c54-4087-aeca-2fcc81c93ac9" in namespace "projected-3090" to be "Succeeded or Failed"
Jul  4 16:07:31.559: INFO: Pod "downwardapi-volume-91df67ee-1c54-4087-aeca-2fcc81c93ac9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.861781ms
Jul  4 16:07:33.565: INFO: Pod "downwardapi-volume-91df67ee-1c54-4087-aeca-2fcc81c93ac9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00740476s
Jul  4 16:07:35.569: INFO: Pod "downwardapi-volume-91df67ee-1c54-4087-aeca-2fcc81c93ac9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011851661s
STEP: Saw pod success
Jul  4 16:07:35.569: INFO: Pod "downwardapi-volume-91df67ee-1c54-4087-aeca-2fcc81c93ac9" satisfied condition "Succeeded or Failed"
Jul  4 16:07:35.571: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-91df67ee-1c54-4087-aeca-2fcc81c93ac9 container client-container: <nil>
STEP: delete the pod
Jul  4 16:07:35.591: INFO: Waiting for pod downwardapi-volume-91df67ee-1c54-4087-aeca-2fcc81c93ac9 to disappear
Jul  4 16:07:35.593: INFO: Pod downwardapi-volume-91df67ee-1c54-4087-aeca-2fcc81c93ac9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 16:07:35.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3090" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":186,"skipped":3381,"failed":0}
SSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:35.598: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's args
Jul  4 16:07:35.620: INFO: Waiting up to 5m0s for pod "var-expansion-e1b90159-1dfd-4100-a59f-0125cfd127e3" in namespace "var-expansion-4063" to be "Succeeded or Failed"
Jul  4 16:07:35.623: INFO: Pod "var-expansion-e1b90159-1dfd-4100-a59f-0125cfd127e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.644221ms
Jul  4 16:07:37.630: INFO: Pod "var-expansion-e1b90159-1dfd-4100-a59f-0125cfd127e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010101442s
Jul  4 16:07:39.634: INFO: Pod "var-expansion-e1b90159-1dfd-4100-a59f-0125cfd127e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013983681s
STEP: Saw pod success
Jul  4 16:07:39.634: INFO: Pod "var-expansion-e1b90159-1dfd-4100-a59f-0125cfd127e3" satisfied condition "Succeeded or Failed"
Jul  4 16:07:39.636: INFO: Trying to get logs from node 18.216.149.32 pod var-expansion-e1b90159-1dfd-4100-a59f-0125cfd127e3 container dapi-container: <nil>
STEP: delete the pod
Jul  4 16:07:39.646: INFO: Waiting for pod var-expansion-e1b90159-1dfd-4100-a59f-0125cfd127e3 to disappear
Jul  4 16:07:39.648: INFO: Pod var-expansion-e1b90159-1dfd-4100-a59f-0125cfd127e3 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  4 16:07:39.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4063" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":356,"completed":187,"skipped":3387,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:39.654: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a collection of services
Jul  4 16:07:39.670: INFO: Creating e2e-svc-a-2wk2h
Jul  4 16:07:39.676: INFO: Creating e2e-svc-b-4jf9p
Jul  4 16:07:39.683: INFO: Creating e2e-svc-c-m2nm2
STEP: deleting service collection
Jul  4 16:07:39.706: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 16:07:39.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6044" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","total":356,"completed":188,"skipped":3422,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:39.713: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:07:39.731: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e872948b-0d31-4758-997c-c9472e7bc2e7" in namespace "downward-api-8682" to be "Succeeded or Failed"
Jul  4 16:07:39.733: INFO: Pod "downwardapi-volume-e872948b-0d31-4758-997c-c9472e7bc2e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005504ms
Jul  4 16:07:41.739: INFO: Pod "downwardapi-volume-e872948b-0d31-4758-997c-c9472e7bc2e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007514652s
Jul  4 16:07:43.747: INFO: Pod "downwardapi-volume-e872948b-0d31-4758-997c-c9472e7bc2e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015787784s
STEP: Saw pod success
Jul  4 16:07:43.747: INFO: Pod "downwardapi-volume-e872948b-0d31-4758-997c-c9472e7bc2e7" satisfied condition "Succeeded or Failed"
Jul  4 16:07:43.749: INFO: Trying to get logs from node 3.138.203.20 pod downwardapi-volume-e872948b-0d31-4758-997c-c9472e7bc2e7 container client-container: <nil>
STEP: delete the pod
Jul  4 16:07:43.762: INFO: Waiting for pod downwardapi-volume-e872948b-0d31-4758-997c-c9472e7bc2e7 to disappear
Jul  4 16:07:43.764: INFO: Pod downwardapi-volume-e872948b-0d31-4758-997c-c9472e7bc2e7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 16:07:43.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8682" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":189,"skipped":3430,"failed":0}

------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:43.769: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:07:43.783: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: creating the pod
STEP: submitting the pod to kubernetes
Jul  4 16:07:43.791: INFO: The status of Pod pod-logs-websocket-27244ff1-169c-4d0c-917a-03ca5dd1afb4 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:07:45.796: INFO: The status of Pod pod-logs-websocket-27244ff1-169c-4d0c-917a-03ca5dd1afb4 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  4 16:07:45.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2072" for this suite.
•{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":356,"completed":190,"skipped":3430,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:45.813: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Jul  4 16:07:45.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-836" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":191,"skipped":3458,"failed":0}

------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:45.868: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test env composition
Jul  4 16:07:45.884: INFO: Waiting up to 5m0s for pod "var-expansion-d6268b8e-aa72-430c-ae24-b028f37f10be" in namespace "var-expansion-12" to be "Succeeded or Failed"
Jul  4 16:07:45.886: INFO: Pod "var-expansion-d6268b8e-aa72-430c-ae24-b028f37f10be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067902ms
Jul  4 16:07:47.894: INFO: Pod "var-expansion-d6268b8e-aa72-430c-ae24-b028f37f10be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009567825s
Jul  4 16:07:49.898: INFO: Pod "var-expansion-d6268b8e-aa72-430c-ae24-b028f37f10be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01414056s
STEP: Saw pod success
Jul  4 16:07:49.898: INFO: Pod "var-expansion-d6268b8e-aa72-430c-ae24-b028f37f10be" satisfied condition "Succeeded or Failed"
Jul  4 16:07:49.900: INFO: Trying to get logs from node 18.216.149.32 pod var-expansion-d6268b8e-aa72-430c-ae24-b028f37f10be container dapi-container: <nil>
STEP: delete the pod
Jul  4 16:07:49.913: INFO: Waiting for pod var-expansion-d6268b8e-aa72-430c-ae24-b028f37f10be to disappear
Jul  4 16:07:49.915: INFO: Pod var-expansion-d6268b8e-aa72-430c-ae24-b028f37f10be no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  4 16:07:49.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-12" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":356,"completed":192,"skipped":3458,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:49.921: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Jul  4 16:07:49.951: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:07:51.957: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Jul  4 16:07:51.966: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:07:53.970: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul  4 16:07:53.980: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul  4 16:07:53.984: INFO: Pod pod-with-poststart-http-hook still exists
Jul  4 16:07:55.985: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul  4 16:07:55.989: INFO: Pod pod-with-poststart-http-hook still exists
Jul  4 16:07:57.984: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul  4 16:07:57.992: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Jul  4 16:07:57.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8616" for this suite.

• [SLOW TEST:8.078 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":356,"completed":193,"skipped":3493,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:07:57.999: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  4 16:07:58.032: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:58.032: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:07:59.040: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:07:59.040: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:08:00.039: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  4 16:08:00.039: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jul  4 16:08:00.052: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  4 16:08:00.052: INFO: Node 3.138.203.20 is running 0 daemon pod, expected 1
Jul  4 16:08:01.059: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  4 16:08:01.059: INFO: Node 3.138.203.20 is running 0 daemon pod, expected 1
Jul  4 16:08:02.061: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  4 16:08:02.061: INFO: Node 3.138.203.20 is running 0 daemon pod, expected 1
Jul  4 16:08:03.061: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  4 16:08:03.061: INFO: Node 3.138.203.20 is running 0 daemon pod, expected 1
Jul  4 16:08:04.067: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  4 16:08:04.067: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9850, will wait for the garbage collector to delete the pods
Jul  4 16:08:04.124: INFO: Deleting DaemonSet.extensions daemon-set took: 3.282997ms
Jul  4 16:08:04.224: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.408083ms
Jul  4 16:08:06.428: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:08:06.428: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  4 16:08:06.430: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20117"},"items":null}

Jul  4 16:08:06.432: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20117"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:08:06.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9850" for this suite.

• [SLOW TEST:8.447 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":356,"completed":194,"skipped":3510,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:08:06.447: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-0739958a-7dd6-4238-8c67-44958d6b9159
STEP: Creating a pod to test consume secrets
Jul  4 16:08:06.469: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8c3bc998-5147-42cb-8501-75b9ab5e0575" in namespace "projected-4426" to be "Succeeded or Failed"
Jul  4 16:08:06.471: INFO: Pod "pod-projected-secrets-8c3bc998-5147-42cb-8501-75b9ab5e0575": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090961ms
Jul  4 16:08:08.478: INFO: Pod "pod-projected-secrets-8c3bc998-5147-42cb-8501-75b9ab5e0575": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009309484s
Jul  4 16:08:10.482: INFO: Pod "pod-projected-secrets-8c3bc998-5147-42cb-8501-75b9ab5e0575": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013279418s
STEP: Saw pod success
Jul  4 16:08:10.482: INFO: Pod "pod-projected-secrets-8c3bc998-5147-42cb-8501-75b9ab5e0575" satisfied condition "Succeeded or Failed"
Jul  4 16:08:10.484: INFO: Trying to get logs from node 18.216.149.32 pod pod-projected-secrets-8c3bc998-5147-42cb-8501-75b9ab5e0575 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  4 16:08:10.497: INFO: Waiting for pod pod-projected-secrets-8c3bc998-5147-42cb-8501-75b9ab5e0575 to disappear
Jul  4 16:08:10.499: INFO: Pod pod-projected-secrets-8c3bc998-5147-42cb-8501-75b9ab5e0575 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  4 16:08:10.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4426" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":195,"skipped":3533,"failed":0}
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:08:10.505: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
Jul  4 16:08:10.526: INFO: Pod name sample-pod: Found 0 pods out of 3
Jul  4 16:08:15.530: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
Jul  4 16:08:15.531: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  4 16:08:15.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2895" for this suite.

• [SLOW TEST:5.051 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":356,"completed":196,"skipped":3537,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:08:15.556: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jul  4 16:08:15.608: INFO: Pod name pod-release: Found 0 pods out of 1
Jul  4 16:08:20.611: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  4 16:08:21.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8153" for this suite.

• [SLOW TEST:6.077 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":356,"completed":197,"skipped":3582,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:08:21.634: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-gqcl
STEP: Creating a pod to test atomic-volume-subpath
Jul  4 16:08:21.655: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gqcl" in namespace "subpath-8504" to be "Succeeded or Failed"
Jul  4 16:08:21.660: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.431096ms
Jul  4 16:08:23.666: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 2.010695187s
Jul  4 16:08:25.671: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 4.015500974s
Jul  4 16:08:27.678: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 6.022803248s
Jul  4 16:08:29.682: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 8.027336757s
Jul  4 16:08:31.688: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 10.032675254s
Jul  4 16:08:33.692: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 12.036440691s
Jul  4 16:08:35.697: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 14.041755122s
Jul  4 16:08:37.705: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 16.049382363s
Jul  4 16:08:39.709: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 18.053778129s
Jul  4 16:08:41.715: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=true. Elapsed: 20.060223165s
Jul  4 16:08:43.723: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Running", Reason="", readiness=false. Elapsed: 22.068054403s
Jul  4 16:08:45.728: INFO: Pod "pod-subpath-test-configmap-gqcl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.073055972s
STEP: Saw pod success
Jul  4 16:08:45.728: INFO: Pod "pod-subpath-test-configmap-gqcl" satisfied condition "Succeeded or Failed"
Jul  4 16:08:45.730: INFO: Trying to get logs from node 3.138.203.20 pod pod-subpath-test-configmap-gqcl container test-container-subpath-configmap-gqcl: <nil>
STEP: delete the pod
Jul  4 16:08:45.745: INFO: Waiting for pod pod-subpath-test-configmap-gqcl to disappear
Jul  4 16:08:45.747: INFO: Pod pod-subpath-test-configmap-gqcl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gqcl
Jul  4 16:08:45.747: INFO: Deleting pod "pod-subpath-test-configmap-gqcl" in namespace "subpath-8504"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  4 16:08:45.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8504" for this suite.

• [SLOW TEST:24.120 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","total":356,"completed":198,"skipped":3601,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:08:45.754: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:08:45.779: INFO: created pod pod-service-account-defaultsa
Jul  4 16:08:45.779: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jul  4 16:08:45.784: INFO: created pod pod-service-account-mountsa
Jul  4 16:08:45.784: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jul  4 16:08:45.787: INFO: created pod pod-service-account-nomountsa
Jul  4 16:08:45.787: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jul  4 16:08:45.795: INFO: created pod pod-service-account-defaultsa-mountspec
Jul  4 16:08:45.795: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jul  4 16:08:45.802: INFO: created pod pod-service-account-mountsa-mountspec
Jul  4 16:08:45.802: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jul  4 16:08:45.805: INFO: created pod pod-service-account-nomountsa-mountspec
Jul  4 16:08:45.805: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jul  4 16:08:45.815: INFO: created pod pod-service-account-defaultsa-nomountspec
Jul  4 16:08:45.815: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jul  4 16:08:45.820: INFO: created pod pod-service-account-mountsa-nomountspec
Jul  4 16:08:45.820: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jul  4 16:08:45.827: INFO: created pod pod-service-account-nomountsa-nomountspec
Jul  4 16:08:45.827: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  4 16:08:45.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1558" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":356,"completed":199,"skipped":3617,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:08:45.847: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's command
Jul  4 16:08:45.911: INFO: Waiting up to 5m0s for pod "var-expansion-5a6f28af-76a3-47cd-a5dc-9fbe2b9a77d0" in namespace "var-expansion-8667" to be "Succeeded or Failed"
Jul  4 16:08:45.915: INFO: Pod "var-expansion-5a6f28af-76a3-47cd-a5dc-9fbe2b9a77d0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.619221ms
Jul  4 16:08:47.921: INFO: Pod "var-expansion-5a6f28af-76a3-47cd-a5dc-9fbe2b9a77d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010233463s
Jul  4 16:08:49.926: INFO: Pod "var-expansion-5a6f28af-76a3-47cd-a5dc-9fbe2b9a77d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014635075s
STEP: Saw pod success
Jul  4 16:08:49.926: INFO: Pod "var-expansion-5a6f28af-76a3-47cd-a5dc-9fbe2b9a77d0" satisfied condition "Succeeded or Failed"
Jul  4 16:08:49.928: INFO: Trying to get logs from node 3.138.203.20 pod var-expansion-5a6f28af-76a3-47cd-a5dc-9fbe2b9a77d0 container dapi-container: <nil>
STEP: delete the pod
Jul  4 16:08:49.942: INFO: Waiting for pod var-expansion-5a6f28af-76a3-47cd-a5dc-9fbe2b9a77d0 to disappear
Jul  4 16:08:49.945: INFO: Pod var-expansion-5a6f28af-76a3-47cd-a5dc-9fbe2b9a77d0 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  4 16:08:49.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8667" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":356,"completed":200,"skipped":3647,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:08:49.951: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  4 16:08:49.973: INFO: Waiting up to 5m0s for pod "downward-api-438557c9-d9c3-49ef-b2b2-ec06d42760c5" in namespace "downward-api-4453" to be "Succeeded or Failed"
Jul  4 16:08:49.975: INFO: Pod "downward-api-438557c9-d9c3-49ef-b2b2-ec06d42760c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.343952ms
Jul  4 16:08:51.980: INFO: Pod "downward-api-438557c9-d9c3-49ef-b2b2-ec06d42760c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007292165s
Jul  4 16:08:53.988: INFO: Pod "downward-api-438557c9-d9c3-49ef-b2b2-ec06d42760c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015347215s
STEP: Saw pod success
Jul  4 16:08:53.988: INFO: Pod "downward-api-438557c9-d9c3-49ef-b2b2-ec06d42760c5" satisfied condition "Succeeded or Failed"
Jul  4 16:08:53.990: INFO: Trying to get logs from node 18.224.151.13 pod downward-api-438557c9-d9c3-49ef-b2b2-ec06d42760c5 container dapi-container: <nil>
STEP: delete the pod
Jul  4 16:08:54.009: INFO: Waiting for pod downward-api-438557c9-d9c3-49ef-b2b2-ec06d42760c5 to disappear
Jul  4 16:08:54.011: INFO: Pod downward-api-438557c9-d9c3-49ef-b2b2-ec06d42760c5 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  4 16:08:54.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4453" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":356,"completed":201,"skipped":3649,"failed":0}
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:08:54.018: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:08:54.041: INFO: created pod
Jul  4 16:08:54.041: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-1627" to be "Succeeded or Failed"
Jul  4 16:08:54.043: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.770716ms
Jul  4 16:08:56.049: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00764634s
Jul  4 16:08:58.055: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01397568s
STEP: Saw pod success
Jul  4 16:08:58.055: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Jul  4 16:09:28.056: INFO: polling logs
Jul  4 16:09:28.063: INFO: Pod logs: 
I0704 16:08:54.924369       1 log.go:195] OK: Got token
I0704 16:08:54.924416       1 log.go:195] validating with in-cluster discovery
I0704 16:08:54.924686       1 log.go:195] OK: got issuer https://18.224.151.13:6443
I0704 16:08:54.924718       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://18.224.151.13:6443", Subject:"system:serviceaccount:svcaccounts-1627:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1656951534, NotBefore:1656950934, IssuedAt:1656950934, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1627", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e9ff8a8b-8100-440b-a31e-95a7c32490f8"}}}
I0704 16:08:54.933247       1 log.go:195] OK: Constructed OIDC provider for issuer https://18.224.151.13:6443
I0704 16:08:54.939150       1 log.go:195] OK: Validated signature on JWT
I0704 16:08:54.939232       1 log.go:195] OK: Got valid claims from token!
I0704 16:08:54.939267       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://18.224.151.13:6443", Subject:"system:serviceaccount:svcaccounts-1627:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1656951534, NotBefore:1656950934, IssuedAt:1656950934, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1627", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e9ff8a8b-8100-440b-a31e-95a7c32490f8"}}}

Jul  4 16:09:28.063: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  4 16:09:28.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1627" for this suite.

• [SLOW TEST:34.060 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":356,"completed":202,"skipped":3654,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:28.079: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  4 16:09:28.109: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Jul  4 16:09:28.112: INFO: starting watch
STEP: patching
STEP: updating
Jul  4 16:09:28.120: INFO: waiting for watch events with expected annotations
Jul  4 16:09:28.121: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Jul  4 16:09:28.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9468" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":356,"completed":203,"skipped":3716,"failed":0}

------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:28.141: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jul  4 16:09:28.161: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9740  038edeac-44af-4259-86b4-ffaab8122c02 20623 0 2022-07-04 16:09:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-07-04 16:09:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:09:28.161: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9740  038edeac-44af-4259-86b4-ffaab8122c02 20624 0 2022-07-04 16:09:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-07-04 16:09:28 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jul  4 16:09:28.169: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9740  038edeac-44af-4259-86b4-ffaab8122c02 20625 0 2022-07-04 16:09:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-07-04 16:09:28 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:09:28.169: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9740  038edeac-44af-4259-86b4-ffaab8122c02 20626 0 2022-07-04 16:09:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-07-04 16:09:28 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  4 16:09:28.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9740" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":356,"completed":204,"skipped":3716,"failed":0}
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:28.174: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  4 16:09:28.193: INFO: Waiting up to 5m0s for pod "downward-api-9dc49aed-5393-4e8f-a060-70e9beb99c36" in namespace "downward-api-8441" to be "Succeeded or Failed"
Jul  4 16:09:28.196: INFO: Pod "downward-api-9dc49aed-5393-4e8f-a060-70e9beb99c36": Phase="Pending", Reason="", readiness=false. Elapsed: 3.287565ms
Jul  4 16:09:30.199: INFO: Pod "downward-api-9dc49aed-5393-4e8f-a060-70e9beb99c36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006514702s
Jul  4 16:09:32.205: INFO: Pod "downward-api-9dc49aed-5393-4e8f-a060-70e9beb99c36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01213626s
STEP: Saw pod success
Jul  4 16:09:32.205: INFO: Pod "downward-api-9dc49aed-5393-4e8f-a060-70e9beb99c36" satisfied condition "Succeeded or Failed"
Jul  4 16:09:32.207: INFO: Trying to get logs from node 3.138.203.20 pod downward-api-9dc49aed-5393-4e8f-a060-70e9beb99c36 container dapi-container: <nil>
STEP: delete the pod
Jul  4 16:09:32.218: INFO: Waiting for pod downward-api-9dc49aed-5393-4e8f-a060-70e9beb99c36 to disappear
Jul  4 16:09:32.220: INFO: Pod downward-api-9dc49aed-5393-4e8f-a060-70e9beb99c36 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  4 16:09:32.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8441" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":356,"completed":205,"skipped":3720,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:32.225: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Jul  4 16:09:32.254: INFO: The status of Pod labelsupdate041e3dcf-1ac7-4883-822a-5a5e1196f0f5 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:09:34.262: INFO: The status of Pod labelsupdate041e3dcf-1ac7-4883-822a-5a5e1196f0f5 is Running (Ready = true)
Jul  4 16:09:34.781: INFO: Successfully updated pod "labelsupdate041e3dcf-1ac7-4883-822a-5a5e1196f0f5"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 16:09:36.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6509" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":206,"skipped":3721,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:36.808: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-60187eeb-f292-4052-bfeb-e32f1516355c
STEP: Creating a pod to test consume configMaps
Jul  4 16:09:36.834: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7979af02-4b5d-4bdc-be71-3c89e78e8b23" in namespace "projected-1437" to be "Succeeded or Failed"
Jul  4 16:09:36.837: INFO: Pod "pod-projected-configmaps-7979af02-4b5d-4bdc-be71-3c89e78e8b23": Phase="Pending", Reason="", readiness=false. Elapsed: 3.281132ms
Jul  4 16:09:38.844: INFO: Pod "pod-projected-configmaps-7979af02-4b5d-4bdc-be71-3c89e78e8b23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010550729s
Jul  4 16:09:40.850: INFO: Pod "pod-projected-configmaps-7979af02-4b5d-4bdc-be71-3c89e78e8b23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015945382s
STEP: Saw pod success
Jul  4 16:09:40.850: INFO: Pod "pod-projected-configmaps-7979af02-4b5d-4bdc-be71-3c89e78e8b23" satisfied condition "Succeeded or Failed"
Jul  4 16:09:40.852: INFO: Trying to get logs from node 18.224.151.13 pod pod-projected-configmaps-7979af02-4b5d-4bdc-be71-3c89e78e8b23 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul  4 16:09:40.865: INFO: Waiting for pod pod-projected-configmaps-7979af02-4b5d-4bdc-be71-3c89e78e8b23 to disappear
Jul  4 16:09:40.867: INFO: Pod pod-projected-configmaps-7979af02-4b5d-4bdc-be71-3c89e78e8b23 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  4 16:09:40.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1437" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":207,"skipped":3734,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:40.874: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-6d8f8667-e16d-4e36-a3bb-76572d28633a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:09:42.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1602" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":208,"skipped":3838,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:42.937: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul  4 16:09:42.957: INFO: Waiting up to 5m0s for pod "pod-d84b62dd-74e7-42fa-9d35-b152c0bc0866" in namespace "emptydir-439" to be "Succeeded or Failed"
Jul  4 16:09:42.959: INFO: Pod "pod-d84b62dd-74e7-42fa-9d35-b152c0bc0866": Phase="Pending", Reason="", readiness=false. Elapsed: 2.741647ms
Jul  4 16:09:44.966: INFO: Pod "pod-d84b62dd-74e7-42fa-9d35-b152c0bc0866": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009593382s
Jul  4 16:09:46.974: INFO: Pod "pod-d84b62dd-74e7-42fa-9d35-b152c0bc0866": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017557657s
STEP: Saw pod success
Jul  4 16:09:46.974: INFO: Pod "pod-d84b62dd-74e7-42fa-9d35-b152c0bc0866" satisfied condition "Succeeded or Failed"
Jul  4 16:09:46.976: INFO: Trying to get logs from node 3.138.203.20 pod pod-d84b62dd-74e7-42fa-9d35-b152c0bc0866 container test-container: <nil>
STEP: delete the pod
Jul  4 16:09:46.992: INFO: Waiting for pod pod-d84b62dd-74e7-42fa-9d35-b152c0bc0866 to disappear
Jul  4 16:09:46.994: INFO: Pod pod-d84b62dd-74e7-42fa-9d35-b152c0bc0866 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 16:09:46.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-439" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":209,"skipped":3861,"failed":0}
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:47.000: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:09:47.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3519" for this suite.
STEP: Destroying namespace "nspatchtest-094a7a03-e1ca-4f6a-9396-ab170e926c6d-4017" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":356,"completed":210,"skipped":3863,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:47.072: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:09:47.087: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:09:53.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6421" for this suite.

• [SLOW TEST:6.206 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":356,"completed":211,"skipped":3871,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:09:53.280: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:09:54.059: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:09:57.081: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:09:57.087: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1098-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:10:00.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9487" for this suite.
STEP: Destroying namespace "webhook-9487-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.931 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":356,"completed":212,"skipped":3889,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:00.211: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:10:00.238: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6ef10c5c-c74c-4bb8-b355-e12b017dd090" in namespace "projected-9343" to be "Succeeded or Failed"
Jul  4 16:10:00.240: INFO: Pod "downwardapi-volume-6ef10c5c-c74c-4bb8-b355-e12b017dd090": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005542ms
Jul  4 16:10:02.245: INFO: Pod "downwardapi-volume-6ef10c5c-c74c-4bb8-b355-e12b017dd090": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007790507s
Jul  4 16:10:04.259: INFO: Pod "downwardapi-volume-6ef10c5c-c74c-4bb8-b355-e12b017dd090": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021683605s
STEP: Saw pod success
Jul  4 16:10:04.259: INFO: Pod "downwardapi-volume-6ef10c5c-c74c-4bb8-b355-e12b017dd090" satisfied condition "Succeeded or Failed"
Jul  4 16:10:04.261: INFO: Trying to get logs from node 3.138.203.20 pod downwardapi-volume-6ef10c5c-c74c-4bb8-b355-e12b017dd090 container client-container: <nil>
STEP: delete the pod
Jul  4 16:10:04.275: INFO: Waiting for pod downwardapi-volume-6ef10c5c-c74c-4bb8-b355-e12b017dd090 to disappear
Jul  4 16:10:04.277: INFO: Pod downwardapi-volume-6ef10c5c-c74c-4bb8-b355-e12b017dd090 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 16:10:04.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9343" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":213,"skipped":3896,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:04.283: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Jul  4 16:10:04.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9263" for this suite.
•{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":356,"completed":214,"skipped":3906,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:04.318: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
Jul  4 16:10:06.351: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  4 16:10:08.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6443" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":356,"completed":215,"skipped":3914,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:08.384: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name projected-secret-test-12dbce13-ee88-4ac7-b0e0-52974b931ea6
STEP: Creating a pod to test consume secrets
Jul  4 16:10:08.412: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-82242da3-d3a9-41b9-8d5b-d96a057cfbb7" in namespace "projected-1606" to be "Succeeded or Failed"
Jul  4 16:10:08.414: INFO: Pod "pod-projected-secrets-82242da3-d3a9-41b9-8d5b-d96a057cfbb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.771168ms
Jul  4 16:10:10.417: INFO: Pod "pod-projected-secrets-82242da3-d3a9-41b9-8d5b-d96a057cfbb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005509387s
Jul  4 16:10:12.424: INFO: Pod "pod-projected-secrets-82242da3-d3a9-41b9-8d5b-d96a057cfbb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011646213s
STEP: Saw pod success
Jul  4 16:10:12.424: INFO: Pod "pod-projected-secrets-82242da3-d3a9-41b9-8d5b-d96a057cfbb7" satisfied condition "Succeeded or Failed"
Jul  4 16:10:12.425: INFO: Trying to get logs from node 18.224.151.13 pod pod-projected-secrets-82242da3-d3a9-41b9-8d5b-d96a057cfbb7 container secret-volume-test: <nil>
STEP: delete the pod
Jul  4 16:10:12.442: INFO: Waiting for pod pod-projected-secrets-82242da3-d3a9-41b9-8d5b-d96a057cfbb7 to disappear
Jul  4 16:10:12.444: INFO: Pod pod-projected-secrets-82242da3-d3a9-41b9-8d5b-d96a057cfbb7 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  4 16:10:12.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1606" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":216,"skipped":3915,"failed":0}
S
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:12.450: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
Jul  4 16:10:12.467: INFO: Creating simple deployment test-deployment-4b2c6
Jul  4 16:10:12.476: INFO: deployment "test-deployment-4b2c6" doesn't have the required revision set
STEP: Getting /status
Jul  4 16:10:14.491: INFO: Deployment test-deployment-4b2c6 has Conditions: [{Available True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4b2c6-688c4d6789" has successfully progressed.}]
STEP: updating Deployment Status
Jul  4 16:10:14.497: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 16, 10, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 16, 10, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 16, 10, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 16, 10, 12, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-4b2c6-688c4d6789\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
Jul  4 16:10:14.498: INFO: Observed &Deployment event: ADDED
Jul  4 16:10:14.498: INFO: Observed Deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4b2c6-688c4d6789"}
Jul  4 16:10:14.499: INFO: Observed &Deployment event: MODIFIED
Jul  4 16:10:14.499: INFO: Observed Deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4b2c6-688c4d6789"}
Jul  4 16:10:14.499: INFO: Observed Deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul  4 16:10:14.499: INFO: Observed &Deployment event: MODIFIED
Jul  4 16:10:14.499: INFO: Observed Deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul  4 16:10:14.499: INFO: Observed Deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4b2c6-688c4d6789" is progressing.}
Jul  4 16:10:14.499: INFO: Observed &Deployment event: MODIFIED
Jul  4 16:10:14.499: INFO: Observed Deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul  4 16:10:14.499: INFO: Observed Deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4b2c6-688c4d6789" has successfully progressed.}
Jul  4 16:10:14.499: INFO: Observed &Deployment event: MODIFIED
Jul  4 16:10:14.499: INFO: Observed Deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul  4 16:10:14.499: INFO: Observed Deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4b2c6-688c4d6789" has successfully progressed.}
Jul  4 16:10:14.499: INFO: Found Deployment test-deployment-4b2c6 in namespace deployment-1137 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul  4 16:10:14.499: INFO: Deployment test-deployment-4b2c6 has an updated status
STEP: patching the Statefulset Status
Jul  4 16:10:14.499: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jul  4 16:10:14.504: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
Jul  4 16:10:14.506: INFO: Observed &Deployment event: ADDED
Jul  4 16:10:14.506: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4b2c6-688c4d6789"}
Jul  4 16:10:14.506: INFO: Observed &Deployment event: MODIFIED
Jul  4 16:10:14.506: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4b2c6-688c4d6789"}
Jul  4 16:10:14.506: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul  4 16:10:14.506: INFO: Observed &Deployment event: MODIFIED
Jul  4 16:10:14.507: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul  4 16:10:14.507: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:12 +0000 UTC 2022-07-04 16:10:12 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4b2c6-688c4d6789" is progressing.}
Jul  4 16:10:14.507: INFO: Observed &Deployment event: MODIFIED
Jul  4 16:10:14.507: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul  4 16:10:14.507: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4b2c6-688c4d6789" has successfully progressed.}
Jul  4 16:10:14.507: INFO: Observed &Deployment event: MODIFIED
Jul  4 16:10:14.507: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul  4 16:10:14.507: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-04 16:10:14 +0000 UTC 2022-07-04 16:10:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4b2c6-688c4d6789" has successfully progressed.}
Jul  4 16:10:14.507: INFO: Observed deployment test-deployment-4b2c6 in namespace deployment-1137 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul  4 16:10:14.507: INFO: Observed &Deployment event: MODIFIED
Jul  4 16:10:14.508: INFO: Found deployment test-deployment-4b2c6 in namespace deployment-1137 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Jul  4 16:10:14.508: INFO: Deployment test-deployment-4b2c6 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  4 16:10:14.512: INFO: Deployment "test-deployment-4b2c6":
&Deployment{ObjectMeta:{test-deployment-4b2c6  deployment-1137  ce6b7e85-2048-4e7f-94a9-9667d5c1ab0d 21114 1 2022-07-04 16:10:12 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-07-04 16:10:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-07-04 16:10:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-07-04 16:10:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004315ea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-4b2c6-688c4d6789",LastUpdateTime:2022-07-04 16:10:14 +0000 UTC,LastTransitionTime:2022-07-04 16:10:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul  4 16:10:14.514: INFO: New ReplicaSet "test-deployment-4b2c6-688c4d6789" of Deployment "test-deployment-4b2c6":
&ReplicaSet{ObjectMeta:{test-deployment-4b2c6-688c4d6789  deployment-1137  846f97ef-5ce1-4c94-8493-6687874a32bf 21110 1 2022-07-04 16:10:12 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-4b2c6 ce6b7e85-2048-4e7f-94a9-9667d5c1ab0d 0xc0043f8270 0xc0043f8271}] []  [{kube-controller-manager Update apps/v1 2022-07-04 16:10:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce6b7e85-2048-4e7f-94a9-9667d5c1ab0d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 16:10:14 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 688c4d6789,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043f8318 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul  4 16:10:14.516: INFO: Pod "test-deployment-4b2c6-688c4d6789-plvnx" is available:
&Pod{ObjectMeta:{test-deployment-4b2c6-688c4d6789-plvnx test-deployment-4b2c6-688c4d6789- deployment-1137  6cb102c9-9c6d-4ba9-bea6-bad338b39118 21109 0 2022-07-04 16:10:12 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[cni.projectcalico.org/containerID:ada34d21a5980a81b3c4e4e467318a5d5e61efd7ab84d91bb512f9484ee7d029 cni.projectcalico.org/podIP:10.42.0.154/32 cni.projectcalico.org/podIPs:10.42.0.154/32] [{apps/v1 ReplicaSet test-deployment-4b2c6-688c4d6789 846f97ef-5ce1-4c94-8493-6687874a32bf 0xc00400db70 0xc00400db71}] []  [{kube-controller-manager Update v1 2022-07-04 16:10:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"846f97ef-5ce1-4c94-8493-6687874a32bf\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 16:10:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 16:10:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.154\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5khfd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5khfd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:10:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:10:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:10:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:10:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.73,PodIP:10.42.0.154,StartTime:2022-07-04 16:10:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 16:10:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://fc06dad03d692a955553313748c9c31a593f692809e8160d9192c54d5f883ee5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.154,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  4 16:10:14.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1137" for this suite.
•{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":356,"completed":217,"skipped":3916,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:14.522: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:10:14.538: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: creating the pod
STEP: submitting the pod to kubernetes
Jul  4 16:10:14.545: INFO: The status of Pod pod-exec-websocket-6a3f0512-90ba-4f25-a139-b974e5da60f1 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:10:16.550: INFO: The status of Pod pod-exec-websocket-6a3f0512-90ba-4f25-a139-b974e5da60f1 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  4 16:10:16.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8036" for this suite.
•{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":356,"completed":218,"skipped":3951,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:16.629: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:10:16.651: INFO: The status of Pod busybox-readonly-fs2cf45265-6e5e-492b-aab1-9f144e07c030 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:10:18.658: INFO: The status of Pod busybox-readonly-fs2cf45265-6e5e-492b-aab1-9f144e07c030 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  4 16:10:18.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3396" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":219,"skipped":3980,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:18.675: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:10:18.712: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:10:21.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1351" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":356,"completed":220,"skipped":4005,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:21.834: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-3478
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  4 16:10:21.848: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul  4 16:10:21.870: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:10:23.878: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:10:25.875: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:10:27.876: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:10:29.875: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:10:31.874: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:10:33.877: INFO: The status of Pod netserver-0 is Running (Ready = true)
Jul  4 16:10:33.881: INFO: The status of Pod netserver-1 is Running (Ready = true)
Jul  4 16:10:33.885: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Jul  4 16:10:35.898: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul  4 16:10:35.898: INFO: Breadth first check of 10.42.2.225 on host 172.31.20.100...
Jul  4 16:10:35.900: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.156:9080/dial?request=hostname&protocol=http&host=10.42.2.225&port=8083&tries=1'] Namespace:pod-network-test-3478 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:10:35.900: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:10:35.901: INFO: ExecWithOptions: Clientset creation
Jul  4 16:10:35.901: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-3478/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.0.156%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.2.225%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  4 16:10:35.979: INFO: Waiting for responses: map[]
Jul  4 16:10:35.979: INFO: reached 10.42.2.225 after 0/1 tries
Jul  4 16:10:35.979: INFO: Breadth first check of 10.42.0.155 on host 172.31.25.73...
Jul  4 16:10:35.982: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.156:9080/dial?request=hostname&protocol=http&host=10.42.0.155&port=8083&tries=1'] Namespace:pod-network-test-3478 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:10:35.982: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:10:35.983: INFO: ExecWithOptions: Clientset creation
Jul  4 16:10:35.983: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-3478/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.0.156%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.0.155%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  4 16:10:36.059: INFO: Waiting for responses: map[]
Jul  4 16:10:36.059: INFO: reached 10.42.0.155 after 0/1 tries
Jul  4 16:10:36.059: INFO: Breadth first check of 10.42.1.226 on host 172.31.23.66...
Jul  4 16:10:36.062: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.156:9080/dial?request=hostname&protocol=http&host=10.42.1.226&port=8083&tries=1'] Namespace:pod-network-test-3478 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:10:36.062: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:10:36.063: INFO: ExecWithOptions: Clientset creation
Jul  4 16:10:36.063: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-3478/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.0.156%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.42.1.226%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  4 16:10:36.136: INFO: Waiting for responses: map[]
Jul  4 16:10:36.136: INFO: reached 10.42.1.226 after 0/1 tries
Jul  4 16:10:36.136: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Jul  4 16:10:36.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3478" for this suite.

• [SLOW TEST:14.315 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":356,"completed":221,"skipped":4033,"failed":0}
SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:36.149: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-e8cef59a-2e5e-4e73-953c-bcd39e2ecb1d
STEP: Creating the pod
Jul  4 16:10:36.183: INFO: The status of Pod pod-configmaps-fd4f3a16-ba1e-41f9-a558-85b6e1750ae6 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:10:38.188: INFO: The status of Pod pod-configmaps-fd4f3a16-ba1e-41f9-a558-85b6e1750ae6 is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-e8cef59a-2e5e-4e73-953c-bcd39e2ecb1d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:10:40.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3487" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":222,"skipped":4036,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:10:40.218: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-872
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-872
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-872
Jul  4 16:10:40.247: INFO: Found 0 stateful pods, waiting for 1
Jul  4 16:10:50.251: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jul  4 16:10:50.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-872 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:10:50.389: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:10:50.389: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:10:50.389: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  4 16:10:50.392: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul  4 16:11:00.397: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  4 16:11:00.397: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 16:11:00.406: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998632s
Jul  4 16:11:01.411: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997974173s
Jul  4 16:11:02.416: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992983786s
Jul  4 16:11:03.421: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988406069s
Jul  4 16:11:04.426: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982629864s
Jul  4 16:11:05.430: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977516986s
Jul  4 16:11:06.437: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.973187619s
Jul  4 16:11:07.443: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967394943s
Jul  4 16:11:08.449: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.960739969s
Jul  4 16:11:09.455: INFO: Verifying statefulset ss doesn't scale past 1 for another 954.936466ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-872
Jul  4 16:11:10.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-872 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  4 16:11:10.596: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  4 16:11:10.596: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  4 16:11:10.596: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  4 16:11:10.598: INFO: Found 1 stateful pods, waiting for 3
Jul  4 16:11:20.604: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 16:11:20.604: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 16:11:20.604: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jul  4 16:11:20.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-872 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:11:20.742: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:11:20.742: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:11:20.742: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  4 16:11:20.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-872 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:11:20.878: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:11:20.878: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:11:20.878: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  4 16:11:20.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-872 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:11:21.061: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:11:21.061: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:11:21.061: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  4 16:11:21.061: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 16:11:21.065: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jul  4 16:11:31.072: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  4 16:11:31.072: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul  4 16:11:31.072: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul  4 16:11:31.081: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998414s
Jul  4 16:11:32.084: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997450327s
Jul  4 16:11:33.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993850976s
Jul  4 16:11:34.094: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988156249s
Jul  4 16:11:35.101: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983839913s
Jul  4 16:11:36.106: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.97687053s
Jul  4 16:11:37.113: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971663972s
Jul  4 16:11:38.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964925089s
Jul  4 16:11:39.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960108483s
Jul  4 16:11:40.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 953.970444ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-872
Jul  4 16:11:41.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-872 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  4 16:11:41.265: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  4 16:11:41.265: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  4 16:11:41.265: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  4 16:11:41.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-872 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  4 16:11:41.391: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  4 16:11:41.391: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  4 16:11:41.391: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  4 16:11:41.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-872 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  4 16:11:41.518: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  4 16:11:41.518: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  4 16:11:41.518: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  4 16:11:41.518: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  4 16:11:51.534: INFO: Deleting all statefulset in ns statefulset-872
Jul  4 16:11:51.536: INFO: Scaling statefulset ss to 0
Jul  4 16:11:51.544: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 16:11:51.546: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  4 16:11:51.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-872" for this suite.

• [SLOW TEST:71.343 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":356,"completed":223,"skipped":4082,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:11:51.561: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jul  4 16:11:51.582: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  4 16:11:56.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1438" for this suite.
•{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":356,"completed":224,"skipped":4095,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:11:56.282: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-080a4d6b-86f0-4e2b-9293-b963d703a03e
STEP: Creating a pod to test consume configMaps
Jul  4 16:11:56.307: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-428447e8-d5fd-46b5-b680-2da2a5026d3d" in namespace "projected-1639" to be "Succeeded or Failed"
Jul  4 16:11:56.309: INFO: Pod "pod-projected-configmaps-428447e8-d5fd-46b5-b680-2da2a5026d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.923182ms
Jul  4 16:11:58.316: INFO: Pod "pod-projected-configmaps-428447e8-d5fd-46b5-b680-2da2a5026d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008730268s
Jul  4 16:12:00.319: INFO: Pod "pod-projected-configmaps-428447e8-d5fd-46b5-b680-2da2a5026d3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012427857s
STEP: Saw pod success
Jul  4 16:12:00.319: INFO: Pod "pod-projected-configmaps-428447e8-d5fd-46b5-b680-2da2a5026d3d" satisfied condition "Succeeded or Failed"
Jul  4 16:12:00.321: INFO: Trying to get logs from node 18.216.149.32 pod pod-projected-configmaps-428447e8-d5fd-46b5-b680-2da2a5026d3d container agnhost-container: <nil>
STEP: delete the pod
Jul  4 16:12:00.344: INFO: Waiting for pod pod-projected-configmaps-428447e8-d5fd-46b5-b680-2da2a5026d3d to disappear
Jul  4 16:12:00.346: INFO: Pod pod-projected-configmaps-428447e8-d5fd-46b5-b680-2da2a5026d3d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  4 16:12:00.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1639" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":225,"skipped":4113,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:12:00.355: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensure pods equal to paralellism count is attached to the job
STEP: patching /status
STEP: updating /status
STEP: get /status
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  4 16:12:02.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3113" for this suite.
•{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","total":356,"completed":226,"skipped":4130,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:12:02.412: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service endpoint-test2 in namespace services-2646
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2646 to expose endpoints map[]
Jul  4 16:12:02.435: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Jul  4 16:12:03.443: INFO: successfully validated that service endpoint-test2 in namespace services-2646 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2646
Jul  4 16:12:03.451: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:12:05.455: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2646 to expose endpoints map[pod1:[80]]
Jul  4 16:12:05.462: INFO: successfully validated that service endpoint-test2 in namespace services-2646 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
Jul  4 16:12:05.462: INFO: Creating new exec pod
Jul  4 16:12:08.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-2646 exec execpodw7ncr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jul  4 16:12:08.596: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jul  4 16:12:08.596: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:12:08.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-2646 exec execpodw7ncr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.46.241 80'
Jul  4 16:12:08.723: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.46.241 80\nConnection to 10.43.46.241 80 port [tcp/http] succeeded!\n"
Jul  4 16:12:08.723: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-2646
Jul  4 16:12:08.731: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:12:10.736: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2646 to expose endpoints map[pod1:[80] pod2:[80]]
Jul  4 16:12:10.745: INFO: successfully validated that service endpoint-test2 in namespace services-2646 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
Jul  4 16:12:11.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-2646 exec execpodw7ncr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jul  4 16:12:11.876: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jul  4 16:12:11.876: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:12:11.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-2646 exec execpodw7ncr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.46.241 80'
Jul  4 16:12:11.995: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.46.241 80\nConnection to 10.43.46.241 80 port [tcp/http] succeeded!\n"
Jul  4 16:12:11.995: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2646
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2646 to expose endpoints map[pod2:[80]]
Jul  4 16:12:12.024: INFO: successfully validated that service endpoint-test2 in namespace services-2646 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
Jul  4 16:12:13.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-2646 exec execpodw7ncr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jul  4 16:12:13.156: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jul  4 16:12:13.156: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:12:13.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-2646 exec execpodw7ncr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.46.241 80'
Jul  4 16:12:13.312: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.46.241 80\nConnection to 10.43.46.241 80 port [tcp/http] succeeded!\n"
Jul  4 16:12:13.312: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-2646
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2646 to expose endpoints map[]
Jul  4 16:12:13.331: INFO: successfully validated that service endpoint-test2 in namespace services-2646 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 16:12:13.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2646" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:10.939 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":356,"completed":227,"skipped":4145,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:12:13.351: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-projected-w49s
STEP: Creating a pod to test atomic-volume-subpath
Jul  4 16:12:13.377: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-w49s" in namespace "subpath-5574" to be "Succeeded or Failed"
Jul  4 16:12:13.379: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Pending", Reason="", readiness=false. Elapsed: 1.738324ms
Jul  4 16:12:15.382: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 2.005026328s
Jul  4 16:12:17.391: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 4.014125813s
Jul  4 16:12:19.400: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 6.023235034s
Jul  4 16:12:21.408: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 8.030612483s
Jul  4 16:12:23.415: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 10.037629629s
Jul  4 16:12:25.418: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 12.040756583s
Jul  4 16:12:27.426: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 14.049017324s
Jul  4 16:12:29.434: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 16.05686712s
Jul  4 16:12:31.441: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 18.063748081s
Jul  4 16:12:33.446: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=true. Elapsed: 20.069086739s
Jul  4 16:12:35.450: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Running", Reason="", readiness=false. Elapsed: 22.073459424s
Jul  4 16:12:37.458: INFO: Pod "pod-subpath-test-projected-w49s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.081007613s
STEP: Saw pod success
Jul  4 16:12:37.458: INFO: Pod "pod-subpath-test-projected-w49s" satisfied condition "Succeeded or Failed"
Jul  4 16:12:37.460: INFO: Trying to get logs from node 18.216.149.32 pod pod-subpath-test-projected-w49s container test-container-subpath-projected-w49s: <nil>
STEP: delete the pod
Jul  4 16:12:37.478: INFO: Waiting for pod pod-subpath-test-projected-w49s to disappear
Jul  4 16:12:37.480: INFO: Pod pod-subpath-test-projected-w49s no longer exists
STEP: Deleting pod pod-subpath-test-projected-w49s
Jul  4 16:12:37.480: INFO: Deleting pod "pod-subpath-test-projected-w49s" in namespace "subpath-5574"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  4 16:12:37.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5574" for this suite.

• [SLOW TEST:24.136 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","total":356,"completed":228,"skipped":4167,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:12:37.488: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Jul  4 16:12:37.505: INFO: PodSpec: initContainers in spec.initContainers
Jul  4 16:13:24.300: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-633f316e-084a-4fad-a774-7783b8d25d41", GenerateName:"", Namespace:"init-container-9822", SelfLink:"", UID:"f5b5c6d0-211d-460d-9daf-f6f1dbcd1308", ResourceVersion:"22091", Generation:0, CreationTimestamp:time.Date(2022, time.July, 4, 16, 12, 37, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"505915687"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"3ebed8ff494954d3dec15e9519323d072a6b6b29fbc82e95fef1dc908c5e04ff", "cni.projectcalico.org/podIP":"10.42.0.160/32", "cni.projectcalico.org/podIPs":"10.42.0.160/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.July, 4, 16, 12, 37, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003879e60), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.July, 4, 16, 12, 38, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003879e90), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.July, 4, 16, 12, 38, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003879ec0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-79b2t", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc003ee1da0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-79b2t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-79b2t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.7", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-79b2t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0043d03b0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"18.224.151.13", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001cd59d0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0043d0440)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0043d0460)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0043d0468), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0043d046c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0036e9250), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.July, 4, 16, 12, 37, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.July, 4, 16, 12, 37, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.July, 4, 16, 12, 37, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.July, 4, 16, 12, 37, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.25.73", PodIP:"10.42.0.160", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.42.0.160"}}, StartTime:time.Date(2022, time.July, 4, 16, 12, 37, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001cd5ab0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001cd5b90)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"docker-pullable://k8s.gcr.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"docker://365f563f727659b6dbda299e30ab1091bce9f919760b8e4a64102703c515d5a5", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003ee1e20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003ee1e00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.7", ImageID:"", ContainerID:"", Started:(*bool)(0xc0043d04ef)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  4 16:13:24.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9822" for this suite.

• [SLOW TEST:46.825 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":356,"completed":229,"skipped":4223,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:13:24.313: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5784
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Jul  4 16:13:24.341: INFO: Found 0 stateful pods, waiting for 3
Jul  4 16:13:34.348: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 16:13:34.349: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 16:13:34.349: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 16:13:34.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-5784 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:13:34.482: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:13:34.482: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:13:34.482: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Jul  4 16:13:44.512: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jul  4 16:13:54.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-5784 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  4 16:13:54.662: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  4 16:13:54.662: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  4 16:13:54.662: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Jul  4 16:14:04.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-5784 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:14:04.812: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:14:04.812: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:14:04.812: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  4 16:14:14.847: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jul  4 16:14:24.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-5784 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  4 16:14:25.006: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  4 16:14:25.006: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  4 16:14:25.006: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  4 16:14:35.025: INFO: Deleting all statefulset in ns statefulset-5784
Jul  4 16:14:35.027: INFO: Scaling statefulset ss2 to 0
Jul  4 16:14:45.041: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 16:14:45.043: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  4 16:14:45.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5784" for this suite.

• [SLOW TEST:80.745 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":356,"completed":230,"skipped":4241,"failed":0}
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:14:45.058: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul  4 16:14:45.080: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  4 16:15:45.097: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Jul  4 16:15:45.113: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jul  4 16:15:45.119: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jul  4 16:15:45.130: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jul  4 16:15:45.133: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Jul  4 16:15:45.145: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Jul  4 16:15:45.148: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:15:55.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2262" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:70.174 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":356,"completed":231,"skipped":4247,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:15:55.232: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:15:55.613: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:15:58.631: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:16:10.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1101" for this suite.
STEP: Destroying namespace "webhook-1101-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:15.524 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":356,"completed":232,"skipped":4262,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:16:10.757: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a pod template
STEP: Replace a pod template
Jul  4 16:16:10.794: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Jul  4 16:16:10.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-3767" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","total":356,"completed":233,"skipped":4274,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:16:10.801: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pod templates
Jul  4 16:16:10.818: INFO: created test-podtemplate-1
Jul  4 16:16:10.821: INFO: created test-podtemplate-2
Jul  4 16:16:10.823: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Jul  4 16:16:10.825: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Jul  4 16:16:10.832: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Jul  4 16:16:10.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-171" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":356,"completed":234,"skipped":4323,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:16:10.840: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:16:11.847: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:16:14.862: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:16:14.867: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:16:18.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1664" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:7.213 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":356,"completed":235,"skipped":4342,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:16:18.054: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Jul  4 16:16:18.095: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:16:20.099: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Jul  4 16:16:20.107: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:16:22.114: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Jul  4 16:16:22.120: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  4 16:16:22.122: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  4 16:16:24.123: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  4 16:16:24.128: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  4 16:16:26.123: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  4 16:16:26.128: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Jul  4 16:16:26.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1825" for this suite.

• [SLOW TEST:8.099 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":356,"completed":236,"skipped":4353,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:16:26.154: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9490 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9490;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9490 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9490;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9490.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9490.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9490.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9490.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9490.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9490.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9490.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9490.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9490.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9490.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9490.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9490.svc;check="$$(dig +notcp +noall +answer +search 63.231.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.231.63_udp@PTR;check="$$(dig +tcp +noall +answer +search 63.231.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.231.63_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9490 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9490;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9490 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9490;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9490.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9490.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9490.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9490.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9490.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9490.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9490.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9490.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9490.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9490.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9490.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9490.svc;check="$$(dig +notcp +noall +answer +search 63.231.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.231.63_udp@PTR;check="$$(dig +tcp +noall +answer +search 63.231.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.231.63_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  4 16:16:30.209: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.211: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.213: INFO: Unable to read wheezy_udp@dns-test-service.dns-9490 from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.216: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9490 from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.218: INFO: Unable to read wheezy_udp@dns-test-service.dns-9490.svc from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.220: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9490.svc from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.222: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9490.svc from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.225: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9490.svc from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.237: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.240: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.243: INFO: Unable to read jessie_udp@dns-test-service.dns-9490 from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.245: INFO: Unable to read jessie_tcp@dns-test-service.dns-9490 from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.248: INFO: Unable to read jessie_udp@dns-test-service.dns-9490.svc from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.250: INFO: Unable to read jessie_tcp@dns-test-service.dns-9490.svc from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.252: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9490.svc from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.255: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9490.svc from pod dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c: the server could not find the requested resource (get pods dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c)
Jul  4 16:16:30.264: INFO: Lookups using dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9490 wheezy_tcp@dns-test-service.dns-9490 wheezy_udp@dns-test-service.dns-9490.svc wheezy_tcp@dns-test-service.dns-9490.svc wheezy_udp@_http._tcp.dns-test-service.dns-9490.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9490.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9490 jessie_tcp@dns-test-service.dns-9490 jessie_udp@dns-test-service.dns-9490.svc jessie_tcp@dns-test-service.dns-9490.svc jessie_udp@_http._tcp.dns-test-service.dns-9490.svc jessie_tcp@_http._tcp.dns-test-service.dns-9490.svc]

Jul  4 16:16:35.322: INFO: DNS probes using dns-9490/dns-test-992db4a1-8e78-4a95-a3f6-55ef7dc16e4c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  4 16:16:35.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9490" for this suite.

• [SLOW TEST:9.217 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":356,"completed":237,"skipped":4390,"failed":0}
SSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:16:35.371: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-projected-all-test-volume-cdb455eb-ac79-4348-9393-788404d8d8a6
STEP: Creating secret with name secret-projected-all-test-volume-41f0a341-1b38-46e5-8d96-5920db795fc0
STEP: Creating a pod to test Check all projections for projected volume plugin
Jul  4 16:16:35.396: INFO: Waiting up to 5m0s for pod "projected-volume-7a09d5e0-4a27-49af-b246-067591e60918" in namespace "projected-9642" to be "Succeeded or Failed"
Jul  4 16:16:35.398: INFO: Pod "projected-volume-7a09d5e0-4a27-49af-b246-067591e60918": Phase="Pending", Reason="", readiness=false. Elapsed: 2.128326ms
Jul  4 16:16:37.405: INFO: Pod "projected-volume-7a09d5e0-4a27-49af-b246-067591e60918": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009377741s
Jul  4 16:16:39.413: INFO: Pod "projected-volume-7a09d5e0-4a27-49af-b246-067591e60918": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017475218s
STEP: Saw pod success
Jul  4 16:16:39.414: INFO: Pod "projected-volume-7a09d5e0-4a27-49af-b246-067591e60918" satisfied condition "Succeeded or Failed"
Jul  4 16:16:39.416: INFO: Trying to get logs from node 3.138.203.20 pod projected-volume-7a09d5e0-4a27-49af-b246-067591e60918 container projected-all-volume-test: <nil>
STEP: delete the pod
Jul  4 16:16:39.440: INFO: Waiting for pod projected-volume-7a09d5e0-4a27-49af-b246-067591e60918 to disappear
Jul  4 16:16:39.442: INFO: Pod projected-volume-7a09d5e0-4a27-49af-b246-067591e60918 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:188
Jul  4 16:16:39.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9642" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":356,"completed":238,"skipped":4394,"failed":0}
S
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:16:39.447: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
Jul  4 16:16:39.473: INFO: observed Pod pod-test in namespace pods-7321 in phase Pending with labels: map[test-pod-static:true] & conditions []
Jul  4 16:16:39.488: INFO: observed Pod pod-test in namespace pods-7321 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC  }]
Jul  4 16:16:39.497: INFO: observed Pod pod-test in namespace pods-7321 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC  }]
Jul  4 16:16:40.184: INFO: observed Pod pod-test in namespace pods-7321 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC  }]
Jul  4 16:16:40.536: INFO: Found Pod pod-test in namespace pods-7321 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:16:39 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
Jul  4 16:16:40.562: INFO: observed event type MODIFIED
Jul  4 16:16:42.571: INFO: observed event type MODIFIED
Jul  4 16:16:42.704: INFO: observed event type MODIFIED
Jul  4 16:16:43.594: INFO: observed event type MODIFIED
Jul  4 16:16:43.602: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  4 16:16:43.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7321" for this suite.
•{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":356,"completed":239,"skipped":4395,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:16:43.613: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:16:43.632: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Jul  4 16:16:47.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-4535 --namespace=crd-publish-openapi-4535 create -f -'
Jul  4 16:16:48.373: INFO: stderr: ""
Jul  4 16:16:48.373: INFO: stdout: "e2e-test-crd-publish-openapi-3264-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jul  4 16:16:48.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-4535 --namespace=crd-publish-openapi-4535 delete e2e-test-crd-publish-openapi-3264-crds test-cr'
Jul  4 16:16:48.442: INFO: stderr: ""
Jul  4 16:16:48.442: INFO: stdout: "e2e-test-crd-publish-openapi-3264-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Jul  4 16:16:48.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-4535 --namespace=crd-publish-openapi-4535 apply -f -'
Jul  4 16:16:48.662: INFO: stderr: ""
Jul  4 16:16:48.663: INFO: stdout: "e2e-test-crd-publish-openapi-3264-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jul  4 16:16:48.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-4535 --namespace=crd-publish-openapi-4535 delete e2e-test-crd-publish-openapi-3264-crds test-cr'
Jul  4 16:16:48.726: INFO: stderr: ""
Jul  4 16:16:48.726: INFO: stdout: "e2e-test-crd-publish-openapi-3264-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Jul  4 16:16:48.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-4535 explain e2e-test-crd-publish-openapi-3264-crds'
Jul  4 16:16:48.954: INFO: stderr: ""
Jul  4 16:16:48.954: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3264-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:16:52.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4535" for this suite.

• [SLOW TEST:9.178 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":356,"completed":240,"skipped":4413,"failed":0}
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:16:52.791: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:16:52.806: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6215
I0704 16:16:52.811247      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6215, replica count: 1
I0704 16:16:53.862433      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 16:16:53.973: INFO: Created: latency-svc-9sr7s
Jul  4 16:16:53.976: INFO: Got endpoints: latency-svc-9sr7s [12.651266ms]
Jul  4 16:16:53.987: INFO: Created: latency-svc-r8spb
Jul  4 16:16:53.988: INFO: Got endpoints: latency-svc-r8spb [11.815501ms]
Jul  4 16:16:53.991: INFO: Created: latency-svc-56p6c
Jul  4 16:16:53.995: INFO: Got endpoints: latency-svc-56p6c [17.993249ms]
Jul  4 16:16:53.998: INFO: Created: latency-svc-vdthr
Jul  4 16:16:54.002: INFO: Got endpoints: latency-svc-vdthr [26.499939ms]
Jul  4 16:16:54.005: INFO: Created: latency-svc-6crwf
Jul  4 16:16:54.009: INFO: Got endpoints: latency-svc-6crwf [33.166483ms]
Jul  4 16:16:54.010: INFO: Created: latency-svc-c5blw
Jul  4 16:16:54.014: INFO: Created: latency-svc-bkpxc
Jul  4 16:16:54.020: INFO: Got endpoints: latency-svc-c5blw [44.046436ms]
Jul  4 16:16:54.020: INFO: Created: latency-svc-vrqtz
Jul  4 16:16:54.021: INFO: Got endpoints: latency-svc-bkpxc [44.899826ms]
Jul  4 16:16:54.028: INFO: Got endpoints: latency-svc-vrqtz [51.412637ms]
Jul  4 16:16:54.030: INFO: Created: latency-svc-rhwdq
Jul  4 16:16:54.034: INFO: Got endpoints: latency-svc-rhwdq [57.158067ms]
Jul  4 16:16:54.039: INFO: Created: latency-svc-4v7tt
Jul  4 16:16:54.039: INFO: Created: latency-svc-ffhwj
Jul  4 16:16:54.039: INFO: Got endpoints: latency-svc-ffhwj [62.931796ms]
Jul  4 16:16:54.042: INFO: Got endpoints: latency-svc-4v7tt [65.579057ms]
Jul  4 16:16:54.065: INFO: Created: latency-svc-sm6jp
Jul  4 16:16:54.071: INFO: Created: latency-svc-x7464
Jul  4 16:16:54.073: INFO: Got endpoints: latency-svc-sm6jp [97.181546ms]
Jul  4 16:16:54.075: INFO: Got endpoints: latency-svc-x7464 [98.645137ms]
Jul  4 16:16:54.079: INFO: Created: latency-svc-kxfc6
Jul  4 16:16:54.083: INFO: Created: latency-svc-xmknx
Jul  4 16:16:54.083: INFO: Got endpoints: latency-svc-kxfc6 [106.735836ms]
Jul  4 16:16:54.085: INFO: Created: latency-svc-tl4g6
Jul  4 16:16:54.087: INFO: Got endpoints: latency-svc-xmknx [110.880415ms]
Jul  4 16:16:54.091: INFO: Got endpoints: latency-svc-tl4g6 [115.233768ms]
Jul  4 16:16:54.092: INFO: Created: latency-svc-k8642
Jul  4 16:16:54.098: INFO: Created: latency-svc-64m5n
Jul  4 16:16:54.100: INFO: Got endpoints: latency-svc-k8642 [111.4121ms]
Jul  4 16:16:54.102: INFO: Got endpoints: latency-svc-64m5n [107.14452ms]
Jul  4 16:16:54.105: INFO: Created: latency-svc-jpn2n
Jul  4 16:16:54.110: INFO: Got endpoints: latency-svc-jpn2n [107.239471ms]
Jul  4 16:16:54.110: INFO: Created: latency-svc-bt727
Jul  4 16:16:54.119: INFO: Created: latency-svc-fdcgf
Jul  4 16:16:54.120: INFO: Got endpoints: latency-svc-bt727 [110.423814ms]
Jul  4 16:16:54.125: INFO: Got endpoints: latency-svc-fdcgf [105.28323ms]
Jul  4 16:16:54.128: INFO: Created: latency-svc-g6lm4
Jul  4 16:16:54.134: INFO: Got endpoints: latency-svc-g6lm4 [112.097566ms]
Jul  4 16:16:54.137: INFO: Created: latency-svc-mk7ld
Jul  4 16:16:54.140: INFO: Created: latency-svc-c6kz8
Jul  4 16:16:54.143: INFO: Got endpoints: latency-svc-c6kz8 [109.194281ms]
Jul  4 16:16:54.145: INFO: Got endpoints: latency-svc-mk7ld [117.274648ms]
Jul  4 16:16:54.149: INFO: Created: latency-svc-wxz5k
Jul  4 16:16:54.151: INFO: Got endpoints: latency-svc-wxz5k [111.56495ms]
Jul  4 16:16:54.155: INFO: Created: latency-svc-jsrmz
Jul  4 16:16:54.161: INFO: Created: latency-svc-n66qd
Jul  4 16:16:54.161: INFO: Created: latency-svc-splw5
Jul  4 16:16:54.162: INFO: Got endpoints: latency-svc-jsrmz [120.490943ms]
Jul  4 16:16:54.164: INFO: Got endpoints: latency-svc-splw5 [90.861623ms]
Jul  4 16:16:54.167: INFO: Got endpoints: latency-svc-n66qd [92.174982ms]
Jul  4 16:16:54.167: INFO: Created: latency-svc-jnnbb
Jul  4 16:16:54.170: INFO: Created: latency-svc-jc2md
Jul  4 16:16:54.173: INFO: Created: latency-svc-85klg
Jul  4 16:16:54.176: INFO: Got endpoints: latency-svc-jnnbb [92.337431ms]
Jul  4 16:16:54.179: INFO: Got endpoints: latency-svc-jc2md [91.750946ms]
Jul  4 16:16:54.180: INFO: Got endpoints: latency-svc-85klg [88.631206ms]
Jul  4 16:16:54.182: INFO: Created: latency-svc-j9d78
Jul  4 16:16:54.185: INFO: Got endpoints: latency-svc-j9d78 [85.195233ms]
Jul  4 16:16:54.189: INFO: Created: latency-svc-k44x2
Jul  4 16:16:54.194: INFO: Got endpoints: latency-svc-k44x2 [92.098717ms]
Jul  4 16:16:54.197: INFO: Created: latency-svc-hbr5d
Jul  4 16:16:54.202: INFO: Got endpoints: latency-svc-hbr5d [91.949798ms]
Jul  4 16:16:54.204: INFO: Created: latency-svc-drsgs
Jul  4 16:16:54.206: INFO: Created: latency-svc-6nhzm
Jul  4 16:16:54.209: INFO: Created: latency-svc-4wp6r
Jul  4 16:16:54.214: INFO: Created: latency-svc-76ccw
Jul  4 16:16:54.219: INFO: Created: latency-svc-7b6jk
Jul  4 16:16:54.223: INFO: Created: latency-svc-xmm2m
Jul  4 16:16:54.228: INFO: Got endpoints: latency-svc-drsgs [107.668808ms]
Jul  4 16:16:54.228: INFO: Created: latency-svc-lqqrl
Jul  4 16:16:54.231: INFO: Created: latency-svc-54q2n
Jul  4 16:16:54.235: INFO: Created: latency-svc-p5s5l
Jul  4 16:16:54.239: INFO: Created: latency-svc-mcczj
Jul  4 16:16:54.243: INFO: Created: latency-svc-mfd7f
Jul  4 16:16:54.246: INFO: Created: latency-svc-6r96h
Jul  4 16:16:54.251: INFO: Created: latency-svc-mhwgg
Jul  4 16:16:54.254: INFO: Created: latency-svc-ns9x6
Jul  4 16:16:54.258: INFO: Created: latency-svc-xb8xf
Jul  4 16:16:54.262: INFO: Created: latency-svc-w4j8j
Jul  4 16:16:54.279: INFO: Got endpoints: latency-svc-6nhzm [153.868236ms]
Jul  4 16:16:54.297: INFO: Created: latency-svc-6r9js
Jul  4 16:16:54.326: INFO: Got endpoints: latency-svc-4wp6r [192.507974ms]
Jul  4 16:16:54.333: INFO: Created: latency-svc-zmdkk
Jul  4 16:16:54.374: INFO: Got endpoints: latency-svc-76ccw [231.197076ms]
Jul  4 16:16:54.380: INFO: Created: latency-svc-hm5n4
Jul  4 16:16:54.425: INFO: Got endpoints: latency-svc-7b6jk [280.192257ms]
Jul  4 16:16:54.431: INFO: Created: latency-svc-29tpx
Jul  4 16:16:54.474: INFO: Got endpoints: latency-svc-xmm2m [323.363079ms]
Jul  4 16:16:54.481: INFO: Created: latency-svc-6rcht
Jul  4 16:16:54.526: INFO: Got endpoints: latency-svc-lqqrl [363.779324ms]
Jul  4 16:16:54.532: INFO: Created: latency-svc-kz9q7
Jul  4 16:16:54.575: INFO: Got endpoints: latency-svc-54q2n [410.832678ms]
Jul  4 16:16:54.582: INFO: Created: latency-svc-z4wqw
Jul  4 16:16:54.629: INFO: Got endpoints: latency-svc-p5s5l [461.987476ms]
Jul  4 16:16:54.634: INFO: Created: latency-svc-pw97p
Jul  4 16:16:54.678: INFO: Got endpoints: latency-svc-mcczj [502.743943ms]
Jul  4 16:16:54.684: INFO: Created: latency-svc-fc9hc
Jul  4 16:16:54.725: INFO: Got endpoints: latency-svc-mfd7f [546.042016ms]
Jul  4 16:16:54.731: INFO: Created: latency-svc-hsd55
Jul  4 16:16:54.775: INFO: Got endpoints: latency-svc-6r96h [594.663014ms]
Jul  4 16:16:54.781: INFO: Created: latency-svc-cxt7r
Jul  4 16:16:54.825: INFO: Got endpoints: latency-svc-mhwgg [640.184772ms]
Jul  4 16:16:54.855: INFO: Created: latency-svc-d9dtn
Jul  4 16:16:54.877: INFO: Got endpoints: latency-svc-ns9x6 [682.819234ms]
Jul  4 16:16:54.888: INFO: Created: latency-svc-qz4j9
Jul  4 16:16:54.925: INFO: Got endpoints: latency-svc-xb8xf [723.878026ms]
Jul  4 16:16:54.933: INFO: Created: latency-svc-9nspq
Jul  4 16:16:54.976: INFO: Got endpoints: latency-svc-w4j8j [748.015428ms]
Jul  4 16:16:54.983: INFO: Created: latency-svc-nn8pv
Jul  4 16:16:55.025: INFO: Got endpoints: latency-svc-6r9js [746.17106ms]
Jul  4 16:16:55.032: INFO: Created: latency-svc-pm8tq
Jul  4 16:16:55.077: INFO: Got endpoints: latency-svc-zmdkk [750.312525ms]
Jul  4 16:16:55.082: INFO: Created: latency-svc-dxdbc
Jul  4 16:16:55.125: INFO: Got endpoints: latency-svc-hm5n4 [750.515318ms]
Jul  4 16:16:55.132: INFO: Created: latency-svc-blprn
Jul  4 16:16:55.176: INFO: Got endpoints: latency-svc-29tpx [750.174823ms]
Jul  4 16:16:55.182: INFO: Created: latency-svc-wqqsf
Jul  4 16:16:55.226: INFO: Got endpoints: latency-svc-6rcht [751.295385ms]
Jul  4 16:16:55.232: INFO: Created: latency-svc-5bqd5
Jul  4 16:16:55.277: INFO: Got endpoints: latency-svc-kz9q7 [751.027061ms]
Jul  4 16:16:55.283: INFO: Created: latency-svc-bbhwt
Jul  4 16:16:55.324: INFO: Got endpoints: latency-svc-z4wqw [749.488641ms]
Jul  4 16:16:55.331: INFO: Created: latency-svc-7cq4d
Jul  4 16:16:55.376: INFO: Got endpoints: latency-svc-pw97p [747.60106ms]
Jul  4 16:16:55.383: INFO: Created: latency-svc-dmn2m
Jul  4 16:16:55.426: INFO: Got endpoints: latency-svc-fc9hc [747.896847ms]
Jul  4 16:16:55.432: INFO: Created: latency-svc-bzzdw
Jul  4 16:16:55.475: INFO: Got endpoints: latency-svc-hsd55 [750.340933ms]
Jul  4 16:16:55.482: INFO: Created: latency-svc-9jmlh
Jul  4 16:16:55.524: INFO: Got endpoints: latency-svc-cxt7r [749.826321ms]
Jul  4 16:16:55.533: INFO: Created: latency-svc-thkdk
Jul  4 16:16:55.575: INFO: Got endpoints: latency-svc-d9dtn [749.798996ms]
Jul  4 16:16:55.582: INFO: Created: latency-svc-vcff6
Jul  4 16:16:55.626: INFO: Got endpoints: latency-svc-qz4j9 [743.707583ms]
Jul  4 16:16:55.633: INFO: Created: latency-svc-6p7th
Jul  4 16:16:55.676: INFO: Got endpoints: latency-svc-9nspq [750.366204ms]
Jul  4 16:16:55.683: INFO: Created: latency-svc-d2nqw
Jul  4 16:16:55.726: INFO: Got endpoints: latency-svc-nn8pv [750.065955ms]
Jul  4 16:16:55.733: INFO: Created: latency-svc-n4hfb
Jul  4 16:16:55.776: INFO: Got endpoints: latency-svc-pm8tq [750.467017ms]
Jul  4 16:16:55.782: INFO: Created: latency-svc-9dnwn
Jul  4 16:16:55.827: INFO: Got endpoints: latency-svc-dxdbc [750.642898ms]
Jul  4 16:16:55.833: INFO: Created: latency-svc-xl7hp
Jul  4 16:16:55.875: INFO: Got endpoints: latency-svc-blprn [749.8629ms]
Jul  4 16:16:55.882: INFO: Created: latency-svc-2jpjk
Jul  4 16:16:55.932: INFO: Got endpoints: latency-svc-wqqsf [755.853126ms]
Jul  4 16:16:55.942: INFO: Created: latency-svc-vkfpf
Jul  4 16:16:55.975: INFO: Got endpoints: latency-svc-5bqd5 [749.218619ms]
Jul  4 16:16:55.982: INFO: Created: latency-svc-s7t5g
Jul  4 16:16:56.024: INFO: Got endpoints: latency-svc-bbhwt [746.75026ms]
Jul  4 16:16:56.030: INFO: Created: latency-svc-mwch2
Jul  4 16:16:56.077: INFO: Got endpoints: latency-svc-7cq4d [752.081202ms]
Jul  4 16:16:56.082: INFO: Created: latency-svc-pd7c5
Jul  4 16:16:56.124: INFO: Got endpoints: latency-svc-dmn2m [747.921208ms]
Jul  4 16:16:56.132: INFO: Created: latency-svc-wtqw6
Jul  4 16:16:56.176: INFO: Got endpoints: latency-svc-bzzdw [750.092854ms]
Jul  4 16:16:56.182: INFO: Created: latency-svc-wxrdc
Jul  4 16:16:56.225: INFO: Got endpoints: latency-svc-9jmlh [750.115224ms]
Jul  4 16:16:56.232: INFO: Created: latency-svc-62mxx
Jul  4 16:16:56.277: INFO: Got endpoints: latency-svc-thkdk [752.205472ms]
Jul  4 16:16:56.282: INFO: Created: latency-svc-dfc5d
Jul  4 16:16:56.325: INFO: Got endpoints: latency-svc-vcff6 [749.599794ms]
Jul  4 16:16:56.332: INFO: Created: latency-svc-xv484
Jul  4 16:16:56.376: INFO: Got endpoints: latency-svc-6p7th [750.008053ms]
Jul  4 16:16:56.382: INFO: Created: latency-svc-p92gm
Jul  4 16:16:56.425: INFO: Got endpoints: latency-svc-d2nqw [749.329748ms]
Jul  4 16:16:56.431: INFO: Created: latency-svc-z95g8
Jul  4 16:16:56.475: INFO: Got endpoints: latency-svc-n4hfb [749.215976ms]
Jul  4 16:16:56.482: INFO: Created: latency-svc-d5ffc
Jul  4 16:16:56.525: INFO: Got endpoints: latency-svc-9dnwn [748.801437ms]
Jul  4 16:16:56.531: INFO: Created: latency-svc-wl5t2
Jul  4 16:16:56.575: INFO: Got endpoints: latency-svc-xl7hp [748.081274ms]
Jul  4 16:16:56.582: INFO: Created: latency-svc-s96tq
Jul  4 16:16:56.625: INFO: Got endpoints: latency-svc-2jpjk [750.360879ms]
Jul  4 16:16:56.632: INFO: Created: latency-svc-pbh4c
Jul  4 16:16:56.677: INFO: Got endpoints: latency-svc-vkfpf [745.654332ms]
Jul  4 16:16:56.683: INFO: Created: latency-svc-jnfvk
Jul  4 16:16:56.725: INFO: Got endpoints: latency-svc-s7t5g [749.822354ms]
Jul  4 16:16:56.732: INFO: Created: latency-svc-cft8w
Jul  4 16:16:56.776: INFO: Got endpoints: latency-svc-mwch2 [751.696191ms]
Jul  4 16:16:56.783: INFO: Created: latency-svc-tzl6t
Jul  4 16:16:56.827: INFO: Got endpoints: latency-svc-pd7c5 [750.048081ms]
Jul  4 16:16:56.833: INFO: Created: latency-svc-zvjjq
Jul  4 16:16:56.876: INFO: Got endpoints: latency-svc-wtqw6 [751.799813ms]
Jul  4 16:16:56.883: INFO: Created: latency-svc-7kzzq
Jul  4 16:16:56.925: INFO: Got endpoints: latency-svc-wxrdc [749.06277ms]
Jul  4 16:16:56.933: INFO: Created: latency-svc-lznw6
Jul  4 16:16:56.975: INFO: Got endpoints: latency-svc-62mxx [749.701084ms]
Jul  4 16:16:56.984: INFO: Created: latency-svc-9hhw9
Jul  4 16:16:57.024: INFO: Got endpoints: latency-svc-dfc5d [747.076766ms]
Jul  4 16:16:57.031: INFO: Created: latency-svc-6nf9r
Jul  4 16:16:57.074: INFO: Got endpoints: latency-svc-xv484 [749.511376ms]
Jul  4 16:16:57.080: INFO: Created: latency-svc-n69wx
Jul  4 16:16:57.126: INFO: Got endpoints: latency-svc-p92gm [749.681919ms]
Jul  4 16:16:57.153: INFO: Created: latency-svc-q6rch
Jul  4 16:16:57.178: INFO: Got endpoints: latency-svc-z95g8 [752.548997ms]
Jul  4 16:16:57.184: INFO: Created: latency-svc-jnp85
Jul  4 16:16:57.225: INFO: Got endpoints: latency-svc-d5ffc [749.667851ms]
Jul  4 16:16:57.232: INFO: Created: latency-svc-bl9np
Jul  4 16:16:57.277: INFO: Got endpoints: latency-svc-wl5t2 [751.957065ms]
Jul  4 16:16:57.283: INFO: Created: latency-svc-bnw82
Jul  4 16:16:57.326: INFO: Got endpoints: latency-svc-s96tq [750.794193ms]
Jul  4 16:16:57.332: INFO: Created: latency-svc-fd62s
Jul  4 16:16:57.378: INFO: Got endpoints: latency-svc-pbh4c [753.051048ms]
Jul  4 16:16:57.384: INFO: Created: latency-svc-27pcf
Jul  4 16:16:57.428: INFO: Got endpoints: latency-svc-jnfvk [750.923223ms]
Jul  4 16:16:57.435: INFO: Created: latency-svc-gc7cp
Jul  4 16:16:57.479: INFO: Got endpoints: latency-svc-cft8w [753.491089ms]
Jul  4 16:16:57.485: INFO: Created: latency-svc-mpx6k
Jul  4 16:16:57.526: INFO: Got endpoints: latency-svc-tzl6t [749.72345ms]
Jul  4 16:16:57.532: INFO: Created: latency-svc-9gfrt
Jul  4 16:16:57.577: INFO: Got endpoints: latency-svc-zvjjq [750.32392ms]
Jul  4 16:16:57.583: INFO: Created: latency-svc-5w4s7
Jul  4 16:16:57.626: INFO: Got endpoints: latency-svc-7kzzq [749.777277ms]
Jul  4 16:16:57.633: INFO: Created: latency-svc-6kzs8
Jul  4 16:16:57.676: INFO: Got endpoints: latency-svc-lznw6 [750.401878ms]
Jul  4 16:16:57.683: INFO: Created: latency-svc-5phvl
Jul  4 16:16:57.725: INFO: Got endpoints: latency-svc-9hhw9 [749.907488ms]
Jul  4 16:16:57.732: INFO: Created: latency-svc-vtxmj
Jul  4 16:16:57.774: INFO: Got endpoints: latency-svc-6nf9r [750.142419ms]
Jul  4 16:16:57.781: INFO: Created: latency-svc-vmjzb
Jul  4 16:16:57.826: INFO: Got endpoints: latency-svc-n69wx [751.974877ms]
Jul  4 16:16:57.833: INFO: Created: latency-svc-7p9qv
Jul  4 16:16:57.875: INFO: Got endpoints: latency-svc-q6rch [749.55705ms]
Jul  4 16:16:57.882: INFO: Created: latency-svc-mjvw7
Jul  4 16:16:57.924: INFO: Got endpoints: latency-svc-jnp85 [746.411143ms]
Jul  4 16:16:57.933: INFO: Created: latency-svc-jl665
Jul  4 16:16:57.975: INFO: Got endpoints: latency-svc-bl9np [749.887762ms]
Jul  4 16:16:57.983: INFO: Created: latency-svc-m762c
Jul  4 16:16:58.025: INFO: Got endpoints: latency-svc-bnw82 [748.090521ms]
Jul  4 16:16:58.033: INFO: Created: latency-svc-pngsh
Jul  4 16:16:58.076: INFO: Got endpoints: latency-svc-fd62s [749.403276ms]
Jul  4 16:16:58.082: INFO: Created: latency-svc-6jkmw
Jul  4 16:16:58.126: INFO: Got endpoints: latency-svc-27pcf [747.559241ms]
Jul  4 16:16:58.132: INFO: Created: latency-svc-wp748
Jul  4 16:16:58.175: INFO: Got endpoints: latency-svc-gc7cp [746.755229ms]
Jul  4 16:16:58.181: INFO: Created: latency-svc-q2hnq
Jul  4 16:16:58.227: INFO: Got endpoints: latency-svc-mpx6k [748.400904ms]
Jul  4 16:16:58.233: INFO: Created: latency-svc-zxjqx
Jul  4 16:16:58.283: INFO: Got endpoints: latency-svc-9gfrt [757.120293ms]
Jul  4 16:16:58.289: INFO: Created: latency-svc-r6cr7
Jul  4 16:16:58.326: INFO: Got endpoints: latency-svc-5w4s7 [749.188754ms]
Jul  4 16:16:58.335: INFO: Created: latency-svc-p55k7
Jul  4 16:16:58.376: INFO: Got endpoints: latency-svc-6kzs8 [749.298418ms]
Jul  4 16:16:58.382: INFO: Created: latency-svc-qzvtx
Jul  4 16:16:58.425: INFO: Got endpoints: latency-svc-5phvl [749.085492ms]
Jul  4 16:16:58.432: INFO: Created: latency-svc-jkgf4
Jul  4 16:16:58.475: INFO: Got endpoints: latency-svc-vtxmj [750.046724ms]
Jul  4 16:16:58.486: INFO: Created: latency-svc-mpjcb
Jul  4 16:16:58.528: INFO: Got endpoints: latency-svc-vmjzb [753.625653ms]
Jul  4 16:16:58.534: INFO: Created: latency-svc-tlxcg
Jul  4 16:16:58.578: INFO: Got endpoints: latency-svc-7p9qv [751.670214ms]
Jul  4 16:16:58.584: INFO: Created: latency-svc-6vht5
Jul  4 16:16:58.626: INFO: Got endpoints: latency-svc-mjvw7 [750.970206ms]
Jul  4 16:16:58.633: INFO: Created: latency-svc-8nm9k
Jul  4 16:16:58.676: INFO: Got endpoints: latency-svc-jl665 [751.40694ms]
Jul  4 16:16:58.682: INFO: Created: latency-svc-sn8pf
Jul  4 16:16:58.732: INFO: Got endpoints: latency-svc-m762c [757.241908ms]
Jul  4 16:16:58.742: INFO: Created: latency-svc-bdvs2
Jul  4 16:16:58.775: INFO: Got endpoints: latency-svc-pngsh [749.955413ms]
Jul  4 16:16:58.782: INFO: Created: latency-svc-822rn
Jul  4 16:16:58.826: INFO: Got endpoints: latency-svc-6jkmw [750.492699ms]
Jul  4 16:16:58.832: INFO: Created: latency-svc-5ctfj
Jul  4 16:16:58.875: INFO: Got endpoints: latency-svc-wp748 [749.195352ms]
Jul  4 16:16:58.882: INFO: Created: latency-svc-gfghh
Jul  4 16:16:58.926: INFO: Got endpoints: latency-svc-q2hnq [750.491188ms]
Jul  4 16:16:58.933: INFO: Created: latency-svc-hj82z
Jul  4 16:16:58.979: INFO: Got endpoints: latency-svc-zxjqx [751.790355ms]
Jul  4 16:16:58.985: INFO: Created: latency-svc-p5w5x
Jul  4 16:16:59.027: INFO: Got endpoints: latency-svc-r6cr7 [743.90668ms]
Jul  4 16:16:59.035: INFO: Created: latency-svc-kw8ql
Jul  4 16:16:59.077: INFO: Got endpoints: latency-svc-p55k7 [750.630669ms]
Jul  4 16:16:59.086: INFO: Created: latency-svc-zwxfb
Jul  4 16:16:59.127: INFO: Got endpoints: latency-svc-qzvtx [750.891565ms]
Jul  4 16:16:59.133: INFO: Created: latency-svc-kprnq
Jul  4 16:16:59.174: INFO: Got endpoints: latency-svc-jkgf4 [749.046292ms]
Jul  4 16:16:59.181: INFO: Created: latency-svc-7tbsr
Jul  4 16:16:59.225: INFO: Got endpoints: latency-svc-mpjcb [749.748286ms]
Jul  4 16:16:59.231: INFO: Created: latency-svc-j42pp
Jul  4 16:16:59.276: INFO: Got endpoints: latency-svc-tlxcg [747.732636ms]
Jul  4 16:16:59.283: INFO: Created: latency-svc-p9rh6
Jul  4 16:16:59.325: INFO: Got endpoints: latency-svc-6vht5 [747.350641ms]
Jul  4 16:16:59.332: INFO: Created: latency-svc-n5v2t
Jul  4 16:16:59.376: INFO: Got endpoints: latency-svc-8nm9k [749.208776ms]
Jul  4 16:16:59.381: INFO: Created: latency-svc-7s6w9
Jul  4 16:16:59.454: INFO: Got endpoints: latency-svc-sn8pf [777.663631ms]
Jul  4 16:16:59.460: INFO: Created: latency-svc-zlp2d
Jul  4 16:16:59.477: INFO: Got endpoints: latency-svc-bdvs2 [744.436597ms]
Jul  4 16:16:59.483: INFO: Created: latency-svc-gsd64
Jul  4 16:16:59.526: INFO: Got endpoints: latency-svc-822rn [751.396429ms]
Jul  4 16:16:59.535: INFO: Created: latency-svc-b9wt4
Jul  4 16:16:59.576: INFO: Got endpoints: latency-svc-5ctfj [749.244961ms]
Jul  4 16:16:59.583: INFO: Created: latency-svc-wvdf2
Jul  4 16:16:59.625: INFO: Got endpoints: latency-svc-gfghh [750.361026ms]
Jul  4 16:16:59.633: INFO: Created: latency-svc-rgw9b
Jul  4 16:16:59.676: INFO: Got endpoints: latency-svc-hj82z [750.415948ms]
Jul  4 16:16:59.683: INFO: Created: latency-svc-fj5zk
Jul  4 16:16:59.728: INFO: Got endpoints: latency-svc-p5w5x [749.053714ms]
Jul  4 16:16:59.734: INFO: Created: latency-svc-9xfq9
Jul  4 16:16:59.775: INFO: Got endpoints: latency-svc-kw8ql [748.662402ms]
Jul  4 16:16:59.782: INFO: Created: latency-svc-6bxjz
Jul  4 16:16:59.825: INFO: Got endpoints: latency-svc-zwxfb [748.146547ms]
Jul  4 16:16:59.832: INFO: Created: latency-svc-4rhjh
Jul  4 16:16:59.875: INFO: Got endpoints: latency-svc-kprnq [748.134423ms]
Jul  4 16:16:59.881: INFO: Created: latency-svc-l87hl
Jul  4 16:16:59.925: INFO: Got endpoints: latency-svc-7tbsr [750.26617ms]
Jul  4 16:16:59.932: INFO: Created: latency-svc-ccx5g
Jul  4 16:16:59.977: INFO: Got endpoints: latency-svc-j42pp [752.139717ms]
Jul  4 16:16:59.984: INFO: Created: latency-svc-z5qwg
Jul  4 16:17:00.025: INFO: Got endpoints: latency-svc-p9rh6 [749.86702ms]
Jul  4 16:17:00.033: INFO: Created: latency-svc-g79rm
Jul  4 16:17:00.076: INFO: Got endpoints: latency-svc-n5v2t [750.166853ms]
Jul  4 16:17:00.082: INFO: Created: latency-svc-67lq8
Jul  4 16:17:00.126: INFO: Got endpoints: latency-svc-7s6w9 [749.949199ms]
Jul  4 16:17:00.132: INFO: Created: latency-svc-pnnpf
Jul  4 16:17:00.178: INFO: Got endpoints: latency-svc-zlp2d [724.02997ms]
Jul  4 16:17:00.184: INFO: Created: latency-svc-rhpzd
Jul  4 16:17:00.225: INFO: Got endpoints: latency-svc-gsd64 [748.255792ms]
Jul  4 16:17:00.232: INFO: Created: latency-svc-sc6lw
Jul  4 16:17:00.275: INFO: Got endpoints: latency-svc-b9wt4 [748.695611ms]
Jul  4 16:17:00.281: INFO: Created: latency-svc-pwktn
Jul  4 16:17:00.326: INFO: Got endpoints: latency-svc-wvdf2 [750.129296ms]
Jul  4 16:17:00.332: INFO: Created: latency-svc-ls9gp
Jul  4 16:17:00.376: INFO: Got endpoints: latency-svc-rgw9b [750.949807ms]
Jul  4 16:17:00.382: INFO: Created: latency-svc-zk68g
Jul  4 16:17:00.427: INFO: Got endpoints: latency-svc-fj5zk [750.554813ms]
Jul  4 16:17:00.434: INFO: Created: latency-svc-r7zjd
Jul  4 16:17:00.476: INFO: Got endpoints: latency-svc-9xfq9 [747.793571ms]
Jul  4 16:17:00.481: INFO: Created: latency-svc-6pwgr
Jul  4 16:17:00.526: INFO: Got endpoints: latency-svc-6bxjz [750.628735ms]
Jul  4 16:17:00.533: INFO: Created: latency-svc-b99p4
Jul  4 16:17:00.575: INFO: Got endpoints: latency-svc-4rhjh [749.440736ms]
Jul  4 16:17:00.581: INFO: Created: latency-svc-rw8qf
Jul  4 16:17:00.624: INFO: Got endpoints: latency-svc-l87hl [749.125726ms]
Jul  4 16:17:00.631: INFO: Created: latency-svc-9jxlv
Jul  4 16:17:00.675: INFO: Got endpoints: latency-svc-ccx5g [750.35186ms]
Jul  4 16:17:00.682: INFO: Created: latency-svc-6d5sk
Jul  4 16:17:00.726: INFO: Got endpoints: latency-svc-z5qwg [748.582886ms]
Jul  4 16:17:00.733: INFO: Created: latency-svc-5m7fb
Jul  4 16:17:00.776: INFO: Got endpoints: latency-svc-g79rm [750.905176ms]
Jul  4 16:17:00.784: INFO: Created: latency-svc-hcxtn
Jul  4 16:17:00.830: INFO: Got endpoints: latency-svc-67lq8 [754.228499ms]
Jul  4 16:17:00.837: INFO: Created: latency-svc-gb652
Jul  4 16:17:00.875: INFO: Got endpoints: latency-svc-pnnpf [748.874386ms]
Jul  4 16:17:00.883: INFO: Created: latency-svc-wpgc9
Jul  4 16:17:00.925: INFO: Got endpoints: latency-svc-rhpzd [746.705896ms]
Jul  4 16:17:00.931: INFO: Created: latency-svc-z7ppm
Jul  4 16:17:00.975: INFO: Got endpoints: latency-svc-sc6lw [749.444178ms]
Jul  4 16:17:00.985: INFO: Created: latency-svc-nx2zl
Jul  4 16:17:01.026: INFO: Got endpoints: latency-svc-pwktn [750.675436ms]
Jul  4 16:17:01.033: INFO: Created: latency-svc-flpwb
Jul  4 16:17:01.076: INFO: Got endpoints: latency-svc-ls9gp [749.911506ms]
Jul  4 16:17:01.094: INFO: Created: latency-svc-v24md
Jul  4 16:17:01.125: INFO: Got endpoints: latency-svc-zk68g [748.799433ms]
Jul  4 16:17:01.131: INFO: Created: latency-svc-7l6bh
Jul  4 16:17:01.175: INFO: Got endpoints: latency-svc-r7zjd [748.33876ms]
Jul  4 16:17:01.184: INFO: Created: latency-svc-4mvwv
Jul  4 16:17:01.227: INFO: Got endpoints: latency-svc-6pwgr [750.870199ms]
Jul  4 16:17:01.232: INFO: Created: latency-svc-l76gx
Jul  4 16:17:01.276: INFO: Got endpoints: latency-svc-b99p4 [749.553524ms]
Jul  4 16:17:01.283: INFO: Created: latency-svc-v556b
Jul  4 16:17:01.327: INFO: Got endpoints: latency-svc-rw8qf [751.750299ms]
Jul  4 16:17:01.333: INFO: Created: latency-svc-bqchk
Jul  4 16:17:01.377: INFO: Got endpoints: latency-svc-9jxlv [752.657164ms]
Jul  4 16:17:01.383: INFO: Created: latency-svc-bpztx
Jul  4 16:17:01.426: INFO: Got endpoints: latency-svc-6d5sk [751.00777ms]
Jul  4 16:17:01.433: INFO: Created: latency-svc-2hhzc
Jul  4 16:17:01.476: INFO: Got endpoints: latency-svc-5m7fb [750.19001ms]
Jul  4 16:17:01.483: INFO: Created: latency-svc-fgzv7
Jul  4 16:17:01.526: INFO: Got endpoints: latency-svc-hcxtn [749.304086ms]
Jul  4 16:17:01.533: INFO: Created: latency-svc-hfc2v
Jul  4 16:17:01.575: INFO: Got endpoints: latency-svc-gb652 [744.900441ms]
Jul  4 16:17:01.581: INFO: Created: latency-svc-pfwtn
Jul  4 16:17:01.626: INFO: Got endpoints: latency-svc-wpgc9 [751.710524ms]
Jul  4 16:17:01.633: INFO: Created: latency-svc-l8gdz
Jul  4 16:17:01.675: INFO: Got endpoints: latency-svc-z7ppm [750.379757ms]
Jul  4 16:17:01.684: INFO: Created: latency-svc-r4zp6
Jul  4 16:17:01.756: INFO: Got endpoints: latency-svc-nx2zl [781.294733ms]
Jul  4 16:17:01.763: INFO: Created: latency-svc-bczsv
Jul  4 16:17:01.774: INFO: Got endpoints: latency-svc-flpwb [748.3562ms]
Jul  4 16:17:01.782: INFO: Created: latency-svc-qp2cr
Jul  4 16:17:01.827: INFO: Got endpoints: latency-svc-v24md [751.489651ms]
Jul  4 16:17:01.876: INFO: Got endpoints: latency-svc-7l6bh [751.067393ms]
Jul  4 16:17:01.926: INFO: Got endpoints: latency-svc-4mvwv [750.659379ms]
Jul  4 16:17:01.977: INFO: Got endpoints: latency-svc-l76gx [749.909975ms]
Jul  4 16:17:02.027: INFO: Got endpoints: latency-svc-v556b [750.828065ms]
Jul  4 16:17:02.076: INFO: Got endpoints: latency-svc-bqchk [748.800466ms]
Jul  4 16:17:02.126: INFO: Got endpoints: latency-svc-bpztx [749.477835ms]
Jul  4 16:17:02.176: INFO: Got endpoints: latency-svc-2hhzc [749.517465ms]
Jul  4 16:17:02.225: INFO: Got endpoints: latency-svc-fgzv7 [749.050874ms]
Jul  4 16:17:02.277: INFO: Got endpoints: latency-svc-hfc2v [751.253903ms]
Jul  4 16:17:02.326: INFO: Got endpoints: latency-svc-pfwtn [751.310714ms]
Jul  4 16:17:02.376: INFO: Got endpoints: latency-svc-l8gdz [749.285055ms]
Jul  4 16:17:02.429: INFO: Got endpoints: latency-svc-r4zp6 [753.479759ms]
Jul  4 16:17:02.476: INFO: Got endpoints: latency-svc-bczsv [719.627308ms]
Jul  4 16:17:02.525: INFO: Got endpoints: latency-svc-qp2cr [750.145063ms]
Jul  4 16:17:02.525: INFO: Latencies: [11.815501ms 17.993249ms 26.499939ms 33.166483ms 44.046436ms 44.899826ms 51.412637ms 57.158067ms 62.931796ms 65.579057ms 85.195233ms 88.631206ms 90.861623ms 91.750946ms 91.949798ms 92.098717ms 92.174982ms 92.337431ms 97.181546ms 98.645137ms 105.28323ms 106.735836ms 107.14452ms 107.239471ms 107.668808ms 109.194281ms 110.423814ms 110.880415ms 111.4121ms 111.56495ms 112.097566ms 115.233768ms 117.274648ms 120.490943ms 153.868236ms 192.507974ms 231.197076ms 280.192257ms 323.363079ms 363.779324ms 410.832678ms 461.987476ms 502.743943ms 546.042016ms 594.663014ms 640.184772ms 682.819234ms 719.627308ms 723.878026ms 724.02997ms 743.707583ms 743.90668ms 744.436597ms 744.900441ms 745.654332ms 746.17106ms 746.411143ms 746.705896ms 746.75026ms 746.755229ms 747.076766ms 747.350641ms 747.559241ms 747.60106ms 747.732636ms 747.793571ms 747.896847ms 747.921208ms 748.015428ms 748.081274ms 748.090521ms 748.134423ms 748.146547ms 748.255792ms 748.33876ms 748.3562ms 748.400904ms 748.582886ms 748.662402ms 748.695611ms 748.799433ms 748.800466ms 748.801437ms 748.874386ms 749.046292ms 749.050874ms 749.053714ms 749.06277ms 749.085492ms 749.125726ms 749.188754ms 749.195352ms 749.208776ms 749.215976ms 749.218619ms 749.244961ms 749.285055ms 749.298418ms 749.304086ms 749.329748ms 749.403276ms 749.440736ms 749.444178ms 749.477835ms 749.488641ms 749.511376ms 749.517465ms 749.553524ms 749.55705ms 749.599794ms 749.667851ms 749.681919ms 749.701084ms 749.72345ms 749.748286ms 749.777277ms 749.798996ms 749.822354ms 749.826321ms 749.8629ms 749.86702ms 749.887762ms 749.907488ms 749.909975ms 749.911506ms 749.949199ms 749.955413ms 750.008053ms 750.046724ms 750.048081ms 750.065955ms 750.092854ms 750.115224ms 750.129296ms 750.142419ms 750.145063ms 750.166853ms 750.174823ms 750.19001ms 750.26617ms 750.312525ms 750.32392ms 750.340933ms 750.35186ms 750.360879ms 750.361026ms 750.366204ms 750.379757ms 750.401878ms 750.415948ms 750.467017ms 750.491188ms 750.492699ms 750.515318ms 750.554813ms 750.628735ms 750.630669ms 750.642898ms 750.659379ms 750.675436ms 750.794193ms 750.828065ms 750.870199ms 750.891565ms 750.905176ms 750.923223ms 750.949807ms 750.970206ms 751.00777ms 751.027061ms 751.067393ms 751.253903ms 751.295385ms 751.310714ms 751.396429ms 751.40694ms 751.489651ms 751.670214ms 751.696191ms 751.710524ms 751.750299ms 751.790355ms 751.799813ms 751.957065ms 751.974877ms 752.081202ms 752.139717ms 752.205472ms 752.548997ms 752.657164ms 753.051048ms 753.479759ms 753.491089ms 753.625653ms 754.228499ms 755.853126ms 757.120293ms 757.241908ms 777.663631ms 781.294733ms]
Jul  4 16:17:02.525: INFO: 50 %ile: 749.403276ms
Jul  4 16:17:02.525: INFO: 90 %ile: 751.750299ms
Jul  4 16:17:02.525: INFO: 99 %ile: 777.663631ms
Jul  4 16:17:02.525: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:188
Jul  4 16:17:02.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6215" for this suite.

• [SLOW TEST:9.742 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":356,"completed":241,"skipped":4416,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:17:02.534: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:188
Jul  4 16:17:02.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-4617" for this suite.
•{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":356,"completed":242,"skipped":4440,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:17:02.582: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jul  4 16:17:06.624: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  4 16:17:06.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8460" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":243,"skipped":4493,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:17:06.639: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Jul  4 16:17:06.664: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:17:08.671: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Jul  4 16:17:08.684: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:17:10.687: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul  4 16:17:10.698: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  4 16:17:10.700: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  4 16:17:12.701: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  4 16:17:12.707: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  4 16:17:14.702: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  4 16:17:14.707: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Jul  4 16:17:14.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4077" for this suite.

• [SLOW TEST:8.074 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":356,"completed":244,"skipped":4522,"failed":0}
SSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:17:14.713: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Jul  4 16:17:14.727: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  4 16:18:14.741: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:18:14.743: INFO: Starting informer...
STEP: Starting pods...
Jul  4 16:18:14.956: INFO: Pod1 is running on 3.138.203.20. Tainting Node
Jul  4 16:18:17.174: INFO: Pod2 is running on 3.138.203.20. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Jul  4 16:18:23.025: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Jul  4 16:18:43.427: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:18:43.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8608" for this suite.

• [SLOW TEST:88.739 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":356,"completed":245,"skipped":4526,"failed":0}
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:18:43.452: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3983
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:18:43.486: INFO: Found 0 stateful pods, waiting for 1
Jul  4 16:18:53.490: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
Jul  4 16:18:53.505: INFO: Found 1 stateful pods, waiting for 2
Jul  4 16:19:03.518: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 16:19:03.518: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  4 16:19:03.531: INFO: Deleting all statefulset in ns statefulset-3983
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  4 16:19:03.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3983" for this suite.

• [SLOW TEST:20.099 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":356,"completed":246,"skipped":4531,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:19:03.551: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  4 16:21:01.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6172" for this suite.

• [SLOW TEST:118.050 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":356,"completed":247,"skipped":4563,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:21:01.601: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:21:01.616: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties
Jul  4 16:21:03.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 --namespace=crd-publish-openapi-6387 create -f -'
Jul  4 16:21:04.794: INFO: stderr: ""
Jul  4 16:21:04.794: INFO: stdout: "e2e-test-crd-publish-openapi-4833-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jul  4 16:21:04.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 --namespace=crd-publish-openapi-6387 delete e2e-test-crd-publish-openapi-4833-crds test-foo'
Jul  4 16:21:04.882: INFO: stderr: ""
Jul  4 16:21:04.882: INFO: stdout: "e2e-test-crd-publish-openapi-4833-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Jul  4 16:21:04.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 --namespace=crd-publish-openapi-6387 apply -f -'
Jul  4 16:21:05.077: INFO: stderr: ""
Jul  4 16:21:05.077: INFO: stdout: "e2e-test-crd-publish-openapi-4833-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jul  4 16:21:05.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 --namespace=crd-publish-openapi-6387 delete e2e-test-crd-publish-openapi-4833-crds test-foo'
Jul  4 16:21:05.135: INFO: stderr: ""
Jul  4 16:21:05.135: INFO: stdout: "e2e-test-crd-publish-openapi-4833-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values
Jul  4 16:21:05.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 --namespace=crd-publish-openapi-6387 create -f -'
Jul  4 16:21:05.302: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Jul  4 16:21:05.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 --namespace=crd-publish-openapi-6387 create -f -'
Jul  4 16:21:05.463: INFO: rc: 1
Jul  4 16:21:05.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 --namespace=crd-publish-openapi-6387 apply -f -'
Jul  4 16:21:05.631: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties
Jul  4 16:21:05.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 --namespace=crd-publish-openapi-6387 create -f -'
Jul  4 16:21:05.790: INFO: rc: 1
Jul  4 16:21:05.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 --namespace=crd-publish-openapi-6387 apply -f -'
Jul  4 16:21:05.948: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Jul  4 16:21:05.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 explain e2e-test-crd-publish-openapi-4833-crds'
Jul  4 16:21:06.108: INFO: stderr: ""
Jul  4 16:21:06.108: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4833-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Jul  4 16:21:06.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 explain e2e-test-crd-publish-openapi-4833-crds.metadata'
Jul  4 16:21:06.270: INFO: stderr: ""
Jul  4 16:21:06.270: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4833-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     Deprecated: ClusterName is a legacy field that was always cleared by the\n     system and never used; it will be removed completely in 1.25.\n\n     The name in the go struct is changed to help clients detect accidental use.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Jul  4 16:21:06.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 explain e2e-test-crd-publish-openapi-4833-crds.spec'
Jul  4 16:21:06.442: INFO: stderr: ""
Jul  4 16:21:06.442: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4833-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Jul  4 16:21:06.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 explain e2e-test-crd-publish-openapi-4833-crds.spec.bars'
Jul  4 16:21:06.628: INFO: stderr: ""
Jul  4 16:21:06.628: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4833-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Jul  4 16:21:06.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-6387 explain e2e-test-crd-publish-openapi-4833-crds.spec.bars2'
Jul  4 16:21:06.820: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:21:09.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6387" for this suite.

• [SLOW TEST:7.536 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":356,"completed":248,"skipped":4592,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:21:09.137: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Jul  4 16:21:10.184: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0704 16:21:10.184267      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  4 16:21:10.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2918" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":356,"completed":249,"skipped":4607,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:21:10.190: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:21:10.216: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jul  4 16:21:10.224: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:21:10.224: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:21:11.232: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:21:11.232: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:21:12.231: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  4 16:21:12.231: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jul  4 16:21:12.248: INFO: Wrong image for pod: daemon-set-g6r44. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:12.248: INFO: Wrong image for pod: daemon-set-jr94f. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:12.248: INFO: Wrong image for pod: daemon-set-xjpt6. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:13.259: INFO: Wrong image for pod: daemon-set-g6r44. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:13.259: INFO: Wrong image for pod: daemon-set-xjpt6. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:14.258: INFO: Wrong image for pod: daemon-set-g6r44. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:14.258: INFO: Wrong image for pod: daemon-set-xjpt6. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:15.256: INFO: Wrong image for pod: daemon-set-g6r44. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:15.256: INFO: Wrong image for pod: daemon-set-xjpt6. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:15.256: INFO: Pod daemon-set-ztcx4 is not available
Jul  4 16:21:16.258: INFO: Wrong image for pod: daemon-set-xjpt6. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:17.258: INFO: Pod daemon-set-968d2 is not available
Jul  4 16:21:17.258: INFO: Wrong image for pod: daemon-set-xjpt6. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  4 16:21:19.258: INFO: Pod daemon-set-jvw8n is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jul  4 16:21:19.265: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  4 16:21:19.265: INFO: Node 18.224.151.13 is running 0 daemon pod, expected 1
Jul  4 16:21:20.272: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  4 16:21:20.272: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-107, will wait for the garbage collector to delete the pods
Jul  4 16:21:20.339: INFO: Deleting DaemonSet.extensions daemon-set took: 4.587649ms
Jul  4 16:21:20.440: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.649832ms
Jul  4 16:21:23.248: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:21:23.248: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  4 16:21:23.250: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26015"},"items":null}

Jul  4 16:21:23.252: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26015"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:21:23.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-107" for this suite.

• [SLOW TEST:13.076 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":356,"completed":250,"skipped":4627,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:21:23.267: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Jul  4 16:21:25.294: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2138 PodName:var-expansion-53178ea3-6496-46b2-83f9-365ec32ef879 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:21:25.294: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:21:25.294: INFO: ExecWithOptions: Clientset creation
Jul  4 16:21:25.294: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/var-expansion-2138/pods/var-expansion-53178ea3-6496-46b2-83f9-365ec32ef879/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path
Jul  4 16:21:25.374: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2138 PodName:var-expansion-53178ea3-6496-46b2-83f9-365ec32ef879 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:21:25.374: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:21:25.374: INFO: ExecWithOptions: Clientset creation
Jul  4 16:21:25.374: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/var-expansion-2138/pods/var-expansion-53178ea3-6496-46b2-83f9-365ec32ef879/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value
Jul  4 16:21:25.969: INFO: Successfully updated pod "var-expansion-53178ea3-6496-46b2-83f9-365ec32ef879"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Jul  4 16:21:25.972: INFO: Deleting pod "var-expansion-53178ea3-6496-46b2-83f9-365ec32ef879" in namespace "var-expansion-2138"
Jul  4 16:21:25.976: INFO: Wait up to 5m0s for pod "var-expansion-53178ea3-6496-46b2-83f9-365ec32ef879" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  4 16:21:57.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2138" for this suite.

• [SLOW TEST:34.734 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":356,"completed":251,"skipped":4666,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:21:58.000: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override all
Jul  4 16:21:58.021: INFO: Waiting up to 5m0s for pod "client-containers-3c980eb2-55b9-42f8-ab62-a0c2186830a6" in namespace "containers-5689" to be "Succeeded or Failed"
Jul  4 16:21:58.024: INFO: Pod "client-containers-3c980eb2-55b9-42f8-ab62-a0c2186830a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.6016ms
Jul  4 16:22:00.030: INFO: Pod "client-containers-3c980eb2-55b9-42f8-ab62-a0c2186830a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009044926s
Jul  4 16:22:02.038: INFO: Pod "client-containers-3c980eb2-55b9-42f8-ab62-a0c2186830a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016305322s
STEP: Saw pod success
Jul  4 16:22:02.038: INFO: Pod "client-containers-3c980eb2-55b9-42f8-ab62-a0c2186830a6" satisfied condition "Succeeded or Failed"
Jul  4 16:22:02.040: INFO: Trying to get logs from node 3.138.203.20 pod client-containers-3c980eb2-55b9-42f8-ab62-a0c2186830a6 container agnhost-container: <nil>
STEP: delete the pod
Jul  4 16:22:02.063: INFO: Waiting for pod client-containers-3c980eb2-55b9-42f8-ab62-a0c2186830a6 to disappear
Jul  4 16:22:02.065: INFO: Pod client-containers-3c980eb2-55b9-42f8-ab62-a0c2186830a6 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Jul  4 16:22:02.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5689" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":356,"completed":252,"skipped":4677,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:22:02.089: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:22:02.114: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jul  4 16:22:07.121: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul  4 16:22:07.121: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  4 16:22:07.134: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-5748  d45bf42e-71b1-4cf6-bc41-f526938d3257 26201 1 2022-07-04 16:22:07 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2022-07-04 16:22:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0054170e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Jul  4 16:22:07.135: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  4 16:22:07.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5748" for this suite.

• [SLOW TEST:5.058 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":356,"completed":253,"skipped":4692,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:22:07.148: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod with failed condition
STEP: updating the pod
Jul  4 16:24:07.695: INFO: Successfully updated pod "var-expansion-f1a20604-3633-41cd-a12e-e89ce11d530e"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Jul  4 16:24:09.706: INFO: Deleting pod "var-expansion-f1a20604-3633-41cd-a12e-e89ce11d530e" in namespace "var-expansion-7973"
Jul  4 16:24:09.712: INFO: Wait up to 5m0s for pod "var-expansion-f1a20604-3633-41cd-a12e-e89ce11d530e" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  4 16:24:41.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7973" for this suite.

• [SLOW TEST:154.579 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":356,"completed":254,"skipped":4706,"failed":0}
[sig-node] RuntimeClass 
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:24:41.727: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Deleting RuntimeClass runtimeclass-4083-delete-me
STEP: Waiting for the RuntimeClass to disappear
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  4 16:24:41.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4083" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":255,"skipped":4706,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:24:41.758: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Jul  4 16:24:41.771: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:24:57.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1808" for this suite.

• [SLOW TEST:15.902 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":356,"completed":256,"skipped":4737,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:24:57.660: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul  4 16:24:57.687: INFO: Waiting up to 5m0s for pod "pod-0997cc8c-ff31-4776-8e0a-823d8abb950c" in namespace "emptydir-7260" to be "Succeeded or Failed"
Jul  4 16:24:57.689: INFO: Pod "pod-0997cc8c-ff31-4776-8e0a-823d8abb950c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.755717ms
Jul  4 16:24:59.697: INFO: Pod "pod-0997cc8c-ff31-4776-8e0a-823d8abb950c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00935606s
Jul  4 16:25:01.701: INFO: Pod "pod-0997cc8c-ff31-4776-8e0a-823d8abb950c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013816598s
STEP: Saw pod success
Jul  4 16:25:01.701: INFO: Pod "pod-0997cc8c-ff31-4776-8e0a-823d8abb950c" satisfied condition "Succeeded or Failed"
Jul  4 16:25:01.703: INFO: Trying to get logs from node 3.138.203.20 pod pod-0997cc8c-ff31-4776-8e0a-823d8abb950c container test-container: <nil>
STEP: delete the pod
Jul  4 16:25:01.723: INFO: Waiting for pod pod-0997cc8c-ff31-4776-8e0a-823d8abb950c to disappear
Jul  4 16:25:01.724: INFO: Pod pod-0997cc8c-ff31-4776-8e0a-823d8abb950c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 16:25:01.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7260" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":257,"skipped":4776,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:01.731: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:25:01.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3146" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":356,"completed":258,"skipped":4791,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:01.775: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:25:01.787: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Jul  4 16:25:05.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-5543 --namespace=crd-publish-openapi-5543 create -f -'
Jul  4 16:25:06.444: INFO: stderr: ""
Jul  4 16:25:06.444: INFO: stdout: "e2e-test-crd-publish-openapi-6365-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jul  4 16:25:06.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-5543 --namespace=crd-publish-openapi-5543 delete e2e-test-crd-publish-openapi-6365-crds test-cr'
Jul  4 16:25:06.501: INFO: stderr: ""
Jul  4 16:25:06.501: INFO: stdout: "e2e-test-crd-publish-openapi-6365-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Jul  4 16:25:06.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-5543 --namespace=crd-publish-openapi-5543 apply -f -'
Jul  4 16:25:06.686: INFO: stderr: ""
Jul  4 16:25:06.686: INFO: stdout: "e2e-test-crd-publish-openapi-6365-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jul  4 16:25:06.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-5543 --namespace=crd-publish-openapi-5543 delete e2e-test-crd-publish-openapi-6365-crds test-cr'
Jul  4 16:25:06.748: INFO: stderr: ""
Jul  4 16:25:06.748: INFO: stdout: "e2e-test-crd-publish-openapi-6365-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Jul  4 16:25:06.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=crd-publish-openapi-5543 explain e2e-test-crd-publish-openapi-6365-crds'
Jul  4 16:25:06.933: INFO: stderr: ""
Jul  4 16:25:06.934: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6365-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:25:10.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5543" for this suite.

• [SLOW TEST:8.979 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":356,"completed":259,"skipped":4823,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:10.754: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-5312
STEP: creating service affinity-nodeport in namespace services-5312
STEP: creating replication controller affinity-nodeport in namespace services-5312
I0704 16:25:10.793580      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-5312, replica count: 3
I0704 16:25:13.845634      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 16:25:13.855: INFO: Creating new exec pod
Jul  4 16:25:16.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-5312 exec execpod-affinitysjxmh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Jul  4 16:25:17.000: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Jul  4 16:25:17.000: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:25:17.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-5312 exec execpod-affinitysjxmh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.195.243 80'
Jul  4 16:25:17.127: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.195.243 80\nConnection to 10.43.195.243 80 port [tcp/http] succeeded!\n"
Jul  4 16:25:17.127: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:25:17.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-5312 exec execpod-affinitysjxmh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.20.100 31347'
Jul  4 16:25:17.247: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.20.100 31347\nConnection to 172.31.20.100 31347 port [tcp/*] succeeded!\n"
Jul  4 16:25:17.247: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:25:17.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-5312 exec execpod-affinitysjxmh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.73 31347'
Jul  4 16:25:17.372: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.73 31347\nConnection to 172.31.25.73 31347 port [tcp/*] succeeded!\n"
Jul  4 16:25:17.372: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:25:17.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-5312 exec execpod-affinitysjxmh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.20.100:31347/ ; done'
Jul  4 16:25:17.558: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.20.100:31347/\n"
Jul  4 16:25:17.558: INFO: stdout: "\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6\naffinity-nodeport-jx7h6"
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Received response from host: affinity-nodeport-jx7h6
Jul  4 16:25:17.558: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-5312, will wait for the garbage collector to delete the pods
Jul  4 16:25:17.622: INFO: Deleting ReplicationController affinity-nodeport took: 3.298527ms
Jul  4 16:25:17.723: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.072677ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 16:25:19.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5312" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:8.993 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":260,"skipped":4827,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:19.747: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  4 16:25:21.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3010" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":356,"completed":261,"skipped":4840,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:21.645: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption is created
Jul  4 16:25:21.667: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:25:23.675: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  4 16:25:24.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5451" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":356,"completed":262,"skipped":4901,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:24.698: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:25:25.468: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:25:28.485: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Jul  4 16:25:30.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=webhook-3139 attach --namespace=webhook-3139 to-be-attached-pod -i -c=container1'
Jul  4 16:25:30.575: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:25:30.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3139" for this suite.
STEP: Destroying namespace "webhook-3139-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:5.915 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":356,"completed":263,"skipped":5005,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:30.613: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Jul  4 16:25:30.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-951" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":356,"completed":264,"skipped":5015,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:30.682: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1574
[It] should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Jul  4 16:25:30.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-4209 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jul  4 16:25:30.797: INFO: stderr: ""
Jul  4 16:25:30.797: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Jul  4 16:25:35.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-4209 get pod e2e-test-httpd-pod -o json'
Jul  4 16:25:35.905: INFO: stderr: ""
Jul  4 16:25:35.905: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"0c4a12825f158781ab00d41582571430b8a3a7a1b36d4f2de9494e378dbeb845\",\n            \"cni.projectcalico.org/podIP\": \"10.42.2.250/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.42.2.250/32\"\n        },\n        \"creationTimestamp\": \"2022-07-04T16:25:30Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4209\",\n        \"resourceVersion\": \"26959\",\n        \"uid\": \"3d1ae2e1-c9a2-4176-824d-975ee9439f75\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-cntfk\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"18.216.149.32\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-cntfk\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-07-04T16:25:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-07-04T16:25:31Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-07-04T16:25:31Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-07-04T16:25:30Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a6b3ed0ea2bc67f16c629d6c97499607916c510715efc09c7213f0553eedf0e9\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-07-04T16:25:31Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.20.100\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.2.250\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.42.2.250\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-07-04T16:25:30Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jul  4 16:25:35.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-4209 replace -f -'
Jul  4 16:25:36.547: INFO: stderr: ""
Jul  4 16:25:36.547: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-2
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1578
Jul  4 16:25:36.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-4209 delete pods e2e-test-httpd-pod'
Jul  4 16:25:37.872: INFO: stderr: ""
Jul  4 16:25:37.873: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 16:25:37.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4209" for this suite.

• [SLOW TEST:7.199 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1571
    should update a single-container pod's image  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":356,"completed":265,"skipped":5070,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:37.880: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:25:38.511: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jul  4 16:25:40.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 4, 16, 25, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 16, 25, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 4, 16, 25, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 4, 16, 25, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:25:43.533: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:25:43.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4995" for this suite.
STEP: Destroying namespace "webhook-4995-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:5.734 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":356,"completed":266,"skipped":5076,"failed":0}
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:43.614: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jul  4 16:25:43.650: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2523  8de274d1-197a-4b70-be83-63d18968c4b5 27089 0 2022-07-04 16:25:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-04 16:25:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:25:43.650: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2523  8de274d1-197a-4b70-be83-63d18968c4b5 27090 0 2022-07-04 16:25:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-04 16:25:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:25:43.650: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2523  8de274d1-197a-4b70-be83-63d18968c4b5 27091 0 2022-07-04 16:25:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-04 16:25:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jul  4 16:25:53.675: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2523  8de274d1-197a-4b70-be83-63d18968c4b5 27122 0 2022-07-04 16:25:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-04 16:25:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:25:53.676: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2523  8de274d1-197a-4b70-be83-63d18968c4b5 27123 0 2022-07-04 16:25:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-04 16:25:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  4 16:25:53.676: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2523  8de274d1-197a-4b70-be83-63d18968c4b5 27124 0 2022-07-04 16:25:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-04 16:25:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  4 16:25:53.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2523" for this suite.

• [SLOW TEST:10.067 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":356,"completed":267,"skipped":5076,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:53.682: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 16:25:53.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-17" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":356,"completed":268,"skipped":5090,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:53.717: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul  4 16:25:53.733: INFO: Waiting up to 5m0s for pod "pod-18da4a4e-0be6-4ed3-898a-6ccc19e258d1" in namespace "emptydir-5510" to be "Succeeded or Failed"
Jul  4 16:25:53.736: INFO: Pod "pod-18da4a4e-0be6-4ed3-898a-6ccc19e258d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.638297ms
Jul  4 16:25:55.741: INFO: Pod "pod-18da4a4e-0be6-4ed3-898a-6ccc19e258d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007498144s
Jul  4 16:25:57.744: INFO: Pod "pod-18da4a4e-0be6-4ed3-898a-6ccc19e258d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011267218s
STEP: Saw pod success
Jul  4 16:25:57.744: INFO: Pod "pod-18da4a4e-0be6-4ed3-898a-6ccc19e258d1" satisfied condition "Succeeded or Failed"
Jul  4 16:25:57.746: INFO: Trying to get logs from node 18.216.149.32 pod pod-18da4a4e-0be6-4ed3-898a-6ccc19e258d1 container test-container: <nil>
STEP: delete the pod
Jul  4 16:25:57.773: INFO: Waiting for pod pod-18da4a4e-0be6-4ed3-898a-6ccc19e258d1 to disappear
Jul  4 16:25:57.774: INFO: Pod pod-18da4a4e-0be6-4ed3-898a-6ccc19e258d1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 16:25:57.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5510" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":269,"skipped":5115,"failed":0}
SSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:25:57.780: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:25:59.812: INFO: Deleting pod "var-expansion-d8fb93ce-cd86-4981-b2ce-8ea218c6c61e" in namespace "var-expansion-7979"
Jul  4 16:25:59.817: INFO: Wait up to 5m0s for pod "var-expansion-d8fb93ce-cd86-4981-b2ce-8ea218c6c61e" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  4 16:26:03.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7979" for this suite.

• [SLOW TEST:6.053 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":356,"completed":270,"skipped":5119,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:26:03.834: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Jul  4 16:26:07.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1626" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":356,"completed":271,"skipped":5144,"failed":0}
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:26:07.917: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jul  4 16:26:11.962: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  4 16:26:11.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2052" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":272,"skipped":5145,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:26:11.977: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Jul  4 16:26:12.009: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:26:14.016: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Jul  4 16:26:14.023: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:26:16.028: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Jul  4 16:26:16.034: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul  4 16:26:16.037: INFO: Pod pod-with-prestop-http-hook still exists
Jul  4 16:26:18.037: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul  4 16:26:18.044: INFO: Pod pod-with-prestop-http-hook still exists
Jul  4 16:26:20.038: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul  4 16:26:20.046: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Jul  4 16:26:20.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6638" for this suite.

• [SLOW TEST:8.093 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":356,"completed":273,"skipped":5167,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:26:20.071: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9273
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating stateful set ss in namespace statefulset-9273
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9273
Jul  4 16:26:20.097: INFO: Found 0 stateful pods, waiting for 1
Jul  4 16:26:30.109: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jul  4 16:26:30.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-9273 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:26:30.235: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:26:30.235: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:26:30.235: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  4 16:26:30.238: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul  4 16:26:40.242: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  4 16:26:40.242: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 16:26:40.252: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jul  4 16:26:40.252: INFO: ss-0  3.138.203.20  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:20 +0000 UTC  }]
Jul  4 16:26:40.252: INFO: 
Jul  4 16:26:40.252: INFO: StatefulSet ss has not reached scale 3, at 1
Jul  4 16:26:41.256: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996761946s
Jul  4 16:26:42.262: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993746059s
Jul  4 16:26:43.268: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988157835s
Jul  4 16:26:44.274: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981752127s
Jul  4 16:26:45.278: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976297485s
Jul  4 16:26:46.284: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972384224s
Jul  4 16:26:47.291: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964740472s
Jul  4 16:26:48.298: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.958974072s
Jul  4 16:26:49.304: INFO: Verifying statefulset ss doesn't scale past 3 for another 952.331366ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9273
Jul  4 16:26:50.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-9273 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  4 16:26:50.435: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  4 16:26:50.435: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  4 16:26:50.435: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  4 16:26:50.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-9273 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  4 16:26:50.570: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul  4 16:26:50.570: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  4 16:26:50.570: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  4 16:26:50.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-9273 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  4 16:26:50.691: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul  4 16:26:50.691: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  4 16:26:50.691: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  4 16:26:50.694: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jul  4 16:27:00.699: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 16:27:00.699: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  4 16:27:00.699: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jul  4 16:27:00.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-9273 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:27:00.831: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:27:00.831: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:27:00.831: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  4 16:27:00.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-9273 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:27:00.974: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:27:00.974: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:27:00.974: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  4 16:27:00.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=statefulset-9273 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  4 16:27:01.104: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  4 16:27:01.104: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  4 16:27:01.104: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  4 16:27:01.104: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 16:27:01.107: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jul  4 16:27:11.115: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  4 16:27:11.115: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul  4 16:27:11.115: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul  4 16:27:11.125: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jul  4 16:27:11.125: INFO: ss-0  3.138.203.20   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:27:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:27:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:20 +0000 UTC  }]
Jul  4 16:27:11.125: INFO: ss-1  18.216.149.32  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:27:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:27:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:40 +0000 UTC  }]
Jul  4 16:27:11.125: INFO: ss-2  18.224.151.13  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:27:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:27:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-04 16:26:40 +0000 UTC  }]
Jul  4 16:27:11.125: INFO: 
Jul  4 16:27:11.125: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  4 16:27:12.128: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.995401044s
Jul  4 16:27:13.133: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.992126064s
Jul  4 16:27:14.139: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.986983526s
Jul  4 16:27:15.144: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.981789207s
Jul  4 16:27:16.149: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.976549931s
Jul  4 16:27:17.153: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.971549023s
Jul  4 16:27:18.159: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.967489994s
Jul  4 16:27:19.165: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.960819507s
Jul  4 16:27:20.171: INFO: Verifying statefulset ss doesn't scale past 0 for another 955.421358ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9273
Jul  4 16:27:21.176: INFO: Scaling statefulset ss to 0
Jul  4 16:27:21.184: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  4 16:27:21.186: INFO: Deleting all statefulset in ns statefulset-9273
Jul  4 16:27:21.187: INFO: Scaling statefulset ss to 0
Jul  4 16:27:21.194: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 16:27:21.195: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  4 16:27:21.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9273" for this suite.

• [SLOW TEST:61.137 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":356,"completed":274,"skipped":5200,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:27:21.208: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:27:21.232: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e74177fc-77b7-4c28-b1cb-be16a6020fb5" in namespace "downward-api-8991" to be "Succeeded or Failed"
Jul  4 16:27:21.234: INFO: Pod "downwardapi-volume-e74177fc-77b7-4c28-b1cb-be16a6020fb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.116058ms
Jul  4 16:27:23.240: INFO: Pod "downwardapi-volume-e74177fc-77b7-4c28-b1cb-be16a6020fb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008086129s
Jul  4 16:27:25.251: INFO: Pod "downwardapi-volume-e74177fc-77b7-4c28-b1cb-be16a6020fb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019148474s
STEP: Saw pod success
Jul  4 16:27:25.251: INFO: Pod "downwardapi-volume-e74177fc-77b7-4c28-b1cb-be16a6020fb5" satisfied condition "Succeeded or Failed"
Jul  4 16:27:25.254: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-e74177fc-77b7-4c28-b1cb-be16a6020fb5 container client-container: <nil>
STEP: delete the pod
Jul  4 16:27:25.267: INFO: Waiting for pod downwardapi-volume-e74177fc-77b7-4c28-b1cb-be16a6020fb5 to disappear
Jul  4 16:27:25.269: INFO: Pod downwardapi-volume-e74177fc-77b7-4c28-b1cb-be16a6020fb5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 16:27:25.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8991" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":275,"skipped":5203,"failed":0}
SSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:27:25.274: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:27:25.303: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:27:27.308: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:29.309: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:31.308: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:33.311: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:35.307: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:37.307: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:39.311: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:41.308: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:43.311: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:45.307: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = false)
Jul  4 16:27:47.308: INFO: The status of Pod test-webserver-5c140aa6-815d-4778-95ba-792e93065709 is Running (Ready = true)
Jul  4 16:27:47.310: INFO: Container started at 2022-07-04 16:27:26 +0000 UTC, pod became ready at 2022-07-04 16:27:45 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  4 16:27:47.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3144" for this suite.

• [SLOW TEST:22.042 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":356,"completed":276,"skipped":5206,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:27:47.317: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:27:47.473: INFO: The status of Pod server-envvars-5c935970-3f06-406b-90bd-07785c46f0be is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:27:49.481: INFO: The status of Pod server-envvars-5c935970-3f06-406b-90bd-07785c46f0be is Running (Ready = true)
Jul  4 16:27:49.578: INFO: Waiting up to 5m0s for pod "client-envvars-0ff49029-a727-4bb3-98a8-aabb2bba6a60" in namespace "pods-5394" to be "Succeeded or Failed"
Jul  4 16:27:49.587: INFO: Pod "client-envvars-0ff49029-a727-4bb3-98a8-aabb2bba6a60": Phase="Pending", Reason="", readiness=false. Elapsed: 8.443003ms
Jul  4 16:27:51.591: INFO: Pod "client-envvars-0ff49029-a727-4bb3-98a8-aabb2bba6a60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012379203s
Jul  4 16:27:53.598: INFO: Pod "client-envvars-0ff49029-a727-4bb3-98a8-aabb2bba6a60": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020085351s
Jul  4 16:27:55.625: INFO: Pod "client-envvars-0ff49029-a727-4bb3-98a8-aabb2bba6a60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.046332647s
STEP: Saw pod success
Jul  4 16:27:55.625: INFO: Pod "client-envvars-0ff49029-a727-4bb3-98a8-aabb2bba6a60" satisfied condition "Succeeded or Failed"
Jul  4 16:27:55.627: INFO: Trying to get logs from node 18.224.151.13 pod client-envvars-0ff49029-a727-4bb3-98a8-aabb2bba6a60 container env3cont: <nil>
STEP: delete the pod
Jul  4 16:27:55.695: INFO: Waiting for pod client-envvars-0ff49029-a727-4bb3-98a8-aabb2bba6a60 to disappear
Jul  4 16:27:55.714: INFO: Pod client-envvars-0ff49029-a727-4bb3-98a8-aabb2bba6a60 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  4 16:27:55.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5394" for this suite.

• [SLOW TEST:8.403 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":356,"completed":277,"skipped":5291,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:27:55.720: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-e9c7d119-19e0-43ce-978d-c93c26b2dc1b
STEP: Creating a pod to test consume configMaps
Jul  4 16:27:55.835: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0c851350-ae76-41a1-b357-1d184b08802c" in namespace "projected-9344" to be "Succeeded or Failed"
Jul  4 16:27:55.844: INFO: Pod "pod-projected-configmaps-0c851350-ae76-41a1-b357-1d184b08802c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.986778ms
Jul  4 16:27:57.849: INFO: Pod "pod-projected-configmaps-0c851350-ae76-41a1-b357-1d184b08802c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014399108s
Jul  4 16:27:59.856: INFO: Pod "pod-projected-configmaps-0c851350-ae76-41a1-b357-1d184b08802c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020684811s
STEP: Saw pod success
Jul  4 16:27:59.856: INFO: Pod "pod-projected-configmaps-0c851350-ae76-41a1-b357-1d184b08802c" satisfied condition "Succeeded or Failed"
Jul  4 16:27:59.858: INFO: Trying to get logs from node 18.216.149.32 pod pod-projected-configmaps-0c851350-ae76-41a1-b357-1d184b08802c container agnhost-container: <nil>
STEP: delete the pod
Jul  4 16:27:59.917: INFO: Waiting for pod pod-projected-configmaps-0c851350-ae76-41a1-b357-1d184b08802c to disappear
Jul  4 16:27:59.974: INFO: Pod pod-projected-configmaps-0c851350-ae76-41a1-b357-1d184b08802c no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  4 16:27:59.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9344" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":278,"skipped":5294,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:27:59.981: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service multi-endpoint-test in namespace services-9746
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9746 to expose endpoints map[]
Jul  4 16:28:00.135: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Jul  4 16:28:01.154: INFO: successfully validated that service multi-endpoint-test in namespace services-9746 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-9746
Jul  4 16:28:01.253: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:28:03.289: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9746 to expose endpoints map[pod1:[100]]
Jul  4 16:28:03.297: INFO: successfully validated that service multi-endpoint-test in namespace services-9746 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-9746
Jul  4 16:28:03.335: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:28:05.348: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9746 to expose endpoints map[pod1:[100] pod2:[101]]
Jul  4 16:28:05.404: INFO: successfully validated that service multi-endpoint-test in namespace services-9746 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
Jul  4 16:28:05.404: INFO: Creating new exec pod
Jul  4 16:28:10.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-9746 exec execpodrrjhn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Jul  4 16:28:10.600: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Jul  4 16:28:10.600: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:28:10.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-9746 exec execpodrrjhn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.81.232 80'
Jul  4 16:28:10.727: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.81.232 80\nConnection to 10.43.81.232 80 port [tcp/http] succeeded!\n"
Jul  4 16:28:10.727: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:28:10.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-9746 exec execpodrrjhn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Jul  4 16:28:10.860: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Jul  4 16:28:10.860: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:28:10.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-9746 exec execpodrrjhn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.81.232 81'
Jul  4 16:28:11.009: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.81.232 81\nConnection to 10.43.81.232 81 port [tcp/*] succeeded!\n"
Jul  4 16:28:11.009: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-9746
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9746 to expose endpoints map[pod2:[101]]
Jul  4 16:28:12.038: INFO: successfully validated that service multi-endpoint-test in namespace services-9746 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-9746
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9746 to expose endpoints map[]
Jul  4 16:28:13.061: INFO: successfully validated that service multi-endpoint-test in namespace services-9746 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 16:28:13.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9746" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:13.096 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":356,"completed":279,"skipped":5305,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:28:13.077: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-8881
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  4 16:28:13.090: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul  4 16:28:13.120: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:28:15.127: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:28:17.127: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:28:19.127: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:28:21.126: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:28:23.129: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  4 16:28:25.128: INFO: The status of Pod netserver-0 is Running (Ready = true)
Jul  4 16:28:25.132: INFO: The status of Pod netserver-1 is Running (Ready = true)
Jul  4 16:28:25.135: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Jul  4 16:28:27.153: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul  4 16:28:27.153: INFO: Breadth first check of 10.42.2.8 on host 172.31.20.100...
Jul  4 16:28:27.155: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.11:9080/dial?request=hostname&protocol=udp&host=10.42.2.8&port=8081&tries=1'] Namespace:pod-network-test-8881 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:28:27.155: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:28:27.155: INFO: ExecWithOptions: Clientset creation
Jul  4 16:28:27.155: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-8881/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.11%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.2.8%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  4 16:28:27.228: INFO: Waiting for responses: map[]
Jul  4 16:28:27.228: INFO: reached 10.42.2.8 after 0/1 tries
Jul  4 16:28:27.228: INFO: Breadth first check of 10.42.0.177 on host 172.31.25.73...
Jul  4 16:28:27.230: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.11:9080/dial?request=hostname&protocol=udp&host=10.42.0.177&port=8081&tries=1'] Namespace:pod-network-test-8881 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:28:27.230: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:28:27.231: INFO: ExecWithOptions: Clientset creation
Jul  4 16:28:27.231: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-8881/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.11%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.0.177%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  4 16:28:27.307: INFO: Waiting for responses: map[]
Jul  4 16:28:27.307: INFO: reached 10.42.0.177 after 0/1 tries
Jul  4 16:28:27.307: INFO: Breadth first check of 10.42.1.10 on host 172.31.23.66...
Jul  4 16:28:27.309: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.11:9080/dial?request=hostname&protocol=udp&host=10.42.1.10&port=8081&tries=1'] Namespace:pod-network-test-8881 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:28:27.309: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:28:27.310: INFO: ExecWithOptions: Clientset creation
Jul  4 16:28:27.310: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/pod-network-test-8881/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.42.1.11%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.42.1.10%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  4 16:28:27.379: INFO: Waiting for responses: map[]
Jul  4 16:28:27.379: INFO: reached 10.42.1.10 after 0/1 tries
Jul  4 16:28:27.379: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Jul  4 16:28:27.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8881" for this suite.

• [SLOW TEST:14.309 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":356,"completed":280,"skipped":5320,"failed":0}
S
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:28:27.385: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Jul  4 16:28:27.403: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6071  b4e75476-64c8-43a7-834c-b2631496c799 27959 0 2022-07-04 16:28:27 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2022-07-04 16:28:27 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xj6gt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xj6gt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 16:28:27.405: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:28:29.413: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Jul  4 16:28:29.413: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6071 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:28:29.413: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:28:29.414: INFO: ExecWithOptions: Clientset creation
Jul  4 16:28:29.414: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/dns-6071/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod...
Jul  4 16:28:29.514: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6071 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  4 16:28:29.514: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:28:29.515: INFO: ExecWithOptions: Clientset creation
Jul  4 16:28:29.515: INFO: ExecWithOptions: execute(POST https://10.43.0.1:443/api/v1/namespaces/dns-6071/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  4 16:28:29.606: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  4 16:28:29.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6071" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":356,"completed":281,"skipped":5321,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:28:29.620: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Jul  4 16:28:29.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 create -f -'
Jul  4 16:28:29.861: INFO: stderr: ""
Jul  4 16:28:29.861: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul  4 16:28:29.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  4 16:28:29.926: INFO: stderr: ""
Jul  4 16:28:29.926: INFO: stdout: "update-demo-nautilus-645rq update-demo-nautilus-gld8g "
Jul  4 16:28:29.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 get pods update-demo-nautilus-645rq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 16:28:29.980: INFO: stderr: ""
Jul  4 16:28:29.980: INFO: stdout: ""
Jul  4 16:28:29.980: INFO: update-demo-nautilus-645rq is created but not running
Jul  4 16:28:34.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  4 16:28:35.044: INFO: stderr: ""
Jul  4 16:28:35.044: INFO: stdout: "update-demo-nautilus-645rq update-demo-nautilus-gld8g "
Jul  4 16:28:35.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 get pods update-demo-nautilus-645rq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 16:28:35.097: INFO: stderr: ""
Jul  4 16:28:35.097: INFO: stdout: "true"
Jul  4 16:28:35.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 get pods update-demo-nautilus-645rq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  4 16:28:35.151: INFO: stderr: ""
Jul  4 16:28:35.151: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  4 16:28:35.151: INFO: validating pod update-demo-nautilus-645rq
Jul  4 16:28:35.155: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  4 16:28:35.155: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  4 16:28:35.155: INFO: update-demo-nautilus-645rq is verified up and running
Jul  4 16:28:35.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 get pods update-demo-nautilus-gld8g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  4 16:28:35.211: INFO: stderr: ""
Jul  4 16:28:35.211: INFO: stdout: "true"
Jul  4 16:28:35.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 get pods update-demo-nautilus-gld8g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  4 16:28:35.272: INFO: stderr: ""
Jul  4 16:28:35.272: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  4 16:28:35.272: INFO: validating pod update-demo-nautilus-gld8g
Jul  4 16:28:35.276: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  4 16:28:35.276: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  4 16:28:35.276: INFO: update-demo-nautilus-gld8g is verified up and running
STEP: using delete to clean up resources
Jul  4 16:28:35.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 delete --grace-period=0 --force -f -'
Jul  4 16:28:35.342: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  4 16:28:35.342: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul  4 16:28:35.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 get rc,svc -l name=update-demo --no-headers'
Jul  4 16:28:35.416: INFO: stderr: "No resources found in kubectl-8292 namespace.\n"
Jul  4 16:28:35.416: INFO: stdout: ""
Jul  4 16:28:35.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8292 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul  4 16:28:35.474: INFO: stderr: ""
Jul  4 16:28:35.474: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 16:28:35.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8292" for this suite.

• [SLOW TEST:5.864 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should create and stop a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":356,"completed":282,"skipped":5401,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:28:35.484: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  4 16:28:37.544: INFO: DNS probes using dns-744/dns-test-76f17e3d-b3de-4d3d-a74c-3af71cbfb430 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  4 16:28:37.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-744" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":356,"completed":283,"skipped":5415,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:28:37.559: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:28:37.577: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e026d54-02a0-451e-881a-3a42ec30dec0" in namespace "projected-1784" to be "Succeeded or Failed"
Jul  4 16:28:37.580: INFO: Pod "downwardapi-volume-0e026d54-02a0-451e-881a-3a42ec30dec0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.692224ms
Jul  4 16:28:39.586: INFO: Pod "downwardapi-volume-0e026d54-02a0-451e-881a-3a42ec30dec0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008682565s
Jul  4 16:28:41.591: INFO: Pod "downwardapi-volume-0e026d54-02a0-451e-881a-3a42ec30dec0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014655896s
STEP: Saw pod success
Jul  4 16:28:41.592: INFO: Pod "downwardapi-volume-0e026d54-02a0-451e-881a-3a42ec30dec0" satisfied condition "Succeeded or Failed"
Jul  4 16:28:41.593: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-0e026d54-02a0-451e-881a-3a42ec30dec0 container client-container: <nil>
STEP: delete the pod
Jul  4 16:28:41.606: INFO: Waiting for pod downwardapi-volume-0e026d54-02a0-451e-881a-3a42ec30dec0 to disappear
Jul  4 16:28:41.610: INFO: Pod downwardapi-volume-0e026d54-02a0-451e-881a-3a42ec30dec0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 16:28:41.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1784" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":284,"skipped":5430,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:28:41.616: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap that has name configmap-test-emptyKey-fd5227b6-f15f-40dd-8241-fa9ef57cc19f
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:28:41.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6943" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":356,"completed":285,"skipped":5451,"failed":0}
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:28:41.636: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4695
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4695
STEP: Waiting until pod test-pod will start running in namespace statefulset-4695
STEP: Creating statefulset with conflicting port in namespace statefulset-4695
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4695
Jul  4 16:28:43.772: INFO: Observed stateful pod in namespace: statefulset-4695, name: ss-0, uid: 0340be45-e261-4a71-a84b-5eabde7d394d, status phase: Pending. Waiting for statefulset controller to delete.
Jul  4 16:28:43.837: INFO: Observed stateful pod in namespace: statefulset-4695, name: ss-0, uid: 0340be45-e261-4a71-a84b-5eabde7d394d, status phase: Failed. Waiting for statefulset controller to delete.
Jul  4 16:28:43.898: INFO: Observed stateful pod in namespace: statefulset-4695, name: ss-0, uid: 0340be45-e261-4a71-a84b-5eabde7d394d, status phase: Failed. Waiting for statefulset controller to delete.
Jul  4 16:28:43.982: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4695
STEP: Removing pod with conflicting port in namespace statefulset-4695
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4695 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  4 16:28:46.149: INFO: Deleting all statefulset in ns statefulset-4695
Jul  4 16:28:46.151: INFO: Scaling statefulset ss to 0
Jul  4 16:28:56.180: INFO: Waiting for statefulset status.replicas updated to 0
Jul  4 16:28:56.182: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  4 16:28:56.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4695" for this suite.

• [SLOW TEST:14.622 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":356,"completed":286,"skipped":5454,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:28:56.258: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul  4 16:28:56.345: INFO: Waiting up to 5m0s for pod "pod-833417d9-4c5e-4d00-84b0-fbb627e20c11" in namespace "emptydir-9411" to be "Succeeded or Failed"
Jul  4 16:28:56.400: INFO: Pod "pod-833417d9-4c5e-4d00-84b0-fbb627e20c11": Phase="Pending", Reason="", readiness=false. Elapsed: 54.537864ms
Jul  4 16:28:58.406: INFO: Pod "pod-833417d9-4c5e-4d00-84b0-fbb627e20c11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060222589s
Jul  4 16:29:00.411: INFO: Pod "pod-833417d9-4c5e-4d00-84b0-fbb627e20c11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065345875s
STEP: Saw pod success
Jul  4 16:29:00.411: INFO: Pod "pod-833417d9-4c5e-4d00-84b0-fbb627e20c11" satisfied condition "Succeeded or Failed"
Jul  4 16:29:00.413: INFO: Trying to get logs from node 18.216.149.32 pod pod-833417d9-4c5e-4d00-84b0-fbb627e20c11 container test-container: <nil>
STEP: delete the pod
Jul  4 16:29:00.457: INFO: Waiting for pod pod-833417d9-4c5e-4d00-84b0-fbb627e20c11 to disappear
Jul  4 16:29:00.463: INFO: Pod pod-833417d9-4c5e-4d00-84b0-fbb627e20c11 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 16:29:00.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9411" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":287,"skipped":5482,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:29:00.491: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:29:00.540: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd6b62aa-30a0-4890-b142-811da32844a0" in namespace "downward-api-7521" to be "Succeeded or Failed"
Jul  4 16:29:00.543: INFO: Pod "downwardapi-volume-bd6b62aa-30a0-4890-b142-811da32844a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.629036ms
Jul  4 16:29:02.546: INFO: Pod "downwardapi-volume-bd6b62aa-30a0-4890-b142-811da32844a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006246695s
Jul  4 16:29:04.554: INFO: Pod "downwardapi-volume-bd6b62aa-30a0-4890-b142-811da32844a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014287981s
STEP: Saw pod success
Jul  4 16:29:04.554: INFO: Pod "downwardapi-volume-bd6b62aa-30a0-4890-b142-811da32844a0" satisfied condition "Succeeded or Failed"
Jul  4 16:29:04.556: INFO: Trying to get logs from node 3.138.203.20 pod downwardapi-volume-bd6b62aa-30a0-4890-b142-811da32844a0 container client-container: <nil>
STEP: delete the pod
Jul  4 16:29:04.581: INFO: Waiting for pod downwardapi-volume-bd6b62aa-30a0-4890-b142-811da32844a0 to disappear
Jul  4 16:29:04.583: INFO: Pod downwardapi-volume-bd6b62aa-30a0-4890-b142-811da32844a0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 16:29:04.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7521" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":288,"skipped":5497,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:29:04.589: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1334
STEP: creating the pod
Jul  4 16:29:04.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8190 create -f -'
Jul  4 16:29:04.774: INFO: stderr: ""
Jul  4 16:29:04.774: INFO: stdout: "pod/pause created\n"
Jul  4 16:29:04.774: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jul  4 16:29:04.774: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8190" to be "running and ready"
Jul  4 16:29:04.777: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.408635ms
Jul  4 16:29:06.783: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.008640051s
Jul  4 16:29:06.783: INFO: Pod "pause" satisfied condition "running and ready"
Jul  4 16:29:06.783: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
STEP: adding the label testing-label with value testing-label-value to a pod
Jul  4 16:29:06.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8190 label pods pause testing-label=testing-label-value'
Jul  4 16:29:06.847: INFO: stderr: ""
Jul  4 16:29:06.847: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jul  4 16:29:06.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8190 get pod pause -L testing-label'
Jul  4 16:29:06.901: INFO: stderr: ""
Jul  4 16:29:06.901: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jul  4 16:29:06.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8190 label pods pause testing-label-'
Jul  4 16:29:06.961: INFO: stderr: ""
Jul  4 16:29:06.961: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jul  4 16:29:06.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8190 get pod pause -L testing-label'
Jul  4 16:29:07.013: INFO: stderr: ""
Jul  4 16:29:07.013: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1340
STEP: using delete to clean up resources
Jul  4 16:29:07.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8190 delete --grace-period=0 --force -f -'
Jul  4 16:29:07.072: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  4 16:29:07.072: INFO: stdout: "pod \"pause\" force deleted\n"
Jul  4 16:29:07.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8190 get rc,svc -l name=pause --no-headers'
Jul  4 16:29:07.128: INFO: stderr: "No resources found in kubectl-8190 namespace.\n"
Jul  4 16:29:07.128: INFO: stdout: ""
Jul  4 16:29:07.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-8190 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul  4 16:29:07.181: INFO: stderr: ""
Jul  4 16:29:07.181: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 16:29:07.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8190" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":356,"completed":289,"skipped":5499,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:29:07.187: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:29:07.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c4032df8-24a5-4da7-b204-c699a400fd94" in namespace "downward-api-7294" to be "Succeeded or Failed"
Jul  4 16:29:07.211: INFO: Pod "downwardapi-volume-c4032df8-24a5-4da7-b204-c699a400fd94": Phase="Pending", Reason="", readiness=false. Elapsed: 1.716505ms
Jul  4 16:29:09.217: INFO: Pod "downwardapi-volume-c4032df8-24a5-4da7-b204-c699a400fd94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008306567s
Jul  4 16:29:11.223: INFO: Pod "downwardapi-volume-c4032df8-24a5-4da7-b204-c699a400fd94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013525452s
STEP: Saw pod success
Jul  4 16:29:11.223: INFO: Pod "downwardapi-volume-c4032df8-24a5-4da7-b204-c699a400fd94" satisfied condition "Succeeded or Failed"
Jul  4 16:29:11.224: INFO: Trying to get logs from node 18.216.149.32 pod downwardapi-volume-c4032df8-24a5-4da7-b204-c699a400fd94 container client-container: <nil>
STEP: delete the pod
Jul  4 16:29:11.237: INFO: Waiting for pod downwardapi-volume-c4032df8-24a5-4da7-b204-c699a400fd94 to disappear
Jul  4 16:29:11.239: INFO: Pod downwardapi-volume-c4032df8-24a5-4da7-b204-c699a400fd94 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 16:29:11.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7294" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":290,"skipped":5523,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:29:11.244: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:29:11.848: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:29:14.867: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:29:14.872: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:29:17.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2863" for this suite.
STEP: Destroying namespace "webhook-2863-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.756 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":356,"completed":291,"skipped":5523,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:29:18.001: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul  4 16:29:18.032: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  4 16:30:18.055: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:18.062: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:30:18.118: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
Jul  4 16:30:18.126: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:188
Jul  4 16:30:18.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8553" for this suite.
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:30:18.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-5260" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:60.328 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":356,"completed":292,"skipped":5549,"failed":0}
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:18.330: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replication controller my-hostname-basic-07179a54-26ff-4d50-8517-c46306ec74d3
Jul  4 16:30:18.437: INFO: Pod name my-hostname-basic-07179a54-26ff-4d50-8517-c46306ec74d3: Found 0 pods out of 1
Jul  4 16:30:23.447: INFO: Pod name my-hostname-basic-07179a54-26ff-4d50-8517-c46306ec74d3: Found 1 pods out of 1
Jul  4 16:30:23.447: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-07179a54-26ff-4d50-8517-c46306ec74d3" are running
Jul  4 16:30:23.449: INFO: Pod "my-hostname-basic-07179a54-26ff-4d50-8517-c46306ec74d3-wsz5d" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-04 16:30:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-04 16:30:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-04 16:30:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-04 16:30:18 +0000 UTC Reason: Message:}])
Jul  4 16:30:23.449: INFO: Trying to dial the pod
Jul  4 16:30:28.459: INFO: Controller my-hostname-basic-07179a54-26ff-4d50-8517-c46306ec74d3: Got expected result from replica 1 [my-hostname-basic-07179a54-26ff-4d50-8517-c46306ec74d3-wsz5d]: "my-hostname-basic-07179a54-26ff-4d50-8517-c46306ec74d3-wsz5d", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  4 16:30:28.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4323" for this suite.

• [SLOW TEST:10.135 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":293,"skipped":5549,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:28.466: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  4 16:30:29.637: INFO: starting watch
STEP: patching
STEP: updating
Jul  4 16:30:29.654: INFO: waiting for watch events with expected annotations
Jul  4 16:30:29.654: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:30:29.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-3475" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":356,"completed":294,"skipped":5581,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:29.996: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-97ee453c-2146-48b5-bb26-2eb7a476349e
STEP: Creating a pod to test consume secrets
Jul  4 16:30:30.105: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-113ec015-97fa-44f8-b49e-9cfaba49bb4b" in namespace "projected-2372" to be "Succeeded or Failed"
Jul  4 16:30:30.111: INFO: Pod "pod-projected-secrets-113ec015-97fa-44f8-b49e-9cfaba49bb4b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.646396ms
Jul  4 16:30:32.145: INFO: Pod "pod-projected-secrets-113ec015-97fa-44f8-b49e-9cfaba49bb4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04039943s
Jul  4 16:30:34.180: INFO: Pod "pod-projected-secrets-113ec015-97fa-44f8-b49e-9cfaba49bb4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074986388s
STEP: Saw pod success
Jul  4 16:30:34.180: INFO: Pod "pod-projected-secrets-113ec015-97fa-44f8-b49e-9cfaba49bb4b" satisfied condition "Succeeded or Failed"
Jul  4 16:30:34.183: INFO: Trying to get logs from node 3.138.203.20 pod pod-projected-secrets-113ec015-97fa-44f8-b49e-9cfaba49bb4b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  4 16:30:34.288: INFO: Waiting for pod pod-projected-secrets-113ec015-97fa-44f8-b49e-9cfaba49bb4b to disappear
Jul  4 16:30:34.298: INFO: Pod pod-projected-secrets-113ec015-97fa-44f8-b49e-9cfaba49bb4b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  4 16:30:34.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2372" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":295,"skipped":5586,"failed":0}

------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:34.304: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:188
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  4 16:30:34.412: INFO: starting watch
STEP: patching
STEP: updating
Jul  4 16:30:34.494: INFO: waiting for watch events with expected annotations
Jul  4 16:30:34.494: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:188
Jul  4 16:30:34.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-6464" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":356,"completed":296,"skipped":5586,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:34.548: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  4 16:30:34.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-584" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":356,"completed":297,"skipped":5625,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:34.703: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 16:30:50.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1469" for this suite.

• [SLOW TEST:16.223 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":356,"completed":298,"skipped":5651,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:50.926: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:30:51.006: INFO: The status of Pod busybox-scheduling-d0327da8-92ed-4202-9200-4dcdb2a714d9 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:30:53.013: INFO: The status of Pod busybox-scheduling-d0327da8-92ed-4202-9200-4dcdb2a714d9 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  4 16:30:53.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2270" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":356,"completed":299,"skipped":5694,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:53.034: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  4 16:30:53.052: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee28291b-d313-452c-a3ee-4f1bd254274b" in namespace "projected-4644" to be "Succeeded or Failed"
Jul  4 16:30:53.054: INFO: Pod "downwardapi-volume-ee28291b-d313-452c-a3ee-4f1bd254274b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.793023ms
Jul  4 16:30:55.062: INFO: Pod "downwardapi-volume-ee28291b-d313-452c-a3ee-4f1bd254274b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009794105s
Jul  4 16:30:57.068: INFO: Pod "downwardapi-volume-ee28291b-d313-452c-a3ee-4f1bd254274b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015285629s
STEP: Saw pod success
Jul  4 16:30:57.068: INFO: Pod "downwardapi-volume-ee28291b-d313-452c-a3ee-4f1bd254274b" satisfied condition "Succeeded or Failed"
Jul  4 16:30:57.069: INFO: Trying to get logs from node 3.138.203.20 pod downwardapi-volume-ee28291b-d313-452c-a3ee-4f1bd254274b container client-container: <nil>
STEP: delete the pod
Jul  4 16:30:57.085: INFO: Waiting for pod downwardapi-volume-ee28291b-d313-452c-a3ee-4f1bd254274b to disappear
Jul  4 16:30:57.087: INFO: Pod downwardapi-volume-ee28291b-d313-452c-a3ee-4f1bd254274b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  4 16:30:57.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4644" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":300,"skipped":5707,"failed":0}
SSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:30:57.093: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
Jul  4 16:31:17.244: INFO: EndpointSlice for Service endpointslice-8263/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Jul  4 16:31:27.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8263" for this suite.

• [SLOW TEST:30.169 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":356,"completed":301,"skipped":5713,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:31:27.262: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Jul  4 16:31:27.288: INFO: The status of Pod annotationupdate6567a1f0-d4f7-4dd4-9d8d-0331564716b6 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:31:29.293: INFO: The status of Pod annotationupdate6567a1f0-d4f7-4dd4-9d8d-0331564716b6 is Running (Ready = true)
Jul  4 16:31:29.812: INFO: Successfully updated pod "annotationupdate6567a1f0-d4f7-4dd4-9d8d-0331564716b6"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  4 16:31:31.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5974" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":302,"skipped":5750,"failed":0}
SSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:31:31.836: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a job [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-160, will wait for the garbage collector to delete the pods
Jul  4 16:31:33.917: INFO: Deleting Job.batch foo took: 3.978281ms
Jul  4 16:31:34.018: INFO: Terminating Job.batch foo pods took: 101.034742ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  4 16:32:05.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-160" for this suite.

• [SLOW TEST:34.093 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":356,"completed":303,"skipped":5754,"failed":0}
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:32:05.929: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  4 16:32:05.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:32:05.962: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:32:06.970: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:32:06.970: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:32:07.971: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  4 16:32:07.971: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Jul  4 16:32:07.992: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29140"},"items":null}

Jul  4 16:32:08.001: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29140"},"items":[{"metadata":{"name":"daemon-set-d2rtw","generateName":"daemon-set-","namespace":"daemonsets-5184","uid":"ba013b3b-1304-4641-baba-d121cf5dea2f","resourceVersion":"29138","creationTimestamp":"2022-07-04T16:32:05Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"3049f7fa9ec784e0207eb69f57f188099211b0fe9ae0f44971f7d59dc0ad3a09","cni.projectcalico.org/podIP":"10.42.2.21/32","cni.projectcalico.org/podIPs":"10.42.2.21/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"cc697dd3-5246-4596-9bda-fac9955e0255","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-07-04T16:32:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc697dd3-5246-4596-9bda-fac9955e0255\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-07-04T16:32:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-07-04T16:32:07Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-qbxbj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-qbxbj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"18.216.149.32","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["18.216.149.32"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:07Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:07Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:05Z"}],"hostIP":"172.31.20.100","podIP":"10.42.2.21","podIPs":[{"ip":"10.42.2.21"}],"startTime":"2022-07-04T16:32:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-07-04T16:32:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://9e5727d5b7d4f8bf3aa134e9aa433ccedee6d7a621b3496258e267bccd86575e","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-ft9px","generateName":"daemon-set-","namespace":"daemonsets-5184","uid":"6e23dff7-6280-4091-a1f9-c84d31ff3c96","resourceVersion":"29136","creationTimestamp":"2022-07-04T16:32:05Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"cfae7daeb3fc2abb956dc39cefac679f7886e4159d5efb73d9f310196883b86d","cni.projectcalico.org/podIP":"10.42.1.20/32","cni.projectcalico.org/podIPs":"10.42.1.20/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"cc697dd3-5246-4596-9bda-fac9955e0255","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-07-04T16:32:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc697dd3-5246-4596-9bda-fac9955e0255\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-07-04T16:32:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-07-04T16:32:07Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.1.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-txh5f","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-txh5f","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"3.138.203.20","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["3.138.203.20"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:07Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:07Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:05Z"}],"hostIP":"172.31.23.66","podIP":"10.42.1.20","podIPs":[{"ip":"10.42.1.20"}],"startTime":"2022-07-04T16:32:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-07-04T16:32:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://a3371539e91c63740db26c6565c38afacda9e006f7272eddc2c5aa8bbee7dc86","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-tsdt2","generateName":"daemon-set-","namespace":"daemonsets-5184","uid":"13a0ec23-ff00-42cb-aff5-623633d4aa83","resourceVersion":"29134","creationTimestamp":"2022-07-04T16:32:05Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f7276adcad73bc53086254227da8acce74ab354225f7a34b9b9431576cc276df","cni.projectcalico.org/podIP":"10.42.0.179/32","cni.projectcalico.org/podIPs":"10.42.0.179/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"cc697dd3-5246-4596-9bda-fac9955e0255","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-07-04T16:32:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc697dd3-5246-4596-9bda-fac9955e0255\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-07-04T16:32:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-07-04T16:32:07Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.0.179\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-t8z86","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-t8z86","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"18.224.151.13","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["18.224.151.13"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:07Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:07Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-04T16:32:05Z"}],"hostIP":"172.31.25.73","podIP":"10.42.0.179","podIPs":[{"ip":"10.42.0.179"}],"startTime":"2022-07-04T16:32:05Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-07-04T16:32:06Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"docker://ffaac6ac8f4874f06f73f969382ed3a10896818d821c427fdef621a4736350cf","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:32:08.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5184" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":356,"completed":304,"skipped":5754,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:32:08.020: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-downwardapi-gfjp
STEP: Creating a pod to test atomic-volume-subpath
Jul  4 16:32:08.062: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-gfjp" in namespace "subpath-123" to be "Succeeded or Failed"
Jul  4 16:32:08.065: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Pending", Reason="", readiness=false. Elapsed: 3.175444ms
Jul  4 16:32:10.069: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 2.007298435s
Jul  4 16:32:12.076: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 4.014492244s
Jul  4 16:32:14.084: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 6.021845945s
Jul  4 16:32:16.096: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 8.034066377s
Jul  4 16:32:18.105: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 10.0426346s
Jul  4 16:32:20.113: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 12.050780949s
Jul  4 16:32:22.120: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 14.057610768s
Jul  4 16:32:24.127: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 16.064834562s
Jul  4 16:32:26.133: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 18.070745028s
Jul  4 16:32:28.141: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=true. Elapsed: 20.078681641s
Jul  4 16:32:30.148: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Running", Reason="", readiness=false. Elapsed: 22.086481202s
Jul  4 16:32:32.156: INFO: Pod "pod-subpath-test-downwardapi-gfjp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.093628738s
STEP: Saw pod success
Jul  4 16:32:32.156: INFO: Pod "pod-subpath-test-downwardapi-gfjp" satisfied condition "Succeeded or Failed"
Jul  4 16:32:32.157: INFO: Trying to get logs from node 18.216.149.32 pod pod-subpath-test-downwardapi-gfjp container test-container-subpath-downwardapi-gfjp: <nil>
STEP: delete the pod
Jul  4 16:32:32.182: INFO: Waiting for pod pod-subpath-test-downwardapi-gfjp to disappear
Jul  4 16:32:32.184: INFO: Pod pod-subpath-test-downwardapi-gfjp no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-gfjp
Jul  4 16:32:32.184: INFO: Deleting pod "pod-subpath-test-downwardapi-gfjp" in namespace "subpath-123"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  4 16:32:32.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-123" for this suite.

• [SLOW TEST:24.170 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","total":356,"completed":305,"skipped":5757,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:32:32.191: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 16:32:39.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9383" for this suite.

• [SLOW TEST:7.037 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":356,"completed":306,"skipped":5774,"failed":0}
SSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:32:39.228: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override command
Jul  4 16:32:39.248: INFO: Waiting up to 5m0s for pod "client-containers-edac2174-08bb-461e-8ce7-d21521c4aba4" in namespace "containers-3079" to be "Succeeded or Failed"
Jul  4 16:32:39.250: INFO: Pod "client-containers-edac2174-08bb-461e-8ce7-d21521c4aba4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.23021ms
Jul  4 16:32:41.254: INFO: Pod "client-containers-edac2174-08bb-461e-8ce7-d21521c4aba4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006471235s
Jul  4 16:32:43.262: INFO: Pod "client-containers-edac2174-08bb-461e-8ce7-d21521c4aba4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013962492s
STEP: Saw pod success
Jul  4 16:32:43.262: INFO: Pod "client-containers-edac2174-08bb-461e-8ce7-d21521c4aba4" satisfied condition "Succeeded or Failed"
Jul  4 16:32:43.263: INFO: Trying to get logs from node 3.138.203.20 pod client-containers-edac2174-08bb-461e-8ce7-d21521c4aba4 container agnhost-container: <nil>
STEP: delete the pod
Jul  4 16:32:43.275: INFO: Waiting for pod client-containers-edac2174-08bb-461e-8ce7-d21521c4aba4 to disappear
Jul  4 16:32:43.277: INFO: Pod client-containers-edac2174-08bb-461e-8ce7-d21521c4aba4 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Jul  4 16:32:43.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3079" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","total":356,"completed":307,"skipped":5779,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:32:43.282: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
STEP: create deployment with httpd image
Jul  4 16:32:43.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-3593 create -f -'
Jul  4 16:32:44.136: INFO: stderr: ""
Jul  4 16:32:44.136: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Jul  4 16:32:44.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-3593 diff -f -'
Jul  4 16:32:44.317: INFO: rc: 1
Jul  4 16:32:44.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-3593 delete -f -'
Jul  4 16:32:44.375: INFO: stderr: ""
Jul  4 16:32:44.375: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 16:32:44.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3593" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":356,"completed":308,"skipped":5789,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:32:44.387: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:32:44.404: INFO: Creating pod...
Jul  4 16:32:46.418: INFO: Creating service...
Jul  4 16:32:46.425: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/pods/agnhost/proxy/some/path/with/DELETE
Jul  4 16:32:46.428: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul  4 16:32:46.428: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/pods/agnhost/proxy/some/path/with/GET
Jul  4 16:32:46.437: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jul  4 16:32:46.437: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/pods/agnhost/proxy/some/path/with/HEAD
Jul  4 16:32:46.445: INFO: http.Client request:HEAD | StatusCode:200
Jul  4 16:32:46.445: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/pods/agnhost/proxy/some/path/with/OPTIONS
Jul  4 16:32:46.447: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul  4 16:32:46.447: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/pods/agnhost/proxy/some/path/with/PATCH
Jul  4 16:32:46.449: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul  4 16:32:46.449: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/pods/agnhost/proxy/some/path/with/POST
Jul  4 16:32:46.452: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul  4 16:32:46.452: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/pods/agnhost/proxy/some/path/with/PUT
Jul  4 16:32:46.454: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jul  4 16:32:46.454: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/services/test-service/proxy/some/path/with/DELETE
Jul  4 16:32:46.457: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul  4 16:32:46.457: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/services/test-service/proxy/some/path/with/GET
Jul  4 16:32:46.460: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jul  4 16:32:46.460: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/services/test-service/proxy/some/path/with/HEAD
Jul  4 16:32:46.462: INFO: http.Client request:HEAD | StatusCode:200
Jul  4 16:32:46.462: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/services/test-service/proxy/some/path/with/OPTIONS
Jul  4 16:32:46.465: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul  4 16:32:46.465: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/services/test-service/proxy/some/path/with/PATCH
Jul  4 16:32:46.480: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul  4 16:32:46.480: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/services/test-service/proxy/some/path/with/POST
Jul  4 16:32:46.483: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul  4 16:32:46.483: INFO: Starting http.Client for https://10.43.0.1:443/api/v1/namespaces/proxy-1175/services/test-service/proxy/some/path/with/PUT
Jul  4 16:32:46.486: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Jul  4 16:32:46.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1175" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":356,"completed":309,"skipped":5812,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:32:46.493: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul  4 16:32:46.506: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  4 16:32:46.511: INFO: Waiting for terminating namespaces to be deleted...
Jul  4 16:32:46.513: INFO: 
Logging pods the apiserver thinks is on node 18.216.149.32 before test
Jul  4 16:32:46.517: INFO: canal-7ftvj from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:32:46.517: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:32:46.517: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:32:46.517: INFO: coredns-85bfbf8f-9f6vk from kube-system started at 2022-07-04 15:17:21 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.517: INFO: 	Container coredns ready: true, restart count 0
Jul  4 16:32:46.517: INFO: metrics-server-585b7cc746-9jchh from kube-system started at 2022-07-04 15:17:33 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.517: INFO: 	Container metrics-server ready: true, restart count 0
Jul  4 16:32:46.517: INFO: agnhost from proxy-1175 started at 2022-07-04 16:32:44 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.517: INFO: 	Container agnhost ready: true, restart count 0
Jul  4 16:32:46.517: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-vttwd from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:32:46.517: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:32:46.517: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  4 16:32:46.517: INFO: 
Logging pods the apiserver thinks is on node 18.224.151.13 before test
Jul  4 16:32:46.521: INFO: canal-twgvp from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:32:46.521: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:32:46.521: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:32:46.521: INFO: coredns-autoscaler-67cbd4599c-62tvv from kube-system started at 2022-07-04 15:17:21 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.521: INFO: 	Container autoscaler ready: true, restart count 0
Jul  4 16:32:46.521: INFO: rke-coredns-addon-deploy-job-q97vx from kube-system started at 2022-07-04 15:17:20 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.521: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Jul  4 16:32:46.521: INFO: rke-metrics-addon-deploy-job-v6dww from kube-system started at 2022-07-04 15:17:32 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.521: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Jul  4 16:32:46.521: INFO: rke-network-plugin-deploy-job-vqpwx from kube-system started at 2022-07-04 15:17:12 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.521: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Jul  4 16:32:46.521: INFO: sonobuoy from sonobuoy started at 2022-07-04 15:20:04 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.521: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  4 16:32:46.521: INFO: sonobuoy-e2e-job-f2b28e16e8b74a5d from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:32:46.521: INFO: 	Container e2e ready: true, restart count 0
Jul  4 16:32:46.521: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:32:46.521: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-6fh2b from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:32:46.521: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:32:46.521: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  4 16:32:46.521: INFO: 
Logging pods the apiserver thinks is on node 3.138.203.20 before test
Jul  4 16:32:46.524: INFO: calico-kube-controllers-74df54cbb7-vdkjz from kube-system started at 2022-07-04 15:17:14 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.524: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  4 16:32:46.524: INFO: canal-2hwcq from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:32:46.524: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:32:46.524: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:32:46.524: INFO: coredns-85bfbf8f-zln4g from kube-system started at 2022-07-04 15:17:23 +0000 UTC (1 container statuses recorded)
Jul  4 16:32:46.524: INFO: 	Container coredns ready: true, restart count 0
Jul  4 16:32:46.524: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-jzqpt from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:32:46.524: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:32:46.524: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b5af9f18-855d-4f2e-b7b6-5a06f6c2d6e9 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.23.66 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-b5af9f18-855d-4f2e-b7b6-5a06f6c2d6e9 off the node 3.138.203.20
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b5af9f18-855d-4f2e-b7b6-5a06f6c2d6e9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:37:50.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4411" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

• [SLOW TEST:304.151 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":356,"completed":310,"skipped":5841,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:37:50.643: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:37:50.659: INFO: Creating simple deployment test-new-deployment
Jul  4 16:37:50.667: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  4 16:37:52.696: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-7161  8250d29a-dece-4b09-bbe6-b36bb4ec42de 29875 3 2022-07-04 16:37:50 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-07-04 16:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 16:37:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0056fcb58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-07-04 16:37:51 +0000 UTC,LastTransitionTime:2022-07-04 16:37:51 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-55df494869" has successfully progressed.,LastUpdateTime:2022-07-04 16:37:51 +0000 UTC,LastTransitionTime:2022-07-04 16:37:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul  4 16:37:52.700: INFO: New ReplicaSet "test-new-deployment-55df494869" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-55df494869  deployment-7161  be7ddb37-8a3f-455f-b95c-690ba8a5fe73 29876 2 2022-07-04 16:37:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 8250d29a-dece-4b09-bbe6-b36bb4ec42de 0xc0034b7f37 0xc0034b7f38}] []  [{kube-controller-manager Update apps/v1 2022-07-04 16:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8250d29a-dece-4b09-bbe6-b36bb4ec42de\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 16:37:51 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034b7fc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul  4 16:37:52.706: INFO: Pod "test-new-deployment-55df494869-d8s5h" is not available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-d8s5h test-new-deployment-55df494869- deployment-7161  0b7cff15-6254-48a3-ac5e-ac8650e4cfb8 29879 0 2022-07-04 16:37:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet test-new-deployment-55df494869 be7ddb37-8a3f-455f-b95c-690ba8a5fe73 0xc0062e4fc7 0xc0062e4fc8}] []  [{kube-controller-manager Update v1 2022-07-04 16:37:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"be7ddb37-8a3f-455f-b95c-690ba8a5fe73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p75n7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p75n7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.224.151.13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:37:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  4 16:37:52.706: INFO: Pod "test-new-deployment-55df494869-g7cqw" is available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-g7cqw test-new-deployment-55df494869- deployment-7161  0b0f01b1-a552-4a8d-a33c-968703253d03 29869 0 2022-07-04 16:37:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:b68fe20437bcb75c8f2daefea41c7280c6335b6e8d40e087b9c1c09a9a14ee75 cni.projectcalico.org/podIP:10.42.2.24/32 cni.projectcalico.org/podIPs:10.42.2.24/32] [{apps/v1 ReplicaSet test-new-deployment-55df494869 be7ddb37-8a3f-455f-b95c-690ba8a5fe73 0xc0062e5150 0xc0062e5151}] []  [{kube-controller-manager Update v1 2022-07-04 16:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"be7ddb37-8a3f-455f-b95c-690ba8a5fe73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 16:37:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 16:37:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.24\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5j86v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5j86v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:37:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:37:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:37:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:37:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:10.42.2.24,StartTime:2022-07-04 16:37:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 16:37:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:docker://886c8401dfb8cd0f7aad44faaadf8e70c95a5518908eccbe029b0c8cd5ec9cb7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.24,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  4 16:37:52.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7161" for this suite.
•{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":356,"completed":311,"skipped":5845,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:37:52.718: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul  4 16:37:52.742: INFO: Waiting up to 5m0s for pod "pod-048ad0c1-2f85-4236-b876-f7ae16741943" in namespace "emptydir-3600" to be "Succeeded or Failed"
Jul  4 16:37:52.744: INFO: Pod "pod-048ad0c1-2f85-4236-b876-f7ae16741943": Phase="Pending", Reason="", readiness=false. Elapsed: 2.224749ms
Jul  4 16:37:54.749: INFO: Pod "pod-048ad0c1-2f85-4236-b876-f7ae16741943": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007139786s
Jul  4 16:37:56.755: INFO: Pod "pod-048ad0c1-2f85-4236-b876-f7ae16741943": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013040145s
STEP: Saw pod success
Jul  4 16:37:56.755: INFO: Pod "pod-048ad0c1-2f85-4236-b876-f7ae16741943" satisfied condition "Succeeded or Failed"
Jul  4 16:37:56.757: INFO: Trying to get logs from node 3.138.203.20 pod pod-048ad0c1-2f85-4236-b876-f7ae16741943 container test-container: <nil>
STEP: delete the pod
Jul  4 16:37:56.780: INFO: Waiting for pod pod-048ad0c1-2f85-4236-b876-f7ae16741943 to disappear
Jul  4 16:37:56.784: INFO: Pod pod-048ad0c1-2f85-4236-b876-f7ae16741943 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 16:37:56.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3600" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":312,"skipped":5850,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:37:56.789: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  4 16:38:00.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-9181" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":313,"skipped":5868,"failed":0}

------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:38:00.850: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-682db329-614d-416d-98a6-5194d006b5f4 in namespace container-probe-7649
Jul  4 16:38:02.879: INFO: Started pod liveness-682db329-614d-416d-98a6-5194d006b5f4 in namespace container-probe-7649
STEP: checking the pod's current state and verifying that restartCount is present
Jul  4 16:38:02.881: INFO: Initial restart count of pod liveness-682db329-614d-416d-98a6-5194d006b5f4 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  4 16:42:03.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7649" for this suite.

• [SLOW TEST:242.801 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":356,"completed":314,"skipped":5868,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:03.651: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  4 16:42:03.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7429" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":315,"skipped":5902,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:03.678: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 16:42:14.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5582" for this suite.

• [SLOW TEST:11.057 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":356,"completed":316,"skipped":5961,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:14.736: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jul  4 16:42:18.788: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  4 16:42:18.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7735" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":356,"completed":317,"skipped":6021,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:18.803: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:42:18.821: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:42:19.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9633" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":356,"completed":318,"skipped":6032,"failed":0}
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:19.842: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-6399e359-9590-49d9-a1ab-fcbaa87343e6
STEP: Creating a pod to test consume configMaps
Jul  4 16:42:19.868: INFO: Waiting up to 5m0s for pod "pod-configmaps-fbb535de-039c-4827-906a-45adc4a6c188" in namespace "configmap-7193" to be "Succeeded or Failed"
Jul  4 16:42:19.870: INFO: Pod "pod-configmaps-fbb535de-039c-4827-906a-45adc4a6c188": Phase="Pending", Reason="", readiness=false. Elapsed: 2.748724ms
Jul  4 16:42:21.874: INFO: Pod "pod-configmaps-fbb535de-039c-4827-906a-45adc4a6c188": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005918937s
Jul  4 16:42:23.879: INFO: Pod "pod-configmaps-fbb535de-039c-4827-906a-45adc4a6c188": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011719672s
STEP: Saw pod success
Jul  4 16:42:23.879: INFO: Pod "pod-configmaps-fbb535de-039c-4827-906a-45adc4a6c188" satisfied condition "Succeeded or Failed"
Jul  4 16:42:23.881: INFO: Trying to get logs from node 18.216.149.32 pod pod-configmaps-fbb535de-039c-4827-906a-45adc4a6c188 container configmap-volume-test: <nil>
STEP: delete the pod
Jul  4 16:42:23.908: INFO: Waiting for pod pod-configmaps-fbb535de-039c-4827-906a-45adc4a6c188 to disappear
Jul  4 16:42:23.911: INFO: Pod pod-configmaps-fbb535de-039c-4827-906a-45adc4a6c188 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:42:23.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7193" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":319,"skipped":6036,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:23.918: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-d61eded5-ceb9-4e75-81e0-361aaec44364
STEP: Creating a pod to test consume configMaps
Jul  4 16:42:23.941: INFO: Waiting up to 5m0s for pod "pod-configmaps-79d87b8f-f649-4dfd-89d9-b22906fcd82a" in namespace "configmap-3486" to be "Succeeded or Failed"
Jul  4 16:42:23.943: INFO: Pod "pod-configmaps-79d87b8f-f649-4dfd-89d9-b22906fcd82a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.405028ms
Jul  4 16:42:25.947: INFO: Pod "pod-configmaps-79d87b8f-f649-4dfd-89d9-b22906fcd82a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006309878s
Jul  4 16:42:27.955: INFO: Pod "pod-configmaps-79d87b8f-f649-4dfd-89d9-b22906fcd82a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014000194s
STEP: Saw pod success
Jul  4 16:42:27.955: INFO: Pod "pod-configmaps-79d87b8f-f649-4dfd-89d9-b22906fcd82a" satisfied condition "Succeeded or Failed"
Jul  4 16:42:27.957: INFO: Trying to get logs from node 3.138.203.20 pod pod-configmaps-79d87b8f-f649-4dfd-89d9-b22906fcd82a container agnhost-container: <nil>
STEP: delete the pod
Jul  4 16:42:27.977: INFO: Waiting for pod pod-configmaps-79d87b8f-f649-4dfd-89d9-b22906fcd82a to disappear
Jul  4 16:42:27.979: INFO: Pod pod-configmaps-79d87b8f-f649-4dfd-89d9-b22906fcd82a no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:42:27.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3486" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":320,"skipped":6080,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:27.985: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul  4 16:42:27.999: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  4 16:42:28.004: INFO: Waiting for terminating namespaces to be deleted...
Jul  4 16:42:28.005: INFO: 
Logging pods the apiserver thinks is on node 18.216.149.32 before test
Jul  4 16:42:28.009: INFO: canal-7ftvj from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:42:28.009: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:42:28.009: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:42:28.009: INFO: coredns-85bfbf8f-9f6vk from kube-system started at 2022-07-04 15:17:21 +0000 UTC (1 container statuses recorded)
Jul  4 16:42:28.009: INFO: 	Container coredns ready: true, restart count 0
Jul  4 16:42:28.009: INFO: metrics-server-585b7cc746-9jchh from kube-system started at 2022-07-04 15:17:33 +0000 UTC (1 container statuses recorded)
Jul  4 16:42:28.009: INFO: 	Container metrics-server ready: true, restart count 0
Jul  4 16:42:28.009: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-vttwd from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:42:28.009: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:42:28.009: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  4 16:42:28.009: INFO: 
Logging pods the apiserver thinks is on node 18.224.151.13 before test
Jul  4 16:42:28.013: INFO: canal-twgvp from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:42:28.013: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:42:28.013: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:42:28.013: INFO: coredns-autoscaler-67cbd4599c-62tvv from kube-system started at 2022-07-04 15:17:21 +0000 UTC (1 container statuses recorded)
Jul  4 16:42:28.013: INFO: 	Container autoscaler ready: true, restart count 0
Jul  4 16:42:28.013: INFO: rke-coredns-addon-deploy-job-q97vx from kube-system started at 2022-07-04 15:17:20 +0000 UTC (1 container statuses recorded)
Jul  4 16:42:28.013: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Jul  4 16:42:28.013: INFO: rke-metrics-addon-deploy-job-v6dww from kube-system started at 2022-07-04 15:17:32 +0000 UTC (1 container statuses recorded)
Jul  4 16:42:28.013: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Jul  4 16:42:28.013: INFO: rke-network-plugin-deploy-job-vqpwx from kube-system started at 2022-07-04 15:17:12 +0000 UTC (1 container statuses recorded)
Jul  4 16:42:28.013: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Jul  4 16:42:28.013: INFO: sonobuoy from sonobuoy started at 2022-07-04 15:20:04 +0000 UTC (1 container statuses recorded)
Jul  4 16:42:28.013: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  4 16:42:28.013: INFO: sonobuoy-e2e-job-f2b28e16e8b74a5d from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:42:28.013: INFO: 	Container e2e ready: true, restart count 0
Jul  4 16:42:28.013: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:42:28.013: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-6fh2b from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:42:28.013: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:42:28.013: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  4 16:42:28.013: INFO: 
Logging pods the apiserver thinks is on node 3.138.203.20 before test
Jul  4 16:42:28.017: INFO: calico-kube-controllers-74df54cbb7-vdkjz from kube-system started at 2022-07-04 15:17:14 +0000 UTC (1 container statuses recorded)
Jul  4 16:42:28.017: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  4 16:42:28.017: INFO: canal-2hwcq from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:42:28.017: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:42:28.017: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:42:28.017: INFO: coredns-85bfbf8f-zln4g from kube-system started at 2022-07-04 15:17:23 +0000 UTC (1 container statuses recorded)
Jul  4 16:42:28.017: INFO: 	Container coredns ready: true, restart count 0
Jul  4 16:42:28.017: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-jzqpt from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:42:28.017: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:42:28.017: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
STEP: verifying the node has the label node 18.216.149.32
STEP: verifying the node has the label node 18.224.151.13
STEP: verifying the node has the label node 3.138.203.20
Jul  4 16:42:28.056: INFO: Pod calico-kube-controllers-74df54cbb7-vdkjz requesting resource cpu=0m on Node 3.138.203.20
Jul  4 16:42:28.056: INFO: Pod canal-2hwcq requesting resource cpu=250m on Node 3.138.203.20
Jul  4 16:42:28.056: INFO: Pod canal-7ftvj requesting resource cpu=250m on Node 18.216.149.32
Jul  4 16:42:28.056: INFO: Pod canal-twgvp requesting resource cpu=250m on Node 18.224.151.13
Jul  4 16:42:28.056: INFO: Pod coredns-85bfbf8f-9f6vk requesting resource cpu=100m on Node 18.216.149.32
Jul  4 16:42:28.056: INFO: Pod coredns-85bfbf8f-zln4g requesting resource cpu=100m on Node 3.138.203.20
Jul  4 16:42:28.056: INFO: Pod coredns-autoscaler-67cbd4599c-62tvv requesting resource cpu=20m on Node 18.224.151.13
Jul  4 16:42:28.056: INFO: Pod metrics-server-585b7cc746-9jchh requesting resource cpu=100m on Node 18.216.149.32
Jul  4 16:42:28.056: INFO: Pod sonobuoy requesting resource cpu=0m on Node 18.224.151.13
Jul  4 16:42:28.056: INFO: Pod sonobuoy-e2e-job-f2b28e16e8b74a5d requesting resource cpu=0m on Node 18.224.151.13
Jul  4 16:42:28.056: INFO: Pod sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-6fh2b requesting resource cpu=0m on Node 18.224.151.13
Jul  4 16:42:28.056: INFO: Pod sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-jzqpt requesting resource cpu=0m on Node 3.138.203.20
Jul  4 16:42:28.056: INFO: Pod sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-vttwd requesting resource cpu=0m on Node 18.216.149.32
STEP: Starting Pods to consume most of the cluster CPU.
Jul  4 16:42:28.056: INFO: Creating a pod which consumes cpu=2485m on Node 18.216.149.32
Jul  4 16:42:28.061: INFO: Creating a pod which consumes cpu=2611m on Node 18.224.151.13
Jul  4 16:42:28.066: INFO: Creating a pod which consumes cpu=2555m on Node 3.138.203.20
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-32bf8e8e-8b77-4758-b4f9-9d2e05d0d311.16feaded67928b93], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7924/filler-pod-32bf8e8e-8b77-4758-b4f9-9d2e05d0d311 to 18.224.151.13]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-32bf8e8e-8b77-4758-b4f9-9d2e05d0d311.16feaded91355504], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-32bf8e8e-8b77-4758-b4f9-9d2e05d0d311.16feaded94261d14], Reason = [Created], Message = [Created container filler-pod-32bf8e8e-8b77-4758-b4f9-9d2e05d0d311]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-32bf8e8e-8b77-4758-b4f9-9d2e05d0d311.16feaded98d37eca], Reason = [Started], Message = [Started container filler-pod-32bf8e8e-8b77-4758-b4f9-9d2e05d0d311]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-936b74b6-87f1-496b-9523-5178b591ee78.16feaded6703c273], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7924/filler-pod-936b74b6-87f1-496b-9523-5178b591ee78 to 18.216.149.32]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-936b74b6-87f1-496b-9523-5178b591ee78.16feaded90d41910], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-936b74b6-87f1-496b-9523-5178b591ee78.16feaded9406f0af], Reason = [Created], Message = [Created container filler-pod-936b74b6-87f1-496b-9523-5178b591ee78]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-936b74b6-87f1-496b-9523-5178b591ee78.16feaded99e3aaee], Reason = [Started], Message = [Started container filler-pod-936b74b6-87f1-496b-9523-5178b591ee78]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a53d248b-eadc-482e-b6a2-921c1f984841.16feaded67bc3996], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7924/filler-pod-a53d248b-eadc-482e-b6a2-921c1f984841 to 3.138.203.20]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a53d248b-eadc-482e-b6a2-921c1f984841.16feaded924925d9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a53d248b-eadc-482e-b6a2-921c1f984841.16feaded952ae898], Reason = [Created], Message = [Created container filler-pod-a53d248b-eadc-482e-b6a2-921c1f984841]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a53d248b-eadc-482e-b6a2-921c1f984841.16feaded9a0ab947], Reason = [Started], Message = [Started container filler-pod-a53d248b-eadc-482e-b6a2-921c1f984841]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16feadede02e8bf5], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.]
STEP: removing the label node off the node 3.138.203.20
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 18.216.149.32
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 18.224.151.13
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:42:31.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7924" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":356,"completed":321,"skipped":6096,"failed":0}

------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:31.146: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1872.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1872.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1872.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1872.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  4 16:42:35.195: INFO: DNS probes using dns-1872/dns-test-b9781ecf-7d94-4c35-9a9d-c0bf305e6736 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  4 16:42:35.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1872" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","total":356,"completed":322,"skipped":6096,"failed":0}
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:35.228: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-0bb96aa5-40b4-42ab-ab72-8f3c18655372
STEP: Creating a pod to test consume configMaps
Jul  4 16:42:35.301: INFO: Waiting up to 5m0s for pod "pod-configmaps-145ef31a-f9c4-4382-b02f-fddcf75da025" in namespace "configmap-5691" to be "Succeeded or Failed"
Jul  4 16:42:35.304: INFO: Pod "pod-configmaps-145ef31a-f9c4-4382-b02f-fddcf75da025": Phase="Pending", Reason="", readiness=false. Elapsed: 2.563313ms
Jul  4 16:42:37.311: INFO: Pod "pod-configmaps-145ef31a-f9c4-4382-b02f-fddcf75da025": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009446925s
Jul  4 16:42:39.320: INFO: Pod "pod-configmaps-145ef31a-f9c4-4382-b02f-fddcf75da025": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018720541s
STEP: Saw pod success
Jul  4 16:42:39.320: INFO: Pod "pod-configmaps-145ef31a-f9c4-4382-b02f-fddcf75da025" satisfied condition "Succeeded or Failed"
Jul  4 16:42:39.322: INFO: Trying to get logs from node 18.216.149.32 pod pod-configmaps-145ef31a-f9c4-4382-b02f-fddcf75da025 container agnhost-container: <nil>
STEP: delete the pod
Jul  4 16:42:39.335: INFO: Waiting for pod pod-configmaps-145ef31a-f9c4-4382-b02f-fddcf75da025 to disappear
Jul  4 16:42:39.337: INFO: Pod pod-configmaps-145ef31a-f9c4-4382-b02f-fddcf75da025 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:42:39.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5691" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":323,"skipped":6099,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:39.344: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 16:42:52.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3411" for this suite.

• [SLOW TEST:13.083 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":356,"completed":324,"skipped":6103,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:52.427: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-a1573f59-1113-4887-af41-2eb03b86a141
STEP: Creating a pod to test consume configMaps
Jul  4 16:42:52.448: INFO: Waiting up to 5m0s for pod "pod-configmaps-20889d21-0137-4d48-a907-6b51653ff795" in namespace "configmap-3050" to be "Succeeded or Failed"
Jul  4 16:42:52.451: INFO: Pod "pod-configmaps-20889d21-0137-4d48-a907-6b51653ff795": Phase="Pending", Reason="", readiness=false. Elapsed: 2.364851ms
Jul  4 16:42:54.463: INFO: Pod "pod-configmaps-20889d21-0137-4d48-a907-6b51653ff795": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014714637s
Jul  4 16:42:56.470: INFO: Pod "pod-configmaps-20889d21-0137-4d48-a907-6b51653ff795": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021407254s
STEP: Saw pod success
Jul  4 16:42:56.470: INFO: Pod "pod-configmaps-20889d21-0137-4d48-a907-6b51653ff795" satisfied condition "Succeeded or Failed"
Jul  4 16:42:56.472: INFO: Trying to get logs from node 3.138.203.20 pod pod-configmaps-20889d21-0137-4d48-a907-6b51653ff795 container agnhost-container: <nil>
STEP: delete the pod
Jul  4 16:42:56.485: INFO: Waiting for pod pod-configmaps-20889d21-0137-4d48-a907-6b51653ff795 to disappear
Jul  4 16:42:56.487: INFO: Pod pod-configmaps-20889d21-0137-4d48-a907-6b51653ff795 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:42:56.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3050" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":325,"skipped":6112,"failed":0}
SS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:42:56.493: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:42:56.517: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-45813b10-e9bb-43e2-aec4-fa39ffb189d4" in namespace "security-context-test-6254" to be "Succeeded or Failed"
Jul  4 16:42:56.520: INFO: Pod "alpine-nnp-false-45813b10-e9bb-43e2-aec4-fa39ffb189d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.608471ms
Jul  4 16:42:58.527: INFO: Pod "alpine-nnp-false-45813b10-e9bb-43e2-aec4-fa39ffb189d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010305053s
Jul  4 16:43:00.533: INFO: Pod "alpine-nnp-false-45813b10-e9bb-43e2-aec4-fa39ffb189d4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015856598s
Jul  4 16:43:02.538: INFO: Pod "alpine-nnp-false-45813b10-e9bb-43e2-aec4-fa39ffb189d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020814026s
Jul  4 16:43:02.538: INFO: Pod "alpine-nnp-false-45813b10-e9bb-43e2-aec4-fa39ffb189d4" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  4 16:43:02.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6254" for this suite.

• [SLOW TEST:6.061 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:298
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":326,"skipped":6114,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:43:02.554: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  4 16:43:02.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3590" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":356,"completed":327,"skipped":6131,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity 
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:43:02.594: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename csistoragecapacity
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/storage.k8s.io
STEP: getting /apis/storage.k8s.io/v1
STEP: creating
STEP: watching
Jul  4 16:43:02.618: INFO: starting watch
STEP: getting
STEP: listing in namespace
STEP: listing across namespaces
STEP: patching
STEP: updating
Jul  4 16:43:02.634: INFO: waiting for watch events with expected annotations in namespace
Jul  4 16:43:02.634: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:188
Jul  4 16:43:02.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-8543" for this suite.
•{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","total":356,"completed":328,"skipped":6156,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:43:02.653: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting the proxy server
Jul  4 16:43:02.667: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-5843 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 16:43:02.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5843" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":356,"completed":329,"skipped":6191,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:43:02.721: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-6701
STEP: creating service affinity-clusterip-transition in namespace services-6701
STEP: creating replication controller affinity-clusterip-transition in namespace services-6701
I0704 16:43:02.744336      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-6701, replica count: 3
I0704 16:43:05.795598      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  4 16:43:05.801: INFO: Creating new exec pod
Jul  4 16:43:08.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-6701 exec execpod-affinityl5bkv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Jul  4 16:43:08.956: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Jul  4 16:43:08.956: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:43:08.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-6701 exec execpod-affinityl5bkv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.43.61.76 80'
Jul  4 16:43:09.090: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.43.61.76 80\nConnection to 10.43.61.76 80 port [tcp/http] succeeded!\n"
Jul  4 16:43:09.090: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  4 16:43:09.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-6701 exec execpod-affinityl5bkv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.61.76:80/ ; done'
Jul  4 16:43:09.283: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n"
Jul  4 16:43:09.283: INFO: stdout: "\naffinity-clusterip-transition-rq9tr\naffinity-clusterip-transition-rq9tr\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-rq9tr\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-rq9tr\naffinity-clusterip-transition-dv87t\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-dv87t\naffinity-clusterip-transition-dv87t\naffinity-clusterip-transition-rq9tr\naffinity-clusterip-transition-dv87t\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-rq9tr\naffinity-clusterip-transition-dv87t"
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-rq9tr
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-rq9tr
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-rq9tr
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-rq9tr
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-dv87t
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-dv87t
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-dv87t
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-rq9tr
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-dv87t
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-rq9tr
Jul  4 16:43:09.283: INFO: Received response from host: affinity-clusterip-transition-dv87t
Jul  4 16:43:09.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=services-6701 exec execpod-affinityl5bkv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.43.61.76:80/ ; done'
Jul  4 16:43:09.483: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.43.61.76:80/\n"
Jul  4 16:43:09.483: INFO: stdout: "\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl\naffinity-clusterip-transition-pbfgl"
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Received response from host: affinity-clusterip-transition-pbfgl
Jul  4 16:43:09.483: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-6701, will wait for the garbage collector to delete the pods
Jul  4 16:43:09.551: INFO: Deleting ReplicationController affinity-clusterip-transition took: 3.680945ms
Jul  4 16:43:09.652: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.947582ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 16:43:11.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6701" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.246 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":330,"skipped":6208,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:43:11.967: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-13d3410c-9140-4cab-81ea-95ed2b7a9fd0
STEP: Creating a pod to test consume secrets
Jul  4 16:43:11.987: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6af69b94-658d-4d7e-bc61-2c63bb49c3dd" in namespace "projected-3699" to be "Succeeded or Failed"
Jul  4 16:43:11.989: INFO: Pod "pod-projected-secrets-6af69b94-658d-4d7e-bc61-2c63bb49c3dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.242726ms
Jul  4 16:43:13.997: INFO: Pod "pod-projected-secrets-6af69b94-658d-4d7e-bc61-2c63bb49c3dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010029526s
Jul  4 16:43:16.003: INFO: Pod "pod-projected-secrets-6af69b94-658d-4d7e-bc61-2c63bb49c3dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015816153s
STEP: Saw pod success
Jul  4 16:43:16.003: INFO: Pod "pod-projected-secrets-6af69b94-658d-4d7e-bc61-2c63bb49c3dd" satisfied condition "Succeeded or Failed"
Jul  4 16:43:16.005: INFO: Trying to get logs from node 18.216.149.32 pod pod-projected-secrets-6af69b94-658d-4d7e-bc61-2c63bb49c3dd container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  4 16:43:16.018: INFO: Waiting for pod pod-projected-secrets-6af69b94-658d-4d7e-bc61-2c63bb49c3dd to disappear
Jul  4 16:43:16.020: INFO: Pod pod-projected-secrets-6af69b94-658d-4d7e-bc61-2c63bb49c3dd no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  4 16:43:16.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3699" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":331,"skipped":6214,"failed":0}
S
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:43:16.026: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption-release is created
Jul  4 16:43:16.051: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:43:18.057: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jul  4 16:43:19.073: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  4 16:43:19.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6348" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":356,"completed":332,"skipped":6215,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:43:19.107: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-10ded08e-8af7-48e9-9766-cfb176a39e35
STEP: Creating a pod to test consume configMaps
Jul  4 16:43:19.178: INFO: Waiting up to 5m0s for pod "pod-configmaps-eb2312aa-eb69-45be-9e70-bce86d4ddeed" in namespace "configmap-9810" to be "Succeeded or Failed"
Jul  4 16:43:19.181: INFO: Pod "pod-configmaps-eb2312aa-eb69-45be-9e70-bce86d4ddeed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.645718ms
Jul  4 16:43:21.183: INFO: Pod "pod-configmaps-eb2312aa-eb69-45be-9e70-bce86d4ddeed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004982396s
Jul  4 16:43:23.190: INFO: Pod "pod-configmaps-eb2312aa-eb69-45be-9e70-bce86d4ddeed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011413539s
STEP: Saw pod success
Jul  4 16:43:23.190: INFO: Pod "pod-configmaps-eb2312aa-eb69-45be-9e70-bce86d4ddeed" satisfied condition "Succeeded or Failed"
Jul  4 16:43:23.191: INFO: Trying to get logs from node 3.138.203.20 pod pod-configmaps-eb2312aa-eb69-45be-9e70-bce86d4ddeed container agnhost-container: <nil>
STEP: delete the pod
Jul  4 16:43:23.207: INFO: Waiting for pod pod-configmaps-eb2312aa-eb69-45be-9e70-bce86d4ddeed to disappear
Jul  4 16:43:23.208: INFO: Pod pod-configmaps-eb2312aa-eb69-45be-9e70-bce86d4ddeed no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  4 16:43:23.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9810" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":333,"skipped":6245,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:43:23.214: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Jul  4 16:43:23.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-7977 create -f -'
Jul  4 16:43:24.092: INFO: stderr: ""
Jul  4 16:43:24.092: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Jul  4 16:43:25.097: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 16:43:25.097: INFO: Found 0 / 1
Jul  4 16:43:26.098: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 16:43:26.098: INFO: Found 1 / 1
Jul  4 16:43:26.098: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jul  4 16:43:26.100: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 16:43:26.100: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul  4 16:43:26.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-7977 patch pod agnhost-primary-ccrf2 -p {"metadata":{"annotations":{"x":"y"}}}'
Jul  4 16:43:26.160: INFO: stderr: ""
Jul  4 16:43:26.160: INFO: stdout: "pod/agnhost-primary-ccrf2 patched\n"
STEP: checking annotations
Jul  4 16:43:26.162: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  4 16:43:26.162: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 16:43:26.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7977" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":356,"completed":334,"skipped":6245,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:43:26.168: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-4361053c-3b75-4de0-92df-cc29052bc423 in namespace container-probe-4811
Jul  4 16:43:28.196: INFO: Started pod busybox-4361053c-3b75-4de0-92df-cc29052bc423 in namespace container-probe-4811
STEP: checking the pod's current state and verifying that restartCount is present
Jul  4 16:43:28.198: INFO: Initial restart count of pod busybox-4361053c-3b75-4de0-92df-cc29052bc423 is 0
Jul  4 16:44:18.346: INFO: Restart count of pod container-probe-4811/busybox-4361053c-3b75-4de0-92df-cc29052bc423 is now 1 (50.148355702s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  4 16:44:18.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4811" for this suite.

• [SLOW TEST:52.193 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":335,"skipped":6269,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:44:18.362: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:44:18.935: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:44:21.952: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Jul  4 16:44:21.968: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:44:21.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9750" for this suite.
STEP: Destroying namespace "webhook-9750-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":356,"completed":336,"skipped":6280,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:44:22.033: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod test-webserver-ec0b5a81-c94e-406a-92f2-d4987807ae98 in namespace container-probe-1109
Jul  4 16:44:24.113: INFO: Started pod test-webserver-ec0b5a81-c94e-406a-92f2-d4987807ae98 in namespace container-probe-1109
STEP: checking the pod's current state and verifying that restartCount is present
Jul  4 16:44:24.115: INFO: Initial restart count of pod test-webserver-ec0b5a81-c94e-406a-92f2-d4987807ae98 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  4 16:48:24.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1109" for this suite.

• [SLOW TEST:242.887 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":337,"skipped":6296,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:48:24.920: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:48:24.935: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jul  4 16:48:24.940: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul  4 16:48:29.952: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul  4 16:48:29.952: INFO: Creating deployment "test-rolling-update-deployment"
Jul  4 16:48:29.955: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jul  4 16:48:29.961: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jul  4 16:48:31.969: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jul  4 16:48:31.971: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  4 16:48:31.978: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-5759  f1304baa-f0d0-429d-8105-6d77d118e548 31725 1 2022-07-04 16:48:29 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-07-04 16:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 16:48:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032fd878 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-07-04 16:48:29 +0000 UTC,LastTransitionTime:2022-07-04 16:48:29 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67c8f74c6c" has successfully progressed.,LastUpdateTime:2022-07-04 16:48:30 +0000 UTC,LastTransitionTime:2022-07-04 16:48:29 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul  4 16:48:31.980: INFO: New ReplicaSet "test-rolling-update-deployment-67c8f74c6c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c  deployment-5759  bc701d95-152a-4832-a6b5-77f21a5b898e 31715 1 2022-07-04 16:48:29 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment f1304baa-f0d0-429d-8105-6d77d118e548 0xc0034ac397 0xc0034ac398}] []  [{kube-controller-manager Update apps/v1 2022-07-04 16:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f1304baa-f0d0-429d-8105-6d77d118e548\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 16:48:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67c8f74c6c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034ac448 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul  4 16:48:31.980: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jul  4 16:48:31.980: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-5759  3801ddca-e447-4600-a70a-09ae5833ae3c 31724 2 2022-07-04 16:48:24 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment f1304baa-f0d0-429d-8105-6d77d118e548 0xc0034ac237 0xc0034ac238}] []  [{e2e.test Update apps/v1 2022-07-04 16:48:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-04 16:48:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f1304baa-f0d0-429d-8105-6d77d118e548\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-07-04 16:48:30 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0034ac318 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  4 16:48:31.982: INFO: Pod "test-rolling-update-deployment-67c8f74c6c-tbvrb" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c-tbvrb test-rolling-update-deployment-67c8f74c6c- deployment-5759  988cd29e-c6ec-45ca-a6b2-1d7d7c6f6f62 31714 0 2022-07-04 16:48:29 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[cni.projectcalico.org/containerID:ec8c391c7c96a5367de727f36d6d0113dc94333122c966bddf1f3561b4db7c17 cni.projectcalico.org/podIP:10.42.2.39/32 cni.projectcalico.org/podIPs:10.42.2.39/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-67c8f74c6c bc701d95-152a-4832-a6b5-77f21a5b898e 0xc0034ac8d7 0xc0034ac8d8}] []  [{kube-controller-manager Update v1 2022-07-04 16:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bc701d95-152a-4832-a6b5-77f21a5b898e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-07-04 16:48:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-07-04 16:48:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.42.2.39\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jkb2n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jkb2n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:18.216.149.32,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:48:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-04 16:48:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.20.100,PodIP:10.42.2.39,StartTime:2022-07-04 16:48:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-04 16:48:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:docker-pullable://k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:docker://0bcf5d6ae02c2df43bdd43c4d9e0ab99f155758241238b0aef8a703294e32382,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.2.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  4 16:48:31.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5759" for this suite.

• [SLOW TEST:7.067 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":338,"skipped":6300,"failed":0}
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:48:31.988: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul  4 16:48:32.009: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  4 16:49:32.026: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Jul  4 16:49:32.044: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jul  4 16:49:32.047: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jul  4 16:49:32.061: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jul  4 16:49:32.065: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Jul  4 16:49:32.080: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Jul  4 16:49:32.085: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:49:48.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6444" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:76.182 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":356,"completed":339,"skipped":6309,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:49:48.170: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  4 16:49:48.206: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:49:48.206: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:49:49.214: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:49:49.214: INFO: Node 18.216.149.32 is running 0 daemon pod, expected 1
Jul  4 16:49:50.212: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  4 16:49:50.212: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status
Jul  4 16:49:50.216: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
Jul  4 16:49:50.222: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
Jul  4 16:49:50.224: INFO: Observed &DaemonSet event: ADDED
Jul  4 16:49:50.224: INFO: Observed &DaemonSet event: MODIFIED
Jul  4 16:49:50.224: INFO: Observed &DaemonSet event: MODIFIED
Jul  4 16:49:50.224: INFO: Observed &DaemonSet event: MODIFIED
Jul  4 16:49:50.224: INFO: Observed &DaemonSet event: MODIFIED
Jul  4 16:49:50.224: INFO: Found daemon set daemon-set in namespace daemonsets-4193 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul  4 16:49:50.224: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
Jul  4 16:49:50.230: INFO: Observed &DaemonSet event: ADDED
Jul  4 16:49:50.230: INFO: Observed &DaemonSet event: MODIFIED
Jul  4 16:49:50.230: INFO: Observed &DaemonSet event: MODIFIED
Jul  4 16:49:50.230: INFO: Observed &DaemonSet event: MODIFIED
Jul  4 16:49:50.230: INFO: Observed &DaemonSet event: MODIFIED
Jul  4 16:49:50.230: INFO: Observed daemon set daemon-set in namespace daemonsets-4193 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul  4 16:49:50.231: INFO: Observed &DaemonSet event: MODIFIED
Jul  4 16:49:50.231: INFO: Found daemon set daemon-set in namespace daemonsets-4193 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Jul  4 16:49:50.231: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4193, will wait for the garbage collector to delete the pods
Jul  4 16:49:50.289: INFO: Deleting DaemonSet.extensions daemon-set took: 3.361892ms
Jul  4 16:49:50.389: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.618254ms
Jul  4 16:49:52.994: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  4 16:49:52.994: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  4 16:49:52.997: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32036"},"items":null}

Jul  4 16:49:52.999: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32036"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:49:53.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4193" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":356,"completed":340,"skipped":6333,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:49:53.013: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul  4 16:49:53.032: INFO: Waiting up to 5m0s for pod "pod-55550490-43e4-46da-935f-c6b75a489cb2" in namespace "emptydir-1636" to be "Succeeded or Failed"
Jul  4 16:49:53.034: INFO: Pod "pod-55550490-43e4-46da-935f-c6b75a489cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.862565ms
Jul  4 16:49:55.039: INFO: Pod "pod-55550490-43e4-46da-935f-c6b75a489cb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007045447s
Jul  4 16:49:57.047: INFO: Pod "pod-55550490-43e4-46da-935f-c6b75a489cb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014844693s
STEP: Saw pod success
Jul  4 16:49:57.047: INFO: Pod "pod-55550490-43e4-46da-935f-c6b75a489cb2" satisfied condition "Succeeded or Failed"
Jul  4 16:49:57.049: INFO: Trying to get logs from node 18.216.149.32 pod pod-55550490-43e4-46da-935f-c6b75a489cb2 container test-container: <nil>
STEP: delete the pod
Jul  4 16:49:57.072: INFO: Waiting for pod pod-55550490-43e4-46da-935f-c6b75a489cb2 to disappear
Jul  4 16:49:57.073: INFO: Pod pod-55550490-43e4-46da-935f-c6b75a489cb2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 16:49:57.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1636" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":341,"skipped":6346,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:49:57.081: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:50:03.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1141" for this suite.
STEP: Destroying namespace "nsdeletetest-652" for this suite.
Jul  4 16:50:03.200: INFO: Namespace nsdeletetest-652 was already deleted
STEP: Destroying namespace "nsdeletetest-7001" for this suite.

• [SLOW TEST:6.122 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":356,"completed":342,"skipped":6364,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:03.204: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:50:03.221: INFO: Waiting up to 5m0s for pod "busybox-user-65534-ec35db4c-ba5a-4c97-ae64-bc816b11be79" in namespace "security-context-test-5250" to be "Succeeded or Failed"
Jul  4 16:50:03.224: INFO: Pod "busybox-user-65534-ec35db4c-ba5a-4c97-ae64-bc816b11be79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.326708ms
Jul  4 16:50:05.227: INFO: Pod "busybox-user-65534-ec35db4c-ba5a-4c97-ae64-bc816b11be79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00572089s
Jul  4 16:50:07.234: INFO: Pod "busybox-user-65534-ec35db4c-ba5a-4c97-ae64-bc816b11be79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012239542s
Jul  4 16:50:07.234: INFO: Pod "busybox-user-65534-ec35db4c-ba5a-4c97-ae64-bc816b11be79" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  4 16:50:07.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5250" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":343,"skipped":6379,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:07.239: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  4 16:50:08.037: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  4 16:50:11.057: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:50:11.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5904" for this suite.
STEP: Destroying namespace "webhook-5904-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":356,"completed":344,"skipped":6387,"failed":0}
SSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:11.123: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Jul  4 16:50:13.159: INFO: Deleting pod "var-expansion-fc70d251-e7b5-4574-b641-56049c11358c" in namespace "var-expansion-2360"
Jul  4 16:50:13.163: INFO: Wait up to 5m0s for pod "var-expansion-fc70d251-e7b5-4574-b641-56049c11358c" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  4 16:50:15.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2360" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":356,"completed":345,"skipped":6392,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:15.177: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-1711defd-bc4b-45ee-92a6-d22126bc4746
STEP: Creating a pod to test consume secrets
Jul  4 16:50:15.199: INFO: Waiting up to 5m0s for pod "pod-secrets-9baad662-5a7f-4197-a8fd-ca1f497e41c5" in namespace "secrets-6511" to be "Succeeded or Failed"
Jul  4 16:50:15.202: INFO: Pod "pod-secrets-9baad662-5a7f-4197-a8fd-ca1f497e41c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.676549ms
Jul  4 16:50:17.209: INFO: Pod "pod-secrets-9baad662-5a7f-4197-a8fd-ca1f497e41c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009744689s
Jul  4 16:50:19.218: INFO: Pod "pod-secrets-9baad662-5a7f-4197-a8fd-ca1f497e41c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018152295s
STEP: Saw pod success
Jul  4 16:50:19.218: INFO: Pod "pod-secrets-9baad662-5a7f-4197-a8fd-ca1f497e41c5" satisfied condition "Succeeded or Failed"
Jul  4 16:50:19.220: INFO: Trying to get logs from node 18.216.149.32 pod pod-secrets-9baad662-5a7f-4197-a8fd-ca1f497e41c5 container secret-volume-test: <nil>
STEP: delete the pod
Jul  4 16:50:19.232: INFO: Waiting for pod pod-secrets-9baad662-5a7f-4197-a8fd-ca1f497e41c5 to disappear
Jul  4 16:50:19.234: INFO: Pod pod-secrets-9baad662-5a7f-4197-a8fd-ca1f497e41c5 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  4 16:50:19.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6511" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":346,"skipped":6397,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:19.240: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul  4 16:50:19.254: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  4 16:50:19.259: INFO: Waiting for terminating namespaces to be deleted...
Jul  4 16:50:19.262: INFO: 
Logging pods the apiserver thinks is on node 18.216.149.32 before test
Jul  4 16:50:19.266: INFO: canal-7ftvj from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:50:19.266: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:50:19.266: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:50:19.266: INFO: coredns-85bfbf8f-9f6vk from kube-system started at 2022-07-04 15:17:21 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.266: INFO: 	Container coredns ready: true, restart count 0
Jul  4 16:50:19.266: INFO: metrics-server-585b7cc746-9jchh from kube-system started at 2022-07-04 15:17:33 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.266: INFO: 	Container metrics-server ready: true, restart count 0
Jul  4 16:50:19.266: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-vttwd from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:50:19.266: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:50:19.266: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  4 16:50:19.266: INFO: 
Logging pods the apiserver thinks is on node 18.224.151.13 before test
Jul  4 16:50:19.270: INFO: canal-twgvp from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:50:19.270: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:50:19.270: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:50:19.270: INFO: coredns-autoscaler-67cbd4599c-62tvv from kube-system started at 2022-07-04 15:17:21 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.270: INFO: 	Container autoscaler ready: true, restart count 0
Jul  4 16:50:19.270: INFO: rke-coredns-addon-deploy-job-q97vx from kube-system started at 2022-07-04 15:17:20 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.270: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Jul  4 16:50:19.270: INFO: rke-metrics-addon-deploy-job-v6dww from kube-system started at 2022-07-04 15:17:32 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.270: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Jul  4 16:50:19.270: INFO: rke-network-plugin-deploy-job-vqpwx from kube-system started at 2022-07-04 15:17:12 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.270: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Jul  4 16:50:19.270: INFO: sonobuoy from sonobuoy started at 2022-07-04 15:20:04 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.270: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  4 16:50:19.270: INFO: sonobuoy-e2e-job-f2b28e16e8b74a5d from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:50:19.270: INFO: 	Container e2e ready: true, restart count 0
Jul  4 16:50:19.270: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:50:19.270: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-6fh2b from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:50:19.270: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:50:19.270: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  4 16:50:19.270: INFO: 
Logging pods the apiserver thinks is on node 3.138.203.20 before test
Jul  4 16:50:19.274: INFO: calico-kube-controllers-74df54cbb7-vdkjz from kube-system started at 2022-07-04 15:17:14 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.274: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  4 16:50:19.274: INFO: canal-2hwcq from kube-system started at 2022-07-04 15:17:14 +0000 UTC (2 container statuses recorded)
Jul  4 16:50:19.274: INFO: 	Container calico-node ready: true, restart count 0
Jul  4 16:50:19.274: INFO: 	Container kube-flannel ready: true, restart count 0
Jul  4 16:50:19.274: INFO: coredns-85bfbf8f-zln4g from kube-system started at 2022-07-04 15:17:23 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.274: INFO: 	Container coredns ready: true, restart count 0
Jul  4 16:50:19.274: INFO: sonobuoy-systemd-logs-daemon-set-365a1b5ae8834b3e-jzqpt from sonobuoy started at 2022-07-04 15:20:07 +0000 UTC (2 container statuses recorded)
Jul  4 16:50:19.274: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  4 16:50:19.274: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  4 16:50:19.274: INFO: webhook-to-be-mutated from webhook-5904 started at 2022-07-04 16:50:11 +0000 UTC (1 container statuses recorded)
Jul  4 16:50:19.274: INFO: 	Container example ready: false, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-952a57c5-2677-48fa-810c-76dd1efa67d9 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-952a57c5-2677-48fa-810c-76dd1efa67d9 off the node 18.216.149.32
STEP: verifying the node doesn't have the label kubernetes.io/e2e-952a57c5-2677-48fa-810c-76dd1efa67d9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Jul  4 16:50:23.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4230" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":356,"completed":347,"skipped":6437,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:23.381: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  4 16:50:39.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-191" for this suite.

• [SLOW TEST:16.073 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":356,"completed":348,"skipped":6451,"failed":0}
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:39.454: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Service
STEP: watching for the Service to be added
Jul  4 16:50:39.480: INFO: Found Service test-service-ndq6x in namespace services-8284 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Jul  4 16:50:39.480: INFO: Service test-service-ndq6x created
STEP: Getting /status
Jul  4 16:50:39.494: INFO: Service test-service-ndq6x has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
Jul  4 16:50:39.502: INFO: observed Service test-service-ndq6x in namespace services-8284 with annotations: map[] & LoadBalancer: {[]}
Jul  4 16:50:39.502: INFO: Found Service test-service-ndq6x in namespace services-8284 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Jul  4 16:50:39.502: INFO: Service test-service-ndq6x has service status patched
STEP: updating the ServiceStatus
Jul  4 16:50:39.508: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
Jul  4 16:50:39.510: INFO: Observed Service test-service-ndq6x in namespace services-8284 with annotations: map[] & Conditions: {[]}
Jul  4 16:50:39.510: INFO: Observed event: &Service{ObjectMeta:{test-service-ndq6x  services-8284  96ed325c-4eca-484d-9bda-5966a923afd8 32461 0 2022-07-04 16:50:39 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-07-04 16:50:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-07-04 16:50:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.43.134.178,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.43.134.178],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Jul  4 16:50:39.510: INFO: Found Service test-service-ndq6x in namespace services-8284 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul  4 16:50:39.510: INFO: Service test-service-ndq6x has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
Jul  4 16:50:39.525: INFO: observed Service test-service-ndq6x in namespace services-8284 with labels: map[test-service-static:true]
Jul  4 16:50:39.525: INFO: observed Service test-service-ndq6x in namespace services-8284 with labels: map[test-service-static:true]
Jul  4 16:50:39.525: INFO: observed Service test-service-ndq6x in namespace services-8284 with labels: map[test-service-static:true]
Jul  4 16:50:39.525: INFO: Found Service test-service-ndq6x in namespace services-8284 with labels: map[test-service:patched test-service-static:true]
Jul  4 16:50:39.525: INFO: Service test-service-ndq6x patched
STEP: deleting the service
STEP: watching for the Service to be deleted
Jul  4 16:50:39.532: INFO: Observed event: ADDED
Jul  4 16:50:39.533: INFO: Observed event: MODIFIED
Jul  4 16:50:39.533: INFO: Observed event: MODIFIED
Jul  4 16:50:39.533: INFO: Observed event: MODIFIED
Jul  4 16:50:39.533: INFO: Found Service test-service-ndq6x in namespace services-8284 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Jul  4 16:50:39.533: INFO: Service test-service-ndq6x deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  4 16:50:39.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8284" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":356,"completed":349,"skipped":6451,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:39.543: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Jul  4 16:50:39.569: INFO: The status of Pod pod-update-activedeadlineseconds-853fe6a7-1b18-4249-948f-697ea07fd014 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:50:41.572: INFO: The status of Pod pod-update-activedeadlineseconds-853fe6a7-1b18-4249-948f-697ea07fd014 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul  4 16:50:42.089: INFO: Successfully updated pod "pod-update-activedeadlineseconds-853fe6a7-1b18-4249-948f-697ea07fd014"
Jul  4 16:50:42.089: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-853fe6a7-1b18-4249-948f-697ea07fd014" in namespace "pods-2498" to be "terminated due to deadline exceeded"
Jul  4 16:50:42.091: INFO: Pod "pod-update-activedeadlineseconds-853fe6a7-1b18-4249-948f-697ea07fd014": Phase="Running", Reason="", readiness=true. Elapsed: 1.740417ms
Jul  4 16:50:44.094: INFO: Pod "pod-update-activedeadlineseconds-853fe6a7-1b18-4249-948f-697ea07fd014": Phase="Running", Reason="", readiness=false. Elapsed: 2.005205464s
Jul  4 16:50:46.101: INFO: Pod "pod-update-activedeadlineseconds-853fe6a7-1b18-4249-948f-697ea07fd014": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.011570057s
Jul  4 16:50:46.101: INFO: Pod "pod-update-activedeadlineseconds-853fe6a7-1b18-4249-948f-697ea07fd014" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  4 16:50:46.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2498" for this suite.

• [SLOW TEST:6.564 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":356,"completed":350,"skipped":6467,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:46.107: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-b78f29aa-bc5b-4ad9-b2d3-69fe51616c8b
STEP: Creating a pod to test consume configMaps
Jul  4 16:50:46.132: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-96ec8ca7-4df5-4c3d-9c2a-b8e2943906a2" in namespace "projected-9939" to be "Succeeded or Failed"
Jul  4 16:50:46.134: INFO: Pod "pod-projected-configmaps-96ec8ca7-4df5-4c3d-9c2a-b8e2943906a2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.797122ms
Jul  4 16:50:48.142: INFO: Pod "pod-projected-configmaps-96ec8ca7-4df5-4c3d-9c2a-b8e2943906a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010003094s
Jul  4 16:50:50.149: INFO: Pod "pod-projected-configmaps-96ec8ca7-4df5-4c3d-9c2a-b8e2943906a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016647991s
STEP: Saw pod success
Jul  4 16:50:50.149: INFO: Pod "pod-projected-configmaps-96ec8ca7-4df5-4c3d-9c2a-b8e2943906a2" satisfied condition "Succeeded or Failed"
Jul  4 16:50:50.151: INFO: Trying to get logs from node 18.216.149.32 pod pod-projected-configmaps-96ec8ca7-4df5-4c3d-9c2a-b8e2943906a2 container agnhost-container: <nil>
STEP: delete the pod
Jul  4 16:50:50.164: INFO: Waiting for pod pod-projected-configmaps-96ec8ca7-4df5-4c3d-9c2a-b8e2943906a2 to disappear
Jul  4 16:50:50.166: INFO: Pod pod-projected-configmaps-96ec8ca7-4df5-4c3d-9c2a-b8e2943906a2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  4 16:50:50.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9939" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":351,"skipped":6487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:50:50.172: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Jul  4 16:50:50.192: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:51:09.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1816" for this suite.

• [SLOW TEST:18.977 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":356,"completed":352,"skipped":6516,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:51:09.149: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Jul  4 16:51:09.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-4088 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jul  4 16:51:09.223: INFO: stderr: ""
Jul  4 16:51:09.223: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Jul  4 16:51:09.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-4088 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Jul  4 16:51:09.816: INFO: stderr: ""
Jul  4 16:51:09.816: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Jul  4 16:51:09.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4141582619 --namespace=kubectl-4088 delete pods e2e-test-httpd-pod'
Jul  4 16:51:11.202: INFO: stderr: ""
Jul  4 16:51:11.202: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  4 16:51:11.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4088" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":356,"completed":353,"skipped":6534,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:51:11.212: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul  4 16:51:11.235: INFO: Waiting up to 5m0s for pod "pod-1a1c202e-2dd7-4841-ba8f-71b880e2be55" in namespace "emptydir-6026" to be "Succeeded or Failed"
Jul  4 16:51:11.237: INFO: Pod "pod-1a1c202e-2dd7-4841-ba8f-71b880e2be55": Phase="Pending", Reason="", readiness=false. Elapsed: 1.844011ms
Jul  4 16:51:13.243: INFO: Pod "pod-1a1c202e-2dd7-4841-ba8f-71b880e2be55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007817642s
Jul  4 16:51:15.247: INFO: Pod "pod-1a1c202e-2dd7-4841-ba8f-71b880e2be55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011593701s
STEP: Saw pod success
Jul  4 16:51:15.247: INFO: Pod "pod-1a1c202e-2dd7-4841-ba8f-71b880e2be55" satisfied condition "Succeeded or Failed"
Jul  4 16:51:15.249: INFO: Trying to get logs from node 18.216.149.32 pod pod-1a1c202e-2dd7-4841-ba8f-71b880e2be55 container test-container: <nil>
STEP: delete the pod
Jul  4 16:51:15.262: INFO: Waiting for pod pod-1a1c202e-2dd7-4841-ba8f-71b880e2be55 to disappear
Jul  4 16:51:15.264: INFO: Pod pod-1a1c202e-2dd7-4841-ba8f-71b880e2be55 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  4 16:51:15.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6026" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":354,"skipped":6563,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:51:15.273: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Jul  4 16:51:15.295: INFO: The status of Pod pod-update-c17f513c-4ed4-44a7-b5f3-10e4b13e1602 is Pending, waiting for it to be Running (with Ready = true)
Jul  4 16:51:17.304: INFO: The status of Pod pod-update-c17f513c-4ed4-44a7-b5f3-10e4b13e1602 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul  4 16:51:17.818: INFO: Successfully updated pod "pod-update-c17f513c-4ed4-44a7-b5f3-10e4b13e1602"
STEP: verifying the updated pod is in kubernetes
Jul  4 16:51:17.822: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  4 16:51:17.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2898" for this suite.
•{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":356,"completed":355,"skipped":6577,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  4 16:51:17.828: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Jul  4 16:51:17.844: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
Jul  4 16:51:20.154: INFO: >>> kubeConfig: /tmp/kubeconfig-4141582619
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  4 16:51:30.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5517" for this suite.

• [SLOW TEST:12.458 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":356,"completed":356,"skipped":6599,"failed":0}
SSSSSSSSSSSSSSSSJul  4 16:51:30.287: INFO: Running AfterSuite actions on all nodes
Jul  4 16:51:30.287: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func19.2
Jul  4 16:51:30.287: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Jul  4 16:51:30.287: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
Jul  4 16:51:30.287: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Jul  4 16:51:30.287: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Jul  4 16:51:30.287: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Jul  4 16:51:30.287: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
Jul  4 16:51:30.287: INFO: Running AfterSuite actions on node 1
Jul  4 16:51:30.287: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/sonobuoy/results/junit_01.xml
{"msg":"Test Suite completed","total":356,"completed":356,"skipped":6615,"failed":0}

Ran 356 of 6971 Specs in 5463.390 seconds
SUCCESS! -- 356 Passed | 0 Failed | 0 Pending | 6615 Skipped
PASS

Ginkgo ran 1 suite in 1h31m5.305807985s
Test Suite Passed
